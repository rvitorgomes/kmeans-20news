"Semantics inside!" but let's not tell the data miners: Intelligent support for data mining Knowledge Discovery in Databases (KDD) has evolved significantly over the past years and reached a mature stage offering plenty of operators to solve complex data analysis tasks. User support for building data analysis workflows, however, has not progressed sufficiently: the large number of operators currently available in KDD systems and interactions between these operators complicates successful data analysis. To help Data Miners we enhanced one of the most used open source data mining tools-RapidMiner-with semantic technologies. Specifically, we first annotated all elements involved in the Data Mining (DM) process-the data, the operators, models, data mining tasks, and KDD workflows-semantically using our eProPlan modelling tool that allows to describe operators and build a task/method decomposition grammar to specify the desired workflows embedded in an ontology. Second, we enhanced RapidMiner to employ these semantic annotations to actively support data analysts. Third, we built an Intelligent Discovery Assistant, eIda, that leverages the semantic annotation as well as HTN planning to automatically support KDD process generation. We found that the use of Semantic Web approaches and technologies in the KDD domain helped us to lower the barrier to data analysis. We also found that using a generic ontology editor overwhelmed KDD-centric users. We, therefore, provided them with problem-centric extensions to Protégé. Last and most surprising, we found that our semantic modeling of the KDD domain served as a rapid prototyping approach for several hard-coded improvements of RapidMiner, namely correctness checking of workflows and quick-fixes, reinforcing the finding that even a little semantic modeling can go a long way in improving the understanding of a domain even for domain experts. © 2014 Springer International Publishing. 

(TD)2PaM: A constraint-based algorithm for mining temporal patterns in transactional databases The analysis of frequent behaviors regarding temporal issues begins to achieve some interest, in particular in the area of health care. However, existing approaches tend to ignore the temporal information and only make use of the order among events occurrence. In this paper, we introduce the notion of temporal constraint, and propose three instantiations of it: complete cyclic temporal constraints, partial cyclic temporal constraints and timespan constraints. Additionally, we propose a new algorithm - (TD)2PaM, that together with these constraints, makes possible to focus the pattern mining process on looking for cyclic and timespan patterns. Experimental results reveal the algorithm to be as efficient as its predecessors, and able to discover more informed patterns. © 2013 Springer-Verlag. Constraints; Ontologies; Pattern Mining; Semantic Aspects of Data Mining; Temporality

A block-structured mining approach from audit logs Contemporary process management systems (e.g., workflow management systems) are driven by explicit process models, i.e., a completely specified workflow design is required in order to enact a given workflow process. Constructing process models from scratch is a complicated time-consuming task that often requires high expertise. And there are discrepancies between the actual workflow processes and the processes as perceived by the management. Therefore, techniques for discovering process models have been developed. Process mining just attempts to improve this by automatically generating a process model from sets of systems ' executions (audit logs). In this paper, a block structured process mining approach from audit logs to support process modeling is designed. Compare with other algorithms, the result of this approach is more visible and understanding of process model. This approach is used to a widely commercial tool for the visualization and analysis of process model. © 2008 IEEE. 

A block-structured mining approach to support process discovery Deploying process-driven information systems is a time-consuming and error-prone. Constructing process models from scratch is a complicated time-consuming task that often requires high expertise. And there are discrepancies between the actual workflow processes and the processes as perceived by the management. Therefore, techniques for discovering process models have been developed. Process mining just attempts to improve this by automatically generating a process model from sets of systems' executions (audit logs). In this paper, a block structured process mining approach from audit logs to support process discovery is designed. Compare with other algorithms, the result of this approach is more visible and understanding of process model. This approach is used to a widely commercial tool for the visualization and analysis of process model. © 2008 IEEE. 

A bottom-up workflow mining approach for workflow applications analysis Engineering workflow applications are becoming more and more complex, involving numerous interacting business objects within considerable processes. Analysing the interaction structure of those complex applications will enable them to be well understood, controlled, and redesigned. Our contribution to workflow mining is a statistical technique to discover workflow patterns from event-based log. Our approach is characterised by a "local" workflow patterns discovery that allows to cover partial results through a dynamic programming algorithm. Those local discovered workflow patterns are then composed iterativety until discovering the global workflow model. Our approach has been implemented within our prototype WorkflowMiner. © Springer-Verlag Berlin Heidelberg 2006. Business process Analysis; Business process intelligence; Workflow mining; Workflow patterns

A business process mining application for internal transaction fraud mitigation Corporate fraud these days represents a huge cost to our economy. In the paper we address one specific type of corporate fraud, internal transaction fraud. Given the omnipresence of stored history logs, the field of process mining rises as an adequate answer to mitigating internal transaction fraud. Process mining diagnoses processes by mining event logs. This way we can expose opportunities to commit fraud in the followed process. In this paper we report on an application of process mining at a case company. The procurement process was selected as example for internal transaction fraud mitigation. The results confirm the contribution process mining can provide to business practice. © 2010 Elsevier Ltd. All rights reserved. Internal fraud; Process mining; Transaction fraud

A Case Study of The Intelligent Process Decentralization Method several researches have been conducted to decompose business processes in Service Oriented Architecture (SOA). There exist several methods that encapsulate each activity of a business process in one agent, while other methods focus on fragmenting a business process and encapsulate each fragment in an agent. As the mentioned approaches decompose a business process without considering the adaptability of a process with run-time environment, the intelligent business process decentralization (IPD) has been presented that uses a process mining approach. This novel approach detects the frequent paths of a business process and encapsulates the most relevant activities as agents. Being disseminated on a network, the agents are able to communicate with each other through a middleware. This essay shows how IPD algorithm works and detects the frequent paths of a loan taking process to decompose it. Adaptive Systems; Service Oriented Architecture; Distributed Orchestrate Engine; Business Process Decomposition; Frequent Path Mining

A case study on analyzing inter-organizational business processes from EDI messages using physical activity mining In order to achieve their goals, organizations collaborate with business partners. Such collaborations represent enactments of inter-organizational business processes and may be supported through the exchange of Electronic Data Interchange (EDI) messages (e.g., electronic purchase orders, invoices etc.). For gaining insights on such processes, recently two distinct approaches for enabling the application of process mining techniques on inter-organizational business processes based on the interchanged EDI messages have been proposed: (i) Message Flow Mining (MFM) and (ii) Physical Activity Mining (PAM). In this paper, we present a case study in which we apply the PAM methodology on a real-world EDI data set obtained from a German manufacturer of consumer goods. Our results demonstrate potential insights that can be gained from applying process mining techniques in the context of inter-organizational business processes. © 2014 IEEE. 

A case study on designing business processes based on collaborative and mining approaches Companies invest a significant amount of time and resources to discover and represent how they work into business processes models. However, traditional process mapping has been done in an ad hoc manner and tends to be resource-intensive and time-consuming due to the informal and ambiguous collection of process information. The Story Mining Method aims to address those problems by the union of free-form narratives about processes and the usage of Text Mining and Natural Language techniques for text translation into process models. This paper presents a case study of the method, detailing its implementation as well as major issues found on a practical scenario within an organization. © 2010 IEEE. 

A clustering approach for artifact-centric business process models Artifact-centric business process has emerged as a representative paradigm of data-centric business process. Being similar to the traditional control-centric business process management, process clustering is also a critical procedure for process mining, process retrieval, process analysis, etc. Process similarity is a very important indicator for process clustering. According to the features of process model, this paper proposes a clustering approach for artifact-centric business process models. Firstly, process similarity is measured based on the key artifact, process structure and process behavior. Secondly, a clustering algorithm for artifact-centric business process models is presented. Lastly, experimental results have proved that the approach is accurate and effective. © 2012 Binary Information Press. Artifact; BPM; Clustering; Graph matching; Lifecycle tree; Process similarity

A comparative study of dimensionality reduction techniques to enhance trace clustering performances Process mining techniques have been used to analyze event logs from information systems in order to derive useful patterns. However, in the big data era, real-life event logs are huge, unstructured, and complex so that traditional process mining techniques have difficulties in the analysis of big logs. To reduce the complexity during the analysis, trace clustering can be used to group similar traces together and to mine more structured and simpler process models for each of the clusters locally. However, a high dimensionality of the feature space in which all the traces are presented poses different problems to trace clustering. In this paper, we study the effect of applying dimensionality reduction (preprocessing) techniques on the performance of trace clustering. In our experimental study we use three popular feature transformation techniques; singular value decomposition (SVD), random projection (RP), and principal components analysis (PCA), and the state-of-The art trace clustering in process mining. The experimental results on the dataset constructed from a real event log recorded from patient treatment processes in a Dutch hospital show that dimensionality reduction can improve trace clustering performance with respect to the computation time and average fitness of the mined local process models. © 2012 Elsevier Ltd. All rights reserved. PCA; Process mining; Random projection; Singular value decomposition; Trace clustering

A comparative study of Workflow Mining systems This work deals with Workflow Mining (WM) a very active and promising research area. First, in this paper we precise the main uses cases of WM, and then we present a critical and comparative study of three representative WM systems of this area: the ProM, InWolve and WorkflowMiner systems. The comparison is made according to quality criteria that we have proposed such as the capacity to filter and convert a Workflow log, the capacity to discover workflow models and the capacity to support Multi-Analysis of processes. One of the most components specific to these systems is the Workflow log which is the basis for any WM system. This paper also compares their workflow log models by considering five requirements (Usability, Refer to the three workflow models, Simplicity, EventStream and TimeStamp). Finally, we summarize this study and we explain how Multi-Agent Systems (MASs) approach to cope with organizational model discovering issue. In our work, we mean by organizational model, the organizational structures (federation, coalition, team, etc.) and the interaction protocols (contract net, auction, vote, etc.). © 2012 IEEE. Multi-Agent Systems Approach; Reverse engineering of Business Processes; Workflow Mining; Workflow models

A comprehensive benchmarking framework (CoBeFra) for conformance analysis between procedural process models and event logs in ProM Process mining encompasses the research area which is concerned with knowledge discovery from information system event logs. Within the process mining research area, two prominent tasks can be discerned. First of all, process discovery deals with the automatic construction of a process model out of an event log. Secondly, conformance checking focuses on the assessment of the quality of a discovered or designed process model in respect to the actual behavior as captured in event logs. Hereto, multiple techniques and metrics have been developed and described in the literature. However, the process mining domain still lacks a comprehensive framework for assessing the goodness of a process model from a quantitative perspective. In this study, we describe the architecture of an extensible framework within ProM, allowing for the consistent, comparative and repeatable calculation of conformance metrics. For the development and assessment of both process discovery as well as conformance techniques, such a framework is considered greatly valuable. © 2013 IEEE. 

A comprehensive investigation of the applicability of process mining techniques for enterprise risk management Process mining techniques and tools perfectly complement the existing set of enterprise risk management approaches. Enterprise risk management aims at minimizing the negative effects of uncertainty on the objectives, while at the same time promoting the potential positive effects. Process mining research has proposed a broad range of techniques and tools that could be used to effectively support the activities related to the different phases of risk management. This paper contributes to the process mining and risk management research by providing a full exploration of the applicability of process mining in the context of the eight components of the COSO Enterprise Risk Management Framework. The identified applications will be illustrated based on the risks involved in insurance claim handling processes. © 2013 Elsevier B.V. Business process analytics; Business rules; Enterprise risk management; Process mining; Process-aware information systems

A context driven approach for workflow mining Existing work on workflow mining ignores the dataflow aspect of the problem. This is not acceptable for service-oriented applications that use Web services with typed inputs and outputs. We propose a novel algorithm WIT (Workflow Inference from Traces) which identifies the context similarities of the observed actions based on the dataflow and uses model merging techniques to generalize the control flow and the dataflow simultaneously. We identify the class of workflows that WIT can learn correctly. We implemented WIT and tested it on a real world medical scheduling domain where WIT was able to find a good approximation of the target workflow. 

A critical evaluation study of model-log metrics in process discovery The development of a well-defined evaluation framework for process discovery techniques is definitely one of the most important challenges within this subdomain of process mining. Any researcher in the field will acknowledge that such a framework is vital. With this paper, we aim to provide a tangible analysis of the currently available model-log evaluation metrics for mined control-flow models. Also, we will indicate strengths and weaknesses of the existing metrics and propose a number of opportunities for future research. © 2011 Springer-Verlag. evaluation metrics; machine learning; process discovery

A data mining application: Analysis of problems occurring during A software project development process Data mining techniques provide people with new power to research and manipulate the existing large volume of data. A data mining process discovers interesting information from the hidden data that can either be used for future prediction and/or intelligently summarising the details of the data. There are many achievements of applying data mining techniques to various areas such as marketing, medical, and financial, although few of them can be currently seen in software engineering domain. In this paper, a proposed data mining application in software engineering domain is explained and experimented. The empirical results demonstrate the capability of data mining techniques in software engineering domain and the potential benefits in applying data mining to this area. © World Scientific Publishing Company. Data; Knowledge discovery; Mining; Software engineering

A data mining-based framework for grid workflow management In this paper we investigate on the exploitation of data mining techniques to analyze data coming from the enactment of workflow-based processes in a service-oriented Grid infrastructure. The extracted knowledge allows users to better comprehend the behavior of the enacted processes, and can be profitably exploited to provide advanced support to several phases in the life-cycle of workflow processes, including (re-)design, matchmaking, scheduling and performance monitoring. To this purpose, we focus on recent data mining techniques specifically aimed at enabling refined analyzes of workflow executions. Moreover, we introduce a comprehensive system architecture that supports the management of Grid workflows by fully taking advantage of such mining techniques. © 2005 IEEE. 

A deductive system for proving workflow models from operational procedures Many modern business environments employ software to automate the delivery of workflows; whereas, workflow design and generation remains a laborious technical task for domain specialists. Several different approaches have been proposed for deriving workflow models. Some approaches rely on process data mining approaches, whereas others have proposed derivations of workflow models from operational structures, domain specific knowledge or workflow model compositions from knowledge-bases. Many approaches draw on principles from automatic planning, but conceptual in context and lack mathematical justification. In this paper we present a mathematical framework for deducing tasks in workflow models from plans in mechanistic or strongly controlled work environments, with a focus around automatic plan generations. In addition, we prove an associative composition operator that permits crisp hierarchical task compositions for workflow models through a set of mathematical deduction rules. The result is a logical framework that can be used to prove tasks in workflow hierarchies from operational information about work processes and machine configurations in controlled or mechanistic work environments. © 2012 Elsevier B.V. All rights reserved. Automation; Management; Modelling; Petri-net; Planning; Workflow

A family of case studies on business process mining using MARBLE Business processes, most of which are automated by information systems, have become a key asset in organizations. Unfortunately, uncontrolled maintenance implies that information systems age overtime until they need to be modernized. During software modernization, ageing systems cannot be entirely discarded because they gradually embed meaningful business knowledge, which is not present in any other artifact. This paper presents a technique for recovering business processes from legacy systems in order to preserve that knowledge. The technique statically analyzes source code and generates a code model, which is later transformed by pattern matching into a business process model. This technique has been validated over a two-year period in several industrial modernization projects. This paper reports the results of a family of case studies that were performed to empirically validate the technique using analysis and meta-analysis techniques. The family of case studies demonstrates that the technique is feasible in terms of effectiveness and efficiency. © 2012 Elsevier Inc. All rights reserved. ADM; BPMN; Business process; Case study; KDM; Meta-analysis; Static analysis

A financial data mining model for extracting customer behavior Facing the problem of variation and chaotic behavior of customers, the lack of sufficient information is a challenge to many business organizations. Human analysts lacking an understanding of the hidden patterns in business data, thus, can miss corporate business opportunities. In order to embrace all business opportunities, enhance the competitiveness, discovery of hidden knowledge, unexpected patterns and useful rules from large databases have provided a feasible solution for several decades. While there is a wide range of financial analysis products existing in the financial market, how to customize the investment portfolio for the customer is still a challenge to many financial institutions. This paper aims at developing an intelligent Financial Data Mining Model (FDMM) for extracting customer behavior in the financial industry, so as to increase the availability of decision support data and hence increase customer satisfaction. The proposed financial model first clusters the customers into several sectors, and then finds the correlation among these sectors. It is noted that better customer segmentation can increase the ability to identify targeted customers, therefore extracting useful rules for specific clusters can provide an insight into customers' buying behavior and marketing implications. To validate the feasibility of the proposed model, a simple dataset is collected from a financial company in Hong Kong. The simulation experiments show that the proposed method not only can improve the workflow of a financial company, but also deepen understanding of investment behavior. Thus, a corporation is able to customize the most suitable products and services for customers on the basis of the rules extracted. Association rules mining; Clustering; Customer behavior; Data mining; Financial industry

A formal framework to elicit roles with business meaning in RBAC systems The role-based access con trol (RBAC) model has proven to be cost effective to reduce the complexity and costs of access permission management. To maximize the advantages offered by RBAC, the role engineering discipline has been introduced. A viable approach is to explore current applications and systems to find de facto roles embedded in existing user permissions, leading to what is usually referred to as role mining. However, a key problem that has not yet been adequately addressed by existing role mining approaches is how to propose roles that have business meaning. In order to do this, we provide a new formal framework that also enjoys practical relevance. In particular, the proposed framework leverages business information - such as business processes and organization structure - to implement role mining algorithms. Our key observation is that a role is likely to be meaningful from a business perspective when it involves activities within the same business process or organizational units within the same branch. To measure the " spreading" of a role among business processes or organization structure, we resort to centrality indices. Such indices are used in our cost-driven approach during the role mining process. Finally, we illustrate the application of the framework through a few examples. Business meaning; RBAC; Role engineering; Role mining; Role-based access control

A framework for application of tree-structured data mining to process log analysis Many data mining and simulation based algorithms have been applied in the process mining field; nevertheless they mainly focus on the process discovery and conformance checking tasks. Even though the event logs are increasingly represented in semi-structured format using XML-based templates, commonly used XML mining techniques have not been explored. In this paper, we investigate the application of tree mining techniques and propose a general framework, within which a wider range of structure aware data mining techniques can be applied. Decision tree learning and frequent pattern mining are used as a case in point in the experiments on publicly available real dataset. The results indicate the promising properties of the proposed framework in adding to the available set of tools for process log analysis by enabling (i) direct data mining of tree-structured process logs (ii) extraction of informative knowledge patterns and (iii) frequent pattern mining at lower minimum support thresholds. © 2012 Springer-Verlag. DSM; frequent subtree mining; process mining; XML database

A framework for comparing process mining algorithms There are many process mining algorithms with different theoretical foundations and aims, raising the question of how to choose the best for a particular situation. A framework is proposed for objectively comparing algorithms for process discovery against a known ground truth, with an implementation using existing tools. Results from an experimental evaluation of five algorithms against basic process structures confirm the validity of the approach. In general, numbers of traces for mining are predictable from the structure and probabilities in the model, but there are some algorithm-specific differences. © 2011 IEEE. Algorithms; Business data processing; Modeling

A framework for cost-aware process management: Cost reporting and cost prediction Organisations are constantly seeking efficiency gains for their business processes in terms of time and cost. Management accounting enables detailed cost reporting of business operations for decision making purposes, although significant effort is required to gather accurate operational data. Process mining, on the other hand, may provide valuable insight into processes through analysis of events recorded in logs by IT systems, but its primary focus is not on cost implications. In this paper, a framework is proposed which aims to exploit the strengths of both fields in order to better support management decisions on cost control. This is achieved by automatically merging cost data with historical data from event logs for the purposes of monitoring, predicting, and reporting process-related costs. The on-demand generation of accurate, relevant and timely cost reports, in a style akin to reports in the area of management accounting, will also be illustrated. This is achieved through extending the open-source process mining framework ProM. © J.UCS. Business process management; Cost prediction; Cost reporting; Management accounting; Process mining

A framework for managing enterprise knowledge for collaborative decision support This paper presents a new knowledge management paradigm in order to assist knowledge workers to make decision effectively and efficiently in the new economy age. The paradigm is called Knowledge Infused Decision Support (KIDS) framework for managing knowledge required for complex decisions in manufacturing processes. KIDS framework tackles two kinds of knowledge: quantitative knowledge and qualitative knowledge. Quantitative knowledge is discovered from enterprise's business databases through data mining, and qualitative knowledge like experience and judgment captured from human in the collaborative decision making process. The infusion of quantitative and qualitative knowledge provides better understanding of business processes and the decision contexts for decision makers to make decisions quickly under the pressures of time- and knowledge-based competition. The knowledge is then codified into enterprise's knowledge repository. A knowledge mapping mechanism is also provided in the framework for not only delivering the relevant knowledge to the knowledge workers, but also enabling them to access knowledge from knowledge repository efficiently and effectively at anytime and anywhere. It finally discusses several applications in manufacturing industry in order to speed up design decision making using quantitative and qualitative knowledge. © 2007 IEEE. 

A framework for semi-automated process instance discovery from decorative attributes Process mining is a relatively new field of research: its final aim is to bridge the gap between data mining and business process modelling. In particular, the assumption underpinning this discipline is the availability of data coming from business process executions. In business process theory, once the process has been defined, it is possible to have a number of instances of the process running at the same time. Usually, the identification of different instances is referred to a specific case id field in the log exploited by process mining techniques. The software systems that support the execution of a business process, however, often do not record explicitly such information. This paper presents an approach that faces the absence of the case id information: we have a set of extra fields, decorating each single activity log, that are known to carry the information on the process instance. A framework is addressed, based on simple relational algebra notions, to extract the most promising case ids from the extra fields. The work is a generalization of a real business case. © 2011 IEEE. 

A framework for service-based business process collaboration Nowadays, Web services-based systems have gained the attention of researchers, and it enables business process system to automatically discover and invocate suitable Web services at run time. Further with portable terminals, it has become more and more popular for mobile users to do their business management in modern business process system. This demands a new framework for system requirements elicitation and design in order to support this new application. In this paper, we introduce a framework for the elicitation of function and performance aware adaptation requirements. In this framework, we present rule for verifying and evaluating the behavior of the collaboration system, and the overall reliability of the system from its architecture. We also propose a process mining method to help reconstruct the architecture of business process from execution logs. An agent-based mechanism to support mobile users completing their remote tasks is also discussed. © 2011 by Binary Information Press. Agent-based system; Behavioral compatibility; Business process collaboration; Software reliability

A Framework for the Analysis of Process Mining Algorithms There are many process mining algorithms and representations, making it difficult to choose which algorithm to use or compare results. Process mining is essentially a machine learning task, but little work has been done on systematically analyzing algorithms to understand their fundamental properties, such as how much data are needed for confidence in mining. We propose a framework for analyzing process mining algorithms. Processes are viewed as distributions over traces of activities and mining algorithms as learning these distributions. We use probabilistic automata as a unifying representation to which other representation languages can be converted. We present an analysis of the Alpha algorithm under this framework and experimental results, which show that from the substructures in a model and behavior of the algorithm, the amount of data needed for mining can be predicted. This allows efficient use of data and quantification of the confidence which can be placed in the results. Business processes; Machine learning; Petri nets; Probabilistic automata; Process mining

A framework for the discovery of predictive fix-time models Fix-time prediction is a key task in bug tracking systems, which has been recently faced through the definition of inductive learning methods, trained to estimate the time needed to solve a case at the moment when it is reported. And yet, the actions performed on a bug along its life can help refine the prediction of its (remaining) fix time, possibly with the help of Process Mining techniques. However, typical bug-tracking systems lack any task-oriented description of the resolution process, and store fine-grain records, just capturing bug attributes' updates. Moreover, no general approach has been proposed to support the definition of derived data, which can help improve considerably fix-time predictions. A new methodological framework for the analysis of bug repositories is presented here, along with an associated toolkit, leveraging two kinds of tools: (i) a combination of modular and flexible data-transformation mechanisms, for producing an enhanced process-oriented view of log data, and (ii) a series of ad-hoc induction techniques, for extracting a prediction model out of such a view. Preliminary results on the bug repository of a real project confirm the validity of our proposal and, in particular, of our log transformation methods. Bug tracking; Business process analysis; Data mining; Prediction

A framework of business intelligence-driven data mining for e-Business This paper proposes a data mining methodology called Business Intelligence-driven Data Mining (BIdDM). It combines knowledge-driven data mining and method-driven data mining, and fills the gap between business intelligence knowledge and existent various data mining methods in e-Business. BIdDM contains two processes: a construction process of a four-layer framework and a data mining process. A methodology is established in setting up the four-layer framework, which is an important part in BIdDM. A case study of B2C e-Shop is provided to illustrate the use of BIdDM. © 2009 IEEE. BI-driven Data Mining; Business intelligence; Data mining

A frequency-based algorithm for workflow outlier mining The concept of workflow is critical in the ERP (Enterprise Resources Planning) system. Any workflow that is irrationally and irregularly designed will not only lead to an ineffective operation of enterprise but also limit the implementation of an effective business strategy. The research proposes an algorithm which makes use of the workflow's executed frequency, the concept of distance-based outlier detection, empirical rules and Method of Exhaustion to mine three types of workflow outliers, including less-occurring workflow outliers of each process (abnormal workflow of each process), less-occurring workflow outliers of all processes (abnormal workflow of all processes) and never-occurring workflow outliers (redundant workflow). In addition, this research adopts real data to evaluate workflow mining feasibility. In terms of the management, it will assist managers and consultants in (1) controlling exceptions in the process of enterprise auditing, and (2) simplifying the business process management by the integration of relevant processes. © 2010 Springer-Verlag Berlin Heidelberg. BPM; Data mining; ERP; Outlier detection; Workflow mining

A fresh look at precision in process conformance Process Conformance is a crucial step in the area of Process Mining: the adequacy of a model derived from applying a discovery algorithm to a log must be certified before making further decisions that affect the system under consideration. Among the different conformance dimensions, in this paper we propose a novel measure for precision, based on the simple idea of counting these situations were the model deviates from the log. Moreover, a log-based traversal of the model that avoids inspecting its whole behavior is presented. Experimental results show a significant improvement when compared to current approaches for the same task. Finally, the detection of the shortest traces in the model that lead to discrepancies is presented. © 2010 Springer-Verlag Berlin Heidelberg. Process Conformance; Process Mining

A fuzzy paradigm approach for business process intelligence The controllability of business processes and their agility in the sense of their easy adjustment to changes in the business environment are critical success factors. A special form of business intelligence targeted towards business processes and extended by the methods of soft computing with the name "Soft Business Process Intelligence" will be recommended in this article. First, the modeling of business processes with regard to the structuring of models and the formalization of fuzziness using the Fuzzy-Set-Theory will be adjusted. Then, a prototypical software implementation will be presented which will provide insights as to how artificial neural networks can be used to uncover business logic in processes (process mining), as well as for the improvement of business processes through learning. © 2006 IEEE. 

A general divide and conquer approach for process mining Operational processes leave trails in the information systems supporting them. Such event data are the starting point for process mining - an emerging scientific discipline relating modeled and observed behavior. The relevance of process mining is increasing as more and more event data become available. The increasing volume of such data ('Big Data') provides both opportunities and challenges for process mining. In this paper we focus on two particular types of process mining: process discovery (learning a process model from example behavior recorded in an event log) and conformance checking (diagnosing and quantifying discrepancies between observed behavior and modeled behavior). These tasks become challenging when there are hundreds or even thousands of different activities and millions of cases. Typically, process mining algorithms are linear in the number of cases and exponential in the number of different activities. This paper proposes a very general divide-and-conquer approach that decomposes the event log based on a partitioning of activities. Unlike existing approaches, this paper does not assume a particular process representation (e.g., Petri nets or BPMN) and allows for various decomposition strategies (e.g., SESE- or passage-based decomposition). Moreover, the generic divide-and-conquer approach reveals the core requirements for decomposing process discovery and conformance checking problems. © 2013 Polish Information Processing Society. 

A general framework for correlating business process characteristics Process discovery techniques make it possible to automatically derive process models from event data. However, often one is not only interested in discovering the control-flow but also in answering questions like =What do the cases that are late have in common=, =What characterizes the workers that skip this check activity=, and =Do people work faster if they have more work=, etc. Such questions can be answered by combining process mining with classification (e.g., decision tree analysis). Several authors have proposed ad-hoc solutions for specific questions, e.g., there is work on predicting the remaining processing time and recommending activities to minimize particular risks. However, as shown in this paper, it is possible to unify these ideas and provide a general framework for deriving and correlating process characteristics. First, we show how the desired process characteristics can be derived and linked to events. Then, we show that we can derive the selected dependent characteristic from a set of independent characteristics for a selected set of events. This can be done for any process characteristic one can think of. The approach is highly generic and implemented as plug-in for the ProM framework. Its applicability is demonstrated by using it to answer to a wide range of questions put forward by the UWV (the Dutch Employee Insurance Agency). © 2014 Springer International Publishing Switzerland. 

A general framework for precision checking Process conformance is the domain within Process Mining that addresses the adequacy between a model and a log of a system. It has four different dimensions: fitness, precision, generalization and structure. This paper presents a metric to evaluate the precision dimension: the extra behavior a formal model tolerates when confronted to a log. Additionally, two important factors are presented together with the metric value: confidence (an estimation of the stability of the metric value for a future window), and a severity assessment to the imprecisions detected. Several techniques are described to accomplish this, including a log-guided traversal of the model, the optimization of binary linear programming models to estimate the confidence, and multi-factored methods to determine the severity. The approach is implemented within an open-source Process Mining platform, and experimental results certify both the significance of the approach and the usefulness of the new factors proposed. © 2012 ICIC International. Business process management; Conformance checking; Process mining

A genetic algorithm for discovering process trees Existing process discovery approaches have problems dealing with competing quality dimensions (fitness, simplicity, generalization, and precision) and may produce anomalous process models (e.g., deadlocking models). In this paper we propose a new genetic process mining algorithm that discovers process models from event logs. The tree representation ensures the soundness of the model. Moreover, as experiments show, it is possible to balance the different quality dimensions. Our genetic process mining algorithm is the first algorithm where the search process can be guided by preferences of the user while ensuring correctness. © 2012 IEEE. 

A genetic algorithm for process discovery guided by completeness, precision and simplicity Several process discovery algorithms have been presented in the last years. These approaches look for complete, precise and simple models. Nevertheless, none of the current proposals obtains a good integration between the three objectives and, therefore, the mined models have differences with the real models. In this paper we present a genetic algorithm (ProDiGen) with a hierarchical fitness function that takes into account completeness, precision and simplicity. Moreover, ProDiGen uses crossover and mutation operators that focus the search on those parts of the model that generate errors during the processing of the log. The proposal has been validated with 21 different logs. Furthermore, we have compared our approach with two of the state of the art algorithms. © 2014 Springer International Publishing Switzerland. genetic mining; Petri nets; process discovery; Process mining

A genetic programming approach to business process mining The aim of process mining is to identify and extract process patterns from data logs to reconstruct an overall process flowchart. As business processes become more and more complex there is a need for managers to understand the processes they already have in place. To undertake such a task manually would be extremely time consuming so the practice of process mining attempts to automatically reconstruct the correct representation of a process based on a set of process execution traces. This paper outlines an alternative approach to business process mining utilising a Genetic Programming (GP) technique coupled with a graph based representation. The graph based representation allows greater flexibility in the analysis of process flowchart structure and offers the possibility of mining complex business processes from incomplete or problematic event logs. A number of event logs have been mined by the GP technique featured in this paper and the results of the experimentation point towards the potential of this novel process mining approach. Copyright 2008 ACM. Business process mining; Genetic programming; Graph based representation

A GP process mining approach from a structural perspective Process mining is the automated acquisition of process models from event workflow logs. And the model's structural complexity directly impacts readability and quality of the model. Although many mining techniques have been developed, most of them ignore mining from a structural perspective. Thus in this paper, we have proposed an improved genetic programming approach with a partial fitness, which is extended from the structuredness complexity metric so as to mine process models, which are not structurally complex. Additionally, the innovative process mining approach using complexity metric and tree based individual representation overcomes the shortcomings in previous genetic process mining approach (i.e., the previous GA approach underperforms when dealing with process models with short parallel and OR structure, etc). Finally, to evaluate our approach, experiments have also been conducted. © 2009 Springer-Verlag. 

A grid portal for solving geoscience problems using distributed knowledge discovery services This paper describes our research effort to employ Grid technologies to enable the development of geoscience applications by integrating workflow technologies with data mining resources and a portal framework in unique work environment called MOSÈ. Using MOSÈ, a user can easily compose and execute geo-workflows for analyzing and managing natural disasters such as landslides, earthquakes, floods, wildfires, etc. MOSÈ is designed to be applicable both for the implementation of response strategies when emergencies occur and for disaster prevention. It takes advantage of the standardized resource access and workflow support for loosely coupled software components provided by web/grid services technologies. The integration of workflows with data mining services significantly improves data analysis. Geospatial data management and mining are critical areas of modern-day geosciences research. An important challenge for geospatial information mining is the distributed nature of the data. MOSÈ provides knowledge discovery services based on the WEKA data mining library and novel distributed data mining algorithms for spatial data analysis. A P2P bio-inspired algorithm for distributed spatial clustering as an example of distributed knowledge discovery service for intensive data analysis is presented. A real case application for the analysis of landslide hazard areas in the Campania Region near the Sarno area shows the advantages of using the portal. © 2009 Elsevier B.V. All rights reserved. Geoscience applications; Grid computing; Grid services; Knowledge discovery services; Spatial data mining; Swarm intelligence

A grid-based multi-relational approach to process mining Industrial, scientific, and commercial applications use information systems to trace the execution of a business process. Relevant events are registered in massive logs and process mining techniques are used to automatically discover knowledge that reveals the execution and organization of the process instances (cases). In this paper, we investigate the use of a multi-level relational frequent pattern discovery method as a means of process mining. In order to process such massive logs we resort to a Grid-based implementation of the knowledge discovery algorithm that distributes the computation on several nodes of a Grid platform. Experiments are performed on real event logs. © 2008 Springer-Verlag Berlin Heidelberg. 

A heuristic genetic process mining algorithm The current GPM algorithm needs many iterations to get good process models with high fitness which makes the GPM algorithm usually time-consuming and sometimes the result can not be accepted. To mine higher quality model in shorter time, a heuristic solution by adding log-replay based crossover operator and direct/indirect dependency relation based mutation operator is put forward. Experiment results on 25 benchmark logs show encouraging results. © 2011 IEEE. Crossover; Genetic process mining; Heuristic; Log replay; Mutation

A hierarchical Markov model to understand the behaviour of agents in business processes Process mining techniques are able to discover process models from event logs but there is a gap between the low-level nature of events and the high-level abstraction of business activities. In this work we present a hierarchical Markov model together with mining techniques to discover the relationship between low-level events and a high-level description of the business process. This can be used to understand how agents perform activities at run-time. In a case study experiment using an agent-based simulation platform (AOR), we show how the proposed approach is able to discover the behaviour of agents in each activity of a business process for which a high-level model is known. © 2013 Springer-Verlag Berlin Heidelberg. Agent-Based Simulation; Agent-Object-Relationship (AOR); Expectation- Maximization; Markov Models; Process Mining

A high-level strategy for C-net discovery Causal nets have been recently proposed as a suitable model for process mining, due to their declarative semantics and compact representation. However, the discovery of causal nets from a log is a complex problem. The current algorithmic support for the discovery of causal nets comprises either fast but inaccurate methods (compromising quality), or accurate algorithms that are computationally demanding, thus limiting the size of the inputs they can process. In this paper a high-level strategy is presented, which uses appropriate clustering techniques to split the log into pieces, and benefits from the additive nature of causal nets. This allows amalgamating structurally the discovered causal net of each piece to derive a valuable model. The claims in this paper are accompanied with experimental results showing the significance of the high-level strategy presented. © 2012 IEEE. Causal nets; Clustering; High-level strategy; Process discovery

A hybrid approach for dynamic business process mining based on reconfigurable nets and event types Process mining aims at extracting business process information from event log generated by Business Process Management Systems to analyze operational performance. It can be an interesting tool for actually measuring the alignment of business process. In this paper, the process mining for dynamic business is discussed. Among different instances of the same dynamic business process, there are often some structural and dynamic changes. A hybrid process mining approach to dynamic business process is proposed. The approach is based on Reconfigurable Net and event types. Reconfigurable Net is used for modeling dynamic changes and two event types (Start, Over) are defined for mining algorithm. The method presented in this paper gives a method of mining dynamic changes in different instances and finally generate a Reconfigurable Workflow Net. © 2005 IEEE. 

A hybrid approach for process mining: Using from-to chart arranged by genetic algorithms In the scope of this study, a hybrid data analysis methodology to business process modeling is proposed in such a way that; From-to Chart, which is basically used as the front-end to figure out the observed patterns among the activities at realistic event logs, is rearranged by Genetic Algorithms to convert these derived raw relations into activity sequence. According to experimental results, acceptably good (sub-optimal or optimal) solutions are obtained for relatively complex business processes at a reasonable processing time period. © 2010 Springer-Verlag. Business Process Modeling (BPM); Event Logs; From-to Chart; Genetic Algorithms (GA); Process Mining

A knowledge-based integrated approach for discovering and repairing declare maps Process mining techniques can be used to discover process models from event data. Often the resulting models are complex due to the variability of the underlying process. Therefore, we aim at discovering declarative process models that can deal with such variability. However, for real-life event logs involving dozens of activities and hundreds or thousands of cases, there are often many potential constraints resulting in cluttered diagrams. Therefore, we propose various techniques to prune these models and remove constraints that are not interesting or implied by other constraints. Moreover, we show that domain knowledge (e.g., a reference model or grouping of activities) can be used to guide the discovery approach. The approach has been implemented in the process mining tool ProM and evaluated using an event log from a large Dutch hospital. Even in such highly variable environments, our approach can discover understandable declarative models. © 2013 Springer-Verlag. Declare; Linear Temporal Logic; Model Repair; Process Discovery

A label-free similarity measure between workflow nets Many activities in business process management, such as process search, process clustering, and process mining, need to determine the similarity between two process models. Although several approaches have recently been proposed to measure the behavioral similarity between business processes, all of them require that tasks in processes are properly labeled. According to these approaches, similarity between two given processes can be dramatically different under different task labeling schemes. In this paper, we consider process similarity measure from another view point, i.e., focusing on the control flow structures and ignoring the task labels. Thus, we propose a label-free similarity measure between process models based on transition adjacent relations (TARs) in the context of workflow nets (WF-nets), as well as an efficient algorithm. The experimental results involving comparison of different similarity measures on artificial processes and evaluation of the efficient algorithm on real-life processes are discussed. ©2009 IEEE. 

A 'Lean' Fuzzy Rule to Speed-Up a Taylor-Made Warehouse Management Process The minimization of the inventory storage cost and - as a consequence - optimize the storage capacity based on the Stock Keeping Unit (SKU) features is a challenging problem in operations management. In order to accomplish this objective, experienced managers make usually effective decisions based on the common sense and practical reasoning models. An approach based on fuzzy logic can be considered as a good alternative to the classical inventory control models. The purpose of this paper is to present a methodology which assigns incoming products to storage locations in storage departments/zones in order to reduce material handling cost and improve space utilization. The iterative Process Mining algorithm based on the concept of Fuzzy Logic systems set and association rules is proposed, which extracts interesting patterns in terms of fuzzy rules, from the centralized process datasets stored as quantitative values. Logistics; Warehouse management; Putaway process; Fuzzy rules; Data Mining

A method for matching customer integration with operational control of service processes Purpose: A major problem of operational control in the services industry is the integration of customers in the delivery process. The aim of this paper is to develop a method that allows service companies to evaluate the impact of customer integration on operational control in service processes. Design/methodology/approach: The development of the proposed method follows a design science approach. Thus, the method is conceptualised on the basis of production, services and information systems research. A case study of loan processing in a bank serves to evaluate the applicability of the method. Findings: As a result of this study, customer integration should be included into operational control following three steps: identification of the type of customer integration; quantification and characterisation of the impact of the integration; and identification of the appropriate mechanisms of operational control to deal with the customer integration better. The results of the case study show that customer integration has an impact on certain activities within a service process only but the results can be used to enhance operational control. Practical implications: The method can be used by process managers of service companies to identify the impact of customer integration on operational control. Thus, decisions within operational control and consequently the overall productivity of a service process can be improved. Originality/value: The paper delivers a new insight how customer integration and operational control can be linked in service processes. Thus, a theoretical gap in service operations literature is filled. Furthermore, the case study demonstrates how the method can be used in practice. © Emerald Group Publishing Limited. Customers; Operational control; Operations management; Process mining; Productivity; Service delivery; Service process

A method of adaptive process mining based on time-varying sliding window and relation of adjacent event dependency Most existing process mining methods were designed for ignoring time variability from real business process data, thus it could be hard to implement adaptive process mining. To deal with this problem, a new method of adaptive process mining was proposed in order to mine unremittingly process models of gradual change which represents the improvement stages of business processes and improve accuracy of mined results. Given related concepts of a time-varying sliding window and relation of adjacent event dependency, update rules of modifying continuously size and progress in a time-varying sliding window were studied based on changed frequency of mined results and arrival rate of process instance streams, and an algorithm of process mining was presented by applying relation of adjacent event dependency among activities. Finally, a plug-in tool in PROM was developed to implement this algorithm. © 2012 IEEE. Adaptability; Process Mining; Relation of Adjacent Event Dependency; Time-varying Sliding Window

A method to identify the difference between two process models Process mining is getting much attentions and interests in the development of the web-based information technique (IT) field. Process conformance, one of process mining techniques, may be the most common method used to find out the (dis)similar working process(es). The distinguishing processes found are greatly instrumental in making business decisions, such as conduction strategies, service tactics, manufacturing process,..., etc., and further to advance their working efficiency. Several process conformance approaches have been developed and discussed over the past decade, but those discussions involving in the investigation to seek for reasons why the working processes are (un)conformable are rare. To advance the function of the process conformance, this paper introduces the two parameters, Support and Confidence, used for newly defining the tinguishability among various processes; meanwhile, they are also taken to identify the roots resulting to the process distinguishing. "Support" parameter functions as the evaluation of the process similarity based on the working activity sequences (or called "from-to" workflows) and on the relationships among the various processes evaluated; "Confidence" as the measure of the process relationships defined by a ratio of the identical activities within two processes to the total activities of each individual process. Moreover, the two proposed parameters had also been applied to a real case, in which the nursing processes worked in the pediatrics department of a hospital were measured and improved. To the best knowledge of the authors, there does not have an exact technique that, so far, is intact of considering the whole situation where all of the process conformance factors are involved; even the presentation of this paper cannot be avoidable. Nevertheless, this paper truly provides a way to find a certain degree of a lower bound of the process distinguishability through the two proposed conformance parameters. © 2012 ACADEMY PUBLISHER. Distinguishability; Petri nets; Process conformance; Process mining; Process similarity

A methodology for building log of collaboration processes The analysis of data produced during collaborative activities allows organizations to improve collaboration management. Since people use several collaboration tools, these kind of data are difficult to obtain. Furthermore they are heterogeneous and require an important preprocessing step to be useful. In the present work we introduce a methodology aimed at obtaining a single log with all data related to team activities. To improve process analysis, such data log is semantically enriched by means of a multidimensional taxonomy capable of describing collaboration activities at various abstraction levels. We also introduce a case study to be used throughout the paper as an illustrative example. © 2014 IEEE. collaboration process analysis; data integration; log preprocessing; process mining; semantic data enrichment

A mining method of business process remodeling in E-business Realization of E-business depends on the capability of business process management system (BPMS). The normal running of BPMS is decided by exact business process models. However the constant change of market requirement results in instability of process models. In BPMS there are a large mount of process logs, which involve information of various business processes. Therefore, this paper design a mining method to remodel business process based on these logs. The process mining algorithm is designed as the core. In the algorithm a Marko transition matrix is set up based on process logs. And according to the matrix the eight mining rules of process logical relations are designed. The mining method can not only automatically remodel the various processes, but also greatly enhance the process modeling efficiency. © 2009 Binary Information Press. Business process management system; Business process remodeling; Economic business; Markov transition matrix; Process log; Process mining

A multi-dimensional quality assessment of state-of-the-art process discovery algorithms using real-life event logs Process mining is the research domain that is dedicated to the a posteriori analysis of business process executions. The techniques developed within this research area are specifically designed to provide profound insight by exploiting the untapped reservoir of knowledge that resides within event logs of information systems. Process discovery is one specific subdomain of process mining that entails the discovery of control-flow models from such event logs. Assessing the quality of discovered process models is an essential element, both for conducting process mining research as well as for the use of process mining in practice. In this paper, a multi-dimensional quality assessment is presented in order to comprehensively evaluate process discovery techniques. In contrast to previous studies, the major contribution of this paper is the use of eight real-life event logs. For instance, we show that evaluation based on real-life event logs significantly differs from the traditional approach to assess process discovery techniques using artificial event logs. In addition, we provide an extensive overview of available process discovery techniques and we describe how discovered process models can be assessed regarding both accuracy and comprehensibility. The results of our study indicate that the HeuristicsMiner algorithm is especially suited in a real-life setting. However, it is also shown that, particularly for highly complex event logs, knowledge discovery from such data sets can become a major problem for traditional process discovery techniques. © 2012 Elsevier Ltd. All rights reserved. Accuracy; Benchmarking; Comprehensibility; Process mining; Real-life event logs

A new method for business process mining based on state equation Workflow mining techniques have recently received remarkable attention because of their ability to assist in the design of complex processes by discovering models according to some log cases, which collected and stored by most information systems. In some situation, there is no model available and need mine it. The paper discuss a novel technique of process model mining based on a large number of logs and represent it in terms of a Petri net. Finally, verify the workflow model based on Petri nets property. © 2011 Springer-Verlag. log cases; Petri nets; process mining; Workflow mining

A new model for discovering process trees from event logs Process mining techniques aim at extracting knowledge from event logs. One of the most important tasks in process mining is process model discovery. In discovering process models, an algorithm is designed to build a process model from a given event log. In this paper, a new model to discover process models has been proposed. A combination of Genetic Algorithm and Simulated Annealing has been used in this model. Genetic Algorithms has previously been used in this context. Previous approaches had drawbacks in fitness evaluation that misguided the algorithm. Another problem was that the quality of the candidates, in the population, was low such that it reduced the chance of finding a perfect answer. In this paper, a new fitness measure has been proposed to evaluate process models based on event logs. Moreover SA has been used to improve the quality of candidates in the population. It has been demonstrated that the proposed model outperformed in terms of rediscovering process models, compared to other approaches which are proposed in the literature, which was the result of better fitness evaluation and increased quality of individuals,. It came to conclusion that using GA and SA in combination with each other can be effective in this context. Business process management; Genetic algorithm; Process mining; Process modeling; Process tree; Simulated annealing

A new process mining algorithm based on event type The aim of process mining is to rediscover the process model from the event log which is recorded by the information system. Although the omnipresence of the event logs in information system, rarely part of them are considered to analyze the processes. In this paper, we present a new mining algorithm based on the event type we defined. This algorithm not only can detect all of the SWF-nets and short-loops, but also can directly detect the implicit dependency. Because we can obtain more task information from the event log, we can deal with a wider subclass of WF-nets with the algorithm we have presented. © 2011 IEEE. Petri net; Post-tasks; Process mining; Workflow

A new process mining algorithm of workflow Workflow process mining technology is not a tool of workflow design, but it is very useful for understanding the current business processes. Workflow process mining does well in knowledge management and decision-making support. The dynamic flow control and fuzziness make the old methods that analysis the performance of workflow not applicable. In order to solve the problem a new workflow process mining algorithm is presented. © 2009 IEEE. Dynamic binding; Scheduling; Workflow

A novel approach for mining stochastic process model from workflow logs Workflow is a series of interrelated and automatic business activities or tasks, in which many participants can automatically exchange their documents, information and tasks according to the predefined rules and models, so that they can achieve some business goals. Techniques of workflow mining are now becoming more important and they have recently received remarkable attention for researchers. By workflow mining approach, the developers can avoid the design of a complex formal process model, and they only need to discover the corresponding models from workflow logs, which are collected and stored by most information systems. This paper proposes a novel approach for mining stochastic workflow model from the execution logs automatically. We first propose a statistical method to construct the original relations among tasks. Then, several algorithms are designed for identifying the different control structures among tasks. In this way, an original workflow net is constructed. Next, by using state equations, we verify and refine the constructed workflow net. Finally, the stochastic relations among tasks are also mined from the logs and incorporated into the workflow net. We also implement a mining tool called SPM_Miner to validate the effectiveness of our method. © 2005 by Binary Information Press. Petri nets; Process mining; Workflow logs; Workflow net

A novel approach for process mining based on event types Despite the omnipresence of event logs in transactional information systems (cf. WFM, ERP, CRM, SCM, and B2B systems), historic information is rarely used to analyze the underlying processes. Process mining aims at improving this by providing techniques and tools for discovering process, control, data, organizational, and social structures from event logs, i.e., the basic idea of process mining is to diagnose business processes by mining event logs for knowledge. Given its potential and challenges it is no surprise that recently process mining has become a vivid research area. In this paper, a novel approach for process mining based on two event types, i.e., START and COMPLETE, is proposed. Information about the start and completion of tasks can be used to explicitly detect parallelism. The algorithm presented in this paper overcomes some of the limitations of existing algorithms such as the a-algorithm (e.g., short-loops) and therefore enhances the applicability of process mining. © 2007 Springer Science+Business Media, LLC. Data mining; DWF-nets; Event types; Petri nets; Process mining; WF-nets; Workflow mining

A novel approach of process mining with event graph Modern enterprises are increasingly moving towards the workflow paradigm in modeling their business process. One prevailing approach counts on process mining that aims to discover workflow models from log files which contain rich process information. The process models discovered are then used to model and design information systems intended for workflow management. Although workflow logs contain rich information, they have not been made full use in many existing modeling formalisms like Petri nets. In this paper, we propose a novel approach for process mining using event graph to integrate various process related information. Analysis is conducted to show the advantages of event graph based models compared to Petri nets. A case study is also reported to illustrate the entire mining process. Finally, a preliminary evaluation is conducted to show the merits of our method in terms of precision, generalization and robustness. © 2010 Springer-Verlag. event graph; Petri nets; process mining; workflow management

A novel approach to process mining: Intentional process models discovery So far, process mining techniques have suggested to model processes in terms of tasks that occur during the enactment of a process. However, research on method engineering and guidance has illustrated that many issues, such as lack of flexibility or adaptation, are solved more effectively when intentions are explicitly specified. This paper presents a novel approach of process mining, called Map Miner Method (MMM). This method is designed to automate the construction of intentional process models from process logs. MMM uses Hidden Markov Models to model the relationship between users' activities logs and the strategies to fulfill their intentions. The method also includes two specific algorithms developed to infer users' intentions and construct intentional process model (Map) respectively. MMM can construct Map process models with different levels of abstraction (fine-grained and coarse-grained process models) with respect to the Map metamodel formalism (i.e., metamodel that specifies intentions and strategies of process actors). This paper presents all steps toward the construction of Map process models topology. The entire method is applied on a large-scale case study (Eclipse UDC) to mine the associated intentional process. The likelihood of the obtained process model shows a satisfying efficiency for the proposed method. © 2014 IEEE. Intention-oriented Process Modeling; Process Mining; unsupervised learning

A novel behavioral similarity measure for artifact-oriented business processes Artifact-oriented business process has emerged as a representative paradigm of data centric business process. As concerned in traditional business process, the measure of the similarity or distance between two processes is becoming a critical issue, which enables a better operation of artifact-oriented business process model such as process retrieval, process mining, etc. This paper proposed a novel method to measure the behavioral similarity between artifact-oriented business processes. In the proposed approach, we computed the similarity between business core data in the process firstly, by calculating the similarity between key artifacts. Secondly, the similarity between task dependency relation sets of the task paths was evaluated according to the lifecycle features of key artifact. Finally, we also measured the similarity between attribute assignment sequence sets in the task executing path. The theoretical analysis also demonstrates the validity of this approach. © 2012 Springer-Verlag GmbH Berlin Heidelberg. Artifact; Attribute Assignment Sequence (AAS); Business Process Management; Lifecycle; Petri net; Task Dependency Relation (TDR)

A novel statistical method for automatically partitioning tools according to engineers' tolerance control in process improvement In the semiconductor industry, tool comparison is a key task in yield or product quality enhancements. We develop a new method to automatically partition tools. The new method is called tolerance control partitioning (TCP). The advantages of TCP include 1) taking into account of unbalanced tool usage in manufacturing processes; 2) further partitioning these tools into several homogenous groups by related metrology results instead of detecting only the significant difference; and 3) partitioning these tools according to engineers' tolerance controls to avoid too many groups with small differences. TCP also could be applied in all similar cases such as experimental recipe or material comparisons. Therefore, using TCP, engineers could speed up yield or product quality ramping. Two simulation cases illustrate the advantages of TCP method. We also applied TCP to two real cases for yield and Cp/Cpk enhancement in the semiconductor industry. The results confirm the practical feasibility of this method. © 2006 IEEE. 

A policy-based process mining framework: Mining business policy texts for discovering process models Many organizations use business policies to govern their business processes, often resulting in huge amounts of policy documents. As new regulations arise such as Sarbanes-Oxley, these business policies must be modified to ensure their correctness and consistency. Given the large amounts of business policies, manually analyzing policy documents to discover process information is very time-consuming and imposes excessive workload. In order to provide a solution to this information overload problem, we propose a novel approach named Policy-based Process Mining (PBPM) to automatically extracting process information from policy documents. Several text mining algorithms are applied to business policy texts in order to discover process-related policies and extract such process components as tasks, data items, and resources. Experiments are conducted to validate the extracted components and the results are found to be very promising. To the best of our knowledge, PBPM is the first approach that applies text mining towards discovering business process components from unstructured policy documents. The initial research results presented in this paper will require more research efforts to make PBPM a practical solution. © Springer-Verlag 2009. Business policy management; Business process management; Process mining; Text mining

A practical approach to automated business process discovery Process mining has been studied for many years but has not been so widely adopted in real business practices. In this study, we propose a practical approach to process mining. This approach has three characteristics. Firstly, we make use of transaction databases of business systems that don't necessarily have an identifier throughout a process instance, rather than workflow logs. Secondly, we visualize and analyze what really happened without model inference. Thirdly, we also analyze exceptional processes as well as typical processes. This approach is implemented in a tool called BPM-E and was successfully adopted in real business systems in Japan, North America, and Europe. We show two case studies of BPME in this paper to explain how it works after the technical description. © 2013 IEEE. Database; Exceptional process; Process mining; Typical process

A principled approach to mining from noisy logs using Heuristics Miner Noise is a challenge for process mining algorithms, but there is no standard definition of noise nor accepted way to quantify it. This means it is not possible to mine with confidence from event logs which may not record the underlying process correctly. We discuss one way of thinking about noise in process mining. We consider mining from a 'noisy log' as learning a probability distribution over traces, representing the true process, from a log which is a sample from multiple distributions: the 'true' process model and one or more 'noise' models. We apply this using a probabilistic analysis of the Heuristics Miner algorithm, and demonstrate on a simple example. We show that for a given model it is possible to predict how much data is needed to mine the underlying model without the noise, and identify differences in the the robustness of Heuristics Miner to different types of noise. © 2013 IEEE. 

A principled approach to the analysis of process mining algorithms Process mining uses event logs to learn and reason about business process models. Existing algorithms for mining the control-flow of processes in general do not take into account the probabilistic nature of the underlying process, which affects the behaviour of algorithms and the amount of data needed for confidence in mining. We contribute a first step towards a novel probabilistic framework within which to talk about approaches to process mining, and apply it to the well-known Alpha Algorithm. We show that knowledge of model structures and algorithm behaviour can be used to predict the number of traces needed for mining. © 2011 Springer-Verlag. Business process mining; Petri nets; probabilistic automata

A probabilistic approach for process mining in incomplete and noisy logs Process mining techniques aim at automatically generating process models from event logs. Many existing techniques in process mining are applicable only under very restrictive conditions about the log completeness. However, due to the completion time of the tasks in the model, the generated logs in most of the real life processes do not satisfy these conditions. In many real life logs, too many log instances are needed for the mining approach to work properly. Therefore, another definitions, metrics and algorithms are required to mine event logs with not enough instances. In this paper, a probabilistic approach is proposed to mine event logs when the number of instances is limited. In order to evaluate the proposed approach, time Petri nets are used to generate more realistic event logs. In comparison with many existing approaches, based are the results of our experiments, the proposed approach is very robust in mining process logs with high degrees of parallelism, incompleteness and noise. Incomplete; Log; Noisy; Probabilistic; Process mining

A procedure for extracting software development process patterns Process patterns represent well-structured and successful recurring activities of Software Development Methodologies (SDMs). They are able to form a library of reusable building blocks that can be utilized in Situational Method Engineering (SME) for constructing a custom SDM or enhancing an existing one to fit specific project situation. Recently, some researchers have subjectively extracted process patterns from existing SDMs based on cumulative experience in various domains; however, how to objectively extract process patterns from SDMs by adopting a systematic procedure has remained as question. In this regard, this paper is concerned with a procedure aiming to take process patterns out of existing SDMs. An example illustrates applicability of the proposed procedure for extracting process patterns in a specific context. © 2010 IEEE. 

A process deviation analysis - A case study Processes are not always executed as expected. Deviations assure the necessary flexibility within a company, but also increase possible internal control weaknesses. Since the number of cases following such a deviation can grow very large, it becomes difficult to analyze them case-by-case. This paper proposes a semi-automatic process deviation analysis method which combines process mining with association rule mining to simplify the analysis of deviating cases. Association rule mining is used to group deviating cases into business rules according to similar attribute values. Consequently, only the resulting business rules need to be examined on their acceptability which makes the analysis less complicated. Therefore, this method can be used to support the search for internal control weaknesses. © 2012 Springer-Verlag. Association Rule Mining; Business Rules; Fuzzy Miner; Internal Control; PAIS; PredictiveAPriori; Process Mining

A process mining approach to redesign business processes - A case study in gas industry Nowadays organizations have to adjust their business processes along with the changing environment, in order to maintain a competitive advantage. Often, a change in a part of the system which is to support the business process implies a change of the whole system, which causes complex redesign activities. In this paper we present a case study involving the process redesign of a Dutch company belonging to gas industry. In order to identify appropriate redesign interventions, process mining and simulation techniques are used. This paper presents a process mining approach used in this case study, which consists of three steps: (i) data preparation, (ii) process mining and performance analysis, and (iii) simulation of the current and redesigned process models. © 2008 IEEE. 

A process mining based approach to knowledge maintenance The quality of knowledge in the knowledge repository determines the effect of knowledge reusing and sharing. Knowledge to be reused should be checked in advance through a knowledge maintenance process. The knowledge maintenance process model is difficult to be constructed because of the balance between the efficiency and the effect. In this paper, process mining is applied to analyze the knowledge maintenance logs to discover process and then construct a more appropriate knowledge maintenance process model. We analyze knowledge maintenance logs from the control flow perspective to find a good characterization of knowledge maintenance tasks and dependencies. In addition, the logs are analyzed from the organizational perspective to cluster the performers who are qualified to do the same kinds of tasks and to get the relations among these clusters. The proposed approach has been applied in the knowledge management system. The result of the experiment shows that our approach is feasible and efficient. © 2010 Springer Science+Business Media, LLC. Knowledge maintenance; Knowledge management; Process mining

A process mining-based analysis of business process work-arounds Business process work-arounds are specific forms of incompliant behavior, where employees intentionally decide to deviate from the required procedures although they are aware of them. Detecting and understanding the work-arounds performed can guide organizations in redesigning and improving their processes and support systems. Existing process mining techniques for compliance checking and diagnosis of incompliant behavior rely on the available information in event logs and emphasize technological capabilities for analyzing this information. They do not distinguish intentional incompliance and do not address the sources of this behavior. In contrast, the paper builds on a list of generic types of work-arounds found in practice and explores whether and how they can be detected by process mining techniques. Results obtained for four work-around types in five real-life processes are reported. The remaining two types are not reflected in events logs and cannot be currently detected by process mining. The detected work-around data are further analyzed for identifying correlations between the frequency of specific work-around types and properties of the processes and of specific activities. The analysis results promote the understanding of work-around situations and sources. © 2014 Springer-Verlag Berlin Heidelberg. 

A process mining-based investigation of adverse events in care processes This paper proposes the Clinical Pathway Analysis Method (CPAM) approach that enables the extraction of valuable organisational and medical information on past clinical pathway executions from the event logs of healthcare information systems. The method deals with the complexity of real-world clinical pathways by introducing a perspective-based segmentation of the date-stamped event log. CPAM enables the clinical pathway analyst to effectively and efficiently acquire a profound insight into the clinical pathways. By comparing the specific medical conditions of patients with the factors used for characterising the different clinical pathway variants, the medical expert can identify the best therapeutic option. Process mining-based analytics enables the acquisition of valuable insights into clinical pathways, based on the complete audit traces of previous clinical pathway instances. Additionally, the methodology is suited to assess guideline compliance and analyse adverse events. Finally, the methodology provides support for eliciting tacit knowledge and providing treatment selection assistance. Clinical pathways; Hospital information systems; Information storage and retrieval; Medical informatics; Quality of healthcare

A process-mining framework for the detection of healthcare fraud and abuse People rely on government-managed health insurance systems, private health insurance systems, or both to share the expensive healthcare costs. With such an intensive need for health insurances, however, health care service providers' fraudulent and abusive behavior has become a serious problem. In this research, we propose a data-mining framework that utilizes the concept of clinical pathways to facilitate automatic and systematic construction of an adaptable and extensible detection model. The proposed approaches have been evaluated objectively by a real-world data set gathered from the National Health Insurance (NHI) program in Taiwan. The empirical experiments show that our detection model is efficient and capable of identifying some fraudulent and abusive cases that are not detected by a manually constructed detection model. © 2005 Elsevier Ltd. All rights reserved. Classification model; Clinical pathways; Data mining; Healthcare abuse; Healthcare fraud

A process-oriented methodology for evaluating the impact of IT: A proposal and an application in healthcare In order to improve the performance of business processes often Information Technologies (ITs) are introduced. However, business processes are known to be complex and distributed among multiple business entities. As a result, the impact of new IT on an entire business process is typically hard to assess as quantitative methods for evaluation are missing. Therefore, in this paper, we propose a process-oriented methodology for evaluating the impact of IT on a business process ahead of its implementation. In our method, process mining and discrete event simulation are key ingredients. Based on automatically stored data, process mining allows for obtaining detailed knowledge on a business process, e.g., it can be discovered how a business process is actually executed. Using discrete event simulation, a model can be built which accurately mimicks the discovered process and which can subsequently be used for exploring and evaluating various redesign of the same process. Our method is evaluated by means of a detailed case study. For a complex dental process, it turns out that the introduction of new digital technologies is largely beneficial for patients and dental lab owners, whereas for dentists there is hardly any benefit. © 2013 Elsevier Ltd. Business process simulation; Digital dentistry; Discrete event simulation; Process mining

A recommender system for process discovery Over the last decade, several algorithms for process discovery and process conformance have been proposed. Still, it is well-accepted that there is no dominant algorithm in any of these two disciplines, and then it is often difficult to apply them successfully. Most of these algorithms need a close-to expert knowledge in order to be applied satisfactorily. In this paper, we present a recommender system that uses portfolio-based algorithm selection strategies to face the following problems: to find the best discovery algorithm for the data at hand, and to allow bridging the gap between general users and process mining algorithms. Experiments performed with the developed tool witness the usefulness of the approach for a variety of instances. © 2014 Springer International Publishing Switzerland. Algorithm Selection; Process Mining; Recommender Systems

A region-based algorithm for discovering Petri nets from event logs The paper presents a new method for the synthesis of Petri nets from event logs in the area of Process Mining. The method derives a bounded Petri net that over-approximates the behavior of an event log. The most important property is that it produces a net with the smallest behavior that still contains the behavior of the event log. The methods described in this paper have been implemented in a tool and tested on a set of examples. © 2008 Springer Berlin Heidelberg. 

A RFID-based recursive process mining system for quality assurance in the garment industry With the increasing concern about product quality, attention has shifted to the monitoring of production processes to be assured of good quality. Achieving good quality is a challenging task in the garment industry due to the great complexity of garment products. This paper presents an intelligent system, using fuzzy association rule mining with a recursive process mining algorithm, to find the relationships between production process parameters and product quality. The goal is to derive a set of decision rules for fuzzy logic that will determine the quantitative values of the process parameters. Learnt process parameters used in production form new inputs of the initial step of the mining algorithm so that new sets of rules can be obtained recursively. Radio frequency identification technology is deployed to increase the efficiency of the system. With the recursive characteristics of the system, process parameters can be continually refined for the purpose of achieving quality assurance. A case study is described in which the system is applied in a garment manufacturing company. After a six-month pilot run of the system, the numbers of critical defects, major defects and minor defects were reduced by 7, 20 and 24%, respectively while production time and rework cost improved by 26 and 30%, respectively. Results demonstrate the practical viability of the system to provide decision support for garment manufacturers who may not be able to determine the appropriate process settings for achieving the desired product quality. © 2012 Taylor & Francis. Fuzzy association rule mining; Fuzzy logic; Garment industry; Quality assurance; RFID

A rule-based approach for process discovery: Dealing with noise and imbalance in process logs Effective information systems require the existence of explicit process models. A completely specified process design needs to be developed in order to enact a given business process. This development is time consuming and often subjective and incomplete. We propose a method that constructs the process model from process log data, by determining the relations between process tasks. To predict these relations, we employ machine learning technique to induce rule sets. These rule sets are induced from simulated process log data generated by varying process characteristics such as noise and log size. Tests reveal that the induced rule sets have a high predictive accuracy on new data. The effects of noise and imbalance of execution priorities during the discovery of the relations between process tasks are also discussed. Knowing the causal, exclusive, and parallel relations, a process model expressed in the Petri net formalism can be built. We illustrate our approach with real world data in a case study. © 2006 Springer Science+Business Media, LLC. Knowledge discovery; Petri nets; Process mining; Rule induction

A semantic approach to the discovery of workflow activity patterns in event logs Workflow activity patterns represent a set of recurrent behaviours that can be found in a wide range of business processes. In this paper we address the problem of determining the presence of these patterns in process models. This is usually done manually by the analyst, who inspects the model and interprets its elements in terms of the semantics of those patterns. Here, we present an approach to perform this discovery based on the event log created during process execution. The approach makes use of an ontology and the semantic annotation of the event log in order to discover the patterns automatically by means of semantic reasoning. We illustrate the application of the proposed approach in a case study involving a purchase process implemented in a commercial workflow system. Copyright © 2012 Inderscience Enterprises Ltd. Business process modelling; Ontology engineering; Process mining; Semantic reasoning; WAPs; Workflow activity patterns

A semi-automatic system with an iterative learning method for discovering the leading indicators in business processes Within Business Intelligence (BI) systems, a Key Performance Indicator (KPI) is a measurement of how well the organization, or a specific individual or process within that organization, performs an operational, tactical, or strategic activity that is critical for the current and future success of that organization [1]. The leading indicators are one type of KPIs that present key drivers of business value, are predictors of future outcomes, and offer the organization the unique opportunity to positively effect, or properly plan for, the future. Therefore, effective leading indicators are critical to the success of any business organization. However, identifying leading indicators is often non-trivial. It may require months to collect requirements, standardizing definitions and rules, prioritizing metrics, and soliciting feedback, etc. Moreover, because the time shifts between the leading indicators and the corresponding affected lagging indicators are vague and often inconstant for variability of business concerns, the traditional approach depending on domain experts experiences is labor-intensive and error-prone. In this paper, we propose a semi-automatic system with an iterative learning process for analyzing operational metrics, factoring out the key performance indicators (KPIs) and then further discovering leading indicators. Two case studies are also conducted by applying the proposed methods in the production printing domain. The proposed system has two key differentiations and novelties: (1) the semi-automatic framework simplifies many traditional labor-intensive and error-prone steps by using temporal data mining techniques combined with specific domain knowledge, thus enabling timely access to operational metrics, KPI analysis, and powerful leading indicator discovery; (2) an iterative learning methodology not only continuingly uncovers the "root" leading indicators, but also enables the flexibility and adaptability for metric updates and additional data collection points. Copyright 2007 ACM. 

A Simulation Approach in Process Mining Conformance Analysis. The Introduction of a Brand New BPMN Element The computerization of organizational processes provides several tools for evaluating the quality of mapping. An executed process produces, in each instance, log files that can be used to reconstruct the actual procedure carried out by the system as well as to highlight deviations or "move" from the mapped path. These "moves" represent a loss that we consider unacceptable for organizations, which manifests its effects in various modes and weights. From this arises, in our view, the need for tools and logic approach to manage and limit the "conformance risk", including as well as a proper consideration and methodological evaluation of the same risk, but also practical solutions and mapping tools that might influence the occurrence. In this paper we propose a methodology and a simulation model of "Conformance Risk Aware Desing" in order to support the modeler in moving from a diagnostic to a preventive and design view of the conformance's matter. (C) 2014. The Authors. Published by Elsevier B.V. BPMN; Business process modelling; Conformance risk; Process mining

A Sliding-Window Method to Discover Recent Frequent Query Patterns from XML Query Streams Providing efficient mining algorithm to discover recent frequent XML user query patterns is crucial, as many applications use XML to represent data in their disciplines over the Internet. These recent frequent XML user query patterns can be used to design an index mechanism or cached and thus enhance XML query performance. Several XML query pattern stream mining algorithms have been proposed to record user queries in the system and thus discover the recent frequent XML query patterns over a stream. By using these recent frequent XML query patterns, the query performance of XML data stream is improved. In this paper, user queries are modeled as a stream of XML queries and the recent frequent XML query patterns are thus mined over the stream. Data-stream mining differs from traditional data mining since its input of mining is data streams, while the latter focuses on mining static databases. To facilitate the one-pass mining process, novel schemes (i.e. XstreamCode and XstreamList) are devised in the mining algorithm (i.e. X(2)StreamMiner) in this paper. X(2)StreamMiner not only reduces the memory space, but also improves the mining performance. The simulation results also show that X(2)StreamMiner algorithm is both efficient and scalable. There are two major contributions in this paper. First, the novel schemes are proposed to encode and store the information of user queries in an XML query stream. Second, based on the two schemes, an efficient XML query stream mining algorithm, X(2)StreamMiner, is proposed to discover the recent frequent XML query patterns. data stream; database; encoding scheme; XML query pattern; XML stream mining

A study of quality and accuracy trade-offs in process mining In recent years, many algorithms have been proposed to extract process models from process execution logs. The process models describe the ordering relationships between tasks in a process in terms of standard constructs like sequence, parallel, choice, and loop. Most algorithms assume that each trace in a log represents a correct execution sequence based on a model. In practice, logs are often noisy, and algorithms designed for correct logs are not able to handle noisy logs. In this paper we share our key insights from a study of noise in process logs both real and synthetic. We found that all process logs can be explained by a block-structured model with two special self-loop and optional structures, making it trivial to build a fully accurate process model for any given log, even one with inaccurate data or noise present in it. However, such a model suffers from low quality. By controlling the use of self-loop and optional structures of tasks and blocks of tasks, we can balance the quality and accuracy trade-off to derive high-quality process models that explain a given percentage of traces in the log. Finally, new quality metrics and a novel quality-based algorithm for model extraction from noisy logs are described. The results of the experiments with the algorithm on real and synthetic data are reported and analyzed at length. © 2012 INFORMS. Knowledge discovery; Process mining; Quality metric; Quality-accuracy trade-off; Quality-based algorithm

A system architecture for manufacturing process analysis based on big data and process mining techniques Interests in manufacturing process management and analysis are increasing, but it is difficult to conduct process analysis due to the increase of manufacturing data. Therefore, we suggest a manufacturing data analysis system that collects event logs from so-called big data and analyzes the collected logs with process mining. There are two kinds of big data generated from manufacturing processes, structured data and unstructured data. Usually, manufacturing process analysis is conducted by using only structured data, however the proposed system uses both structured and unstructured data for enhancing the process analysis results. The system automatically discovers a process model and conducts various performance analysis on the manufacturing processes. Big data; Hadoop distributed file system (HDFS); Process mining; Text mining

A two-step fast algorithm for the automated discovery of declarative workflows Declarative approaches are particularly suitable for modeling highly flexible processes. They especially apply to artful processes, i.e., rapid informal processes that are typically carried out by those people whose work is mental rather than physical (managers, professors, researchers, engineers, etc.), the so called 'knowledge workers'. This paper describes MINERful++, a two-step algorithm for an efficient discovery of constraints that constitute declarative workflow models. As a first step, a knowledge base is built, with information about temporal statistics gathered from execution traces. Then, the statistical support of constraints is computed, by querying that knowledge base. MINERful++ is fast, modular, independent of the specific formalism adopted for representing constraints, based on a probabilistic approach and capable of eliminating the redundancy of subsumed constraints. © 2013 IEEE. 

A universal significant reference model set for process mining evaluation framework Process mining has caught the attention of researchers and practioners. Because a wide variety of process mining techniques have been proposed, it is difficult to choose a suitable process mining algorithm for a given enterprise or application domain. Model rediscoverability of process mining algorithms has been proposed as a benchmark to address this issue. Given a process model (we call it original model) and its corresponding event log, the model rediscoverability is to measure how similar between the original model and the process model mined by the process mining algorithm. As evaluating available process mining algorithms against a large set of business process models is computationally expensive, some recent works have been done to accelerate the evaluation by only evaluating a portion of process models (the so-called reference models) and recommending the others via a regression model. The effect of the recommendation is highly dependent on the quality of the reference models. Nevertheless, choosing the significant reference models from a given model set is also time-consuming and ineffective. This paper generalizes a universal significant reference model set. Furthermore, this paper also proposes a selection of process model features to increase the accuracy of recommending process mining algorithm. Experiments using artificial and real-life datasets show that our proposed reference model set and selected features are practical and outperform the traditional ones. © Springer International Publishing Switzerland 2014. Feature Selection; Process Mining; Universal Significant Reference Model

A workflow frequent pattern mining algorithm To improve workflow for adapting to the uncertainty of business environments, workflow frequent patterns are used. First, the frequent pattern discovery problem is defined, and a frequent pattern-mining algorithm based on Apriori algorithm is proposed. Frequent patterns can quantify the strength of logical relations between activities and trend forecast and crucial business decision-making can be supported by frequent patterns in key activities. © 2007 IEEE. Apriori algorithm; Frequent patterns; Mining; Workflow models

A workflow process mining algorithm based on synchro-net Sometimes historic information about workflow execution is needed to analyze business processes. Process mining aims at extracting information from event logs for capturing a business process in execution. In this paper a process mining algorithm is proposed based on Synchro-Net which is a synchronization-based model of workflow logic and workflow semantics. With this mining algorithm based on the model, problems such as invisible tasks and short-loops can be dealt with at ease. A process mining example is presented to illustrate the algorithm, and the evaluation is also given. Petri net; Process mining; Workflow; Workflow logic; Workflow semantics

A workflow-mining-based approach to knowledge maintenance The quality of knowledge in the knowledge repository determines the effects of knowledge reusing and sharing. The control of the knowledge maintenance process is necessary. Workflow system has been used to support the control of knowledge maintenance process. However, it is difficult to create an appropriate knowledge maintenance process. In this paper, workflow mining is used to support the design of knowledge maintenance process. At first, the characteristics of knowledge maintenance process are discussed deeply. Then the workflow-mining-based knowledge maintenance approach including the novel knowledge maintenance process mining algorithm is proposed. Finally, the acquisition process for the lessons learned knowledge is used as a case study to illustrate the proposed approach. © 2008 Crown. Knowledge maintenance; Knowledge management; Knowledge repository; Workflow mining

Abductive workflow mining using Binary resolution on task successor rules The notion of abductive workflow mining is introduced, which refers to the process of discovering important workflows from event logs that are believed to cause or explain certain behaviour. The approach is based on the notion of abductive reasoning, where hypotheses are found that, if added to a rule base, would necessarily cause an observation to be true. We focus on the instance of workflow mining where there are critical tasks in the underlying process that, if observed, must be scrutinized more diligently to ensure that they are sufficiently motivated and executed under acceptable circumstances. Abductive workflow mining is then the process of determining activity that would necessarily imply that the critical activity should take place. Whenever critical activity is observed, one can then inspect the abductive workflow to ascertain whether there was sufficient reason for the critical activity to occur. To determine such workflows, we mine recorded log activity for task successor rules, which indicate which tasks succeed other tasks in the underlying process. Binary resolution is then applied to find the abductive explanations for a given activity. Preliminary experiments show that relatively small and concise abductive workflow models can be constructed, in comparison with constructing a complete model for the entire log. © 2008 Springer Berlin Heidelberg. 

Abnormal process instances identification method in healthcare environment In order to gain the competitive advantage, more and more hospitals put their attention on determining and optimizing the standard clinical pathway. However, there are many abnormal instances in the event logs which disturb the effect of the process mining and the process analysis. Also, the prescription and the medical test items may have a large difference in the specific disease, where has the similar clinical pathways due to the multi-factor in the clinical pathways. In this paper, an abnormal process instances identification method (APIIM) is proposed. Given the event logs and the standard clinical pathway, the method classifies the instances based on the classification attributes and identifies the abnormal instances by the outlier detection technology. Moreover, a case study using the real data in one hospital is implemented and the result shows that the method is effective and efficient in discovering the abnormal process instances in the healthcare environment. © 2011 IEEE. business process mining; clinical pathway; outlier detection; process analysis

Abstractions in process mining: A taxonomy of patterns Process mining refers to the extraction of process models from event logs. Real-life processes tend to be less structured and more flexible. Traditional process mining algorithms have problems dealing with such unstructured processes and generate spaghetti-like process models that are hard to comprehend. One reason for such a result can be attributed to constructing process models from raw traces without due pre-processing. In an event log, there can be instances where the system is subjected to similar execution patterns/behavior. Discovery of common patterns of invocation of activities in traces (beyond the immediate succession relation) can help in improving the discovery of process models and can assist in defining the conceptual relationship between the tasks/activities. In this paper, we characterize and explore the manifestation of commonly used process model constructs in the event log and adopt pattern definitions that capture these manifestations, and propose a means to form abstractions over these patterns. We also propose an iterative method of transformation of traces which can be applied as a pre-processing step for most of today's process mining techniques. The proposed approaches are shown to identify promising patterns and conceptually-valid abstractions on a real-life log. The patterns discussed in this paper have multiple applications such as trace clustering, fault diagnosis/anomaly detection besides being an enabler for hierarchical process discovery. © 2009 Springer Berlin Heidelberg. 

Acquiring logistics process intelligence: Methodology and an application for a Chinese bulk port The processes of logistics service providers are considered as highly human-centric, flexible and complex. Deviations from the standard operating procedures as described in the designed process models, are not uncommon and may result in significant uncertainties. Acquiring insight in the dynamics of the actual logistics processes can effectively assist in mitigating the uncovered risks and creating strategic advantages, which are the result of uncertainties with respectively a negative and a positive impact on the organizational objectives. In this paper a comprehensive methodology for applying process mining in logistics is presented, covering the event log extraction and preprocessing as well as the execution of exploratory, performance and conformance analyses. The applicability of the presented methodology and roadmap is demonstrated with a case study at an important Chinese port that specializes in bulk cargo. © 2013 Elsevier Ltd. All rights reserved. Knowledge discovery; Logistics process; Logistics process intelligence; Process mining

Active trace clustering for improved process discovery Process discovery is the learning task that entails the construction of process models from event logs of information systems. Typically, these event logs are large data sets that contain the process executions by registering what activity has taken place at a certain moment in time. By far the most arduous challenge for process discovery algorithms consists of tackling the problem of accurate and comprehensible knowledge discovery from highly flexible environments. Event logs from such flexible systems often contain a large variety of process executions which makes the application of process mining most interesting. However, simply applying existing process discovery techniques will often yield highly incomprehensible process models because of their inaccuracy and complexity. With respect to resolving this problem, trace clustering is one very interesting approach since it allows to split up an existing event log so as to facilitate the knowledge discovery process. In this paper, we propose a novel trace clustering technique that significantly differs from previous approaches. Above all, it starts from the observation that currently available techniques suffer from a large divergence between the clustering bias and the evaluation bias. By employing an active learning inspired approach, this bias divergence is solved. In an assessment using four complex, real-life event logs, it is shown that our technique significantly outperforms currently available trace clustering techniques. © 1989-2012 IEEE. Active learning; Event logs; Process mining; Trace clustering

Activity mining by global trace segmentation Process Mining is a technology for extracting non-trivial and useful information from execution logs. For example, there are many process mining techniques to automatically discover a process model describing the causal dependencies between activities . Unfortunately, the quality of a discovered process model strongly depends on the quality and suitability of the input data. For example, the logs of many real-life systems do not refer to the activities an analyst would have in mind, but are on a much more detailed level of abstraction. Trace segmentation attempts to group low-level events into clusters, which represent the execution of a higher-level activity in the (available or imagined) process meta-model. As a result, the simplified log can be used to discover better process models. This paper presents a new activity mining approach based on global trace segmentation. We also present an implementation of the approach, and we validate it using a real-life event log from ASML's test process. © 2010 Springer-Verlag. Event Log Schema Transformation; Process Mining; Trace Segmentation

Adapting workflow technology to design-based research: Development of a method for organizing the "messiness" of research in technology-rich online learning environments A fundamental challenge of design-based research is that there are many variables that affect success of a design. Designers collect large amounts of data, but limited time and resources make analysis difficult and conclusions uncertain. Workflow technology is utilized in business and applied science environments to automate work processes and reveal "know-how," often tacit in scientific processes, which facilitate multiple levels of reuse. We developed a method for representing activity in an experimental online course as workflow expressions. Bielaczyc's (2006) Social Infrastructure Framework (SIF) is utilized to identify important variables, and comprehensive data mining (CDM) techniques are used to recover data from course session modules and activity logs. In this paper we review the literature related to our theoretical framework, describe the CDM-based methodology, and give an example of how we are using it to support design-based research within an online college course. 

Adaptive Automated Teller Machines Nowadays, Automated Teller Machines (ATMs) provide significant online support to bank customers. A limitation of ATM usage is that customers often have to wait in a queue, especially at ATMs installed at busy locations. Also, old people tend to consume more ATM usage time, possibly frustrating customers in the queue. In these situations, ATMs should "adapt" to the behavior of the customers to minimize the usage time. To this end, we apply data mining techniques to an ATM transaction dataset obtained from an international bank based in Kuwait. We pre-process this dataset, and convert it into a specific XML format to mine it through the ProM (process mining) tool. Our results reveal that customers withdraw money most frequently, followed by purchases (through an ATM card) and balance inquiry transactions. Customers re-do these transactions frequently, and also employ them one after the other. We acquire the distributions of the withdrawn amount, based on individual customers, the location (ATM terminal) and time of the withdrawl. Based on these results, we have proposed a set of five adaptive ATM interfaces, which show only frequent transactions and frequently-withdrawn amounts, display the current balance autonomously, and query explicitly for viewing purchase history, or for performing another withdrawl. An online survey on 216 ATM customers reveals that a majority of customers are willing to use these interfaces for minimizing their usage time. Our work has been approved by the banking authority of Pakistan, and we are currently implementing our interfaces for a Pakistani bank. © 2012 Elsevier Ltd. All rights reserved. Adaptive interfaces; Automated Teller Machines; Data mining; Efficient usage time; Process mining; Usability

Agent assignment for process management: Agent performance evaluation framework Convergence of data mining and process management is ideal - but still limited. An example of such a convergence is presented in the form of APE Framework that addresses the problem of static-agent-assignment-strategies in Workflow Management Systems (WfMS) - one cause of poor business process performance since all eligible agents may be assigned to a task instead of only assigning those which are expected to be "successful". To solve this problem, the APE Framework first identifies successful agents by investigating the history of workflow executions with methods from data mining and taking the process model into account as a source for domain knowledge. It then updates its findings into an organizational database - a data source wherefrom WfMS make assignments. Thus, through this convergence, the APE Framework enables WfMS to allocate only successful agents - instead of merely static list of all eligible agents. © 2010 IEEE. Continuous resource management; Data mining; Domain knowledge; Goal model; Performance evaluation; Wfms

Agent assignment for process management: Competency-driven Dynamic Resource Management Methodology Convergence of data mining and process management is ideal - but still limited. An example of such a convergence is presented in the form of Competency-driven Dynamic Resource Management (CDRM) Methodology that addresses the lack of agent-assignment-strategy in Workflow Management Systems (WfMS). Currently, WfMSs do not have any strategy to allocate resources (employees, agents) to their business processes on the basis their history of success of business process performance. Traditionally, WfMS uses role concept to allocate resources to their business processes - one cause of poor business process performance since all eligible agents may be assigned to a task instead of only assigning those which are expected to be "successful". To solve this problem, the CDRM Methodology applies data mining techniques using their work history as a data source and process model as a source of domain knowledge to first perform analytical analysis of employees' performance. It then updates its findings into an organizational database - a data source wherefrom WfMS make assignments. Thus, through this convergence, the CDRM Methodology enables WfMS to allocate only successful agents - instead of merely role based static list of all eligible agents causing poor performance. © 2011 IEEE. Classification; Data mining; Performance evaluation; Process; Task assignment; Workflow management system

Aggregating causal runs into workflow nets This paper provides three aggregation algorithms for deriving system nets from sets of partially-ordered causal runs. The three algorithms differ with respect to the assumptions about the information contained in the causal runs. Specifically, we look at the situations where labels of conditions (i.e. references to places) or events (i.e. references to transitions) are unknown. Since the paper focuses on aggregation in the context of process mining, we solely look at workflow nets, i.e. a class of Petri nets with unique start and end places. The difference of the work presented here and most work on process mining is the assumption that events are logged as partial orders instead of linear traces. Although the work is inspired by applications in the process mining and workflow domains, the results are generic and can be applied in other application domains. © 2012 Springer-Verlag. 

Aggregating individual models of decision-making processes When faced with a difficult decision, it would be nice to have access to a model that shows the essence of what others did in the same situation. Such a model should show what, and in which sequence, needs to be done so that alternatives can be correctly determined and criterions can be carefully considered. To make it trustworthy, the model should be mined from a large number of previous instances of similar decisions. Our decision-process mining framework aims to capture, in logs, the processes of large numbers of individuals and extract meaningful models from those logs. This paper shows how individual decision data models can be aggregated into a single model and how less frequent behavior can be removed from the aggregated model. We also argue that main process mining algorithms perform poorly on decision logs. © 2012 Springer-Verlag Berlin Heidelberg. decision data model; decision process mining; product based workflow design

Algorithms for anomaly detection of traces in logs of process aware information systems This paper discusses four algorithms for detecting anomalies in logs of process aware systems. One of the algorithms only marks as potential anomalies traces that are infrequent in the log. The other three algorithms: threshold, iterative and sampling are based on mining a process model from the log, or a subset of it. The algorithms were evaluated on a set of 1500 artificial logs, with different profiles on the number of anomalous traces and the number of times each anomalous traces was present in the log. The sampling algorithm proved to be the most effective solution. We also applied the algorithm to a real log, and compared the resulting detected anomalous traces with the ones detected by a different procedure that relies on manual choices. © 2012 Elsevier Ltd. All rights reserved. Anomaly detection; Process mining; Process-aware systems

Aligning event logs and declarative process models for conformance checking Process mining can be seen as the "missing link" between data mining and business process management. Although nowadays, in the context of process mining, process discovery attracts the lion's share of attention, conformance checking is at least as important. Conformance checking techniques verify whether the observed behavior recorded in an event log matches a modeled behavior. This type of analysis is crucial, because often real process executions deviate from the predefined process models. Although there exist solid conformance checking techniques for procedural models, little work has been done to adequately support conformance checking for declarative models. Typically, traces are classified as fitting or non-fitting without providing any detailed diagnostics. This paper aligns event logs and declarative models, i.e., events in the log are related to activities in the model if possible. The alignment provides then sophisticated diagnostics that pinpoint where deviations occur and how severe they are. The approach has been implemented in ProM and has been evaluated using both synthetic logs and real-life logs from Dutch municipalities. © 2012 Springer-Verlag. 

Alignment based precision checking Most organizations have process models describing how cases need to be handled. In fact, legislation and standardization (cf. the Sarbanes-Oxley Act, the Basel II Accord, and the ISO 9000 family of standards) are forcing organizations to document their processes. These processes are often not enforced by information systems. However, torrents of event data are recorded by today's information systems. These recorded events reflect how processes are really executed. Often reality deviates from the modeled behavior. Therefore, measuring the extent process executions conform to a predefined process model is increasingly important. In this paper, we propose an approach to measure the precision of a process model with respect to an event log. Unlike earlier approaches, we first align model and log thus making our approach more robust, even in case of deviations. The approach has been implemented in the ProM 6 tool and evaluated using both artificial and real life cases. © 2013 Springer-Verlag Berlin Heidelberg. Conformance checking; Log-model alignment; Precision measurement; Process mining

An algorithm for conformance checking based on statistics In process mining, after we get the model from the log by using mining algorithm, the coexistence of process model with event log brings such a problem: whether the model and the event log are mutually consistent. The conformance checking means that by comparing the model getting by the model discovery with the actual process' action or the event log, we can find that whether the model is factual. Fitness shows the scope of the contact between the event traces in the logs and the effective execution path in the process models. Log means the every record is a actual reflection of the running of the system. Every record can affect the fitness. So we can analysis every record and use the statistical method to measure the fitness. This article gives a new algorithm to measure the fitness by using statistical method. Experiments show that this algorithm can measure the fitness accurately. Conformance; Fitness; Process Mining; Statistics

An analytical framework for understanding knowledge-sharing processes in online QandA communities Online communities have become popular knowledge sources for both individuals and organizations. Computer-mediated communication research shows that communication patterns play an important role in the collaborative efforts of online knowledge-sharing activities. Existing research is mainly focused on either user egocentric positions in communication networks or communication patterns at the community level. Very few studies examine thread-level communication and process patterns and their impacts on the effectiveness of knowledge sharing. In this study, we fill this research gap by proposing an innovative analytical framework for understanding thread-level knowledge sharing in online Q&A communities based on dialogue act theory, network analysis, and process mining. More specifically, we assign a dialogue act tag for each post in a discussion thread to capture its conversation purpose and then apply graph and process mining algorithms to examine knowledge-sharing processes. Our results, which are based on a real support forum dataset, show that the proposed analytical framework is effective in identifying important communication, conversation, and process patterns that lead to helpful knowledge sharing in online Q&A communities 

An approach to identifying false traces in process event logs By means of deriving knowledge from event logs, the application of process mining algorithms can provide valuable insight into the actual execution of business processes and help identify opportunities for their improvement. The event logs may be collected by people manually or generated by a variety of software applications, including business process management systems. However logging may not always be done in a reliable manner, resulting in events being missed or interchanged. Consequently, the results of the application of process mining algorithms to such "polluted" logs may not be so reliable and it would be preferable if false traces, i.e. polluted traces which are not possibly valid as regards the process model to be discovered, could be identified first and removed before such algorithms are applied. In this paper an approach is proposed that assists with identifying false traces in event logs as well as the cause of their pollution. The approach is empirically validated. © Springer-Verlag 2013. Business process management; Event log; Noise identification; Process mining

An automatic business process modeling method based on Markov matrix Recently an automatic process modeling method is presented in the field of business process management, which is also called as process mining. Process mining technology can automatically deduce process models through given mining algorithm from large numbers of process logs. Thereby the modeling efficiency, objectivity and quality will be greatly improved than before. However the research of this new modeling method is in primary stage. The known mining algorithms are not perfect. In this paper a process mining algorithm based on Markov transition matrix is designed, which can reduce the effect of capability of process expression and quality of process logs on mining and further enhances the automatic process modeling capability. © 2006 IEEE. Business process management; Markov transition matrix; Process log; Process mining

AN effective algorithm for business process mining based on modified FP-tree algorithm A number of business organizations are beginning to realize the importance of business process management. However, process can often go the way they were initially not designed for or a non-efficient performance process model could be designed. To solve this problem, business process mining which can be used as the basis for the business process re-engineering has been recognized to an important concept. However, current research in the domain of process mining has only focused on extracting a workflow-based process model from completed process logs. Thus, there is a limitation in expressing various types of business processes, and moreover, process discovery and log scanning take a considerable amount of time. In this paper, we present a modified FP-tree algorithm for FP-tree based business processes, which are used for association analysis in data mining. Our modified algorithm supports the discovery of an appropriate level of the process model according to the user's need without rescanning all the process logs during updating. © 2010 IEEE. Business process; Data mining; Process mining

An efficient process mining method based on discrete particle swarm optimization Process mining is to extract business process models from event logs, the mining process is an important learning task. However, the discovery of these processes poses many challenges, including noise, non-local, non-free choice constructs and so on. In the study, we give out the definition of the behavior redundancy degree which is benefit to analyze the behavior conformance. Then, in order to build the optimal the process model, a process mining method based on Discrete Particle Swarm Optimization (DPSO) is presented. The method can take into account the basic Petri net structure and the metrics of behavior conformance and avoid the blindness of building process model. Finally, a DPSO process mining plug-in is developed and a number of event log is tested in the DPSO mining plug-in based on PROM platform. Theoretical analysis and experimental results show that DPSO-based mining method has better behavior fitness and behavior appropriateness in business process mining. © 2011 Asian Network for Scientific Information. Behavior conformance; Discrete particle swarm optimization; Petri net; Process mining

An efficient recommendation method for improving business process modeling In modern commerce, both frequent changes of custom demands and the specialization of the business process require the capacity of modeling business processes for enterprises effectively and efficiently. Traditional methods for improving business process modeling, such as workflow mining and process retrieval, still requires much manual work. To address this, based on the structure of a business process, a method called workflow recommendation technique is proposed in this paper to provide process designers with support for automatically constructing the new business process that is under consideration. In this paper, with the help of the minimum depth-first search (DFS) codes of business process graphs, we propose an efficient method for calculating the distance between process fragments and select candidate node sets for recommendation purpose. In addition, a recommendation system for improving the modeling efficiency and accuracy was implemented and its implementation details are discussed. At last, based on both synthetic and real-world datasets, we have conducted experiments to compare the proposed method with other methods and the experiment results proved its effectiveness for practical applications. © 2005-2012 IEEE. Business process modeling; enterprise systems; industrial informatics; string edit distance; workflow; workflow recommendation

An efficient workcase classification method and tool in workflow mining This paper1 conceives a workcase classification method and implements it as a tool so as to be used in workflow mining systems. The method is for resolving the workcase classification problem issued for mining an activity firing or execution sequence of a workcase from monitoring and audit logs. That is, it finally generates a workcase classification decision tree consisting of a minimal set of critical activities to be used for deciding the corresponding researchable-path of the workcases. Why is the method efficient? Because it uses a minimal decision tree in classifying workcases' reachable-paths. And the tool is a graphical visualizer of the method, and consists of three subsystems used to automatically generate information control net, activity dependency net and minimal activity net through their corresponding algorithms. Especially the method and tool might be an impeccable solution for the specific domain of massively parallel large-scale workflow procedures. In a consequence, workflow mining methodologies and systems are rapidly growing and coping with a wide diversity of domains in terms of their applications and working environments. So, the literature needs various, advanced, and specialized workflow mining techniques and architectures that are used for finally feed-backing their analysis results to the redesign and reengineering phase of the existing workflow and business process models. We strongly believe that this work might be one of those impeccable attempts and pioneering contributions for pioneering and advancing the workflow mining technology. © 2005 IEEE. Activity firing sequence; Reachable-path rediscovery; Workcase classification method and tool; Workflow mining

An empirical comparison of static and dynamic business process mining Legacy information systems age over time as a consequence of the uncontrolled maintenance and need to be modernized. Process mining allows the discovery of business processes embedded in legacy information systems, which is necessary to preserve the legacy business knowledge, and align them with the new, modernized information systems. There are two main approaches to address the mining of business processes from legacy information systems: (i) the static approach that only considers legacy source code's elements from a syntactical viewpoint; and (ii) the dynamic approach, which also considers information derived by system execution. Unfortunately, there is a lack of empirical evidence facilitating the selection of one of them. This paper provides a formal comparison of the static and dynamic approach through a case study. This study shows that the static approach provides better performance, while the dynamic approach discovers more accurate business processes. © 2011 ACM. business process mining; case study; software modernization

An event processing platform for business process management The execution of business processes generates a lot of data comprising final process results as well as information about intermediate activities, both communicated as events. Automated process execution environments are centrally controlled by process engines that hold the connection between events and the processes they occure in. In contrast, in manual process execution environments, e.g., logistics, these events may not be correlated to the process they origin from. The correlation information is usually not present in the event but in so-called context data, which exists orthogonally to the corresponding process. However, in the areas of process monitoring and analysis, events need to be correlated to specific process instances. To close the gap between recorded events without process correlation and required events with process correlation, we propose a framework that enriches recorded events with context data to create events correlated to processes, so-called process events. © 2013 IEEE. Business Activity Monitoring; Business Process Management; Event; Event Processing; Process Analysis; Process Mining; Process Monitoring

An evolving process mining algorithm based on stable stages analysis The Purpose of process mining is to discover the actual process of the running system by analyzing its runtime log information. Traditional process mining algorithms are based on hypothesis that the process to be mined is unchangeable, so they can't mine evolving processes correctly. This paper proposes the concept of stable stages analysis, the SP-A stable stage analysis algorithm, and an algorithm based on stable stages analysis for mining evolving processes. It recognize stable stages based on process log, and then continuously mine the process logs of each stage, finding process model according to each stable stage, and to identify the evolving history of evolving processes. By experimental evaluations, the validity of the algorithms is proved. © 2011 IEEE. Evolving Processes; Process Management; Process Mining; Stable Stages Analysis

An experimental evaluation of feedback loops in a business process mining genetic algorithm This paper experiments with the use of feedback loops in a genetic business process mining algorithm. The use of genetic algorithms for process mining is explained along with a description of the research background to process mining. Of particular interest in this paper is the crossover operator. Experiments are described where problems encountered in mining processes are fed back into the crossover operator and used in the selection of crossover points. Both roulette wheel and tournament methods are used in the process of selecting crossover points. The paper concludes that the use of such problem feedback loops can be beneficial in the mining of simple business processes. However the paper makes clear that feedback loops are best employed as part of an 'intelligent' mining technique. © 2007 IEEE. 

An experimental evaluation of passage-based process discovery In the area of process mining, the ILP Miner is known for the fact that it always returns a Petri net that perfectly fits a given event log. Like for most process discovery algorithms, its complexity is linear in the size of the event log and exponential in the number of event classes (i.e., distinct activities). As a result, the potential gain by partitioning the event classes is much higher than the potential gain by partitioning the traces in the event log over multiple event logs. This paper proposes to use the so-called passages to split up the event classes over multiple event logs, and shows the results are for seven large real-life event logs and one artificial event log: The use of passages indeed alleviates the complexity, but much hinges on the size of the largest passage detected. © 2013 Springer-Verlag Berlin Heidelberg. Fitness; Passages; Petri nets; Process Discovery

An exploratory approach for understanding customer behavior processes based on clustering and sequence mining In this paper, a novel approach towards enabling the exploratory understanding of the dynamics inherent in the capture of customers' data at different points in time is outlined. The proposed methodology combines state-of-art data mining clustering techniques with a tuned sequence mining method to discover prominent customer behavior trajectories in data bases, which - when combined - represent the "behavior process" as it is followed by particular groups of customers. The framework is applied to a real-life case of an event organizer; it is shown how behavior trajectories can help to explain consumer decisions and to improve business processes that are influenced by customer actions. © Springer International Publishing Switzerland 2014. Behavior process; Business knowledge; Clustering; Direct marketing; Sequence mining; Trajectories

An extensible framework for analysing resource behaviour using event logs Business processes depend on human resources and managers must regularly evaluate the performance of their employees based on a number of measures, some of which are subjective in nature. As modern organisations use information systems to automate their business processes and record information about processes' executions in event logs, it now becomes possible to get objective information about resource behaviours by analysing data recorded in event logs. We present an extensible framework for extracting knowledge from event logs about the behaviour of a human resource and for analysing the dynamics of this behaviour over time. The framework is fully automated and implements a predefined set of behavioural indicators for human resources. It also provides a means for organisations to define their own behavioural indicators, using the conventional Structured Query Language, and a means to analyse the dynamics of these indicators. The framework's applicability is demonstrated using an event log from a German bank. © 2014 Springer International Publishing. employee performance measurements; Process mining; resource behaviour indicators

An ICN-based workflow process rediscovery framework Workflow management systems help execute, monitor, and manage work process flow and execution. These systems, as they are executing, keep a record of who does what and when (i.e., log of events). The activity of using computer software to examine these records and derive various structural data results is termed workflow rediscovery. It has encompassed behavioral (process/control-flow), social, informational (data-flow), and organizational perspectives of a workflow model. Particularly, this paper 1 focuses on rediscovering the behavioral aspect of an ICN-based workflow model 2 from the workflow enactment histories (log of events). We term this activity workflow process rediscovery. That is, this paper proposes a formalized framework from the logging activity to the algorithmic activity of the workflow process rediscovery, termed an ICN-based workflow process rediscovery framework complete with a series of formal definitions and their related algorithms. The essential algorithm, s-algorithm, is able to handle the basic behavioral primitives (sequential, alternative, parallel) and the loop behavioral primitive through incrementally amalgamating a series of temporal workcases that are temporal orders of the associated workflow activities' enactment events. This paper precisely describes analytic estimation and performance analysis of the algorithm. © 2012 ICIC International. Events log; Information control net; Temporal workcase; Workflow management system; Workflow process mining and rediscovery; Workflow process rediscovery framework

An impact of the user and time parameters to sequence alignment methods for process mining Process mining is relatively new domain that opens many opportunities for process control and improvement. Anyway, the basis of the process mining is the examination of bunch of data from processes. There are many methods that already had been used in this domain and many other are still waiting for the discovery of their benefits. One of the main issues is to find out whether the new method is useful or not. The main purpose of this paper is to present the usability of sequence alignment method in process mining especially from the user and time perspective. Process Mining; Sequence Alignment Methods

An improved algorithm for discovering the models with short loops constructs The short loops constructs are common in the process models derived from the event logs in most information systems. But the current algorithms are unsatisfied when differentiating length-one loops and length-two loops if the sets of traces they can execute are identical. So, we first put forward a method based on the conformance checking techniques to handle the above problem. Next, using a Petri-net-based representation, some new ordering relations are defined to detect the short loops. At last, it is proven that an algorithm is proposed to discover the process models with short loops correctly. The improved approach in this paper can be applied in other process mining techniques. © 2012 SPIE. conformance checking; process mining; short loops; workflow mining

An improved simulated annealing algorithm for process mining The target of process mining is to automatically extract process models from event logs related to actual business process executions. One of the most important fields concerned is control flow mining, i.e., ordering of activities. However, the presence of complicated constructs, such as duplicate tasks, invisible tasks and non-free-choice structures, hinders us from correctly discovering the relations between activities. Therefore, an improved simulated annealing approach is proposed in this paper to tackle these problems. To verify the performance, experiments are conducted in the process minig framework. The result is expressed in terms of Petri net. © 2009 IEEE. Control flow mining; Petri net; Process mining; Simulated annealing

An improved virus evolutionary genetic algorithm for workflow mining Combined with virus evolutionary mechanism, the virus evolutionary genetic model algorithm which oriented workflow mining is put forward. It is based on the original main population that infection the population of individuals. First, in the workflow virus evolutionary mechanism introduction, it needs Petri net and causal relationship with matrix, the population of virus of individuals to chromosomes, setting the virus vitality and appealing. Second, the algorithm combines with the genetic algorithm in workflow mining on design. It designs a virus operators, infection operation and degradation operation. At the same time, the virus evolutionary genetic mode algorithm considers the virus itself has certain vitality. Experiments show that it can increase the diversity of the original population, and avoid premature convergence and precocious phenomena. © 2005 - 2013 JATIT & LLS. All rights reserved. Causal matrix; Hybrid genetic algorithm; Virus; Workflow mining

An incremental process mining approach to extract knowledge from legacy systems Several approaches have already been proposed to extract both business processes and business rules from a legacy source code. These approaches consider static source code analysis for the extraction procedure. However, business processes have components that can not be directly extracted by static analysis (i.e., participants, responsibilities, and concurrent activities). Moreover, well-known static analysis algorithms do not support the incremental extraction of information from the legacy code. Large legacy systems can benefit from an incremental analysis strategy in order to provide iterative information extraction as well as to achieve partial results much earlier. This paper discusses a new approach for business knowledge extraction from legacy systems. The approach considers an incremental process mining technique to extract business process structures and the business rules associated to it. Discovery results can be used in various ways by business analysts and software architects, e.g. documentation of legacy systems or for re-engineering purposes. © 2010 IEEE. Business rules; Legacy systems; Process mining; Workflow

An information-theoretic framework for process structure and data mining Mining process logs has been increasingly attracting the data mining community, due to the chances the development of process mining techniques can offer to the analysis and design of complex processes. Currently, these techniquesfocus on "structural" aspects by only considering which activities were executed and in which order, and disregard any other kind of data usually kept by real systems (e.g., activity executors, parameter values, and time-stamps). In this article, we aim at discovering different process variants by clustering process logs. To this purpose, an information-theoretic framework is used to simultaneously cluster the logged process traces, encoding structural information, as well as a number of performance metrics associated with them. Each cluster is equipped with a specific model, so providing the analyst with a compact and handy description of major execution scenarios for the process. Copyright © 2007, IGI Global. Co-clustering; Mutual information; Process mining; Workflow management

An infrastructure for cost-effective testing of operational support algorithms based on colored Petri nets Operational support is a specific type of process mining that assists users while process instances are being executed. Examples are predicting the remaining processing time of a running insurance claim and recommending the action that minimizes the treatment costs of a particular patient. Whereas it is easy to evaluate prediction techniques using cross validation, the evaluation of recommendation techniques is challenging as the recommender influences the execution of the process. It is therefore impossible to simply use historic event data. Therefore, we present an approach where we use a colored Petri net model of user behavior to drive a real workflow system and real implementations of operational support, thereby providing a way of evaluating algorithms for operational support before implementation and a costly test using real users. In this paper, we evaluate algorithms for operational support using different user models. We have implemented our approach using Access/CPN 2.0. © 2012 Springer-Verlag. 

An initial approach to mining multiple perspectives of a business process In this work, we present some preliminary ideas about the development of an approach to mining different perspectives of a business process. Process mining, to date, has been narrowly concerned with mining the control-flow of a business process. There are very few process mining algorithms aimed at mining different business process perspectives. We believe one of the primary reasons for the paucity of process mining algorithms in perspectives other than control-flow is that there has been no general definition of what a business process perspective is. With this work, we provide a formal and general definition of a business process perspective, and present an approach to mine other business process perspectives using this definition. Copyright 2009 ACM. Business process perspectives; Process mining; Workflow mining

An integrated approach for ship block manufacturing process performance evaluation: Case from a Korean shipbuilding company For effective ship manufacturing, a ship is divided into hundreds of properly sized blocks in the design stage. Each block is produced in its own manufacturing process, and subsequently the blocks are assembled into the body of a ship. Performance evaluation of the block manufacturing process (BMP) has been an important issue in the shipbuilding industry, since the BMP is related to overall shipbuilding productivity. However, performance evaluation of BMP entails many difficulties due to the many block types and many differences between actual and planned operations. To address this issue, this paper proposes a systematic approach to evaluate the performance of BMPs by integrating process mining (PM) and data envelopment analysis (DEA). The approach evaluates performance based on actual work data, which are saved in the databases of production information systems, and provides guidelines for the improvement of underperforming BMPs in relation to the manufacturing processes. For demonstrative purpose, the proposed approach is applied to a Korean shipbuilding company. © 2014 Elsevier B.V. Block manufacturing process; Data envelopment analysis; Performance evaluation; Process mining; Shipbuilding

An intelligent production workflow mining system for continual quality enhancement In today's globally competitive industries, high-quality and high-reliability products play an important role in achieving customer satisfaction, and insisting on quality is always the only way to survive in an enterprise. Studies indicate that automating quality audits and adding decision support in quality improvement is an attractive idea. In this environment, production workflow mining is an approach for extracting knowledge from different manufacturing processes in order to assist real-time quality prediction and improvement. This papers attempts to propose an intelligent production workflow mining system (IPWMS) embracing online analytical processing (OLAP) and data mining technology, together with the use of artificial intelligence combining artificial neural networks (ANNs) and fuzzy rule sets to realize knowledge discovery and decision support in high-quality manufacturing. To validate the feasibility of the proposed system, a prototype is developed and evaluated in a company, and a description of this case example is covered in this paper. Continual quality enhancement; Fuzzy logic; Neural continual quality enhancement; Neural networks; Online analytical processing; Production workflow

An inter organization communication architecture model for real time activity base online transmission to increase the work process efficiency of container terminal The purpose of this research is to analyze the impact of instituting automated container yard management on the operation of a prototype EBILCY. This paper studies a total yard operation inflow and outflow of containers and cargos where different stakeholders depend on the operation of off-dock terminal. The primary challenge is to efficiently operate the operations and acquire the real-time data to minimize the operation lag due to information passing delay. In particular, to automate the every process, an online activity base strategy is used. This strategy groups jointly co-operate with OLAP and data mining process to reduce the manual work. An approach has been introduced to automate the all operational activity of off-dock as well as container terminal in real time basis. The methodology is approaching a cost-effective and authenticated communication through different stake holders of container terminal i.e. Main Line Operator (MLO), Freight Forwarder, C&F Agents, Shipper, Consignee etc. The model is solved using message passing strategy. Due to required interaction and multiple hub access issues a standard structure is introduced with details specification. The communication architecture has implemented through the authenticated portable database tool, Extended Markup Language (XML). To establish the easy communication through the end point, email client is introduced. For ensuring the information security MD5 encryption method has also used. This approach helps to atomize the full industry segment to work in one umbrella. The standard message structure ensures data validity among the stakeholders. This approach also can be used to communicate within different application where this approach would be work as a communication agent. ©2007 IEEE. Automation; Communication architecture; Container terminal; Data mining; Off-dock; OLAP

An iterative approach for business process template synthesis from compliance rules Companies have to adhere to compliance requirements. Typically, both, business experts and compliance experts, are involved in compliance analysis of business operations. Hence, these experts need a common understanding of the business processes for effective compliance management. In this paper, we argue that process templates generated out of compliance requirements can be used as a basis for negotiation among business and compliance experts. We introduce a semi automated approach to synthesize process templates out of compliance requirements expressed in Linear Temporal Logic (LTL). As part of that, we show how general constraints related to business process execution are incorporated. Building upon existing work on process mining algorithms, our approach to synthesize process templates considers not only control-flow, but also data-flow dependencies. Finally, we elaborate on the application of the derived process templates and present an implementation of our approach. © 2011 Springer-Verlag. Analysis of business process compliance specification; Process mining; Process synthesis

An iterative approach to synthesize business process templates from compliance rules Companies have to adhere to compliance requirements. The compliance analysis of business operations is typically a joint effort of business experts and compliance experts. Those experts need to create a common understanding of business processes to effectively conduct compliance management. In this paper, we present a technique that aims at supporting this process. We argue that process templates generated out of compliance requirements provide a basis for negotiation among business and compliance experts. We introduce a semi-automated and iterative approach to the synthesis of such process templates from compliance requirements expressed in Linear Temporal Logic (LTL). We show how generic constraints related to business process execution are incorporated and present criteria that point at underspecification. Further, we outline how such underspecification may be resolved to iteratively build up a complete specification. For the synthesis, we leverage existing work on process mining and process restructuring. However, our approach is not limited to the control-flow perspective, but also considers direct and indirect data-flow dependencies. Finally, we elaborate on the application of the derived process templates and present an implementation of our approach. © 2012 Elsevier Ltd. All rights reserved. Analysis of business process compliance; Process mining; Process synthesis; Specification

An ontology for workflow organizational model mining Continuous and unforeseeable evolution of business rules, processing logics, and organizational structures within enterprises, requires from business process management systems to integrate continuous design. Supporting business process rediscovery based on workflow logs analysis, workflow mining gathers retroactive (re)design techniques necessary to understand business process execution reality. Most of the works in this area focus on the control flow perspective, while very few of them address the organizational aspect. In addition, the used workflow mining techniques suffer from the lack of automation due to the purely syntactic logs. In this paper, we propose an Organizational Ontology (OrO) specifying the organizational model. This ontology is used to semantically annotate log files and establish an organizational knowledge base that will be used to discover relationships between performers in a workflow. Our approach has been implemented within the ProM framework. © 2012 IEEE. Organizational model; Organizational ontology; ProM; SBPM; Workflow mining

An operational decision support framework for monitoring business constraints Only recently, process mining techniques emerged that can be used for Operational decision Support (OS), i.e., knowledge extracted from event logs is used to handle running process instances better. In the process mining tool ProM, a generic OS service has been developed that allows ProM to dynamically interact with an external information system, receiving streams of events and returning meaningful insights on the running process instances. In this paper, we present the implementation of a novel business constraints monitoring framework on top of the ProM OS service. We discuss the foundations of the monitoring framework considering two logic-based approaches, tailored to Linear Temporal Logic on finite traces and the Event Calculus. © 2012 Springer-Verlag Berlin Heidelberg. Declare; monitoring; operational decision support; process mining

An outlook on Semantic business process mining and monitoring Semantic Business Process Management (SBPM) has been proposed as an extension of BPM with Semantic Web and Semantic Web Services (SWS) technologies in order to increase and enhance the level of automation that can be achieved within the BPM life-cycle. In a nutshell, SBPM is based on the extensive and exhaustive conceptualization of the BPM domain so as to support reasoning during business processes modelling, composition, execution, and analysis, leading to important enhancements throughout the life-cycle of business processes. An important step of the BPM life-cycle is the analysis of the processes deployed in companies. This analysis provides feedback about how these processes are actually being executed (like common control-flow paths, performance measures, detection of bottlenecks, alert to approaching deadlines, auditing, etc). The use of semantic information can lead to dramatic enhancements in the state-of-the-art in analysis techniques. In this paper we present an outlook on the opportunities and challenges on semantic business process mining and monitoring, thus paving the way for the implementation of the next generation of BPM analysis tools. © Springer-Verlag Berlin Heidelberg 2007. 

Analysis of a collaborative workflow process with distributed actors Current workflow management technology offers rich support for process-oriented coordination of distributed teamwork. In this paper, we evaluate the performance of an industrial workflow process where similar tasks can be performed by various actors at many different locations. We analyzed a large workflow process log with state-of-the-art mining tools associated with the ProM framework. Our analysis leads to the conclusion that there is a positive effect on process performance when workflow actors are geographically close to each other. Our case study shows that the use of workflow technology in itself is not sufficient to level geographical barriers between team members and that additional measures are required for a desirable performance. Case study; Performance evaluation; Process mining; Workflow management

Analysis of collaborative writing processes using hidden markov models and semantic heuristics In this paper we are interested in discovering collaborative writing patterns in student data collected from a system we designed to support student collaborative writing, and which has been used by over 1,000 students in the past year. A particular functionality that we are investigating is the extraction and display to learners and teachers of the process followed during the course of the writing. We used a heuristic to derive semantic interpretation of specific sequences of raw data and Markov models (MM) to derive the processes. We propose two models, a Heuristic MM and a Hidden MM for analysing student's writing behavior. We also refined the semantic preprocessing by adding the notion of pauses between activities. We illustrate our approach and compare these models using real data from two groups of high and low performance level and highlight the different information they each provide. © 2010 IEEE. Collaborative writing; Hidden markov model; Process mining; Text mining

Analysis of multi-agent interactions with process mining techniques Process mining and multi-agent models are powerful techniques for the analysis of processes and organizations. However, the integration of both fields has seldom been considered due to the lack of common conceptual background. We propose to close this gap by using Petri nets as an operational semantics and consider process mining a useful addition to monitor and debug multi-agent systems in the development phase. Mining results can be represented in the formalized form of Petri nets that allows to validate or verify the actual behavior. On our way to mining complex interactions within (simulated) organizations, we present a plug-in extension of our Petri net-based agent platform MULAN/CAPA for recording interaction logs. Using process mining, the logs can be mapped by some intermediate steps to agent protocols e.g. represented as AgentUML interaction protocol diagrams. These diagrams are a descriptive representation form that combines organizational and control flow information. Furthermore, they can be mapped to executable Petri net, thus allowing to feed mining results back into the design phase. © Springer-Verlag Berlin Heidelberg 2006. Agent interactions; Conversations; High-level Petri nets; Interaction mining; Mining; Modeling; MULAN; Multi-agent systems; Nets-within-nets; Process mining; Reference nets; RENEW; Simulation

Analysis of productive learning behaviors in a structured inquiry cycle using hidden Markov models This paper demonstrates the generality of the hidden Markov model approach for exploratory sequence analysis by applying the methodology to study students' learning behaviors in a new domain, i.e., an asynchronous, online environment that promotes an explicit inquiry cycle while permitting a great deal of learner control. Our analysis demonstrates that the high-performing students have more linear learning behaviors, and that their behaviors remain consistent across different study modules. We also compare our approach to a process mining approach, and suggest how they may complement one another. 

Analyzing multi-agent activity logs using process mining techniques Distributed autonomous robotic systems exhibit complex behavior that - although programmed, but due to the impact of the environment - only materializes as the process unfolds. Thus, the actual behavior of such a system cannot be known in advance but must be observed to be evaluated or verified. In this paper we propose to use process mining techniques to extract, compare, and enhance models of the actual behavior of a multi-agent robotic system through analyzing collected log data. We use the example of robot soccer as such a multi-agent robotic system, and we demonstrate which types of analysis are currently possible in the context of the process mining tool set ProM. 

Analyzing resource behavior using process mining It is vital to use accurate models for the analysis, design, and/or control of business processes. Unfortunately, there are often important discrepancies between reality and models. In earlier work, we have shown that simulation models are often based on incorrect assumptions and one example is the speed at which people work. The "Yerkes-Dodson Law of Arousal" suggests that a worker that is under time pressure may become more efficient and thus finish tasks faster. However, if the pressure is too high, then the worker's performance may degrade. Traditionally, it was difficult to investigate such phenomena and few analysis tools (e.g., simulation packages) support workload-dependent behavior. Fortunately, more and more activities are being recorded and modern process mining techniques provide detailed insights in the way that people really work. This paper uses a new process mining plug-in that has been added to ProM to explore the effect of workload on service times. Based on historic data and by using regression analysis, the relationship between workload and services time is investigated. This information can be used for various types of analysis and decision making, including more realistic forms of simulation. © 2010 Springer-Verlag. Business process Simulation; Process Mining; Yerkes-Dodson Law of Arousal

Anomaly detection using fuzzy association rules Data mining techniques are a very important tool for extracting useful knowledge from databases. Recently, some approaches have been developed for mining novel kinds of useful information, such as anomalous rules. These kinds of rules are a good technique for the recognition of normal and anomalous behaviour, that can be of interest in several area domains such as security systems, financial data analysis, network traffic flow, etc. The aim of this paper is to propose an association rule mining process for extracting the common and anomalous patterns in data that is affected by some kind of imprecision or uncertainty, obtaining information that will be meaningful and interesting for the user. This is done by mining fuzzy anomalous rules. We present a new approach for mining such rules, and we apply it to the case of detecting normal and anomalous patterns on credit data. Copyright © 2014 Inderscience Enterprises Ltd. Anomalous rules; Anomaly detection; Credit; Data mining; Digital forensics; Electronic security; Fuzzy association rules

Anomaly detection using model generation for event-based systems without a preexisting formal model Detecting and debugging faults more efficiently can significantly improve the performance of systems, and a first step toward fault detection is anomaly detection. A new anomaly detection solution is proposed in this paper for event-based systems that consist of processes that interact through shared resources and that do not have a preexisting formal discrete event system model. This solution generates models of the system, assesses the models' performance in detecting faults, and then uses the models and their performance to detect anomalies in new event streams. A new resource-based Petri net formalism is introduced to model these types of systems. The model generation uses an algorithm based on workflow mining to generate resource-based models. The proposed solution is demonstrated on two manufacturing cell examples. © 2012 IEEE. Discrete-event systems; fault diagnosis; modeling; Petri nets

Anomaly detection using process mining Recently, several large companies have been involved in financial scandals related to mismanagement, resulting in financial damages for their stockholders. In response, certifications and manuals for best practices of governance were developed, and in some cases, tougher federal laws were implemented (e.g. the Sarboness Oxley Act). Companies adhered to these changes adopting the best practices for corporate governance by deploying Process Aware Information Systems (PAISs) to automate their business processes. However, these companies demand a rapid response to strategic changes, so the adoption of normative PAISs may compromise their competitiveness. On one hand companies need flexible PAISs for competitiveness reasons. On the other hand flexibility may compromise security of system because users can execute tasks that could result into violation of financial loses. In order to re-balance this trade-off, we present in this work how ProM tools can support anomaly detection in logs of PAIS. Besides, we present the results of the application of our approach with a real case. © 2009 Springer Berlin Heidelberg. Anomaly detection; Auditing systems; Process mining

Applicability of process discovery algorithms for software organizations Process modeling is one of the most significant tasks software process improvement teams perform. Conventionally modeling is performed by teams composed of domain experts and process engineers and it takes considerable effort and time. In recent years there have been studies which use the data extracted from the actual events that took place to determine process models. In this paper we present the results of a case study we conducted to determine the effectiveness of four process discovery and process mining algorithms. After applying process discovery algorithms we compare the results by the actual process and process definitions. We discuss the discrepancies between the actual flow and the process definitions, and the weaknesses and strong aspects of the algorithms. © 2009 IEEE. Process discovery; Process mining

Application development framework for measurement-based product testing management Measurement-based product testing management systems (MPTMS) are widely used during the life cycle of products to validate the design and test the products. Unfortunately, measurement data from measurement systems are isolated with testing task information in the MPTMSs. Furthermore, the development of MPTMSs often begins from scratch, which leads to low development efficiency and low reusability. To solve the problems mentioned above, an application development framework is designed. The framework supports seamless integration between MPTMSs and measurement systems. Meanwhile, components like resource management, organization management, workflow management, testing task management and process mining are provided to improve the reusability of the framework. The development process of MPTMSs consists of workflow model design, components reuse and user interfaces customization. Moreover, an application example is given to validate the framework and the result shows its availability. © 2013 ACADEMY PUBLISHER. Application development framework; Measurement systems; Measurement-based product testing management systems; Process mining; Workflow management

Application of process mining in healthcare - A case study in a Dutch Hospital To gain competitive advantage, hospitals try to streamline their processes. In order to do so, it is essential to have an accurate view of the "careflows" under consideration. In this paper, we apply process mining techniques to obtain meaningful knowledge about these flows, e.g., to discover typical paths followed by particular groups of patients. This is a non-trivial task given the dynamic nature of healthcare processes. The paper demonstrates the applicability of process mining using a real case of a gynecological oncology process in a Dutch hospital. Using a variety of process mining techniques, we analyzed the healthcare process from three different perspectives: (1) the control flow perspective, (2) the organizational perspective and (3) the performance perspective. In order to do so we extracted relevant event logs from the hospital's information system and analyzed these logs using the ProM framework. The results show that process mining can be used to provide new insights that facilitate the improvement of existing careflows. © 2008 Springer-Verlag. 

Applied process mining in software development Current study uses the event process logs of a custom software development process used internally in the IT department of a large automotive company. The target is to extract hidden information about the process, difficult to identify due to the wideness and complexity of the input data. The log file contains all incident records tracked during one release of a software product. This analysis was performed using process mining techniques and tools included in ProM Framework, an academic project of the Eindhoven Technical University. The paper describes the steps followed to extract the working process model, organizational network and statistical information. Based on the obtained results, an action plan is put in practice with the scope of improving the development process and the release result. © 2014 IEEE. event log; heuristic miner; process mining; process model

Applying data mining and petri net in reengineering of manufacture management information system This paper studied association rules mining algorithm for mining process model in workflow log of manufacture management information system with XML technology, applied Petri Net in modelling, simulation and optimization of process model, and studied the method for reengineering and optimization of information system based on function units in terms of optimized process model, it was pointed that the difference between actual process model and the process model implied in information system would lead to the decrease of efficiency of information system, and the reengineering and optimization of information system based on actual optimized process model would lead to improvement of efficiency. It was proved with experiments that the association rules mining algorithm put forward in this paper is better than traditional algorithm Apriori in performance. © 2006 IEEE. Data mining; Enterprise resource planning; Petri nets; Reengineering

Applying data mining techniques to business process reengineering based on simultaneous use of two novel proposed approaches Business process reengineering (BPR) can help organisations to identify and improve their business processes. A major problem is the high volume of business process datasets with characteristics such as high dimensionality, noise, uncertainty in process datasets and complicated interactions among process variables. Data mining (DM) techniques facilitate the identification and analysis of business processes, and improve their performance by extracting the hidden knowledge in business process datasets. In this paper, we present the application of DM to BPR, based on two novel approaches. By a literature review, the first approach proposes DMbBPR model, mainly focuses on the applications of data mining to each BPR phase. The second approach presents a novel combinational model based on the knowledge management cycle and CRISP-DM process in the framework of process monitoring architecture. To achieve better results, both approaches should be considered simultaneously in order to effectively identify, analyse, and improve business processes. Copyright © 2013 Inderscience Enterprises Ltd. BPR; Business process reengineering; Business processes integration; CRISP-DM; Data mining; Knowledge management; Process monitoring

Applying Fuzzy-Genetic mining in conformance and dependency relations In this paper, we used genetic algorithm to discover a Petri net given an event log received from one of the universities in Thailand. The event log contained information about 299 cases and 569 activities. For each case, the performed tasks - in regard to students' registration process - and the moment of completion were recorded. In short, using Genetic algorithms made us capable of simulating the control flow perspective of students' registration process in the case study. In contrary with Alpha-algorithm and Heuristic Miner approaches, the problem of noise is naturally tackled by the genetic algorithm because, per definition, these algorithms are robust to noise. Yet the main challenge in a genetic approach is the definition of a good fitness measure because it guides the global search performed by the genetic algorithm. Therefore, initially, this paper explains how the genetic algorithm works and then, experiments with real-life registration log shows that the fitness measure indeed leads to the mining of process models that are complete (can reproduce all the behavior in the log) and precise (do not allow for extra behavior that cannot be derived from the event log). Consequently, the discovered graphical models were depicted and compared in Genetic and Fuzzy environments. © 2012 IEEE. Fuzzy mining; Genetic algorithm; Petri Nets; Process Discovery; Process Mining; Prom; students' registration process

Applying inductive logic programming to process mining The management of business processes has recently received a lot of attention. One of the most interesting problems is the description of a process model in a language that allows the checking of the compliance of a process execution (or trace) to the model. In this paper we propose a language for the representation of process models that is inspired to the SCIFF language and is an extension of clausal logic. A process model is represented in the language as a set of integrity constraints that allow conjunctive formulas as disjuncts in the head. We present an approach for inducing these models from data: we define a subsumption relation for the integrity constraints, we define a refinement operator and we adapt the algorithm ICL to the problem of learning such formulas. The system has been applied to the problem of inducing the model of a sealed bid auction and of the NetBill protocol. The data used for learning and testing were randomly generated from correct models of the processes. © 2008 Springer-Verlag Berlin Heidelberg. Business processes; Interaction protocols; Learning from interpretations; Process mining

Applying process mining approach to support the verification of a multi-agent system Using agent development tools to construct an agent-based system is a well applied approach. However, the development tools usually do not have the function to check the feasibility about the workflow of the agent system during it implementation stage. Therefore, to develop an evaluation approach to analyze the feasibility of a developing agent system such that the improper workflow of an agent system can be found in the early design stage is a necessary task to reduce the risk of implementation. In this research, a Petri Net (PN) based three-stage evaluation approach was developed. In the conceptual stage, the pitfall of the current agent system developing process was examined and an improvement analysis process was specified. Then, in the system design stage, an evaluation approach which extracted the process log file from a developing agent system into a PN model in terms of a process mining approach-a algorithm was proposed. This model was simulated in a PN simulation package. The agent system performance was evaluated in terms of analyzing the deadlock phenomena of the PN model. Finally, in the implementation stage, the proposed concept was implemented by using an agent developing tool JADE and a PN simulation tool CPN. An agent-based robotic assembly system was used to examine the possible deadlock of the agent system. © 2010 Systems Engineering Society of China and Springer-Verlag Berlin Heidelberg. Agent-based systems; Petri Nets; Process mining; Workflow feasibility

Applying process mining in SOA environments Process mining is an emerging analysis technique, which extracts process knowledge from data and provides various benefits to organizations. In Service Oriented Computing environment, different services collaborate with others to carry out the operations and therefore overall picture of operations and execution is not clear. Process mining extracts the information from log files of systems, as recorded during executions, and depicts the reality. In order to apply process mining, extraction of process trace data from log files is a pre-requisite step. A case study demonstrates the practical applicability of our proposed framework for extraction of the process trace data from application systems and integration portals. © 2010 Springer-Verlag. Business process analysis; Log files; Process mining; Process trace data; SAP Process Integration

Approaching process mining with sequence clustering: Experiments and findings Sequence clustering is a technique of bioinformatics that is used to discover the properties of sequences by grouping them into clusters and assigning each sequence to one of those clusters. In business process mining, the goal is also to extract sequence behaviour from an event log but the problem is often simplified by assuming that each event is already known to belong to a given process and process instance. In this paper, we describe two experiments where this information is not available. One is based on a real-world case study of observing a software development team for three weeks. The other is based on simulation and shows that it is possible to recover the original behaviour in a fully automated way. In both experiments, sequence clustering plays a central role. © Springer-Verlag Berlin Heidelberg 2007. Process discovery; Process mining; Sequence clustering; Task identification; Workflow logs

Aspect mining in business process management Automatic discovery of process models from event logs is an important and promising area in Business Process Management. Process models document how business processes should be performed, so they capture different concerns related to business processes. Some of these concerns are not limited to one process model, and they are repeated in many others as well, called cross-cutting concerns. Although many works have been done to enable discovering different process models, there is no investigation about how models with cross-cutting concerns can be discovered from even logs. Therefore, this work proposes an approach to enable discovering these models from event logs. The investigation is performed based on a case-study from the banking domain. The result shows how these concerns hinder existing process discovery techniques, and how the proposed approach can solve the problem. Aspect Mining; Aspect Oriented; Business Process Management; Process Discovery; Process Mining

Assessing event correlation in non-process-aware information systems Many present-day companies carry out a huge amount of daily operations through the use of their information systems without ever having done their own enterprise modeling. Business process mining is a well-proven solution which is used to discover the underlying business process models that are supported by existing information systems. Business process discovery techniques employ event logs as input, which are recorded by process-aware information systems. However, a wide variety of traditional information systems do not have any in-built mechanisms with which to collect events (representing the execution of business activities). Various mechanisms with which to collect events from non-process-aware information systems have been proposed in order to enable the application of process mining techniques to traditional information systems. Unfortunately, since business processes supported by traditional information systems are implicitly defined, correlating events into the appropriate process instance is not trivial. This challenge is known as the event correlation problem. This paper presents an adaptation of an existing event correlation algorithm and incorporates it into a technique in order to collect event logs from the execution of traditional information systems. The technique first instruments the source code to collect events together with some candidate correlation attributes. Based on several well-known design patterns, the technique provides a set of guidelines to support experts when instrumenting the source code. The event correlation algorithm is subsequently applied to the data set of events to discover the best correlation conditions, which are then used to create event logs. The technique has been semi-automated to facilitate its validation through an industrial case study involving a writer management system and a healthcare evaluation system. The study demonstrates that the technique is able to discover an appropriate correlation set and obtain well-formed event logs, thus enabling business process mining techniques to be applied to traditional information systems. © 2012 Springer-Verlag. Business process mining; Case study; Event correlation; Event model

Assessing medical treatment compliance based on formal process modeling The formalization and analysis of medical guidelines play an essential role in clinical practice nowadays. Due to their inexorably generic nature such guidelines leave room for different interpretation and implementation. Hence, it is desirable to understand this variability and its implications for patient treatment in practice. In this paper we propose an approach for comparing guideline-based treatment processes with empirical treatment processes. The methodology combines ideas from workflow modeling, process simulation, process mining, and statistical methods of evidence-based medicine. The applicability of the approach is illustrated based on the Cutaneous Melanoma use case. © 2011 Springer-Verlag Berlin. Healthcare Processes; Process Mining; Process Modeling

Assessment of data quality in accounting data with association rules Business rules are an effective way to control data quality. Business experts can directly enter the rules into appropriate software without error prone communication with programmers. However, not all business situations and possible data quality problems can be considered in advance. In situations where business rules have not been defined yet, patterns of data handling may arise in practice. We employ data mining to accounting transactions in order to discover such patterns. The discovered patterns are represented in form of association rules. Then, deviations from discovered patterns can be marked as potential data quality violations that need to be examined by humans. Data quality breaches can be expensive but manual examination of many transactions is also expensive. Therefore, the goal is to find a balance between marking too many and too few transactions as being potentially erroneous. We apply appropriate procedures to evaluate the classification accuracy of developed association rules and support the decision on the number of deviations to be manually examined based on economic principles. (C) 2013 Elsevier Ltd. All rights reserved. 

Automatic Determination of Parameters' Values for Heuristics Miner plus The choice of parameters' values for noise-tolerant Process Mining algorithms is not trivial, especially for users that are not expert in Process Mining. Exhaustive exploration of all possible set of values is not feasible, since several parameters are real-valued. Selecting the "right" values, however, is important, since otherwise the control-flow network returned by the mining can be quite far from the correct one. Here we face this problem for a specific Process Mining algorithm, i.e. Heuristics Miner++. We recognize that the domain of real-valued parameters can be actually partitioned into a finite number of equivalence classes and we suggest exploring the parameters space by a local search strategy driven by a Minimum Description Length principle. We believe that the proposed approach is sufficiently general to be used for other Process Mining algorithms. Experimental results on a set of randomly generated process models show promising results. 

Automatic discovery of data-centric and artifact-centric processes Process discovery is a technique that allows for automatically discovering a process model from recorded executions of a process as it happens in reality. This technique has successfully been applied for classical processes where one process execution is constituted by a single case with a unique case identifier. Data-centric and artifact-centric systems such as ERP systems violate this assumption. Here a process execution is driven by process data having various notions of interrelated identifiers that distinguish the various interrelated data objects of the process. Classical process mining techniques fail in this setting. This paper presents an automatic technique for discovering for each notion of data object in the process a separate process model that describes the evolution of this object, also known as artifact life-cycle model. Given a relational database that stores process execution information of a data-centric system, the technique extracts event information, case identifiers and their interrelations, discovers the central process data objects and their associated events, and decomposes the data source into multiple logs, each describing the cases of a separate data object. Then classical process discovery techniques can be applied to obtain a process model for each object. The technique is implemented and has been evaluated on the production ERP system of a large retailer. © 2013 Springer-Verlag Berlin Heidelberg. artifact; ERP system; event log; process discovery

Automatic extraction of process control flow from I/O operations Many end users will expect the output of process mining to be a model they can easily understand. On the other hand, knowing which objects were accessed in each operation can be a valuable input for process discovery. From these two trends it is possible to establish an analogy between process mining and the discovery of program structure. In this paper we present an approach for extracting process control-flow from a trace of read and write operations over a set of objects. The approach is divided in two independent phases. In the first phase, Fourier analysis is used to identify periodic behavior that can be represented with loop constructs. In the second phase, a match-and-merge technique is used to produce a control-flow graph capable of generating the input trace and thus representing the process that generated it. The combination of these techniques provides a structured and compact representation of the unknown process, with very good results in terms of conformance metrics. © 2008 Springer Berlin Heidelberg. Control-flow graphs; Fourier analysis; Process mining

Automatic modeling of frequent user behaviours in intelligent environments Intelligent Environments depend on their capability to understand and anticipate user's habits and needs. Therefore, learning user's common behaviours becomes an important step towards allowing an environment to provide such personalized services. Due to the complexity of the entire learning system, this paper will focus on the automatic discovering of models of user's behaviours. Discovering the models means to discover the order of such actions, representing user's behaviours as sequences of actions. © 2010 IEEE. Intelligent environments; Learning behavioural patterns; Workflow mining

Bayesian belief network application in process mining Business process mining gains more and more attention from both scientific and business communities. Its value has been recognized in information systems reverse engineering field as it allows discover knowledge about the implementation and execution of business processes in order to analyse and improve them. The probabilistic model of business process execution is essential for its analysis, however, there is very little research done on this topic. In this paper, we present a novel approach on automatic extraction of probabilistic models from mined business processes. We present an example of application of our approach in a real world scenario. The results achieved by application of our approach can faciliate decision making for the business users and therefore may be used for process analysis or enhancement of information systems with additional decision support capabilities. Bayesian belief networks; Business process analysis; Process mining

Bayesian classification of events for task labeling using workflow models We investigate a method designed to improve accuracy of workflow mining in the case that the identification of task labels for log events are uncertain. Here we consider how the accuracy of an independent task identifier, such as a classification or clustering engine, can be improved by examining workflow. After briefly introducing the notion of iterative workflow mining, where the mined workflow is used to help improve the true task labelings which, when re-mined, will produce a more accurate workflow model, we demonstrate a Bayesian updating approach to determining posterior probabilities for each label for a given event, by considering the probabilities from the previous step as well as information as to the beliefs of the labels that can be gained by examining the workflow model. Experiments show that labeling accuracy can be increased significantly, resulting in more accurate workflow models. © 2009 Springer Berlin Heidelberg. Bayesian classification; Process mining; Task labeling; Workflow

Bayesian network construction from event log for lateness analysis in port logistics The handling of containers in port logistics consists of several activities, such as discharging, loading, gate-in and gate-out, among others. These activities are carried out using various equipment including quay cranes, yard cranes, trucks, and other related machinery. The high inter-dependency among activities and equipment on various factors often puts successive activities off schedule in real-time, leading to undesirable activity down time and the delay of activities. A late container process, in other words, can negatively affect the scheduling of the following ones. The purpose of the study is to analyze the lateness probability using a Bayesian network by considering various factors in container handling. We propose a method to generate a Bayesian network from a process model which can be discovered from event logs in port information systems. In the network, we can infer the activities' lateness probabilities and, sequentially, provide to port managers recommendations for improving existing activities. 

Behaviour patterns detection for persuasive design in Nursing Homes to help dementia patients Nursing homes usually host large accounts of persons with different levels of dementia. Detecting dementia process in early stages may allow the application of mechanisms to reduce or stop the cognitive impairment. Our ultimate objective is to demonstrate that the use of persuasive techniques may serve to motivate these subjects and induct re-learning mechanisms to stop mental impairment. Nevertheless, this requires the study of the behaviour of each patient individually in order to detect conduct disorders in their living ambient. This study presents a behavior pattern detection architecture based on the Ambient Assisted Living paradigm and Workflow Mining technology to enable re-learning mechanisms in dementia processes via providing tools to automate the conduct disorder detection. This architecture fosters the use of Workflows as representation languages to allow health professionals to represent persuasive motivation protocols in the AAL environment to react individually to dementia symptoms detected. © 2011 IEEE. 

Beyond process mining: From the past to present and future Traditionally, process mining has been used to extract models from event logs and to check or extend existing models. This has shown to be useful for improving processes and their IT support. Process mining techniques analyze historic information hidden in event logs to provide surprising insights for managers, system developers, auditors, and end users. However, thus far, process mining is mainly used in an offline fashion and not for operational decision support. While existing process mining techniques focus on the process as a whole, this paper focuses on individual process instances (cases) that have not yet completed. For these running cases, process mining can used to check conformance, predict the future, and recommend appropriate actions. This paper presents a framework for operational support using process mining and details a coherent set of approaches that focuses on time information. Time-based operational support can be used to detect deadline violations, predict the remaining processing time, and recommend activities that minimize flow times. All of this has been implemented in ProM and initial experiences using this toolset are reported in this paper. © Springer-Verlag Berlin Heidelberg 2010. 

Beyond workflow mining In the domain of Business Process Management and Workflow Management Systems, the log of work transactions executed has been found to be a useful artifact. The ideas, work, and literature on workflow mining have been primarily concerned with examining the workflow event log to rediscover control flow. Workflow mining has generally been defined as "the process of extracting a workflow model from a log of executions of activities". In fact, most of the literature specifically and narrowly is concerned with rediscovering the precedence relations amongst activities. It is generally a hidden assumption that all activities are known a priori because they are listed by label in the workflow event log. In this position paper, we explore the possibility of removing this assumption, and thus performing workflow discovery rather than precedence rediscovery. Workflow discovery does not assume that process structure or even activities are known a priori and is concerned with discovering a wholistic perspective of workflow. Workflow management systems are people systems that must be designed, deployed, and understood within their social and organizational contexts. Thus, we argue in this document that there is a need to expand the concept of workflow mining beyond the behavioral perspective to encompass the social, organizational, and activity assignment perspectives; as well as other perspectives. To this end, we introduce a general framework and meta-model for workflow discovery, and show one approach to workflow discovery in a multidimensional perspective. © Springer-Verlag Berlin Heidelberg 2006. 

Bottleneck mining and Petri net simulation in education situations In this paper we applied two process diagnostics (Conformance Checker and Performance Analysis) based on Prom process mining tool. In this paper, we used conformance ProM plugin in order to detect discrepancies between the flows prescribed in a students' registration model and the actual process instances (flows) in one of the universities in Thailand. Furthermore, we extended the models with performance characteristics and business rules. Our aim was to know whether the model and the log conform to each other or not. As a result, analyzing the gap between a model and the real world both helped us to detect violations and to ensure transparency. It worth to mention that, some of the information in the text are extracted from the book 'Process Mining: Discovery, Conformance, and Enhancement of Business Processes' by Wil Van Der Aalst and from the website www.processmining.com. © 2012 IEEE. Bottlenecks; Conformance Checker; Missed Tokens; Performance Analysis; Process Diagnosis; Process Mining; Prom

Bridging abstraction layers in process mining While the maturity of process mining algorithms increases and more process mining tools enter the market, process mining projects still face the problem of different levels of abstraction when comparing events with modeled business activities. Current approaches for event log abstraction try to abstract from the events in an automated way that does not capture the required domain knowledge to fit business activities. This can lead to misinterpretation of discovered process models. We developed an approach that aims to abstract an event log to the same abstraction level that is needed by the business. We use domain knowledge extracted from existing process documentation to semi-automatically match events and activities. Our abstraction approach is able to deal with n:m relations between events and activities and also supports concurrency. We evaluated our approach in two case studies with a German IT outsourcing company. © 2014 Elsevier Ltd. Abstraction; Event mapping; Process mining

Bridging abstraction layers in process mining by automated matching of events and activities While the maturity of process mining algorithms increases and more process mining tools enter the market, process mining projects still face the problem of different levels of abstraction when comparing events with modeled business activities. Current approaches for event log abstraction most often try to abstract from the events in an automated way which does not capture the required domain knowledge to fit business activities. This can lead to misinterpretation of discovered process models. We developed an approach which aims to abstract an event log to the same abstraction level which is needed by the business. We use domain knowledge extracted from existing process documentation in order to automatically match events and activities. Our proposed abstraction approach is able to deal with n:m relations between events and activities and also supports concurrency. We evaluated our approach in a case study with a German IT outsourcing company. © 2013 Springer-Verlag. Abstraction; Event Mapping; Process Mining

Bridging abstraction layers in process mining: Event to activity mapping While the maturity of process mining algorithms emerges and more process mining tools enter the market, process mining projects still face the problem of different levels of abstraction when comparing events recorded by supporting IT systems with defined business activities. Current approaches for event log abstraction most often try to abstract from the events in an automated way which does not capture the required domain knowledge to fit business activities. This can lead to misinterpretation of discovered process models and wrong conformance results. We developed an approach which aims to abstract an event log to the same abstraction level which is needed by the business. Therefore, we capture domain knowledge about event to activity mappings in a formalized way and propose an algorithm to correctly cluster events to activity instances. We evaluated our approach in a case study with a German IT outsourcing company. © 2013 Springer-Verlag. Abstraction; Event Mapping; Process Mining

Business alignment: Using process mining as a tool for Delta analysis and conformance testing Increasingly, business processes are being controlled and/or monitored by information systems. As a result, many business processes leave their "foot-prints" in transactional information systems, i.e., business events are recorded in so-called event logs. Process mining aims at improving this by providing techniques and tools for discovering process, control, data, organizational, and social structures from event logs, i.e., the basic idea of process mining is to diagnose business processes by mining event logs for knowledge. In this paper we focus on the potential use of process mining for measuring business alignment, i.e., comparing the real behavior of an information system or its users with the intended or expected behavior. We identify two ways to create and/or maintain the fit between business processes and supporting information systems: Delta analysis and conformance testing. Delta analysis compares the discovered model (i.e., an abstraction derived from the actual process) with some predefined processes model (e.g., the workflow model or reference model used to configure the system). Conformance testing attempts to quantify the "fit" between the event log and some predefined processes model. In this paper, we show that Delta analysis and conformance testing can be used to analyze business alignment as long as the actual events are logged and users have some control over the process. © Springer-Verlag London Limited 2005. Business alignment; Business process management; Conformance testing; Delta analysis; Process mining; Workflow management

Business impact analysis-a framework for a comprehensive analysis and optimization of business processes The ability to continuously adapt its business processes is a crucial ability for any company in order to survive in today's dynamic world. In order to accomplish this task, a company needs to profoundly analyze all its business data. This generates the need for data integration and analysis techniques that allow for a comprehensive analysis. A particular challenge when conducting this analysis is the integration of process data generated by workflow engines and operational data that is produced by business applications and stored in data warehouses. Typically, these two types of data are not matched as their acquisition and analysis follows different principles, i.e., a process-oriented view versus a view focusing on business objects. To address this challenge, we introduce a framework that allows to improve business processes considering an integrated view on process data and operational data. We present and evaluate various architectural options for the data warehouse that provides this integrated view based on a specialized federation layer. This integrated view is also reflected in a set of operators that we introduce. We show how these operators ease the definition of analysis queries and how they allow to extract hidden optimization patterns by using data mining techniques. © 2013 Springer-Verlag Berlin Heidelberg. 

Business models enhancement through discovery of roles Control flow discovery algorithms are able to reconstruct the workflow of a business process from a log of performed activities. These algorithms, however, do not pay attention to the reconstruction of roles, i.e. they do not group activities according to the skills required to perform them. Information about roles in business processes is commonly considered important and explicitly integrated into the process representation, e.g. as swimlanes in BPMN diagrams. This work proposes an approach to enhance a business process model with information on roles. Specifically, the identification of roles is based on the detection of handover of roles. On the basis of candidates for roles handover, the set of activities is first partitioned and then subsets of activities which are performed by the same originators are merged, so to obtain roles. All significant partitions of activities are automatically generated. Experimental results on several logs show that the set of generated roles is not too large and it always contains the correct definition of roles. We also propose an entropy based measure to rank the candidate roles which returns promising experimental results. © 2013 IEEE. organizational mining; process enhancement; process mining; social network analysis

Business process analysis in healthcare environments: A methodology based on process mining Performing business process analysis in healthcare organizations is particularly difficult due to the highly dynamic, complex, ad hoc, and multi-disciplinary nature of healthcare processes. Process mining is a promising approach to obtain a better understanding about those processes by analyzing event data recorded in healthcare information systems. However, not all process mining techniques perform well in capturing the complex and ad hoc nature of clinical workflows. In this work we introduce a methodology for the application of process mining techniques that leads to the identification of regular behavior, process variants, and exceptional medical cases. The approach is demonstrated in a case study conducted at a hospital emergency service. For this purpose, we implemented the methodology in a tool that integrates the main stages of process analysis. The tool is specific to the case study, but the same methodology can be used in other healthcare environments. © 2011 Elsevier Ltd. All Rights Reserved. Business process analysis; Healthcare processes; Process mining; Sequence clustering

Business process compliance checking  applying and evaluating a generic pattern matching approach for conceptual models in the financial sector Given the strong increase in regulatory requirements for business processes the management of business process compliance becomes a more and more regarded field in IS research. Several methods have been developed to support compliance checking of conceptual models. However, their focus on distinct modeling languages and mostly linear (i.e., predecessor-successor related) compliance rules may hinder widespread adoption and application in practice. Furthermore, hardly any of them has been evaluated in a real-world setting. We address this issue by applying a generic pattern matching approach for conceptual models to business process compliance checking in the financial sector. It consists of a model query language, a search algorithm and a corresponding modelling tool prototype. It is (1) applicable for all graph-based conceptual modeling languages and (2) for different kinds of compliance rules. Furthermore, based on an applicability check, we (3) evaluate the approach in a financial industry project setting against its relevance for decision support of audit and compliance management tasks. 

Business process continuous improvement system based on workflow mining technology As an important part of business process management, continuous improvement is a crucial factor determining the enterprises' capability of keeping competition in rapidly changing marketplace. In this paper, we integrate the data mining technology into the workflow management system to find out the tacit business process knowledge, and put forward the concept of Workflow Mining. Based on this foundation, business process continuous improvement framework on workflow historical process information mining is proposed. It includes four levels: historical information acquisition, performance evaluation, structural defects identification and generation of improved model. Key techniques of each layer are discussed, and prototype system is developed to support the implementation of this method. Enterprise application shows that this system has strong flexibility and extensibility, and its structure is reasonable. © 2008 IEEE. 

Business process discovery by using process skeletonization Process Management software and solutions mainly address structured processes in enterprises, but there are still many business applications that are less structured by their nature, such as human-centric and ad hoc workflows. Existing process mining algorithms often have difficulties in extracting a skeletal structure of a less-structured process model from real-life event logs. We propose a new process mining algorithm by using a skeleton-extraction procedure, which brings structure to less structured business processes. We present experimental mining results from real insurance claim examination event logs and verified the effectiveness of the proposed algorithm. © 2013 IEEE. Process mining; Process skeleton; Weakly structured process

Business process impact visualization and anomaly detection Business operations involve many factors and relationships and are modeled as complex business process workflows. The execution of these business processes generates vast volumes of complex data. The operational data are instances of the process flow, taking different paths through the process. The goal is to use the complex information to analyze and improve operations and to optimize the process flow. In this paper, we introduce a new visualization technique, called VisImpact that turns raw operational business data into valuable information. VisImpact reduces data complexity by analyzing operational data and abstracting the most critical factors, called impact factors, which influence business operations. The analysis may identify single nodes of the business flow graph as important factors but it may also determine aggregations of nodes to be important. Moreover, the analysis may find that single nodes have certain data values associated with them which have an influence on some business metrics or resource usage parameters. The impact factors are presented as nodes in a symmetric circular graph, providing insight into core business operations and relationships. A cause-effect mechanism is built in to determine 'good' and 'bad' operational behavior and to take action accordingly. We have applied VisImpact to real-world applications, fraud analysis and service contract analysis, to show the power of VisImpact for finding relationships among the most important impact factors and for immediate identification of anomalies. The VisImpact system provides a highly interactive interface including drilldown capabilities down to transaction levels to allow multilevel views of business dynamics. © 2006 Palgrave Macmillan Ltd. All rights reserved. Business intelligence; Visual data mining; Visualization technique

Business process learning for real time enterprises Existing approaches for business process mining cannot satisfy Real-Time Enterprise (RTE) goals, such as time-based competition. To support RTE requirements we propose a Process Learning System (PLS) that is capable of learning business processes from a few observed traces and do this in a timeframe that is close to the actual time for completing the process. Unlike existing approaches PLS employs a rich process model that facilitates "guessing" business processes, utilizes domain-specific knowledge captured by activity and resource ontologies, ensures that learned processes comply with specified business rules, and optimizes them to reduce required cost and time. In this paper we focus on the architecture of PLS, and describe the functionality and algorithms employed by key PLS components. We use examples from initial experiments involving learning of processes that assemble complex products from specialized parts. © Springer-Verlag Berlin Heidelberg 2007. 

Business process measurement in small enterprises after the installation of an ERP software We report the observation of the first six months of operation after the installation of an ERP software in a group of small Italian enterprises (some dealers of various products and one manufacturer). Before the ERP, no explicit process descriptions existed within the companies: the operations were manually performed, using office automation software or legacy programs that were not process oriented. The new ERP is equipped with a workflow engine, a number of standard processes that should be followed by the users, and a tracking system that logs the main steps of the processes. We use process mining tools to analyze the events logged by the ERP during the sales, the purchases and the manufacture cycles. Our aim is to 1) compare the ideal processes suggested by the ERP with the real paths followed by the users 2) describe the eventual adaptation of these paths, as the users became acquainted with the ERP 3) highlight critical segments in terms of time spent, iterations, etc. 4) compare the processes of different companies that are in similar business areas. The final goal is to get a better understanding of the processes and a rationalization of the operations. It must be stressed that both the ERP and the main tools used are open source, so that the process measurement is affordable even for very small (micro) enterprises. Business process mining; Enterprise resource planning; Open source software; Small enterprises

Business process mining and reconstruction for financial audits In modern companies business processes and information systems are highly integrated and transactions are executed system based and automated. The data generated in the course of processing transactions commonly provides the basis for internal and external financial reporting. The financial statements are subject to audits due to regulatory requirements. Contemporary audit approaches take into account internal control frameworks over relevant business processes and underlying information systems, but they lack adequate audit procedures needed to handle voluminous data flows when business processes are highly integrated and automated. We face a discrepancy between an integrated and automated transaction processing on the one side and manual audit procedures on the other. Financial audits would be more effective and efficient if an audit approach with system based and automated procedures would be applied. This article describes how business process mining and reconstruction of mined processes can be used to overcome this discrepancy. © 2012 IEEE. 

Business process mining and rules detection for unstructured information In this article we show how to find evidence of incomplete or fractured processes in non-structured reports of known business processes, by means of rules, patterns and detection of cause-effect relationships. A priori classifications and probabilities of process activities are used as inputs for the analysis and rules detection. In this method we use a domain-specific ontology associated to process activities in order to improve on previous results, where occurrence of a process in a document set was detected by means of SLM. © 2010 IEEE. Business process; Business process mining; Data mining; Statistical language model; Text mining

Business process mining based on simulated annealing In order to identify business processes effectively, historical data, such as event log, can be used as a base to retrieve abstract process model. The result of process mining can provide necessary information to deploy process-aware information systems. Process structure patterns disclosing the relationship among activities is one of the most important aspects. To retrieve the process model comprehensively and quickly, this paper propose a simulated annealing process mining approach to address this issue. Main contribution of the work includes:(1)Apply the simulated annealing approach under the setting of process mining. (2)Represent events as "causal matrix". (3)Evaluate the mining result with a quantitative measurement, incorporate the ideas above into existing simulated annealing algorithm to form an integrated solution. We give experimental results which created by the ProM, a platform for business process mining, with the data it provides. © 2008 IEEE. Petri-net; Process mining; Simulate annealing

Business process mining from e-commerce web logs The dynamic nature of the Web and its increasing importance as an economic platform create the need of new methods and tools for business efficiency. Current Web analytic tools do not provide the necessary abstracted view of the underlying customer processes and critical paths of site visitor behavior. Such information can offer insights for businesses to react effectively and efficiently. We propose applying Business Process Management (BPM) methodologies to e-commerce Website logs, and present the challenges, results and potential benefits of such an approach. We use the Business Process Insight (BPI) platform, a collaborative process intelligence toolset that implements the discovery of loosely-coupled processes, and includes novel process mining techniques suitable for the Web. Experiments are performed on custom click-stream logs from a large online travel and booking agency. We first compare Web clicks and BPM events, and then present a methodology to classify and transform URLs into events. We evaluate traditional and custom process mining algorithms to extract business models from real-life Web data. The resulting models present an abstracted view of the relation between pages, exit points, and critical paths taken by customers. Such models show important improvements and aid high-level decision making and optimization of e-commerce sites compared to current state-of-art Web analytics. © 2013 Springer-Verlag. 

Business process mining from group stories Process Modeling has been adopted by organizations in various contexts, such as analysis for best practices, system design and Information Technology architecture. Despite its importance, modeling process is still costly and complex. The process mining technique extracts information from systems event log, however, a business process incorporates human activities, which will never be present in logs. This paper presents an approach that explores the narrative technique associated with text mining and natural language interpretation for automatic generation of process models. © 2009 IEEE. Business process elicitation; Storytelling; Text mining

Business process mining: An industrial application Contemporary information systems (e.g., WfM, ERP, CRM, SCM, and B2B systems) record business events in so-called event logs. Business process mining takes these logs to discover process, control, data, organizational, and social structures. Although many researchers are developing new and more powerful process mining techniques and software vendors are incorporating these in their software, few of the more advanced process mining techniques have been tested on real-life processes. This paper describes the application of process mining in one of the provincial offices of the Dutch National Public Works Department, responsible for the construction and maintenance of the road and water infrastructure. Using a variety of process mining techniques, we analyzed the processing of invoices sent by the various subcontractors and suppliers from three different perspectives: (1) the process perspective, (2) the organizational perspective, and (3) the case perspective. For this purpose, we used some of the tools developed in the context of the ProM framework. The goal of this paper is to demonstrate the applicability of process mining in general and our algorithms and tools in particular. © 2006 Elsevier B.V. All rights reserved. Business process analysis; Business process management; Data mining; Petri nets; Process mining; Social network analysis; Workflow management

Business process workarounds: What can and cannot be detected by process mining Business process workarounds are specific forms of incompliant behavior, where employees intentionally decide to deviate from the required procedures although they are aware of them. Detecting and understanding the workarounds performed can guide organizations in redesigning and improving their processes and support systems. Existing process mining techniques for compliance checking and diagnosis of incompliant behavior rely on the available information in event logs and emphasize technological capabilities for analyzing this information. It is therefore not certain that all the forms of workaround behavior are addressed. In contrast, the paper builds on a list of generic types of workarounds found in practice, and explores whether and how they can be detected by process mining techniques. Results obtained for four workaround types in five real-life processes are reported. The remaining two types are not reflected in events logs and cannot be detected by process mining. © 2013 Springer-Verlag. Business process workarounds; Compliance checking; Process mining

Business Processes Reengineering Based on Data Mining As market competition intensifying, Business Process Reengineering (BPR) has become the inevitable choice for enterprises to develop their competitive advantages. Effectively promoting the implementation of BPR is an important way to scale the business for enterprises. As a new type of data-processing tools in dealing with massive data, Data Mining technology has an important role in transforming data into valuable information, supporting enterprises in business process reengineering, and so on. This paper discusses the data mining technology applied to support BPR with the help of the data analysis software -- SPSS. In this article presents the data mining technology in analyzing of critical success factors, identifying core business processes, optimizing the flow of information and feedback. Data Mining; Data Warehouse; BPR; Core Business Process

Business rule patterns and their application to process analytics The advanced rule-based compliance checking approach enables a timely investigation of a complete set of enriched process event data. By providing more than sixty formally grounded business rule patterns, we are able to remove the partial fit between the abilities of traditional process mining techniques and the contemporary requirements of compliance checking. In this contribution we demonstrate the applicability of the approach on two case studies: A purchase-to-pay process and a reimbursement process. © 2013 IEEE. Business rules; Compliance checking; Process mining and enterprise systems

Capturing designers' knowledge demands in collaborative team Collaborative team members usually come from diverse disciplines; their demands for knowledge are also different from each other. This paper is mainly concerned with how to capturing designers' knowledge demands in collaborative team. With the view from workflow, designers' knowledge demand is modeled from three aspects, members, roles, and tasks' requirements for knowledge. Based on the model of knowledge demand, some intelligent mining methods are proposed so that designers' knowledge demand could be derived automatically. With the knowledge demand model, a knowledge supply system could be developed to realize: knowledge within an appropriate domain could be delivered to the proper user among the collaborative team. © Springer-Verlag Berlin Heidelberg 2007. Collaborative design; Knowledge demand; Knowledge management; Workflow

Case construction for mining supply chain processes Process mining algorithms aim at the automatic extraction of business process models from logs. Most of these algorithms perform well on single-system event traces that explicitly refer to a process instance or case. However, in many operational environments such case identifiers are not directly recorded for events. In supply chain processes there are even further challenges, since different identification numbers, vertical integration and numerous aggregation steps prevent individual work steps to become traceable as a case. As a result, there are little experiences with the use of process mining in supply chains. To address this problem, we consider Radio Frequency Identification (RFID) for identifying the movements of the business objects. Based on an example process from the Supply Chain Operations Reference Model (SCOR), we highlight the two key challenges of making RFID events available for process mining: case identification and focus shifts. We demonstrate how RFID events that conform to the EPCglobal standard can be used to construct cases such that process mining can be applied. A respective algorithm is sketched that we implemented in a tool which generates MXML process mining data from EPCglobal event traces. In this way, we provide a contribution towards applying process mining techniques for supply chain analysis. © 2009 Springer Berlin Heidelberg. Business Process Modeling; EPCglobal; Process Mining; RFID; Supply Chain Management

Case mining in knowledge maintenance Process mining has emerged as a way to analyze processes based on the event logs of the systems that support them. Today's knowledge management systems embedded with workflow systems produce detailed event logs. The omnipresence of event logs is an important enabler for process mining. The primary goal of process mining in knowledge maintenance is to extract knowledge from these logs and use it for a detailed analysis of reality. Most knowledge maintenance process mining algorithms focused on the control flow mining and organization mining. As a result, other aspects have been neglected, e. g., the factors influencing the knowledge maintenance process. Therefore, we focus on case mining. We will present techniques to find the correlation between case properties and the performance. To do this, we use existing techniques in an innovative manner. The proposed approach is applied to an aviation design institute to validate its feasibility. The description of this case study is covered in this paper. Case mining; Knowledge maintenance; Knowledge management; Process mining

Case study in process mining in a multinational enterprise Process mining has become an active area of research and while there are numerous papers on approaches to process mining there are fewer detailing its application to real industrial scenarios and its applicability in these spaces. In this paper we introduce the approach to process mining used in a number of multinational enterprises and then reflect upon the issues that have been encountered during our ongoing work. In our opinion these issues are a clear example of the challenges that need to be addressed during business process discovery from heterogeneous data. © 2012 IFIP International Federation for Information Processing. Case Study; Data Driven Process Discovery; Industrial Application; Process Improvement; Process Mining

Change mining in adaptive process management systems The wide-spread adoption of process-aware information systems has resulted in a bulk of computerized information about real-world processes. This data can be utilized for process performance analysis as well as for process improvement. In this context process mining offers promising perspectives. So far, existing mining techniques have been applied to operational processes, i.e., knowledge is extracted from execution logs (process discovery), or execution logs are compared with some a-priori process model (conformance checking). However, execution logs only constitute one kind of data gathered during process enactment. In particular, adaptive processes provide additional information about process changes (e.g., ad-hoc changes of single process instances) which can be used to enable organizational learning. In this paper we present an approach for mining change logs in adaptive process management systems. The change process discovered through process mining provides an aggregated overview of all changes that happened so far. This, in turn, can serve as basis for all kinds of process improvement actions, e.g., it may trigger process redesign or better control mechanisms. © Springer-Verlag Berlin Heidelberg 2006. 

Change sequence mining for interdependent context aware service processes using partial derivatives Service process usually needs to be tailored for reuse because of change of context .In this paper, we present a mining approach to mining process change sequences based on different context using partial derivatives of the factors affecting the change context, thus finding the best feasible sequence. ©2009 IEEE. 

Characterizing workflow nets using regions The target of workflow mining is to obtain a workflow management systems from a possibly complete set of event logs of the system. This gives a fruitful support for devel-oping complex business transaction sequences and business collaboration applications. We investigate on how the theory of regions, used to synthesize nets from marking graphs, can be used to mine Workflow Nets. We show that using minimal regions we can mine the correct net. We also briefly discuss on how transitions systems can be obtained by event logs. © 2006 IEEE. Business process modeling and analysis; Formal models in business process management; Process mining; Theory of regions

Classification and evaluation of timed running schemas for workflow based on process mining The system running logs of a workflow contain much information about the behavior and logical structure between activities. In this paper, a mining approach is proposed to discover the structural and temporal model for a workflow from its timed running logs. The mining results are represented in the formalized form of Petri nets extended with two timing factors that allows validation or verification the actual behaviors, especially the temporal constraints between activities. According to the reachability graph of the extended Petri net model mined, all running schemas of a workflow can be generated, which defines the temporal constraints between running activities. By calculating the earliest and latest start time of each activity, the earliest starting and latest existing time of each state in the running schema can be determined. Based on the temporal relations between the timing factors of each running state, the running schemas can be classified into six classes. The effects of the six classes of running schemas on the implementation of the whole workflow are evaluated so as to obtain the best one that can ensure the workflow is finished in the shortest time. The standards for the ideal, reliable and favorable running schemas and their existence conditions are discussed, which can be used to evaluate the running logs and control the future running of a workflow. © 2008 Elsevier Inc. All rights reserved. Classification; Evaluation; Petri net; Process mining; Running logs; Running schema; Workflow

Classifiers for behavioral patterns identification induced from huge temporal data A new method of constructing classifiers from huge volume of temporal data is proposed in the paper. The novelty of introduced method lies in a multi-stage approach to constructing hierarchical classifiers that combines process mining, feature extraction based on temporal patterns and constructing classifiers based on a decision tree. Such an approach seems to be practical when dealing with huge volume of temporal data. As a proof of concept a system has been constructed for packet-based network traffic anomaly detection, where anomalies are represented by spatio-temporal complex concepts and called by behavioral patterns. Hierarchical classifiers constructed with the new approach turned out to be better than "flat" classifiers based directly on captured network traffic data. Behavioral patterns; Classifiers; Huge temporal data; LTL temporal logic; State graphs; Temporal patterns

Clinical pathway analysis using graph-based approach and Markov models Cluster analysis is one of the most important aspects in the data mining process for discovering groups and identifying interesting distributions or patterns over the considered data sets. A new method for sequences clustering and prediction is presented in this paper, which is based on a hybrid model that uses our b-coloring based clustering approach as well as Markov chain models. The paper focuses on clinical pathway analysis but the method applies to every kind of sequences, and a generic decision support framework has been developed for managers and experts. The interesting result is that the clusters obtained have a twofold representation. Firstly, there is a set of dominant sequences which reflects the properties of the cluster and also guarantees that clusters are well separated within the partition. On the other hand, the behavior of each cluster is governed by a finite-state Markov chain model which allows probabilistic prediction. These models can be used for predicting possible paths for a new patient, and for helping medical professionals to eventually react to exceptions during the clinical process. ©2007 IEEE. 

Clustering and Operation Analysis for Assembly Blocks Using Process Mining in Shipbuilding Industry A block assembly process in the shipbuilding industry consists of many work stages. Block assembly involves many workers in many shops. Each assembly block, which is a part of a ship, has a different structure requiring specific work processes. Therefore, in order to better understand such real processes, an information system for monitoring of block position has been developed. Recently, the necessity of using data accumulated in information systems has become greater. This paper proposes a new, clustering and operation analysis method for assembly blocks based on process mining techniques suitable for the shipbuilding industry. The approach consists of four steps: 1) trace clustering from the task perspective, 2) trace clustering from the work shop perspective, 3) definition of new clusters considering task and work shop simultaneously, and 4) comparison of new clusters with other clusters from the process perspective. The output of clustering and operation analysis can be used for production planning purposes such as resource allocation and operation scheduling for assembly blocks. The effectiveness of the proposed method was verified in a case study using real event logs generated from the Block Assembly Monitoring System (BAMS), an information system. Shipbuilding; block assembly; process mining; trace clustering; process model

Colored Petri nets for integrating the data perspective in process audits The complexity of business processes and the data volume of processed transactions increase with the ongoing integration of information systems. Process mining can be used as an innovative approach to derive information about business processes by analyzing recorded data from the source information systems. Although process mining offers novel opportunities to analyze and inspect business processes it is rarely used for audit purposes. The application of process mining has the potential to significantly improve process audits if requirements from the application domain are considered adequately. A common requirement for process audits is the integration of the data perspective. We introduce a specification of Colored Petri Nets that enables the modeling of the data perspective for a specific application domain. Its application demonstrates how information from the application domain can be used to create process models that integrate the data perspective for the purpose of process audits. © Springer-Verlag 2013. Business intelligence; Business process audits; Business process intelligence; Business process modeling; Petri nets; Process mining

Coloured Petri net diagnosers for lumped process systems A model-based method is proposed in this paper for algorithmic generation of diagnosers in coloured Petri net (CPN) form from characteristic input-output traces obtained from a qualitative model of lumped process systems. The qualitative model contains the description of the considered persistent faults in the form of fault indicators, and it is transformed into a CPN. The diagnosers are constructed from a CPN obtained by the process mining methodology using the generated input-output traces for identically constant inputs. The concepts and methods are illustrated using a simple case study consisting of an industrial storage tank system with additive and multiplicative failures on sensors, and on the behaviour of a pump. © 2010 Springer-Verlag. Coloured Petri nets; diagnoser; process mining; qualitative model

Combination of Process Mining and Simulation Techniques for Business Process Redesign: A Methodological Approach Organizations of all sizes are currently supporting their performance on information systems that record the real execution of their business processes in event logs. Process mining tools analyze the log to provide insight on the real problems of the process, as part of the diagnostic phase. Nonetheless, to complete the lifecycle of a process, the latter has to be redesigned, a task for which simulation techniques can be used in combination with process mining, in order to evaluate different improvement alternatives before they are put in practice. In this context, the current work presents a methodological approach to the integration of process mining and simulation techniques in a process redesign project. © International Federation for Information Processing 2013. BPM; data mining; process mining; process redesign; simulation

Combined Bayesian Networks and Rough-Granular Approaches for Discovery of Process Models Based on Vehicular Traffic Simulation The aim of this paper is to summarize our experiments for discovering process of creation of traffic jams. These experiments were conducted during work on our master theses. We obtained data sets from the vehicular traffic simulator which were used to create a proper ontology based on the domain knowledge. The ontology was used as a schema for hierarchical classifier, which used Bayesian network created by genetic algorithm and rough sets based methods. © Springer-Verlag Berlin Heidelberg 2010. Bayesian network; cellular automaton; domain knowledge; Granules; hierarchical classifier; ontology; ontology approximation; process mining; rough sets; time window; traffic modelling

Combining business process and data discovery techniques for analyzing and improving integrated care pathways Hospitals increasingly use process models for structuring their care processes. Activities performed to patients are logged to a database but these data are rarely used for managing and improving the efficiency of care processes and quality of care. In this paper, we propose a synergy of process mining with data discovery techniques. In particular, we analyze a dataset consisting of the activities performed to 148 patients during hospitalization for breast cancer treatment in a hospital in Belgium. We expose multiple quality of care issues that will be resolved in the near future, discover process variations and best practices and we discover issues with the data registration system. For example, 25 % of patients receiving breast-conserving therapy did not receive the key intervention "revalidation". We found this was caused by lowering the length of stay in the hospital over the years without modifying the care process. Whereas the process representations offered by Hidden Markov Models are easier to use than those offered by Formal Concept Analysis, this data discovery technique has proven to be very useful for analyzing process anomalies and exceptions in detail. © 2010 Springer-Verlag Berlin Heidelberg. Breast cancer; data discovery; integrated care pathways; process mining

Comparative research of modeling methods for workflow process The workflow model is key component of workflow system, it is significant for business process reengineering and optimization that the workflow management system is researched and developed. In this paper, the current state of research in workflow process modeling are overviewed after describing the essence and standard of workflow process modelling, the main common modelling theories include flow figure, status figure, activity network figure, IDEF, ECAA, Petri Net, and so on. In order to solve the deficiency of formalized and graphic expression ability, complicated modeling procedure, the methods of solution for problems and development trend of workflow related theories are put forward, the main single advanced modeling methods are process data mining, extended Petri Nets and process algebra, and suit modeling environment for these methods are analyzed and compared, and, the combined modeling framework is introduced in the last part. © 2008 IEEE. 

Comparison of predictive data mining methods for their application in a design process A design process is characterized by acquisition and processing of information or knowledge, respectively. The acquisition of information and knowledge can be direct, indirect or automatic. This paper presents an approach of how to automatically extract design knowledge from process data. Several data mining algorithms were tested on a benchmark data sets to find the best performing ones. Especially the C&RT algorithm turned out to be interesting as its extracted knowledge is rule-represented and can be used to cope with tasks that up to now require the experience of expert designers. 

Completion Time and Next Activity Prediction of Processes Using Sequential Pattern Mining Process mining is a research discipline that aims to discover, monitor and improve real processing using event logs. In this paper we describe a novel approach that (i) identifies partial process models by exploiting sequential pattern mining and (ii) uses the additional information about the activities matching a partial process model to train nested prediction models from event logs. Models can be used to predict the next activity and completion time of a new (running) process instance. We compare our approach with a model based on Transition Systems implemented in the ProM5 Suite and show that the attributes in the event log can improve the accuracy of the model without decreasing performances. The experimental results show how our algorithm improves of a large margin ProM5 in predicting the completion time of a process, while it presents competitive results for next activity prediction. 

Comprehensive computational support for collaborative learning from writing Learning about subject matter and about writing by collaboratively authoring an electronic document is an important variant of computer-supported collaborative learning. Collaborative writing is particularly often practiced in Higher Education. Our research has the goal to develop comprehensive software support tools for collaborative discipline-based writing, and to study how the team writing process is affected by the use of these tools. This paper describes initial tool developments that integrate computational document analysis methods with process mining methods into a comprehensive writing environment and reports first experiences gained in a undergraduate engineering course. CSCL; Formative feedback; Process mining; Text mining; Writing

Comprehensive rule-based compliance checking and risk management with process mining Process mining researchers have primarily focused on developing and improving process discovery techniques, while attention for the applicability of process mining has been below par. As a result, there only exists a partial fit with the traditional requirements for compliance checking and risk management. This paper proposes a comprehensive rule-based process mining approach for a timely investigation of a complete set of enriched process event data. Additionally, the contribution elaborates a two-dimensional business rule taxonomy that serves as a source of business rules for the comprehensive rule-based compliance checking approach. Finally, the study provides a formal grounding for and an evaluation of the comprehensive rule-based compliance checking approach. © 2012 Elsevier B.V. Business rules; Compliance checking; Process mining; Process-aware information systems; Risk management

Comprehensive workflow mining Workflow Management Systems (WFMS) assist with the execution, monitoring and management of a process. These systems, as they are executing, keep a record of who does what and when (e.g. a workflow event log). The activity of using computer software to examine these records to produce useful knowledge about a process is called workflow mining. Currently, workflow mining research is narrowly focused on the rediscovery of control flow models. In this position paper, we present comprehensive workflow mining to broaden the scope of workflow mining. We present the concepts of comprehensive workflow mining using the Information Control Net (ICN) workflow modeling language. Copyright 2006 ACM. Comprehensive workflow mining; Process mining; Workflow mining

Confidence-aware sequence alignment for process diagnostics Traditional process modeling in contemporary information systems concentrates on the design and configuration phases, while less attention is dedicated to the enactment phase. Instead of starting with a process design, process mining attempts to discover interesting patterns from a set of real time execution namely event logs, which can be handled as a main data source for end-user behavior analysis, and translate this discovered knowledge into process model. One of the challenging issues in process mining is process diagnostics, i.e. encompassing process performance analysis, anomaly detection, diagnosis, inspection of interesting patterns, and sequence alignment is applicable to find out common subsequences of activities in event logs that are found to recur within a process instance or across the process instances emphasizing some domain significance. In this study, we focus on a hybrid quantitative approach for performing process diagnostics, i.e. comparing the similarity among process models based on the established dominant behavior concept, confidence metric and Needleman-Wunsch algorithm with dynamic pay-off matrix. © 2013 IEEE. Confidence metric; Dominant behavior; Needleman-Wunsch Algorithm; Process diagnostics; Process mining; Sequence alignment

Conformance analysis on software development: An experience with process mining Software organisations are investing more and more time and resources in their development processes. Conformance analysis is considered an important issue concerning process improvement initiatives. Process mining can be a valuable tool to gather data from event logs produced by management tools for software development environments. Process analysts can use the information obtained to quantify the correspondence between the process models and the real execution. This work discusses the issues concerning process mining in the context of software development processes. We also report an exploratory case study that takes activity records from a software maintenance project in a large software operation. The results were useful to an exploratory analysis as well as to examine the issues involved in the knowledge discovery process in this type of environment. Copyright © 2011 Inderscience Enterprises Ltd. Conformance checking; Process mining; Software quality

Conformance checking and diagnosis for declarative business process models in data-aware scenarios A business process (BP) consists of a set of activities which are performed in coordination in an organizational and technical environment and which jointly realize a business goal. In such context, BP management (BPM) can be seen as supporting BPs using methods, techniques, and software in order to design, enact, control, and analyze operational processes involving humans, organizations, applications, and other sources of information. Since the accurate management of BPs is receiving increasing attention, conformance checking, i.e.; verifying whether the observed behavior matches a modelled behavior, is becoming more and more critical. Moreover, declarative languages are more frequently used to provide an increased flexibility. However, whereas there exist solid conformance checking techniques for imperative models, little work has been conducted for declarative models. Furthermore, only control-flow perspective is usually considered although other perspectives (e.g.; data) are crucial. In addition, most approaches exclusively check the conformance without providing any related diagnostics. To enhance the accurate management of flexible BPs, this work presents a constraint-based approach for conformance checking over declarative BP models (including both control-flow and data perspectives). In addition, two constraint-based proposals for providing related diagnosis are detailed. To demonstrate both the effectiveness and the efficiency of the proposed approaches, the analysis of different performance measures related to a wide diversified set of test models of varying complexity has been performed. © 2014 Elsevier Ltd. All rights reserved. Business process management; Conformance checking; Constraint programming; Declarative business process models; Diagnosis; Process mining

Conformance checking for BPMN-based process models Measuring how well business process models conform to the execution of the process in reality is an important topic with many applications. While current conformance checking approaches are tailored to formal models such as Petri nets they lack support for domain-specific standards such as BPMN. In this paper we present two approaches for directly measuring the conformance of business process models based on BPMN elements and event logs. We define methods for extracting properties from such models that enable an easy comparison to event logs on a local level (i.e. for individual parts of the process and individual events). Furthermore, we present a method for replaying whole event logs on such models, allowing for a global conformance measure (i.e. on trace level). By utilising the previously extracted properties, we eliminate the need for expensive state-space exploration. BPMN; Model analysis; Model conformance; Process mining

Conformance checking in the large: Partitioning and topology The torrents of event data generated by today's systems are an important enabler for process mining. However, at the same time, the size and variability of the resulting event logs are challenging for today's process mining techniques. This paper focuses on "conformance checking in the large" and presents a novel decomposition technique that partitions larger processes into sets of subprocesses that can be analyzed more easily. The resulting topological representation of the partitioning can be used to localize conformance problems. Moreover, we provide techniques to refine the decomposition such that similar process fragments are not considered twice during conformance analysis. All the techniques have been implemented in ProM, and experimental results are provided. © 2013 Springer-Verlag. Conformance Checking; Process Diagnosis; Process Mining

Conformance checking of electronic business processes to secure distributed transactions Advances in computer technologies facilitate the implementation of inter-organizational business processes. At the same time, managing the security of these processes is increasingly difficult. Compliance with high level specifcations, like normatives and pre-agreed protocols, rules and requirements, is difficult to validate. Here we discuss how Conformance Checking, a specific area of Process Mining, can be adapted for this purpose. Its role is to verify if an execution of a business process satisfies specifications represented by formal models (e.g. Petri Nets, Transition Systems, structures based on partial orders, etc). In the process mining literature, few efforts have been dedicated to online checking of business processes and choreographies for security purposes. The main requirement is high precision and reliability of event logs. They should record, precisely and unambiguously, all security-relevant activities of the analyzed process. Mantaining high-level logs becomes difficult with choreographies: log data are distributed, and must be related to events. Important metadata of event logs, like timestamps, can be ambiguous. Moreover, some data cannot be distributed due to security or privacy issues. These problems result in security-relevant ambiguities in event logs. Here we define a framework to create high-level event logs for online inter-organizational compliance checking using a Validation Authority. The system described here has been implemented in the issuing infrastructure for the Italian Electronic Identity card. 

Conformance checking of processes based on monitoring real behavior Many companies have adopted Process-aware Information Systems (PAIS) to support their business processes in some form. On the one hand these systems typically log events (e.g., in transaction logs or audit trails) related to the actual business process executions. On the other hand explicit process models describing how the business process should (or is expected to) be executed are frequently available. Together with the data recorded in the log, this situation raises the interesting question "Do the model and the log conform to each other?". Conformance checking, also referred to as conformance analysis, aims at the detection of inconsistencies between a process model and its corresponding execution log, and their quantification by the formation of metrics. This paper proposes an incremental approach to check the conformance of a process model and an event log. First of all, the fitness between the log and the model is measured (i.e., "Does the observed process comply with the control flow specified by the process model?"). Second, the appropriateness of the model can be analyzed with respect to the log (i.e., "Does the model describe the observed process in a suitable way?"). Appropriateness can be evaluated from both a structural and a behavioral perspective. To operationalize the ideas presented in this paper a Conformance Checker has been implemented within the ProM framework, and it has been evaluated using artificial and real-life event logs. © 2007 Elsevier B.V. All rights reserved. Business Process Intelligence; Petri Nets; Process Mining; Workflow Management

Conformance checking using cost-based fitness analysis The growing complexity of processes in many organizations stimulates the adoption of business process analysis techniques. Typically, such techniques are based on process models and assume that the operational processes in reality conform to these models. However, experience shows that reality often deviates from hand-made models. Therefore, the problem of checking to what extent the operational process conforms to the process model is important for process management, process improvement, and compliance. In this paper, we present a robust replay analysis technique that is able to measure the conformance of an event log for a given process model. The approach quantifies conformance and provides intuitive diagnostics (skipped and inserted activities). Our technique has been implemented in the ProM 6 framework. Comparative evaluations show that the approach overcomes many of the limitations of existing conformance checking techniques. © 2011 IEEE. Business process analysis; Business process management; Conformance checking; Fitness analysis; Process mining

Consistent process mining over big data triple stores 'Big Data' techniques are often adopted in cross-organization scenarios for integrating multiple data sources to extract statistics or other latent information. Even if these techniques do not require the support of a schema for processing data, a common conceptual model is typically defined to address name resolution. This implies that each local source is tasked of applying a semantic lifting procedure for expressing the local data in term of the common model. Semantic heterogeneity is then potentially introduced in data. In this paper we illustrate a methodology designed to the implementation of consistent process mining algorithms in a 'Big Data' context. In particular, we exploit two different procedures. The first one is aimed at computing the mismatch among the data sources to be integrated. The second uses mismatch values to extend data to be processed with a traditional map reduce algorithm. © 2013 IEEE. Big Data; Data Integration; Process Mining

Constructing decision trees from process logs for performer recommendation This paper demonstrates that the discovery technique using historical event logs can be extended to predict business performance and recommend performers for running instances. For the prediction and recommendation, we adopt decision trees, which is a decision support tool in management science. Decision trees are commonly used to help identify the most likely alternative to reach a goal. To provide effective performer recommendation, we use several filters with previous performers and key tasks to the decision tree. These filters allow for a suitable recommendation according to the characteristics of the processes. The proposed approach is implemented on ProM framework and it is then evaluated through an experiment using reallife event logs, taken from a Dutch Financial Institute. The main contribution of this paper is to provide a real-time decision support tool by recommendation of the best performer for a target performance indicator during process execution based on historical data. © Springer International Publishing Switzerland 2014. Decision tree; Performer recommendation; Process mining

Constructing Workflow Clusters Based On Appropriateness Conformance Checker Process mining techniques attempt to extract non-trivial and useful information from event logs recorded by information systems. Process mining techniques have recently received notable attention in the literature for their ability to assist in the (re)design of complex processes by automatically discovering models that explain the events registered in some log traces provided as input. Real-life processes tend to be less structured and more flexible. An approach to overcome this is to cluster process instances such that each of the resulting clusters corresponds to coherent sets of process instances that can each be adequately represented by a process model. On the other hand the conformance checker methods check if model and the log conform to each other or not. This paper proposed an approach to use Appropriateness Conformance Checker methods to split the event log into homogeneous subsets and for each subset a process model is created. To illustrate this we present a real-life case study from reality mining dataset provided by MIT (Massachusetts Institute of Technology) Media Laboratory. The whole approach has been implemented in ProM the process mining framework. Process mining; workflow mining; reality mining; process clustering; conformance checker

Construction of process models from example runs This contribution suggests a novel approach for a systematic and automatic generation of process models from example runs. The language used for process models is place/transition Petri nets, the language used for example runs is labelled partial orders. The approach adopts techniques from Petri net synthesis and from process mining. In addition to a formal treatment of the approach, a case study is presented and implementation issues are discussed. © 2009 Springer. 

Context-aware compliance checking Organizations face more and more the burden to show that their business is compliant with respect to many different boundaries. The activity of compliance checking is commonly referred to as auditing. As information systems supporting the organization's business record their usage, process mining techniques such as conformance checking offer the auditor novel tools to automate the auditing activity. However, these techniques tend to look at process instances (i.e., cases) in isolation, whereas many compliance rules can only be evaluated when considering interactions between cases and contextual information. For example, a rule like "a paper should not be reviewed by a reviewer that has been a co-author" cannot be checked without considering the corresponding context (i.e., other papers, other issues, other journals, etc.). To check such compliance rules, we link event logs to the context. Events modify a pre-existing context and constraints can be checked on the resulting context. The approach has been implemented in ProM. The resulting context is represented as an ontology, and the semantic web rule language is used to formalize constraints. © 2012 Springer-Verlag. auditing; business rules; compliance checking; ontologies; process mining

Context-aware predictions on business processes: An ensemble-based solution The discovery of predictive models for process performances is an emerging topic, which poses a series of difficulties when considering complex and flexible processes, whose behaviour tend to change over time depending on context factors. We try to face such a situation by proposing a predictive-clustering approach, where different context-related execution scenarios are equipped with separate prediction models. Recent methods for the discovery of both Predictive Clustering Trees and state-aware process performance predictors can be reused in the approach, provided that the input log is preliminary converted into a suitable propositional form, based on the identification of an optimal subset of features for log traces. In order to make the approach more robust and parameter free, we also introduce an ensemble-based clustering method, where multiple PCTs are learnt (using different, randomly selected, subsets of features), and integrated into an overall model. Several tests on real-life logs confirmed the validity of the approach. © 2013 Springer-Verlag. Clustering; Ensemble Learning; Prediction; Process Mining

Context-aware process mining framework for business process flexibility Workflow Management Systems (WFMSs) have been regarded as one of the main types of the next generation information systems. They are perceived that workflow technology not only requires the support for complex data model functionality, but also flexibility for dynamically modifying the workflow specifications. Nowadays, approaches that aim to increase flexibility neglects the Business Process Context. Context is any information that can be used to characterize the situation of an entity (i.e., a person, computing device, or non-computational physical object). This paper proposes a Context-aware process mining framework by which contexts will be automatically captured from Business Process execution environments in order to maximize the flexibility of business Processes. Indeed, it describes how process mining techniques are used to extract information on business process context and how we reason about those information. Copyright 2010 ACM. Artifact; Business process; Business rules; Context-aware; Process mining

Continuous process improvement based on adaptive workflow mining technique As an important part of business process management, continuous improvement is a crucial factor determining the enterprises' capability of keeping competition in rapidly changing marketplace. In this paper, we propose a business process continuous improvement framework based on workflow historical process information mining. In order to inspect each improvement stage of the process improvement, an adaptive process mining method is proposed to reconstruct a series of workflow models from logs. In this method, a sliding window is defined on the process audit streams, and the sliding window size and process schedule method are continuously adjusted by the updating rules to adaptively find the various stages of the process changes in the log. Case study and comparisons are used to illustrate the accuracy and high performance of the proposed algorithms in the end. © 2012 Binary Information Press. Adaptive mining algorithm; Continuous process improvement; Workflow mining

Control charts of workflows This paper focuses on the control of the performance characteristics of workflows modeled with stochastic Petri nets (SPN's). This goal is achieved by focusing on a new model for Artificial Social Systems (ASS's) behaviors, and by introducing equivalent transfer functions for SPN's. ASS's exist in practically every multi-agent system, and play a major role in the performance and effectiveness of the agents. This is the reason why we introduce a more suggestive model for ASS's. To model these systems, a class of Petri nets is adopted, and briefly introduced in the paper. This class allows representing the flow of physical resources and control information data of the ASS's components. In the analysis of SPN we use simulations in respect to timing parameters in a generalized semi-Markov process (GSMP). By using existing results on perturbation (e.g., delays in supply with raw materials, derangements of equipments, etc.) analysis and by extending them to new physical interpretations we address unbiased sensitivity estimators correlated with practical solutions in order to attenuate the perturbations. © 2008 Springer-Verlag. Artificial Social Systems; Control Charts of Workflows; Equivalent Transfer Functions; Stochastic Petri Nets

Control loop model of virtual company in BPM simulation The motivation of the paper is to introduce agent-based technology in the business process simulation. As in other cases, such simulation needs sufficient input data. However, in the case of business systems, real business data are not always available. Therefore, multi-agent systems often operate with randomly (resp. pseudo randomly) generated parameters. This method can also represent unpredictable phenomena. The core of the paper is to introduce the control loop model methodology in JADE business process simulation implementation. At the end of this paper the analysis of agent-based simulation outputs through process mining methods and methods for analysis of agents' behavior in order to verify the correctness of used methodology is presented. The business process simulation inputs are randomly generated using the normal distribution. The results obtained show that using random number generation function with normal distribution can lead to the correct output data and therefore can be used to simulate real business processes. © 2013 Springer-Verlag. 

Control-flow discovery from event streams Process Mining represents an important research field that connects Business Process Modeling and Data Mining. One of the most prominent task of Process Mining is the discovery of a control-flow starting from event logs. This paper focuses on the important problem of control-flow discovery starting from a stream of event data. We propose to adapt Heuristics Miner, one of the most effective control-flow discovery algorithms, to the treatment of streams of event data. Two adaptations, based on Lossy Counting and Lossy Counting with Budget, as well as a sliding window based version of Heuristics Miner, are proposed and experimentally compared against both artificial and real streams. Experimental results show the effectiveness of control-flow discovery algorithms for streams on artificial and real datasets. 

Controlled automated discovery of collections of business process models Automated process discovery techniques aim at extracting process models from information system logs. Existing techniques in this space are effective when applied to relatively small or regular logs, but generate spaghetti-like and sometimes inaccurate models when confronted to logs with high variability. In previous work, trace clustering has been applied in an attempt to reduce the size and complexity of automatically discovered process models. The idea is to split the log into clusters and to discover one model per cluster. This leads to a collection of process models - each one representing a variant of the business process - as opposed to an all-encompassing model. Still, models produced in this way may exhibit unacceptably high complexity and low fitness. In this setting, this paper presents a two-way divide-and-conquer process discovery technique, wherein the discovered process models are split on the one hand by variants and on the other hand hierarchically using subprocess extraction. Splitting is performed in a controlled manner in order to achieve user-defined complexity or fitness thresholds. Experiments on real-life logs show that the technique produces collections of models substantially smaller than those extracted by applying existing trace clustering techniques, while allowing the user to control the fitness of the resulting models. © 2014 Elsevier Ltd. Clone detection; Process discovery; Process mining; Trace clustering

Control-path oriented workflow intelligence analyses This paper proposes two kinds of control-path oriented workflow knowledge analysis approaches which will be applied to a workflow intelligence and quality improvement framework aiming at the high degree of the workflow traceability and rediscoverability. The framework needs two kinds of algorithms - One is for generating the total sequences of the control-paths from a workflow model, and the other is for rediscovering the runtime enactment history of each control-path out of the total sequences from the corresponding workflow's execution logs. The proposed approaches have something to do with the former, and each of them include a set of detailed algorithms for analyzing the total sequences of the control-path perspective of a workflow model. Eventually, the analyzed results from the approaches will be effectively used for some rediscovery approaches to rediscover control-path oriented workflow intelligence from the runtime enactment history, which is called workflow events log. Based upon those control-path oriented workflow intelligences, it will be realized for a workflow model not only to be gradually refined, but also to be finally revealed to maximize its quality by repeatedly redesigning, reengineering and/or refining during its whole life-long time period. Workflow control-path analysis and rediscovery; Workflow intelligence and quality; Workflow knowledge analysis; Workflow mining and rediscoverability; Workflow traceability

Cost model development using virtual manufacturing and data mining: Part i - Methodology development This paper reports on research, the aim of which has been to investigate the use of virtual manufacturing and data mining techniques to automate the identification of manufacturing process time estimating relationships that form the basis of product and process cost models. Such models provide information that is critical to all stages of the product development process and to ensuring that development of cost-effective product design and production methods. Use of virtual manufacturing models and data mining techniques enables the majority of the activities involved in the cost model development process to be automated. Hence, reducing the time and effort required, reducing the current high level of reliance on expert judgment and enabling higher levels of cost detail to be estimated. The research reported, therefore, focuses on the use of virtual manufacturing to generate datasets which are then analysed using data mining to identify suitable cost models for manufacturing processes. Part I, of this two-part paper, describes the development of a model development methodology that makes use of virtual manufacturing models and data mining techniques and uses case study data to validate this methodology. Part II will then examine in detail the effectiveness of alternative data mining algorithms in terms of their ability to develop relationships that are (1) representative of the real causal relationships that exist and (2) provide a high level of estimating accuracy. © 2012 Springer-Verlag London Limited. 

Cost model development using virtual manufacturing and data mining: Part II - Comparison of data mining algorithms Cost models of manufacturing processes are an important tool enabling enterprises to make reasonable predictions and forecasts in relation to the production costs for existing and new products. Accurate and robust cost models can help to provide significant competitive advantage for manufacturing organisations. Advanced computational methods such as virtual manufacturing and data mining have been identified as potentially powerful techniques for generating cost models that bypass the problems associated with traditional cost modelling processes. Part I, of this two-part paper, described the development of a cost model development methodology that makes use of virtual manufacturing models and data mining techniques and used case study data to validate this methodology. A critical part of this methodology is the selection and use of effective data analysis techniques that can identify accurate and robust cost estimating relationships. Part II now examines in detail the effectiveness of alternative data mining algorithms in terms of their ability to develop relationships that are (1) representative of the real causal relationships that exist and (2) able to provide a high level of estimating accuracy. More specifically, it focuses on the data generated by virtual manufacturing models and how the size and complexity of the generated data sets impact the accuracy of the cost estimating relationships. © 2012 Springer-Verlag London Limited. 

Coupling case based reasoning and process mining for a web based crisis management decision support system This paper presents a research in progress that aims to design and develop a web-based shared environment for stakeholders involved in disaster management. The goal of this environment is two-fold. Firstly it will provide a reliable disaster information source to facilitate the exchange and the analysis of previous crisis information. Secondly, it will assimilate best practices and provide recommendations based on experiences from previous disasters. One of the first steps towards such an environment is to elaborate a common and generic disaster model. This model is also a reference to define a template for the case base of previous disasters. In order for our system to provide recommendations based on previous practices, we combine case based reasoning with process mining. This article presents the first step towards a disaster management decision support system, specifically providing guidance on how to integrate process mining in the case based reasoning cycle. © 2013 IEEE. Generic Disaster Model; Process Mining; Case Based Reasoning; Previous practices; Crisis Management Decision Support.

Creating Process-Agents incrementally by mining process asset library Software process trustworthiness is the degree of confidence that a software process produces expected trustworthy work products that satisfy requirements. Software processes are dynamic and highly people-dependent. The performance of software processes relies not only on the process itself, but also on the personnel's capabilities. Therefore, management of human resources and evaluation of a company's work force capabilities are crucial and will affect software process trustworthiness. Our software process modeling method OEC-SPM (Organization-Entity Capability based Software Process Modeling) has been shown to take into account personnel's capabilities and groups software developers with certain capabilities into a Process-Agent, which is a way of organizing human resources and process asset libraries in software organizations, and will help to improve trustworthiness of software processes. This paper proposes a novel method for incrementally mining Process-Agents from process asset libraries to support OEC-SPM. The method can automatically and incrementally create Process-Agents under three scenarios with high efficiency. Furthermore, we assess the method with the data from real industry setting. The results show that the utilization of human resources in an organization can be optimized when personnel's capabilities are taken into account. Additionally, reasonable resource scheduling making use of Process-Agents will result in higher trustworthiness. © 2013 Elsevier Inc. All rights reserved. Clustering; Human resource; Process-Agent; Software process; Trustworthiness

Cross-organizational collaborative workflow mining from a multi-source log Today's enterprise business processes become increasingly complex given that they are often executed by geographically dispersed partners or different organizations. Designing and modeling such a cross-organizational workflow is a complicated, time-consuming process and requires that a designer has extensive experience. Workflow logs captured by different cross-organizational systems provide a very valuable source of information on how business processes are executed in reality and thus can be used to derive workflow models through process mining. In this paper, we investigate the application of process mining for workflow integration based on the concept of RM-WF-Net, a type of Petri net extended with resource and message factors. Four coordination patterns are defined for workflow integration. A process mining approach is presented to discover the coordination patterns between different organizations and the workflow models in different organizations from the running logs containing the information about resource allocation. A process integration approach is then presented to obtain the model for a cross-organizational workflow based on the model mined for each organization and the coordination patterns between different organizations. © 2012 Elsevier B.V. Collaborative workflow; Coordination pattern; Cross-organizational workflow; Petri net; Process mining; Running log

Crowd-based mining of reusable process model patterns Process mining is a domain where computers undoubtedly outperform humans. It is a mathematically complex and computationally demanding problem, and event logs are at too low a level of abstraction to be intelligible in large scale to humans. We demonstrate that if instead the data to mine from are models (not logs), datasets are small (in the order of dozens rather than thousands or millions), and the knowledge to be discovered is complex (reusable model patterns), humans outperform computers. We design, implement, run, and test a crowd-based pattern mining approach and demonstrate its viability compared to automated mining. We specifically mine mashup model patterns (we use them to provide interactive recommendations inside a mashup tool) and explain the analogies with mining business process models. The problem is relevant in that reusable model patterns encode valuable modeling and domain knowledge, such as best practices or organizational conventions, from which modelers can learn and benefit when designing own models. © 2014 Springer International Publishing Switzerland. Crowdsourcing; Mashups; Model patterns; Pattern mining

Data- and Resource-Aware Conformance Checking of Business Processes Process mining is not restricted to process discovery and also includes conformance checking, i.e., checking whether observed behavior recorded in the event log matches modeled behavior. Many organizations have descriptive or normative models that do not adequately describe the actual processes. Therefore, a variety of techniques for conformance checking have been proposed. However, all of these techniques focus on the control-flow and abstract from data and resources. This paper describes an approach that aligns event log and model while taking all perspectives into account (i.e., also data and resources). This way it is possible to quantify conformance and analyze differences between model and reality. The approach has been implemented in ProM and evaluated using a variety of model-log combinations. © 2012 Springer-Verlag. 

Data flow-oriented process mining to support security audits The automated execution of dynamically-evolving business processes in service-oriented architectures requires audit methods to assert that they fulfill required security properties. Process mining techniques can provide models for the actual process behavior, but mostly disregard the dynamics of processes running in highly flexible environments and neglect the data flow perspective. This research plan is on novel data-oriented mining techniques to tackle these shortcomings in order to support effective security audits. © 2012 Springer-Verlag. 

Data improvement to enable process mining on integrated non-log data sources Process models derived using Process Mining (PM) are often very complex due to Data Quality Issues (DQIs). Some of those DQIs arise from integration of different data sources or the transformation of non-process oriented data, hence are structural and can be abstracted from the domain. Activity Sequencing and Activity Hierarchy are two concepts for improving certain DQIs in order to improve PM outcomes. The approaches are evaluated by showing the improvement of derived process models using a simplified real world scenario with simulated data. © 2013 Springer-Verlag Berlin Heidelberg. Data Enrichment; Data Integration; Data Quality Improvement; Process Mining

Data Quality and Completeness in a Web Stroke Registry as the Basis for Data and Process Mining Electronic health records often show missing values and errors jeopardizing their effective exploitation. We illustrate the re-engineering process needed to improve the data quality of a web-based, multicentric stroke registry by proposing a knowledge-based data entry support able to help users to homogeneously interpret data items, and to prevent and detect treacherous errors. The re-engineering also improves stroke units coordination and networking, through ancillary tools for monitoring patient enrollments, calculating stroke care indicators, analyzing compliance with clinical practice guidelines, and entering stroke units profiles. Finally we report on some statistics, such as calculation of indicators for assessing the quality of stroke care, data mining for knowledge discovery, and process mining for comparing different processes of care delivery. The most important results of the re-engineering are an improved user experience with data entry, and a definitely better data quality that guarantees the reliability of data analyses. data acquisition; disease registry; human computer interaction; statistical indicators; stroke unit

Data transformation and semantic log purging for process mining Existing process mining approaches are able to tolerate a certain degree of noise in the process log. However, processes that contain infrequent paths, multiple (nested) parallel branches, or have been changed in an ad-hoc manner, still pose major challenges. For such cases, process mining typically returns spaghetti-models, that are hardly usable even as a starting point for process (re-)design. In this paper, we address these challenges by introducing data transformation and pre-processing steps that improve and ensure the quality of mined models for existing process mining approaches. We propose the concept of semantic log purging, the cleaning of logs based on domain specific constraints utilizing semantic knowledge which typically complements processes. Furthermore we demonstrate the feasibility and effectiveness of the approach based on a case study in the higher education domain. We think that semantic log purging will enable process mining to yield better results, thus giving process (re-)designers a valuable tool. © 2012 Springer-Verlag Berlin Heidelberg. Data transformation; Log purging; Process constraints; Process mining

Data warehousing and mining technologies for adaptability in turbulent resources business environments Resources businesses often undergo turbulent and volatile periods, due to rapid increase of resource demand and poorly organised resources data volumes. This volatile industry operates multifaceted business units that manage heterogeneous data sources. Data integration and interactive business processes, distributed across complex business environments, need attention. Historical resources data, geographically (spatial dimension) archived for decades (periodic dimension), are source of analysing past business data dimensions and predicting their future turbulences. Periodic data, modelled in an integrated and robust warehouse environment, are explored using data mining methodologies. The data models presented, will optimise future inputs in the turbulent resources business environments. Copyright © 2011 Inderscience Enterprises Ltd. Data mining; Data warehousing; Resources business data

Data-aware process mining: Discovering decisions in processes using alignments Process discovery, i.e., learning process models from event logs, has attracted the attention of researchers and practitioners. Today, there exists a wide variety of process mining techniques that are able to discover the control-flow of a process based on event data. These techniques are able to identify decision points, but do not analyze data flow to find rules explaining why individual cases take a particular path. Fortunately, recent advances in conformance checking can be used to align an event log with data and a process model with decision points. These alignments can be used to generate a well-defined classification problem per decision point. This way data flow and guards can be discovered and added to the process model. Copyright 2013 ACM. Business process data-flow pespective; Machine-learning techniques; Process discovery

Data-aware remaining time prediction of business process instances Accurate prediction of the completion time of a business process instance would constitute a valuable tool when managing processes under service level agreement constraints. Such prediction, however, is a very challenging task. A wide variety of factors could influence the trend of a process instance, and hence just using time statistics of historical cases cannot be sufficient to get accurate predictions. Here we propose a new approach where, in order to improve the prediction quality, both the control and the data flow perspectives are jointly used. To achieve this goal, our approach builds a process model which is augmented by time and data information in order to enable remaining time prediction. The remaining time prediction of a running case is calculated combining two factors: (a) the likelihood of all the following activities, given the data collected so far; and (b) the remaining time estimation given by a regression model built upon the data. Data-aware Prediction; Naive Bayes; Process mining; Support Vector Regression

Dealing with concept drifts in process mining Although most business processes change over time, contemporary process mining techniques tend to analyze these processes as if they are in a steady state. Processes may change suddenly or gradually. The drift may be periodic (e.g., because of seasonal influences) or one-of-a-kind (e.g., the effects of new legislation). For the process management, it is crucial to discover and understand such concept drifts in processes. This paper presents a generic framework and specific techniques to detect when a process changes and to localize the parts of the process that have changed. Different features are proposed to characterize relationships among activities. These features are used to discover differences between successive populations. The approach has been implemented as a plug-in of the ProM process mining framework and has been evaluated using both simulated event data exhibiting controlled concept drifts and real-life event data from a Dutch municipality. © 2012 IEEE. Concept drift; flexibility; hypothesis tests; process changes; process mining

Decision mining for multi choice workflow patterns Decision mining is combination of process mining and machine learning technique to retrieve information about how an attribute in a business process affects a case's route choice. It identifies decision point by looking for XOR-splits in petri-net workflow model and analyzing rules for each choice based on available attributes using decision tree. Problem emerges when decision mining technique is used on a workflow that does not use either XOR or AND splits, for example OR-split gateway logic. OR-split does not have explicit representation in petri nets and it makes decision mining algorithm cannot find its decision point. Workflow pattern that uses OR-split as its splitting logic is multi choice. Multi choice does not have its own explicit representation in form of petri net and it is problematic to apply decision mining to this workflow pattern. To make multi choice can be analyzed by decision miner some modification needs to be applied to the petri net representation of this pattern. This paper proposes modification of OR-split gateway representation in petri net. The new representation of OR-split uses combination the existing XOR-split and AND-split to make the model easier to be analyzed using decision miner. The proposed modification do not affect the conformance of event log and process model, but will allow each choice branch to be checked by decision miner. © 2013 IEEE. decision mining; decision tree; multi choice; process mining; workflow pattern

Decision-making in information systems based on new development framework and business process mining The studies on software project failures have identified problems in capturing requirements, managing complexity and dynamic changes of the environment because of the using traditional software engineering, where requirement capturing is static and prolonged. This issue is especially important for decision-making in dynamically changing business. The paper offers modernization of information system development methods used for implementation of automated information-, rule-, knowledge-, model-based decision processes. The paper propose to assist processes by early separation and development of a business logic model and implementation of decision-making, knowledge discovery process models and business process analysis using probabilistic models by proposing an information systems development framework. The advantages of such approach are early separation and development of a business logic model and further support for business people for modification of business logic without involvement of software developers and minimizing their persistence in the latter exploitation stages. Finally, the paper presents experimental results for stochastic decision extraction from system database using process mining and probabilistic models to ease framework implementation. Decision model; Decision-making in information systems; Information systems development framework; Probabilistic models; Process mining

Declarative process discovery with evolutionary computing The field of process mining deals with the extraction of knowledge from event logs. One task within the area of process mining entails the discovery of process models to represent real-life behavior as observed in day-to-day business activities. A large number of such process discovery algorithms have been proposed during the course of the past decade, among which techniques to mine declarative process models (e.g. Declare and AGNEs Miner) as well as evolutionary based techniques (e.g. Genetic Miner and Process Tree Miner). In this paper, we present the initial results of a newly proposed evolutionary based process discovery algorithm which aims to discover declarative process models, hence combining these two classes (declarative and genetic) of discovery techniques. To do so, we herein use a language bias similar to the one found in AGNEs Miner to allow for the conversion from a set of declarative control-flow based constraints (determining the conditions which have to be satisfied to enable to execution of an activity) to a procedural process model, i.e. a Petri net, though this language bias can be extended to include data-based constraints as well. 

Declarative workflows: Balancing between flexibility and support Today's process-aware information systems tend to either support business processes or provide flexibility. Classical workflow management systems offer good process support as long as the processes are structured and do not require much flexibility. Information systems that allow for flexibility have a tendency to lack process-related support. If systems offer guidance, then they are typically also inclined to ''enforce guidelines'' and are perceived as inflexible. Moreover, implementing flexible systems is far from trivial. This paper will show that using a more declarative approach can assist in a better balance between flexibility and support. This is demonstrated by presenting the Declare framework that aims to take care of the full spectrum of flexibility while at the same time supports the user using recommendations and other process-mining-based diagnostics. Business Process Management; Flexibility; Process mining; Workflow management

Decomposing Petri nets for process mining: A generic approach The practical relevance of process mining is increasing as more and more event data become available. Process mining techniques aim to discover, monitor and improve real processes by extracting knowledge from event logs. The two most prominent process mining tasks are: (i) process discovery: learning a process model from example behavior recorded in an event log, and (ii) conformance checking: diagnosing and quantifying discrepancies between observed behavior and modeled behavior. The increasing volume of event data provides both opportunities and challenges for process mining. Existing process mining techniques have problems dealing with large event logs referring to many different activities. Therefore, we propose a generic approach to decompose process mining problems. The decomposition approach is generic and can be combined with different existing process discovery and conformance checking techniques. It is possible to split computationally challenging process mining problems into many smaller problems that can be analyzed easily and whose results can be combined into solutions for the original problems. © 2013 Springer Science+Business Media New York. Distributed conformance checking; Distributed process discovery; Petri nets; Process decomposition; Process mining

Decomposing process mining problems using passages Process discovery-discovering a process model from example behavior recorded in an event log-is one of the most challenging tasks in process mining. Discovery approaches need to deal with competing quality criteria such as fitness, simplicity, precision, and generalization. Moreover, event logs may contain low frequent behavior and tend to be far from complete (i.e., typically only a fraction of the possible behavior is recorded). At the same time, models need to have formal semantics in order to reason about their quality. These complications explain why dozens of process discovery approaches have been proposed in recent years. Most of these approaches are time-consuming and/or produce poor quality models. In fact, simply checking the quality of a model is already computationally challenging. This paper shows that process mining problems can be decomposed into a set of smaller problems after determining the so-called causal structure. Given a causal structure, we partition the activities over a collection of passages. Conformance checking and discovery can be done per passage. The decomposition of the process mining problems has two advantages. First of all, the problem can be distributed over a network of computers. Second, due to the exponential nature of most process mining algorithms, decomposition can significantly reduce computation time (even on a single computer). As a result, conformance checking and process discovery can be done much more efficiently. © 2012 Springer-Verlag. business process management; conformance checking; distributed computing; process discovery; process mining

Delta analysis: A hybrid quantitative approach for measuring discrepancies between business process models Business process management (BPM) continues to play a significant role in today's highly globalized world. In order to detect and prevent the gap between reference process model and the actual operation, process mining techniques discover operational model on the basis of the process logs. An important issue at BPM is to measure the similarity between the reference process model and discovered process model so that it can be possible to pinpoint where process participants deviate from the intended process description. In this paper, a hybrid quantitative approach is presented to measure the similarity between the process models. The proposed similarity metric is based on a hybrid process mining technique that makes use of genetic algorithms. The proposed approach itself is also a hybrid model that considers process activity dependencies and process structure. © 2011 Springer-Verlag. Business Process Management (BPM); Delta Analysis; Process Mining; Process Modeling; Similarity Measurement

Deriving Event Graphs through Process Mining for Runtime Change Management  

Design and implementation of a data mining grid-aware architecture Current business processes often use data from several sources. Data is characterized to be heterogeneous, incomplete and usually involves a huge amount of records. This implies that data must be transformed in a set of patterns, rules or some kind of formalism, which helps to understand the underlying information. The participation of several organizations in this process makes the assimilation of data more difficult. Data mining is a widely used approach for the transformation of data to useful patterns, aiding the comprehensive knowledge of the concrete domain information. Nevertheless, traditional data mining techniques find difficulties in their application on current scenarios, due to the complexity previously mentioned. Data Mining Grid tries to fix these problems, allowing data mining process to be deployed in a grid environment, in which data and services resources are geographically distributed, belong to several virtual organizations and the security can be flexibly solved. We propose both a novel architecture for Data Mining Grid, named DMGA, and the implementation of this architecture, named WekaG. © 2006 Elsevier Ltd. All rights reserved. Data mining; Data mining grid architecture (DMGA); WekaG

Design of an automatic workflow modeling method in cooperative WFMS WFMS is a typical computer supported cooperative application system. However it is difficult for the workflow models defined by current methods to support well the cooperative work among participators. Recently a new modeling method is presented, which is called as workflow mining. This new method has the capability of automatic modeling, strong objectivity, high efficiency and low cost, so it can improve the modeling quality and support well the cooperative work. Nowadays the new technology is in primary stage, the known mining algorithms are not perfect. In this paper a workflow mining algorithm based on Markov transition matrix is designed, which can reduce the effect of complexity of process structure and quality of workflow logs on the process mining and improve the automatic modeling efficiency. ©2006 IEEE. Markov transition matrix; WFMS; Workflow log; Workflow mining; Workflow modeling

Design of intelligent business process system and process remodeling Traditional business process management systems only focus on process definition and running. This paper designs an intelligent business process system to realize process diagnosis, analysis, optimization, and prediction. Process mining engine is the key component of the intelligent system. This paper designs a process mining algorithm based on Markov matrix to realize business process remodeling. Realization of intelligent business process system can effectively improve the process management ability of managers. © 2008 IEEE. 

Design of the integrated monitoring framework based on ontology for analyzing the customer feedback This study was carried out as a part of the development of the integrated monitoring system which analyzes the customer feedback data to evaluate the services on offer and reconfigure and recommend the services based on the evaluation result for effective performance management in the B2C industry. This system is based on the framework which can monitor quantitative and qualitative analysis data from the process mining analysis for the system log generated in the hospital, customer satisfaction survey and customer dissatisfaction messages on the social media. This framework is designed to provide the infrastructure for integrated query of necessary data and inference by managing the relevant information between the analysis results based on the ontology, and this framework is intended primarily for the services offered in the hospital. © 2013 IEEE. framework; ontology; process mining; satisfaction survey; sentimental analysis; system integration

Detecting abnormal behavior in social network websites by using a process mining technique Detecting abnormal user activity in social network websites could prevent from cyber-crime occurrence. The previous research focused on data mining while this research is based on user behavior process. In this study, the first step is defining a normal user behavioral pattern and the second step is detecting abnormal behavior. These two steps are applied on a case study that includes real and syntactic data sets to obtain more tangible results. The chosen technique used to define the pattern is process mining, which is an affordable, complete and noise-free event log. The proposed model discovers a normal behavior by genetic process mining technique and abnormal activities are detected by the fitness function, which is based on Petri Net rules. Although applying genetic mining is time consuming process, it can overcome the risks of noisy data and produces a comprehensive normal model in Petri net representation form.© 2014 Science Publications. Anomaly detection; Genetic algorithm; Petri net; Process mining; Social network

Detecting implicit dependencies between tasks from event logs Process mining aims at extracting information from event logs to capture the business process as it is being executed. In spite of many researchers' persistent efforts, there are still some challenging problems to be solved. In this paper, we focus on mining non-free-choice constructs, where the process models are represented in Petri nets. In fact, there are totally two kinds of causal dependencies between tasks, i.e., explicit and implicit ones. Implicit dependency is very hard to mine by current mining approaches. Thus we propose three theorems to detect implicit dependency between tasks and give their proofs. The experimental results show that our approach is powerful enough to mine process models with non-free-choice constructs. © Springer-Verlag Berlin Heidelberg 2006. 

Determining process model precision and generalization with weighted artificial negative events Process mining encompasses the research area which is concerned with knowledge discovery from event logs. One common process mining task focuses on conformance checking, comparing discovered or designed process models with actual real-life behavior as captured in event logs in order to assess the 'goodness' of the process model. This paper introduces a novel conformance checking method to measure how well a process model performs in terms of precision and generalization with respect to the actual executions of a process as recorded in an event log. Our approach differs from related work in the sense that we apply the concept of so-called weighted artificial negative events toward conformance checking, leading to more robust results, especially when dealing with less complete event logs that only contain a subset of all possible process execution behavior. In addition, our technique offers a novel way to estimate a process model's ability to generalize. Existing literature has focused mainly on the fitness (recall) and precision (appropriateness) of process models, whereas generalization has been much more difficult to estimate. The described algorithms are implemented in a number of ProM plugins, and a Petri net conformance checking tool was developed to inspect process model conformance in a visual manner. © 2013 IEEE. artificial negative events; conformance checking; generalization; precision; process mining

Developing a real-time process data acquisition system for automatic process measurement As the population aging is a global and unalterable trend, and the whole society is lacking of productive workforce to provide healthcare services, there is a pressure to develop smart services to support the elderly persons live a more independent life and improve the quality of open healthcare. This paper combines together the concepts of smart living environment and process management, we discuss a novel method called automatic process measurement that uses wireless technologies to collect process data for process mining and process analysis. Besides, this paper presents the real-time data acquisition system that is capable of measuring elderly people's behavior and nurse's behavior. We apply the system to three Linux-based platforms and evaluate it in laboratory and practical environment. The proposed system fulfills the measurement needs of collecting process data for automatic process modeling. © 2012 Springer-Verlag. automatic process measurement; Bluetooth; process mining; Real-time data acquisition

Developing mining-grid centric E-finance portals for risk management and decision making E-finance industry is rapidly transforming and evolving toward more dynamic, flexible and intelligent solutions. This paper describes a model with dynamic multilevel workflows corresponding to a multilayer Grid architecture. The mining-grid is used for multiaspect analysis in building e-finance portals on the Wisdom Web. The application and research demonstrate that mining-grid centric design is effective for developing intelligent risk management and decision making financial systems. This paper concentrates on how to develop a mining-grid centric e-finance portal (MGCFP), not only for supplying effective online financial services for both retail and corporate customers, but also for intelligent credit risk management and decision making for financial enterprises and partners. © World Scientific Publishing Company. E-finance; Enterprise portal; Mining-grid centric; Risk management

Development of a co-operative distributed process mining system for quality assurance In this paper, a co-operative distributed process mining system (CDPMS) is developed to streamline the workflow along the supply chain in order to offer shorter delivery times, more flexibility and higher customer satisfaction with learning ability. The proposed system is equipped with the 'distributed process mining' feature which is used to discover the hidden relationships among each working decision in distributed manner. This method incorporates the concept of data mining and knowledge refinement into decision making process for ensuring 'doing the right things' within the workflow. An example of implementation is given, based on the case of slider manufacturer. Co-operative distributed process mining; Online analytical processing; Quality assurance

Development of a distributed process mining system for reactivetion etching enhancement A Distributed Process Mining System (DPMS) is discussed in this paper which aims to optimize the process in order to offer shorter production time, easier quality defect identification and higher customer satisfaction. This proposed system is equipped with the idea of "distributed process mining" discovering the hidden relationships between each working decision in distributed manner. This method incorporates the On-line Analytical Processing (OLAP) and the decision tree-based Artificial Neural Networks (ANNs) algorithms into decision making for ensuring "doing the right things" within the process and relevant workflow. A case study of using Reactive Ion Etching (RIE) in a magnetic head manufacturer is included. © 2006 IEEE. 

Development of a process mining system for supporting knowledge discovery in a supply chain network In today's competitive environment, business organizations are forced to maintain their competitive advantage by their ability to cut costs, increase revenue and uncover hidden issues. In order to enhance the visibility and transparency of value added information in a supply chain network, a process mining system is proposed for discovering a set of fuzzy association rules based on the daily captured logistics operation data, within the network. The proposed methodology provides all levels of employees with the ability to enhance their knowledge and understanding of the current business environment. Once interesting association rules have been extracted, organizations can identify the root-causes of quality problems in a supply chain and improve performance by fine-tuning the configuration of process parameters in specified processes. The application of the proposed methodology in a case company has also been studied. The prototype system has been developed and evaluated after performing a spatial analysis. The results obtained indicate that the system is capable of extracting high-quality and actionable information in the case company. © 2009 Elsevier B.V. All rights reserved. Business intelligence; Customer satisfaction; Supply chain network

Development of a responsive logistics workflow system: An OLAP-based hybrid approach Inefficient data interchange and analysis obstruct the accomplishment of enterprise integration in terms of bidirectional interchange of information, coordination of decisions and enhancement of assimilation of subsystems within and outside of the relevant organisation. An efficient information exchange mechanism requires appropriate tools for data mining, thereby allowing the transformation of clusters of data into organised information. In particular, a data-mining approach that provides a solution to accomplish enterprise integration is needed. This paper proposes a generic roadmap for the design and implementation of a multiagent model which integrates the data-mining technique called On-Line Analytical Processing (OLAP) and Genetic Algorithm (GA), which is incorporated to achieve optimisation of workflow, thereby providing essential supports in enterprise integration. To validate the feasibility of the generic roadmap for such a model, a system prototype has been developed for managing workflows in a company. Copyright © 2006 Inderscience Enterprises Ltd. Genetic Algorithm (GA); Logistics workflow; Multiagent model; On-Line Analytical Processing (OLAP)

Development of an intelligent quality management system using fuzzy association rules In order to survive in the increasingly customer-oriented marketplace, continuous quality improvement marks the fastest growing quality organization's success. In recent years, attention has been focused on intelligent systems which have shown great promise in supporting quality control. However, only a small number of the currently used systems are reported to be operating effectively because they are designed to maintain a quality level within the specified process, rather than to focus on cooperation within the production workflow. This paper proposes an intelligent system with a newly designed algorithm and the universal process data exchange standard to overcome the challenges of demanding customers who seek high-quality and low-cost products. The intelligent quality management system is equipped with the "distributed process mining" feature to provide all levels of employees with the ability to understand the relationships between processes, especially when any aspect of the process is going to degrade or fail. An example of generalized fuzzy association rules are applied in manufacturing sector to demonstrate how the proposed iterative process mining algorithm finds the relationships between distributed process parameters and the presence of quality problems. © 2007 Elsevier Ltd. All rights reserved. Production quality; Quality improvement; Quality information system

Development of distance measures for process mining, discovery, and integration Business processes continue to play an important role in today's service-oriented enterprise computing systems. Mining, discovering, and integrating process-oriented services has attracted growing attention in the recent years. In this article, we present a quantitative approach to modeling and capturing the similarity and dissimilarity between different process designs. We derive the similarity measures by analyzing the process dependency graphs of the participating workflow processes. We first convert each process dependency graph into a normalized process matrix. Then we calculate the metric space distance between the normalized matrices. This distance measure can be used as a quantitative and qualitative tool in process mining, process merging, and process clustering, and ultimately it can reduce or minimize the costs involved in design, analysis, and evolution of workflow systems. Copyright © 2007, IGI Global. Business process; Process mining; Similarity

Discovering branching conditions from business process execution logs Process mining is a family of techniques to discover business process models and other knowledge of business processes from event logs. Existing process mining techniques are geared towards discovering models that capture the order of execution of tasks, but not the conditions under which tasks are executed - also called branching conditions. One existing process mining technique, namely ProM's Decision Miner, applies decision tree learning techniques to discover branching conditions composed of atoms of the form "v op c" where "v" is a variable, "op" is a comparison predicate and "c" is a constant. This paper puts forward a more general technique to discover branching conditions where the atoms are linear equations or inequalities involving multiple variables and arithmetic operators. The proposed technique combine invariant discovery techniques embodied in the Daikon system with decision tree learning techniques. © 2013 Springer-Verlag. 

Discovering business process model from unstructured activity logs Many real world business processes are executed without explicit orchestration and hence do not generate structured execution logs. This is particularly true for the class of business processes which are executed in service delivery centers in emerging markets where rapid changes in processes and in the people executing the processes are common. In such environments, the process execution logs are usually a mix of human entered activity log of actions performed and the auto-generated logs by various tools used during the process execution. Process discovery from unstructured execution logs has been a relatively unexplored research area. In this paper, we propose an approach for process discovery from unstructured logs using gaussian mixture models and hidden markov models. We apply this approach to the logs generated by a real-world business process used in a service delivery center and demonstrate that the results obtained are comparable to an approach of manually labeling the logs followed by a best known process discovery algorithm in literature. The approach proposed is generic and applicable to a wide range of business process execution settings. © 2010 IEEE. Business process discovery; Hidden markov models; Process mining

Discovering business processes in legacy systems using business rules and log mining This paper shows a method to semi-automate the discovery of business processes implemented implicitly in the source code of legacy systems. The method identifies the encoding of the business activities through the business rules implemented in legacy source code. In this paper we propose a tool to executes the source code instrumentation, identifying the business rules implemented in the legacy system and enabling the creation of event logs. This allows using log mining techniques to discover the partial order of execution of the business rules. Thus it is possible to discover business processes implemented implicitly in the source code of legacy systems. This paper also presents a case study conducted in a medical information system. © 2013 IEEE. Business processes; Business rules; Legacy system; Process mining

Discovering business rules through process mining Business rules guide the operation of an organization, thus its documentation provides an important source of information both for developing technological solutions (information systems, databases)and for evaluating information systems implementations. Despite its importance, manual creation and maintenance of business rule documentation is very costly, and practically infeasible in complex organizations. This paper describes a method for discovering business rules from the information systems event logs, through the use of process mining and data mining techniques. We exemplify the method execution to discover two selected sub-types of business rules, namely condition action assertions and authorization action assertions. © 2009 Springer Berlin Heidelberg. Business rules; Classification; Data mining; Process mining

Discovering colored Petri nets from event logs Process-aware information systems typically log events (e.g., in transaction logs or audit trails) related to the actual execution of business processes. Analysis of these execution logs may reveal important knowledge that can help organizations to improve the quality of their services. Starting from a process model, which can be discovered by conventional process mining algorithms, we analyze how data attributes influence the choices made in the process based on past process executions using decision mining, also referred to as decision point analysis. In this paper we describe how the resulting model (including the discovered data dependencies) can be represented as a Colored Petri Net (CPN), and how further perspectives, such as the performance and organizational perspective, can be incorporated. We also present a CPN Tools Export plug-in implemented within the ProM framework. Using this plug-in, simulation models in ProM obtained via a combination of various process mining techniques can be exported to CPN Tools. We believe that the combination of automatic discovery of process models using ProM and the simulation capabilities of CPN Tools offers an innovative way to improve business processes. The discovered process model describes reality better than most hand-crafted simulation models. Moreover, the simulation models are constructed in such a way that it is easy to explore various redesigns. © Springer-Verlag 2007. 

Discovering context-aware models for predicting business process performances Discovering predictive models for run-time support is an emerging topic in Process Mining research, which can effectively help optimize business process enactments. However, making accurate estimates is not easy especially when considering fine-grain performance measures (e.g., processing times) on a complex and flexible business process, where performance patterns change over time, depending on both case properties and context factors (e.g., seasonality, workload). We try to face such a situation by using an ad-hoc predictive clustering approach, where different context-related execution scenarios are discovered and modeled accurately via distinct state-aware performance predictors. A readable predictive model is obtained eventually, which can make performance forecasts for any new running process case, by using the predictor of the cluster it is estimated to belong to. The approach was implemented in a system prototype, and validated on a real-life context. Test results confirmed the scalability of the approach, and its efficacy in predicting processing times and associated SLA violations. © 2012 Springer-Verlag. 

Discovering event correlation rules for semi-structured business processes In this paper we describe an algorithm to discover event correlation rules from arbitrary data sources. Correlation rules can be useful for determining relationships between events in order to isolate instances of a running business process for the purposes of monitoring, discovery and other applications. We have implemented our algorithm and validate our approach on events generated by a simulator that implements a real-world inspired export compliance regulations scenario consisting of 24 activities and corresponding event types. This simulated scenario involves a wide range of heterogeneous systems (e.g. Order Management, Document Management, E-Mail, and Export Violation Detection Services) as well as workflow-supported human-driven interactions (Process Management System). Experimental results demonstrate that our algorithm achieves a high level of accuracy in the detection of correlation rules. This paper confirms that our algorithm is a step towards semi-automating the task of detecting correlations. We also demonstrate how correlation rules discovered by our algorithm can be used to create aggregation nodes that allow more efficient querying, filtering and analytics. The results in this paper encourage future directions such as distributed statistics calculation, and scalability in terms of handling massive data sets. © 2011 ACM. complex event processing; correlation discovery. business process discovery; data mining; event analysis

Discovering exclusive patterns in frequent sequences This paper presents a new concept for pattern discovery in frequent sequences with potentially interesting applications. Based on data mining, the approach aims to discover exclusive sequential patterns (ESPs) by checking the relative exclusion of patterns across data sequences. ESP mining pursues the post-processing of sequential patterns and augments existing work on structural relations patterns mining. A three phase ESP mining method is proposed together with component algorithms, where a running worked example explains the process. Experiments are performed on real-world and synthetic datasets which showcase the results of ESP mining and demonstrate its effectiveness, illuminating the theories developed. An outline case study in workflow modelling gives some insight into future applicability. Copyright © 2010 Inderscience Enterprises Ltd. Data mining; ESP; ESP mining; Exclusive sequential patterns; Frequent sequences; Sequential patterns postprocessing; Workflow modelling

Discovering expressive process models by clustering log traces Process mining techniques have recently received notable attention in the literature for their ability to assist in the (re)design of complex processes by automatically discovering models that explain the events registered in some log traces provided as input. Following this line of research, the paper investigates an extension of such basic approaches, where the identification of different variants for the process is explicitly accounted for, based on the clustering of log traces. Indeed, modeling each group of similar executions with a different schema allows us to single out "conformant" models, which, specifically, minimize the number of modeled enactments that are extraneous to the process semantics. Therefore, a novel process mining framework is introduced and some relevant computational issues are deeply studied. As finding an exact solution to such an enhanced process mining problem is proven to require high computational costs, in most practical cases, a greedy approach is devised. This is founded on an iterative, hierarchical, refinement of the process model, where, at each step, traces sharing similar behavior patterns are clustered together and equipped with a specialized schema. The algorithm guarantees that each refinement leads to an increasingly sound model, thus attaining a monotonic search. Experimental results evidence the validity of the approach with respect to both effectiveness and scalability. © 2006 IEEE. Association rules; Classification; Clustering; Data mining; Process mining; Workflow management

Discovering expressive process models from noised log data Process-oriented systems have been increasingly attracting data mining researchers, mainly due to the advantages that the application of inductive process mining techniques to log data could open to both the analysis of complex processes and the design of new process models. However, the actual impact of process mining in the industry is endangered by some simplifying assumptions these techniques relies on. In fact, current approaches have still problems to mine models over languages that allow for complex constructs, e.g., duplicate tasks, hidden tasks, non-free-choice constructs, and/or when noise is admitted in the log. In this paper, some advances to facing these problems are made, by proposing an algorithm which can deal with duplicate and hidden tasks, as well as with the presence of noise and non-free choice relationships among process activities. Importantly, due to the local nature of the search strategy exploited by the algorithm, the proposed approach seems suited to scale in real-world application scenarios. Copyright ©2009 ACM. Process mining; Workflow management systems

Discovering frequent work procedures from resource connections Intelligent desktop assistants could provide more help for users if they could learn models of the users' workflows. However, discovering desktop workflows is difficult because they unfold over extended periods of time (days or weeks) and they are interleaved with many other workflows because of user multi-tasking. This paper describes an approach to discovering desktop workflows based on rich instrumentation of information flow actions such as copy/paste, SaveAs, file copy, attach file to email message, and save attachment. These actions allow us to construct a graph whose nodes are files, email messages, and web pages and whose edges are these information flow actions. A class of workflows that we call work procedures can be discovered by applying graph mining algorithms to find frequent subgraphs. This paper describes an algorithm for mining frequent closed connected subgraphs and then describes the results of applying this method to data collected from a group of real users. Copyright 2009 ACM. Automated assistance; Data mining; Intelligent interfaces; Provenance; Resource management; Workflow

Discovering multi-perspective process models Process Mining techniques exploit the information stored in the executions log of a process in order to extract some high-level process model, which can be used for both analysis and design tasks. Most of these techniques focus on "structural" (control-flow oriented) aspects of the process, in that they only consider what elementary activities were executed and in which ordering. In this way, any other "non-structural" information, usually kept in real log systems (e.g., activity executors, parameter values, and time-stamps), is completely disregarded, yet being a potential source of knowledge. In this paper, we overcome this limitation by proposing a novel approach for discovering process models, where the behavior of a process is characterized from both structural and non-structural viewpoints. In a nutshell, different variants of the process (classes) are recognized through a structural clustering approach, and represented with a collection of specific workflow models. Relevant correlations between these classes and non-structural properties are made explicit through a rule-based classification model, which can be exploited for both explanation and prediction purposes. Results on real-life application scenario evidence that the discovered models are often very accurate and capture important knowledge on the process behavior. Business process intelligence; Decision trees; Process mining

Discovering process models from event multiset The aim of process mining is to discover the process model from the event log which is recorded by the information system. Typical steps of process mining algorithm can be described as: (1) generating event traces from event log, (2) analyzing event traces and obtaining ordering relations of tasks, (3) generating process model with ordering relations of tasks. The first two steps could be very time consuming involving millions of events and thousands of event traces. This paper presents a novel algorithm (?-algorithm) which almost eliminates these two steps in generating event traces from event log and analyzing event traces so as to reduce the performance of process mining algorithm. Firstly, we retrieve the event multiset (input data of algorithm marked as MS) which records the frequency of each event but ignores their orders when extracted from event logs. The event in event multiset contains the information of post-activities. Secondly, we obtain ordering relations from event multiset. The ordering relations contain causal dependency, potential parallelism and non-potential parallelism. Finally, we discover a process models with ordering relations. The complexity of ?-algorithm is only bound up with the event classes (the set of events in event logs) that has significantly improved the performance of existing process mining algorithms and is expected to be more practical in real-world process mining based on event logs, as well as being able to detect SWF-nets, short-loops and most of implicit dependency (generated by non-free choice constructions). © 2012 Elsevier Ltd. All rights reserved. Business process models; Event multiset; Petri nets; Post-tasks; Process mining

Discovering process models from unlabelled event logs Existing process mining techniques are able to discover process models from event logs where each event is known to have been produced by a given process instance. In this paper we remove this restriction and address the problem of discovering the process model when the event log is provided as an unlabelled stream of events. Using a probabilistic approach, it is possible to estimate the model by means of an iterative Expectaction-Maximization procedure. The same procedure can be used to find the case id in unlabelled event logs. A series of experiments show how the proposed technique performs under varying conditions and in the presence of certain workflow patterns. Results are presented for a running example based on a technical support process. © 2009 Springer Berlin Heidelberg. 

Discovering process models through relational disjunctive patterns mining The automatic discovery of process models can help to gain insight into various perspectives (e.g., control flow or data perspective) of the process executions traced in an event log. Frequent patterns mining offers a means to build human understandable representations of these process models. This paper describes the application of a multi-relational method of frequent pattern discovery into process mining. Multi-relational data mining is demanded for the variety of activities and actors involved in the process executions traced in an event log which leads to a relational (or structural) representation of the process executions. Peculiarity of this work is in the integration of disjunctive forms into relational patterns discovered from event logs. The introduction of disjunctive forms enables relational patterns to express frequent variants of process models. The effectiveness of using relational patterns with disjunctions to describe process models with variants is assessed on real logs of process executions. © 2011 IEEE. Disjunctive Patterns; Frequent Pattern Discovery; Process Mining; Process Variants; Relational Data Mining

Discovering process models with genetic algorithms using sampling Process mining, a new business intelligence area, aims at discovering process models from event logs. Complex constructs, noise and infrequent behavior are issues that make process mining a complex problem. A genetic mining algorithm, which applies genetic operators to search in the space of all possible process models, deals with the aforementioned challenges with success. Its drawback is high computation time due to the high time costs of the fitness evaluation. Fitness evaluation time linearly depends on the number of process instances in the log. By using a sampling-based approach, i.e. evaluating fitness on a sample from the log instead of the whole log, we drastically reduce the computation time. When the desired fitness is achieved on the sample, we check the fitness on the whole log; if it is not achieved yet, we increase the sample size and continue the computation iteratively. Our experiments show that sampling works well even for relatively small logs, and the total computation time is reduced by 6 up to 15 times. © 2010 Springer-Verlag. business intelligence; Genetic algorithms; process mining; sampling

Discovering reference models by mining process variants using a heuristic approach Recently, a new generation of adaptive Process-Aware Information Systems (PAISs) has emerged, which enables structural process changes during runtime. Such flexibility, in turn, leads to a large number of process variants derived from the same model, but differing in structure. Generally, such variants are expensive to configure and maintain. This paper provides a heuristic search algorithm which fosters learning from past process changes by mining process variants. The algorithm discovers a reference model based on which the need for future process configuration and adaptation can be reduced. It additionally provides the flexibility to control the process evolution procedure, i.e., we can control to what degree the discovered reference model differs from the original one. As benefit, we cannot only control the effort for updating the reference model, but also gain the flexibility to perform only the most important adaptations of the current reference model. Our mining algorithm is implemented and evaluated by a simulation using more than 7000 process models. Simulation results indicate strong performance and scalability of our algorithm even when facing large-sized process models. © 2009 Springer Berlin Heidelberg. 

Discovering reference process models by mining process variants Recently, a new generation of adaptive Process-Aware Information Systems (PAIS) has emerged, which allows for dynamic process and service changes (e.g., to insert, delete, and move activities and service executions in a running process). This, in turn, has led to a large number of process variants derived from the same model, but differing in structure due to the applied changes. Generally, such process variants are expensive to configure and difficult to maintain. This paper provides a sophisticated approach which fosters learning from past process changes and allows for mining process variants. As a result we obtain a generic process model for which the average distance between this model and the respective process variants becomes minimal. By adopting this generic model in the PAIS, need for future process configuration and adaptation decreases. We have validated the proposed mining method and implemented it in a powerful proof of-concept prototype. © 2008 IEEE. 

Discovering signature patterns from event logs More and more information about processes is recorded in the form of so-called 'event logs'. High-tech systems such as X-ray machines and high-end copiers provide their manufacturers and services organizations with detailed event data. Larger organizations record relevant business events for process improvement, auditing, and fraud detection. Traces in such event logs can be classified as desirable or undesirable (e.g., faulty or fraudulent behavior). In this paper, we present a comprehensive framework for discovering signatures that can be used to explain or predict the class of seen or unseen traces. These signatures are characteristic patterns that can be used to discriminate between desirable and undesirable behavior. As shown, these patterns can, for example, be used to predict remotely whether a particular component in an X-ray machine is broken or not. Moreover, the signatures also help to improve systems and organizational processes. Our framework for signature discovery is fully implemented in ProM and supports class labeling, feature extraction and selection, pattern discovery, pattern evaluation and cross-validation, reporting, and visualization. A real-life case study is used to demonstrate the applicability and scalability of the approach. © 2013 IEEE. Discriminatory Patterns; Event Log; Process Mining; Signature Patterns

Discovering simulation models Process mining is a tool to extract non-trivial and useful information from process execution logs. These so-called event logs (also called audit trails, or transaction logs) are the starting point for various discovery and analysis techniques that help to gain insight into certain characteristics of the process. In this paper we use a combination of process mining techniques to discover multiple perspectives (namely, the control-flow, data, performance, and resource perspective) of the process from historic data, and we integrate them into a comprehensive simulation model. This simulation model is represented as a colored Petri net (CPN) and can be used to analyze the process, e.g., evaluate the performance of different alternative designs. The discovery of simulation models is explained using a running example. Moreover, the approach has been applied in two case studies; the workflows in two different municipalities in the Netherlands have been analyzed using a combination of process mining and simulation. Furthermore, the quality of the CPN models generated for the running example and the two case studies has been evaluated by comparing the original logs with the logs of the generated models. © 2008 Elsevier B.V. All rights reserved. Colored Petri nets; Petri nets; Process mining; Simulation models

Discovering social networks from event logs Process mining techniques allow for the discovery of knowledge based on so-called "event logs", i.e., a log recording the execution of activities in some business process. Many information systems provide such logs, e.g., most WFM, ERP, CRM, SCM, and B2B systems record transactions in a systematic way. Process mining techniques typically focus on performance and control-flow issues. However, event logs typically also log the performer, e.g., the person initiating or completing some activity. This paper focuses on mining social networks using this information. For example, it is possible to build a social network based on the hand-over of work from one performer to the next. By combining concepts from workflow management and social network analysis, it is possible to discover and analyze social networks. This paper defines metrics, presents a tool, and applies these to a real event log within the setting of a large Dutch organization. © Springer 2005. Business process management; Data mining; Petri nets; Process mining; Social network analysis; Workflow management

Discovering structured event logs from unstructured audit trails for workflow mining Workflow mining aims to find graph-based process models based on activities, emails, and various event logs recorded in computer systems. Current workflow mining techniques mainly deal with well-structured and -symbolized event logs. In most real applications where workflow management software tools are not installed, these structured and symbolized logs are not available. Instead, the artifacts of daily computer operations may be readily available. In this paper, we propose a method to map these artifacts and content-based logs to structured logs so as to bridge the gap between the unstructured logs of real life situations and the status quo of workflow mining techniques. Our method consists of two tasks: discovering workflow instances and activity types. We use a clustering method to tackle the first task and a classification method to tackle the second. We propose a method to combine these two tasks to improve the performance of two as a whole. Experimental results on simulated data show the effectiveness of our method. © 2009 Springer Berlin Heidelberg. 

Discovering the most frequent patterns of executions in business processes described in BPEL Emerging Business Process Management Systems (BPMS) are revolutionizing the way enterprises address inter-/intra- company process integration and business IT alignment problems. BPMS is becoming the tool of choice for process lifecycle management. Continuous process improvement is the key focus of process lifecycle management. To carry out this task effectively process designers need a deep understanding of the process behavior. They will need efficient mining algorithms that deliver pertinent and valuable information on all executed instances of a complex process. We propose an algorithm that mines the frequent paths of execution for processes described in BPEL by extending the formalism that has been proposed for mining frequent patterns in a workflow. © Springer-Verlag Berlin Heidelberg 2005. 

Discovering the source of failures The process mining technique used by a Chilean Telecommunications Company to discover the source of failures in business processes in an automatic and efficient way is presented. Process mining is a set of business process management (BPM) techniques that helps analyze business processes using the event logs obtained from information systems that support the business processes. There are three types of analysis that could be conducted with process mining that includes process discovery, conformance checking and extension. Process discovery algorithms reveal the actual process from event logs. Conformance checking compares the event log against an a priori model of the process and the extension analysis allows identifying other useful information, such as bottlenecks, business rules or execution patterns. Business processes could be analyzed from different perspectives, such as control flow, organizational or time. PSDA allow discovering the sources of failures by analyzing the control flow perspective. 

Discovering user communities in large event logs The organizational perspective of process mining supports the discovery of social networks within organizations by analyzing event logs recorded during process execution. However, applying these social network mining techniques to real data generates very complex models that are hard to analyze and understand. In this work we present an approach to overcome these difficulties by focusing on the discovery of communities from such event logs. The clustering of users into communities allows the analysis and visualization of the social network at different levels of abstraction. The proposed approach also makes use of the concept of modularity, which provides an indication of the best division of the social network into community clusters. The approach was implemented in the ProM framework and it was successfully applied in the analysis of the emergency service of a medium-sized hospital. © 2012 Springer-Verlag. Community Structure; Hierarchical Clustering; Modularity; Process Mining; Social Network Analysis

Discovering web service workflows using web services interaction mining Recovering and analysis of workflows executed in Service-Oriented Systems (SOS) can be expected to gain more and more relevance in service-oriented information technology in the not so distant future. Our work attempts to perform workflow mining in logs provided by service-oriented architectures. Firstly, we introduce the idea of Web Services Interaction Mining (WSIM) and give an overview of related fields of research. Secondly, we propose a classification of SOS according to the log information they provide and analyse mining opportunities in the respective classes. To illustrate the potential of WSIM, we describe a complete workflow mining cycle in a SOS of very rich log information. Since such rich logs are often not available, we then direct our attention to mining in limited logs. We present our first steps towards a workflow mining algorithm, specifically tailored to Web Services (WS). We conclude with a discussion of open issues and future work. Copyright © 2006 Inderscience Enterprises Ltd. Process mining; Web Services (WS) mining; Workflows

Discovering workflow-aware virtual knowledge flows for knowledge dissemination In order to effectively disseminate task-relevant and process-scope knowledge, knowledge-intensive enterprises adopt knowledge flows to explicitly represent workers' knowledge needs and referencing behavior of codified knowledge during the execution of business tasks. However, due to differences in expertise and experience, individual workers impose varied knowledge needs on the knowledge flows directed by the workflows they participate in. This study proposes a model of workflow-aware knowledge-flow views, i.e. virtual knowledge flows abstracted from workflow-driven knowledge flows, to provide adaptable knowledge granularity. Moreover, a text mining approach is developed to derive knowledge-flow views from codified knowledge objects of knowledge flows, such as documents. Both task knowledge semantics and task execution sequences are utilized to evaluate the degrees of workers' knowledge demands in workflow contexts. Knowledge management systems can thus present different abstracted knowledge flows to diverse workflow participants, and facilitate knowledge sharing and collaboration. © Springer-Verlag Berlin Heidelberg 2013. Knowledge flow; Knowledge management; Text mining; Workflow

Discovery and analysis of e-mail-driven business processes E-mail is used as the primary tool for business communication and collaboration. This paper presents a novel e-mail interaction mining method to discover and analyze e-mail-driven business processes. An e-mail-driven business process is perceived as a human collaboration process that consists of interactions between people who may each play different roles. The notion of message threads (i.e. sets of e-mail messages that are replies to each other) is used as the fundamental building block to construct the interactions in the e-mail-driven business process. The proposed method adopts an interaction-centric business process modeling language to visualize the discovered e-mail-driven business process. The method identifies message threads from an e-mail archive, and constructs an interaction-centric process model based on the temporal order and similarity of the threads. Process-related information is extracted from e-mail header fields. A software tool, named E-mail Interaction Miner, implements the proposed method. A case study is used to apply and evaluate the method on a set of e-mails collected from a Dutch gas transport company. The evaluation results are discussed. These results comprise business process improvement opportunities for the case organization, and contributions to theory and language development. © 2011 Elsevier Ltd. All Rights Reserved. Business process discovery; Case study; E-mail logs; Human collaboration and interaction; Message threads; Process mining

Discovery of cancellation regions within process mining techniques Process mining is a relatively new field of computer science which deals with process discovery and analysis based on event logs. In this work we consider the problem of discovering workflow nets with cancellation regions from event logs. Cancellations occur in the majority of real-life event logs. In spite of huge amount of process mining techniques little has been done on cancellation regions discovery. We show that the state-based region algorithm gives labeled Petri nets with overcomplicated control flow structure for logs with cancellations. We propose a novel method to discover cancellation regions from the transition systems built on event logs and show the way to construct equivalent workflow net with reset arcs to simplify the control flow structure. 

Discovery of events with negative behavior against given sequential patterns The dramatic drop in the prices of data collection and storage devices has not only enabled organisations to store almost every activity of their business processes, they can also retain every state of these activities as well. Availability of these masses of data also means that by implementing different data mining techniques we can yield more accurate and useful information to be used for important decision making. One of the key mining techniques on such data is to discover sequential patterns. Most of the existing sequential pattern mining approaches mainly deal with finding the positive behaviour of a sequential pattern that can help in predicting the next event after a sequence of events. In this paper we propose the concept of Negative Behaviour Against the Sequential Pattern (NBASP) that is to discover the events/event-sets which are unlikely to follow the given sequential pattern and discuss its applications in a variety of domains. A comprehensive problem definition and efficient algorithm to discover NBASP is presented. © 2010 IEEE. Component; Data mining; Post mining environment; Sequential pattern

Discovery of frequent episodes in event logs Lion's share of process mining research focuses on the discovery of end-to-end process models describing the characteristic behavior of observed cases. The notion of a process instance (i.e., the case) plays an important role in process mining. Pattern mining techniques (such as frequent itemset mining, association rule learning, sequence mining, and traditional episode mining) do not consider process instances. An episode is a collection of partially ordered events. In this paper, we present a new technique (and corresponding implementation) that discovers frequently occurring episodes in event logs thereby exploiting the fact that events are associated with cases. Hence, the work can be positioned in-between process mining and pattern mining. Episode discovery has its applications in, amongst others, discovering local patterns in complex processes and conformance checking based on partial orders. We also discover episode rules to predict behavior and discover correlated behaviors in processes. We have developed a ProM plug-in that exploits efficient algorithms for the discovery of frequent episodes and episode rules. Experimental results based on real-life event logs demonstrate the feasibility and usefulness of the approach. 

Discovery of information diffusion process in social networks Information diffusion analysis in social networks is of significance since it enables us to deeply understand dynamic social interactions among users. In this paper, we introduce approaches to discovering information diffusion process in social networks based on process mining. Process mining techniques are applied from three perspectives: social network analysis, process discovery and community recognition. We then present experimental results by using a real-life social network data. The proposed techniques are expected to employ as new analytical tools in online social networks such as blog and wikis for company marketers, politicians, news reporters and online writers. Copyright © 2012 The Institute of Electronics, Information and Communication Engineers. Information diffusion process; Online social networks; Process mining; Social network services

Discovery of outpatient care process of a tertiary university hospital using process mining Objectives: There is a need for effective processes in healthcare clinics, especially in tertiary hospitals, that consist of a set of complex steps for outpatient care, in order to provide high quality care and reduce the time cost. This study aimed to discover the potential of a process mining technique to determine an outpatient care process that can be utilized for further improvements. Methods: The outpatient event log was defined, and the log data for a month was extracted from the hospital information system of a tertiary university hospital. That data was used in process mining to discover an outpatient care process model, and then the machine-driven model was compared with a domain expert-driven process model in terms of the accuracy of the matching rate. Results: From a total of 698,158 event logs, the most frequent pattern was found to be "Consultation registration > Consultation > Consultation scheduling > Payment > Outside-hospital prescription printing" (11.05% from a total cases). The matching rate between the expert-driven process model and the machine-driven model was found to be approximately 89.01%, and most of the processes occurred with relative accuracy in accordance with the expert-driven process model. Conclusions: Knowledge regarding the process that occurs most frequently in the pattern is expected to be useful for hospital resource assignments. Through this research, we confirmed that process mining techniques can be applied in the healthcare area, and through detailed and customized analysis in the future, it can be expected to be used to improve actual outpatient care processes. © 2013 The Korean Society of Medical Informatics. Hospital information systems; Outpatients; Process mining; Workflow analysis

Discovery of sequential patterns with quantity factors The sequential pattern mining stems from the need to obtain patterns that are repeated in multiple transactions in a database of sequences, which are related to time, or another type of criterion. This work presents the proposal of a new technique for the discovery of sequential patterns from a database of sequences, where the patterns not only provide information on how these relate to the time, but also, that in the mining process itself should be included the quantity factors associated with each of the items that are part of a sequence, and as a result of this process can be obtain information relating to how they relate these items with regard to the amounts associated. The proposed algorithm uses divide and conquer techniques, as well as indexing and partitioning of the database. 

Discrete modeling and simulation of business processes using event logs An approach to business process modelling for short term KPI prediction, based on event logs and values of environment variables, is proposed. Ready-for-simulation process model is built semi-automatically, expert only inputs desired environment variables, which are used as features during the learning process. Process workflow is extracted as a Petri Net model using a combination of process mining algorithms. Dependencies between features and process variables are formalized using decision and regression trees techniques. Experiments were conducted to predict KPIs of real companies. © The Authors. Published by Elsevier B.V. Business process simulation; Data mining; Petri nets; Process mining

Distributed genetic process mining Process mining aims at discovering process models from data logs in order to offer insight into the real use of information systems. Most of the existing process mining algorithms fail to discover complex constructs or have problems dealing with noise and infrequent behavior. The genetic process mining algorithm overcomes these issues by using genetic operators to search for the fittest solution in the space of all possible process models. The main disadvantage of genetic process mining is the required computation time. In this paper we present a coarse-grained distributed variant of the genetic miner that reduces the computation time. The degree of the improvement obtained highly depends on the parameter values and event logs characteristics. We perform an empirical evaluation to determine guidelines for setting the parameters of the distributed algorithm. © 2010 IEEE. 

Distributed genetic process mining using sampling Process mining aims at discovering process models from event logs. Complex constructs, noise and infrequent behavior are issues that make process mining a complex problem. A genetic mining algorithm, which applies genetic operators to search in the space of all possible process models, can successfully deal with the aforementioned challenges. In this paper, we reduce the computation time by using a distributed setting. The population is distributed between the islands of a computer network (e.g. a grid). To further accelerate the method we use sample-based fitness evaluations, i.e. we evaluate the individuals on a sample of the event log instead of the entire event log, gradually increasing the sample size if necessary. Our experiments show that both sampling and distributing the event log significantly improve the performance. The actual speed-up is highly dependent of the combination of the population size and sample size. © 2011 Springer-Verlag Berlin Heidelberg. business intelligence; Genetic algorithms; process mining; sampling

Divide-and-conquer strategies for process mining The goal of Process Mining is to extract process models from logs of a system. Among the possible models to represent a process, Petri nets is an ideal candidate due to its graphical representation, clear semantics and expressive power. The theory of regions can be used to transform a log into a Petri net, but unfortunately the transformation requires algorithms with high complexity. This paper provides techniques to overcome this limitation. Either by using decomposition techniques, or by clustering events in the log and working on projections, the proposed approach can be used to widen the applicability of classical region-based techniques. © 2009 Springer Berlin Heidelberg. 

Does process mining add to internal auditing? An experience report In this paper we report on our experiences of applying business process mining in a real business context. The context for the application is using process mining for the purpose of internal auditing of a procurement cycle in a large multinational financial institution. One of the targeted outcomes of an internal audit is often the reporting on internal controls over financial reporting (ICFR), since this reporting is mandatory for Sarbanes-Oxley regulated organisations. Our process mining analyses resulted in more identified issues concerning ICFR than the traditional auditing approach. Issues that were identified using process mining analysis concerned violations of the segregation of duties principle, payments without approval, and violations of company specific internal procedures. © 2011 Springer-Verlag. control monitoring; internal audit; process mining

Domain-driven data mining for IT infrastructure support Support analytics (i.e., statistical analysis, modeling and mining of customer/operations support tickets data) is important in service industries. In this paper, we adopt a domain-driven data mining approach to support analytics with a focus on IT infrastructure Support (ITIS) services. We identify specific business questions and then propose algorithms for answering them. The questions are: (1) How to reduce the overall workload? (2) How to improve efforts spent in ticket processing? (3) How to improve compliance to service level agreements? We propose novel formalizations of these notions and propose rigorous statistics-based algorithms for these questions. The approach is domain-driven in the sense that the results produced are directly usable by and easy to understand for end-users having no expertise in data-mining, do not require any experimentation and often discover novel and non-obvious answers. All this helps in better acceptance among end-users and more active use of the results produced. The algorithms have been implemented and have produced satisfactory results on more than 25 real-life ITIS datasets, one of which we use for illustration. © 2010 IEEE. Business process improvements; Customer support; Domain-driven data-mining; IT infrastructure support; ITIL; Support analytics

DTMiner: A Tool for Decision Making Based on Historical Process Data Process mining is a discipline that uses techniques to extract knowledge from event logs recorded by information systems in most companies these days. Among main perspectives of process mining, organizational and time perspectives focus on information about resources stored on the event logs and timing and frequency of the events, respectively. In this paper we introduce a method that combines organizational and time perspectives of process mining with a decision support tool called decision trees. The method takes the information of historical process data by means of an event log, generates a decision tree, annotates the decision tree with processing times, and recommends the best performer for a given running instance of the process. We finally illustrate the method through several experiments using a developed plug-in for the process mining framework ProM, first using synthetic data and then using a real-life event log. process mining tool; decision tree; decision making; recommendation

Dynamic time warping in analysis of student behavioral patterns E-learning systems store large amount of data based on the history of users' interactions with the system. These pieces of information are usually used for further course optimization, finding e-tutors in collaboration learning, analysis of students' behavior, or for other purposes. The paper deals with an analysis of students' behavior in learning management system. The main goal of the paper is to find, how selected methods can influence finding of behavioral patterns in learning management system and how we can reduce the amount of extracted sequences. The methods of process mining and sequential pattern mining were used for extraction of behavioral patterns. The authors present the comparison of selected methods for the definition of students' behavior with the focus to influence of dynamic time warping. Obtained patterns and relations between them are presented using complex networks; the visualization and pattern clusters extraction is optimized by spectral graph partitioning. 

Effect of Temporal Relationships in Associative Rule Mining for Web Log Data The advent of web-based applications and services has created such diverse and voluminous web log data stored in web servers, proxy servers, client machines, or organizational databases. This paper attempts to investigate the effect of temporal attribute in relational rule mining for web log data. We incorporated the characteristics of time in the rule mining process and analysed the effect of various temporal parameters. The rules generated from temporal relational rule mining are then compared against the rules generated from the classical rule mining approach such as the Apriori and FP-Growth algorithms. The results showed that by incorporating the temporal attribute via time, the number of rules generated is subsequently smaller but is comparable in terms of quality. 

Effective Active Learning Strategies for the Use of Large-Margin Classifiers in Semantic Annotation: An Optimal Parameter Discovery Perspective Classical supervised machine learning techniques have been explored for semantically annotating unstructured textual data such as consumers' comments archived at social media websites to extract business intelligence. However, these techniques often require a large number of manually labeled training examples to produce accurate annotations. Several active learning approaches that are designed based on probabilistic sequence models have been explored to minimize the number of labeled training examples for semantic annotation tasks. Recent research has shown that large-margin classifiers are viable alternatives to automated semantic annotation, given their strong generalization capabilities and the ability to process high-dimensional data. However, the existing active learning methods that are designed for probabilistic sequence models cannot be easily adapted and applied to large-margin classifiers. The main contribution of this paper is the development of novel active learning methods for large-margin classifiers to fill the aforementioned research gap. In particular, we propose an innovative perspective of taking active learning as a search of optimal parameters for large-margin classifiers. A rigorous evaluation involving two benchmark tests and an empirical test based on real-world data extracted from Amazon.com reveals that the proposed active learning methods can train effective classifiers with significantly fewer training examples while achieving similar annotation performance, compared to a typical state-of-the-art classifier that only uses several labeled training examples. More specifically, one of our proposed active learning methods can reduce the number of training examples by 19.74% at the 68% level of F 1 when compared to the best baseline method, as evaluated based on the Amazon data set. Our research opens the door to the application of intelligent semantic annotation techniques to support real-world applications such as automatically analyzing consumer comments for customer relationship management. 

Effects of architecture and technical development process on micro-process Current software development methodologies (such as agile and RUP) are largely management-centred, macro-process life-cycle models. While they may include some fine-grained micro-process development practices, they usually provide little concrete guidance on appropriate microprocess level day-to-day development activities. The major factors that affect such micro-process activities are not well understood. We propose that software architecture and technical development processes are two major factors. We describe how these two factors affect micro-process activities. We validate our claim by mining micro-processes from two commercial projects and investigating relationships with software architecture and technical development processes. © Springer-Verlag Berlin Heidelberg 2007. Architecture; Macro-process; Micro-process; Process mining

Efficiency calculation of mined web navigational patterns The proposed work does a web utility mining process for identifying the useful web navigation patterns. An optimal prefix tree is generated from the log file details and the mining is performed. From the set of mined web navigational patterns the efficiency is found by considering certain parameters. The parameters like frequency, utility, downloads, book mark, selection are considered for each web page and efficiency for the web navigation pattern is found. The work is done by using real data set extracted from an e-commerce web site and with synthetic data set. This provides a better analysis of the web site. The result provided by this proposed work can be used or various application in developing the web site contents. Non sequential pattern; Pattern weight; Sequential pattern; Utility; Web path traversal

Efficient discovery of understandable declarative process models from event logs Process mining techniques often reveal that real-life processes are more variable than anticipated. Although declarative process models are more suitable for less structured processes, most discovery techniques generate conventional procedural models. In this paper, we focus on discovering Declare models based on event logs. A Declare model is composed of temporal constraints. Despite the suitability of declarative process models for less structured processes, their discovery is far from trivial. Even for smaller processes there are many potential constraints. Moreover, there may be many constraints that are trivially true and that do not characterize the process well. Naively checking all possible constraints is computationally intractable and may lead to models with an excessive number of constraints. Therefore, we have developed an Apriori algorithm to reduce the search space. Moreover, we use new metrics to prune the model. As a result, we can quickly generate understandable Declare models for real-life event logs. © 2012 Springer-Verlag Berlin Heidelberg. business process management; declarative process models; process mining

Efficient selection of process mining algorithms While many process mining algorithms have been proposed recently, there does not exist a widely accepted benchmark to evaluate and compare these process mining algorithms. As a result, it can be difficult to choose a suitable process mining algorithm for a given enterprise or application domain. Some recent benchmark systems have been developed and proposed to address this issue. However, evaluating available process mining algorithms against a large set of business models (e.g., in a large enterprise) can be computationally expensive, tedious, and time-consuming. This paper investigates a scalable solution that can evaluate, compare, and rank these process mining algorithms efficiently, and hence proposes a novel framework that can efficiently select the process mining algorithms that are most suitable for a given model set. In particular, using our framework, only a portion of process models need empirical evaluation and others can be recommended directly via a regression model. As a further optimization, this paper also proposes a metric and technique to select high-quality reference models to derive an effective regression model. Experiments using artificial and real data sets show that our approach is practical and outperforms the traditional approach. © 2008-2012 IEEE. benchmark; Business process mining; evaluation

Efficient ticket routing by resolution sequence mining IT problem management calls for quick identification of resolvers to reported problems. The efficiency of this process highly depends on ticket routing - -transferring problem ticket among various expert groups in search of the right resolver to the ticket. To achieve efficient ticket routing, wise decision needs to be made at each step of ticket transfer to determine which expert group is likely to be, or to lead to the resolver. In this paper, we address the possibility of improving ticket routing efficiency by mining ticket resolution sequences alone, without accessing ticket content. To demonstrate this possibility, a Markov model is developed to statistically capture the right decisions that have been made toward problem resolution, where the order of the Markov model is carefully chosen according to the conditional entropy obtained from ticket data. We also design a search algorithm, called Variable-order Multiple active State search(VMS), that generates ticket transfer recommendations based on our model. The proposed framework is evaluated on a large set of real-world problem tickets. The results demonstrate that VMS significantly improves human decisions: Problem resolvers can often be identified with fewer ticket transfers. © 2008 ACM. Markov model; Sequence mining; Workflow mining and optimization

Email analytics for activity management and insight discovery Emails constitute the bulk of all official communications in any organization. Email repositories are tacit store-houses of knowledge about people, projects and processes. Mining one's own email repository can also provide interesting and valuable insights about his or her engagements and contacts along different dimensions. In this paper, we propose an email analytics framework that combines text-mining, network analysis and data analytics principles to mine email repositories for useful insights. While individuals are more attuned to looking at emails as individual items along with a history that is embedded in the trail, mining the whole collection can also lead to knowledge discovery about similarities and dissimilarities of different engagements. This in turn can lead to valuable information like comparative status reports on various projects or deeper insights about why certain projects succeed while others don't. Given the volumes, diversity and noisy nature of e-mails, it becomes impossible for human beings to comprehend the impact of all of it unless the task is automated and approached in a structured fashion. We show that combination of text and network analytics along with temporal reasoning can provide valuable insights about task-states, actionable items, recommendations and forecasts. These insights can be exploited very effectively for project-management tasks like automated identification of bottlenecks or their causes, elimination of inefficiencies, early-warnings and suggestions about proactive measures to avoid problems. It is possible to extend the framework quite easily to analyze multiple email repositories of different users, though this work does not address the privacy or security concerns that might exist. © 2013 IEEE. Clustering; Email-analytics; Fourier transform; Locality sensitive hashing; Temporal-analysis

EMail Mining: Knowledge intensive process discovery through e-mails Process-Oriented Knowledge Management aims at identifying, modeling, analyzing and refining Knowledge Intensive Processes (KIP). The amount of knowledge embedded in the execution of the activities within these processes constitutes the essence of organizational knowledge, what makes the discovery of the KIP relevant as primary support for knowledge management. Information shared while using collaborative tools - such as e-mails - are important sources for understanding KIP. This paper presents eMail Mining, a method for the automatic discovery of relevant information that characterizes knowledge intensive processes, from the informal exchange of existing knowledge in e-mails. © 2012 IEEE. Knowledge Intensive Process; Natural Language Processing; Process Mining

Empirical assessment of business model transformations based on model simulation Business processes are recognized by organizations as one of the most important intangible assets, since they let organizations improve their competitiveness. Business processes are supported by enterprise information systems, which can evolve over time and embed particular business rules that are not present anywhere else. Thus, there are many organizations with inaccurate business processes, which prevent the modernization of enterprise information systems in line with the business processes that they support. Therefore, business process mining techniques are often used to retrieve reliable business processes from the event logs recorded during the execution of enterprise systems. Unfortunately, such event logs are represented with purpose-specific notations such as Mining XML and still don't apply the recent software modernization standard: ISO 19506 (KDM, Knowledge Discovery Metamodel). This paper presents an exogenous model transformation between these two notations. The main advantage is that process mining techniques can be effectively reused within software modernization projects according to the standard notation. This paper is particularly focused on the empirical evaluation of this transformation by simulating different kinds of business process models and several event logs with different sizes and configurations from such models. After analyzing all the model transformation executions, the study demonstrates that the transformation can provide suitable KDM models in a linear time in accordance with the size of the input models. © 2012 Springer-Verlag. Business Processes; Event Logs; Knowledge Discovery Metamodel; Model Simulation

Empirical discovery of potential value leaks in processes by means of formal concept analysis Process improvement programs rely heavily on various techniques for the identification of deficiencies in the processes and for the explanation of their root causes, in order to formulate adequate remediating actions. Six-sigma and Lean Management approaches are useful statistical techniques in this context. In the practical application of such techniques, the process analyst is often restricted by the semantic expressiveness of the process analysis models. Many popular process modeling techniques also suffer from limitations in the adequate representation of probabilistic behavior in processes. The latter is important, for example, for detecting the impact of exceptions and variations in processes. In this paper additional techniques are proposed based on Formal Concept Analysis (FCA). This is primarily based on the semantic richness of FCA-schema's, which are algebraic lattices. It is shown how many-to-many transitions in processes can easily be identified in an FCA-based Process representation. These transitions are not only the expression of potential Value Leaks as they also lead to explanations of their root causes. The techniques described in this paper are not a replacement, but rather an augmentation for Six-sigma and Lean Management approaches. In the paper several examples that are known in the Process Mining literature are presented and discussed. The techniques that are proposed are scalable and extend easily to large scale examples. © 2013 IEEE. Economic value leak; Formal concept analysis; Process deficiencies; Process discovery

End-to-end process extraction in process unaware systems Knowledge of current business processes is a critical requirement for organizational initiatives like compliance management, regulatory reporting, process optimization, reengineering the IT systems and outsourcing. Existing process discovery techniques expect process execution information or event logs while organization's business processes are often executed on heterogeneous systems across different departments, by integration and data hand-offs between systems. Traditional information systems, however, are designed for storing and processing transaction data which persists in databases and other data storage mechanisms. In this paper we identify the challenges and propose a solution for extracting end-to-end processes from persistent process execution data available in multiple heterogeneous applications. The approach consists of analyzing persistent system data to identify and obtain events in a non-intrusive manner. The approach to get the end-to-end process involves a combination of data and process mining. © 2013 Springer-Verlag Berlin Heidelberg. 

Enhance process flexibility by case-based reasoning and process mining Current process models are hard to describe uncertain factors in applications before run-time, which results in inflexibility of Process-Aware Information Systems. For this problem, a method to achieve process flexibility by underspecification based on so-called flexible block was proposed. The flexible block is running in ad hoc manner firstly, then it's inside process structure is gotten through process mining after the running history data accumulated to a degree. And then, the application scenarios were matched, and the process model of flexible block was educed through interactive case-based reasoning. Practices indicate the approach proposed by this paper can reuse the modeling knowledge very well. Modeling efficiency of flexible block is improved along with the increase of its executing times. The business process models contained flexible blocks are with high flexibility. ©2009 IEEE. Business process model; Flexibility; Interactive case-based reasoning; Process mining

Enhanced CFPMA approach for mining frequent patterns in web log data The World Wide Web resulted in a huge amount of data that are accessed by different users. This large quantity of web traffic should be handled effectively to acquire desired information. Web usage mining discovers the activities of the users while they are navigating through the web. The web usage mining process is essential for efficient web site management, personalization, business and support services, and network traffic flow analysis, etc. The useful information about the navigational behavior of users can be acquired by employing frequent pattern discovery approaches in web log data. In this paper, an enhanced Conviction Frequent Pattern Mining Algorithm (CFPMA) is proposed to manage huge volume of web traffic and to extract useful data. The approach identifies frequent itemsets in the web log data. The Least Byte (LB) prediction technique is used in the proposed method to acquire candidate itemsets that are processed further to extract frequent patterns. The frequent patterns are evaluated based on the conviction threshold value. The experimental results show that the proposed CFPMA technique achieves low execution time and higher accuracy when compared with the other existing methods. Candidate itemset; Conviction value; Frequent patterns; Least byte record; Web log file; Web usage mining

Enhancing decision patterns dicovered by process mining with semantic related data Business processes can be automatic, semiautomatic or manual processes. Semi-automatic and manual processes are involved in some parts by people. Understanding how people work or make judgments in processes can help management to evaluate their performance and suggest essential information to enhance their decision making. This paper describes a case study of using process mining to discover decision patterns of a worker in a semi-automatic business process. It was found that the discovered rules could be improved by enhancing the business execution log file with semantic related data. The experimental results before and after improvements were compared. Decision making; Decision pattern; Log enhancing; Process mining; Semantic related attribute

Enhancing declare maps based on event correlations Traditionally, most process mining techniques aim at discovering procedural process models (e.g., Petri nets, BPMN, and EPCs) from event data. However, the variability present in less-structured flexible processes complicates the discovery of such procedural models. The "open world" assumption used by declarative models makes it easier to handle this variability. However, initial attempts to automatically discover declarative process models result in cluttered diagrams showing misleading constraints. Moreover, additional data attributes in event logs are not used to discover meaningful causalities. In this paper, we use correlations to prune constraints and to disambiguate event associations. As a result, the discovered process maps only show the more meaningful constraints. Moreover, the data attributes used for correlation and disambiguation are also used to find discriminatory patterns, identify outliers, and analyze bottlenecks (e.g., when do people violate constraints or miss deadlines). The approach has been implemented in ProM and experiments demonstrate the improved quality of process maps and diagnostics. © 2013 Springer-Verlag. 

Enhancing precision in Process Conformance: Stability, confidence and severity Process Conformance is becoming a crucial area due to the changing nature of processes within an Information System. By confronting specifications against system executions (the main problem tackled in process conformance), both system bugs and obsolete/incorrect specifications can be revealed. This paper presents novel techniques to enrich the process conformance analysis for the precision dimension. The new features of the metric proposed in this paper provides a complete view of the precision between a log and a model. The techniques have been implemented as a plug-in in an open-source Process Mining platform and experimental results witnessing both the theory and the goals of this work are presented. © 2011 IEEE. 

Enhancing the digital data retrieval system using novel techniques The increase of crime rate around the globe projects the accuracy lag in the current techniques which are followed in process of retrieving and analyzing stored information in the cache gathered from varied channels of communication systems for the digital investigation systems. Taking these accuracy lags as a primary issue the principle objective for the development of this strategically organized system by renewing the existing procedural oriented system and to develop a genuine and a user-friendly framework on crime related information mining system which is mainly objected to extract and inspect appropriate information from cache memory which assimilates emails, chat threads and any text messages for the discovery of the criminal tasks and solve the enigma with the help of the validity concealed within the data. This procedural orientated system is built by merging of the three aspects employed to the data which is given as the input for textual evidencing which are the mails, text messages, chat threads, etc. The three procedural features are, the segregation of the body and header part of the textual corpuses containing all kinds of textual proofs from variety of communication channels which is accomplished using PHP script concept of regular expressions and along with which preprocessing of text to the body portion of the input corpus is done by stemming and tokenization processes, in order to increase the reliability in the text mining process and for the convenience to the forensic departments of investigation in criminology. The final aspect is the search technique implemented in this methodology which is built for the most highly effective and efficient data retrieval process. Even though the followed procedure is an ancient technique in this procedure which is the segregation of body and header in a mail, the primary aspect of this methodology focuses on building an efficient search engine for the purpose of effectiveness in retrieval. For the effective search engine a hybrid algorithm inherited from various other old searching algorithms is used for improvement of the system. This algorithm constitutes of three features mainly; it uses bit-parallelism simulation of the suffix automaton of xR, it is the alternative form of the Reverse Factor algorithm and if the pattern length is not longer than the memory-word size of the system efficiency in rate of retrieval is high. A procedural methodical would be bought by the utilization of this kind of technique to improvise the existing system initiating the searching system which is highly efficacious; the efficiency of this algorithm for searching is evidenced by its complexity of time and memory and with its values of precision and recall. Integrating all the factors specified would assist in easier reviewing of the text documents. © 2005 - 2014 JATIT &amp; LLS. All rights reserved. Information retrieval; Preprocessing; Stemming; Textual evidences; Tokenization

Enterprise data architecture principles for high-level Multi-Int fusion: A pragmatic guide for implementing a heterogeneous data exploitation framework Databases have been an integral component of Data Fusion from the outset when the JDL model was introduced. As advances in High-Level fusion using Multi-Int data have been made, the original concept of databases as a static repository of Level 0/1 content has evolved to support heterogeneous data, and as a necessary enabler of High-Level fusion processes. Relatively recent database technologies now support specialized storage for complex content such as multi-media, geospatial, and semantic data types. Additionally, database functionality has been extended from what was once almost exclusively storage and retrieval, to include integrated forensic and predictive algorithms, as well as decision support frameworks such as the data cube. These data mining capabilities provide a rich tool-set from which to tailor a fusion application. However, due to their inherent trade-off space, they present a significant design and integration challenge when implementing an enterprise architecture, which has to provide a comprehensive and cohesive framework across the entire fusion workflow, and which has to meet the needs of various Communities-of- Interest. This paper expounds on the role of data architecture as a key discipline to help analyze and synthesize an enterprise fusion system-of-systems, and presents selected principles to maximize heterogeneous data exploitation. © 2012 ISIF (Intl Society of Information Fusi). Data Analytics; Data Mining; High-Level Fusion

ERP event log preprocessing: Timestamps vs. accounting logic Process mining has been gaining significant attention in academia and practice. A promising first step to apply process mining in the audit domain was taken with the mining of process instances from accounting data. However, the resulting process instances constitute graphs. Commonly, timestamp oriented event log formats require a sequential list of activities and do not support graph structures. Thus, event log based process mining techniques cannot readily be applied to accounting data. To close this gap, we present an algorithm that determines an activity sequence from accounting data. With this algorithm, mined process instance graphs can be decomposed in a way they fit into sequential event log formats. Event log based process mining techniques can then be used to construct process models. A case study demonstrates the effectiveness of the presented approach. Results reveal that the preprocessing of the event logs considerably improves the derived process models. © 2013 Springer-Verlag. ERP Accounting Data; Log File Preprocessing; Process Instances; Process Mining

Event-log-data-based method for efficiency evaluation of block assembly processes in shipbuilding industry This paper proposes an event-log-data-based method for efficiency evaluation of block assembly processes in the shipbuilding industry. The method utilizes accumulated event logs from production system data to evaluate the relative efficiencies among various blocks, and provides guidelines for the efficiency improvement of inefficient blocks. To demonstrate the proposed method, it was applied to actual event-log data from the 'A' shipbuilding company in Korea. © 2014 ICIC International. Block assembly; Data envelopment analysis (DEA); Efficiency evaluation; Improvement; Process mining

Evolutionary learning of business process models from legacy systems using incremental process mining Incremental Process Mining is a recent research area that brings flexibility and agility to discover process models from legacy systems. Some algorithms have been proposed to perform incremental mining of process models. However, these algorithms do not provide all aspects of evolutionary learning, such as update and exclusion of elements from a process model. This happens when updates in the process definition occur, forcing a model already discovered to be refreshed. This paper presents new techniques to perform incremental mining of execution logs. It enables the discovery of changes in the process instances, keeping the discovered process model synchronized with the process being executed. Discovery results can be used in various ways by business analysts and software architects, e.g. documentation of legacy systems or for re-engineering purposes. Evolutionary learning; Incremental process mining; Legacy systems; Process mining

Examining Learner Control in a Structured Inquiry Cycle Using Process Mining High potential variation in prior knowledge, metacognitive skills, and motivation within learner populations can prompt design strategies that combine explicit structuring and scaffolding with increased learner control. We examine the use of such a strategy-a structured inquiry cycle-in a corpus of online modules (50) for adult informal learners using process mining. We apply process analysis techniques previously demonstrated by others to formative assessment data from the modules. We then use process modeling for mining module deliveries (N=5617) to investigate learner control within the inquiry cycle as a whole. Our experience suggests roles for these techniques beyond assessing conformity, both for design reflection and in preparation for deeper inquiry on self-regulation. 

Exploiting inductive logic programming techniques for declarative process mining In the last few years, there has been a growing interest in the adoption of declarative paradigms for modeling and verifying process models. These paradigms provide an abstract and human understandable way of specifying constraints that must hold among activities executions rather than focusing on a specific procedural solution. Mining such declarative descriptions is still an open challenge. In this paper, we present a logic-based approach for tackling this problem. It relies on Inductive Logic Programming techniques and, in particular, on a modified version of the Inductive Constraint Logic algorithm. We investigate how, by properly tuning the learning algorithm, the approach can be adopted to mine models expressed in the ConDec notation, a graphical language for the declarative specification of business processes. Then, we sketch how such a mining framework has been concretely implemented as a ProM plug-in called DecMiner. We finally discuss the effectiveness of the approach by means of an example which shows the ability of the language to model concurrent activities and of DecMiner to learn such a model. © 2009 Springer. 

Exploration and analysis of undocumented processes using heterogeneous and unstructured business data The business world has become more dynamic than ever before. Global competition and today's rapid pace of development in many fields has led to shorter time-to-market intervals, as well as more complex products and services. These developments do often imply impromptu changes to existing business processes. These dynamics are aggravated when unforeseen paths have to be taken like it is often the case when problems are solved in customer support situations. This leads to undocumented business processes which pose a serious problem for management. In order to cope with this problem the discipline of Process Mining has emerged. In classical Process Mining, event logs generated for example by workflow management systems are used to create a process model. In order for classical Process Mining to work, the process therefore has to be implemented in such a system, it just lacks documentation. The above mentioned impromptu changes and impromptu processes do, however, lack any such documentation. In many cases event logs do not exist, at least not in the strict sense of the definition. Instead, traces left by a process might include unstructured data, such as emails or notes in a human readable format. In this paper we will demonstrate how it is possible to search and locate processes that exist in a company, but that are neither documented, nor implemented in any business process management system. The idea is to use all data stores in a company to find a trace of a process instance and to reconstruct and visualize it. The trace of this single instance is then generalized to a process template that covers all instances of that process. This generalization step generates a description that can manually be adapted in order to fit all process instances. While retrieving instances from structured data can be described by simple queries, retrieving process steps from unstructured data often requires more elaborate approaches. Hence, we have modified a search-engine to combine a simple word-search with ad-hoc ontologies that allow for defining synonym relations on a query-by-query basis. © 2014 IEEE. heterogeneous business data; ontology; Process Discovery; Process Mining; semantic layer; synonym search

Exploring regulatory processes during a computer-supported collaborative learning task using process mining The purpose of this study was to explore sequences of social regulatory processes during a computer-supported collaborative learning task and their relationship to group performance. Analogous to self-regulation during individual learning, we conceptualized social regulation both as individual and as collaborative activities of analyzing, planning, monitoring and evaluating cognitive and motivational aspects during collaborative learning. We analyzed the data of 42 participants working together in dyads. They had 90 min to develop a common handout on a statistical topic while communicating only via chat and common editor. The log files of chat and editor were coded regarding activities of social regulation. Results show that participants in dyads with higher group performance (N = 20) did not differ from participants with lower group performance (N = 22) in the frequencies of regulatory activities. In an exploratory way, we used process mining to identify process patterns for high versus low group performance dyads. The resulting models show clear parallels between high and low achieving dyads in a double loop of working on the task, monitoring, and coordinating. Moreover, there are no major differences in the process of high versus low achieving dyads. Both results are discussed with regard to theoretical and empirical issues. Furthermore, the method of process mining is discussed. © 2012 Elsevier Ltd. All rights reserved. Computer-supported collaborative learning; Process mining; Research methods; Self-regulated learning; Social regulation

Exploring the CSCW spectrum using process mining Process mining techniques allow for extracting information from event logs. For example, the audit trails of a workflow management system or the transaction logs of an enterprise resource planning system can be used to discover models describing processes, organizations, and products. Traditionally, process mining has been applied to structured processes. In this paper, we argue that process mining can also be applied to less structured processes supported by computer supported cooperative work (CSCW) systems. In addition, the ProM framework is described. Using ProM a wide variety of process mining activities are supported ranging from process discovery and verification to conformance checking and social network analysis. © 2006 Elsevier Ltd. All rights reserved. Business activity monitoring; Business process intelligence; CSCW; Data mining; Process mining

Extending the a-algorithm to mine repetitive task based on complex structure Process mining is helpful for deploying new business processes as well as auditing, analyzing and improving the already enacted ones. The business process system log often has a large number of the namesake task and repetitive task. The existing alpha algorithm of the mining algorithm cannot distinguish them very well. It leads to the results that the process mining often produce inaccurate flow model. In order to improve the accuracy of the process mining, the paper puts forward an improved method. The new method not only can dig the complex structure, such as circulation structure, free choice structure and so on, it still can dig the eponymous task and repeat task in the log. © (2014) Trans Tech Publications, Switzerland. Complex structure; Namesake task; Process mining; Repetitive task

Extracting real-life log with data perspective in PLM system for business process analysis Event log is the important starting point of any process analysis technique. Existent business process analysis techniques are applied mainly to manual or simulated logs, considering mainly information about control perspective. In this paper, we first analyze the feature of data perspective of PLM (Product Lifecycle Management) system in manufacturing area, and extend the MXML format to support the log with data perspective information in PLM domain. Subsequently, we introduce an approach of data cleaning to separate the multi-version process information in real-life data set. In the end, we produce real-life log with information about data perspective in PLM system, then, mine the process model from real-life log and evaluate the proposed approach by fitness measuring. © 2008 IEEE. 

Extracting workflow structures through Bayesian learning and provenance data Mining workflow models has been a problem of interest for the past few years. Event logs have been the main source of data for the mining process. Previous workflow mining approaches mostly focused on mining control flows that were based on data mining methods, as well as exploited time constraints of events to discover the workflow models. In this work, we present a mining approach which not only takes the behaviourial aspect of workflows into account, but also takes advantage of their informational perspective. Provenance information is a source of reasoning, learning, and analysis since it provides information regarding the service inputs, outputs and quality of service values. Therefore, provenance information along with Bayesian structure-learning methods are exploited for this purpose. Two constraint-based Bayesian structure-learning algorithms are investigated and modified in order to make use of additional provenance information. We will show that this leads to better mining results based on three common mining scenarios. 

Facilitating operational control of business services: A method for analysing and structuring customer integration The efficient delivery of services is a major task for service companies to survive in competition. But, services are characterised by the integration of customers in the process of service delivery. In this context, operational control of business services is an important issue as business service performance often suffers from operational problems caused by customers involved. In order to react, a service company has to identify the possible options for operational control clearly. This is not easy as the impact of customer integration is ambiguous. To facilitate this, a method for analysing and structuring customer integration in business services is proposed. The aim is to cluster, quantify and qualify customer integration in business services from a production point of view. Applying this method (as demonstrated using a real business service) operational control will be facilitated due to a better transparency of customer integration. © 2010 Michael Leyer and Jürgen Moormann. Operational control; Performance management; Process mining; Service

Facilitating wasteful activities discovery in pure service environment through usage of process mining This paper describes the possibilities of using process mining in order to facilitate the discovery of wasteful activities (in terms of lean service) in pure service organizations. The specificities of pure service systems will be analyzed, with special focus on value creation and wasteful activities in service organizations. Existing process mining algorithms can be applied to event logs (cases that have been completed, i.e. "post-mortem" cases) created by Enterprise Systems in order to discover wasteful activities and flow interruptions. Process mining application can also be extended to operational support of lean transformation (partial cases), in order to analyze cases that have not yet been completed ("pre-mortem" cases) and predict the appearance of wasteful activities and to recommend suitable actions for minimizing possible wastes. Lean transformation; Process mining; Wastes

Federated enactment of workflow patterns In this paper we address two research questions concerning workflows: 1) how do we abstract and catalogue recurring workflow patterns?; and 2) how do we facilitate optimisation of the mapping from workflow patterns to actual resources at runtime? Our aim here is to explore techniques that are applicable to large-scale workflow compositions, where the resources could change dynamically during the lifetime of an application. We achieve this by introducing a registry-based mechanism where pattern abstractions are catalogued and stored. In conjunction with an enactment engine, which communicates with this registry, concrete computational implementations and resources are assigned to these patterns, conditional to the execution parameters. Using a data mining application from the life sciences, we demonstrate this new approach. © 2010 Springer-Verlag. 

Finding suitable activity clusters for decomposed process discovery Event data can be found in any information system and provide the starting point for a range of process mining techniques. The widespread availability of large amounts of event data also creates new challenges. Existing process mining techniques are often unable to handle "big event data" adequately. Decomposed process mining aims to solve this problem by decomposing the process mining problem into many smaller problems which can be solved in less time, using less resources, or even in parallel. Many decomposed process mining techniques have been proposed in literature. Analysis shows that even though the decomposition step takes a relatively small amount of time, it is of key importance in finding a high-quality process model and for the computation time required to discover the individual parts. Currently there is no way to assess the quality of a decomposition beforehand. We define three quality notions that can be used to assess a decomposition, before using it to discover a model or check conformance with. We then propose a decomposition approach that uses these notions and is able to find a high-quality decomposition in little time. Decomposed process discovery; Decomposed process mining; Distributed computing; Event log

Framework, strategy and evaluation of health care processes with RFID The working environment in health care organizations is characterized by its demand for highly dynamic process and labor management in which (a) medical personnel are generally associated with several disparate types of tasks, (b) service location and service personnel change frequently, (c) highly uncertain environment where emergency issues could arise at any time, and (d) the stakes are high since invaluable human lives are involved. There is an urgent need from both researchers and health care organizations to develop reasonable management strategies for maintaining a good balance between efficient management and superior medical service quality. We discuss the potential for real-time health care coordination and effective medical process and labor management enabled by RFID item-level tracking/tracing identification technology. We explore the uniqueness of instance-level process mining and its application in health care environment. We then propose an adaptive learning framework that supports real-time health care coordination and analyze its benefits compared to traditional routine process and labor management. We find that while RFID-enabled real-time medical process and labor management provides marginal improvement for premium medical service providers, it generates appreciable improvement both in terms of efficiency and service quality for public health care institutions where availability of necessary resources such as medical staff and equipment are highly constrained. © 2010 Elsevier B.V. All rights reserved. Health care; RFID

Fraud detection in process aware systems In the last years, some large companies have been involved in scandals related to financial mismanagement, which represented a large financial damage to their stockholders. To recover market confidence, certifications for best practices of governance were developed, and in some cases, harder laws were implemented. Companies adhered to these changes as a response to the market, deploying process aware systems (PAS) and adopting the best practices of governance. However, companies demand a rapid response to strategic changes or changes in business models between partners, which may impose serious drawbacks to the adoption of normative PAS to the competitiveness of these companies. Thus, while companies need flexible PAS, flexibility may compromise security. To re-balance the trade-off between security and flexibility, we present in this work an anomaly detection algorithm for PAS. The identification of anomalous events can help the adoption of flexible PAS without the loss of security properties. Copyright © 2011 Inderscience Enterprises Ltd. Anomaly detection; Flexible workflow systems; PAS; Process aware systems; Process mining

From local patterns to global models: Towards domain driven educational process mining Educational process mining (EPM) aims at (i) constructing complete and compact educational process models that are able to reproduce all observed behavior (process model discovery), (ii) checking whether the modeled behavior (either pre-authored or discovered from data) matches the observed behavior (conformance checking), and (iii) projecting information extracted from the logs onto the model, to make the tacit knowledge explicit and facilitate better understanding of the process (process model extension). In this paper we propose a new domain-driven framework for EPM which assumes that a set of pattern templates can be predefined to focus the mining in a desired way and make it more effective and efficient. We illustrate the ideas behind our approach with examples of academic curricular modeling, mining, and conformance checking, using the student database of our department. © 2009 IEEE. 

From petri nets to Guard-Stage-Milestone models Artifact-centric modeling is an approach for modeling business processes based on business artifacts, i.e., entities that are central for the company's operations. Existing process mining methods usually focus on traditional process-centric rather than artifact-centric models. Furthermore, currently no methods exist for discovering models in Guard-Stage-Milestone (GSM) notation from event logs. To bridge this gap, we propose a method for translating Petri Net models into GSM which gives the possibility to use the numerous existing algorithms for mining Petri Nets for discovering the life cycles of single artifacts and then generating GSM models. © 2013 Springer-Verlag Berlin Heidelberg. Artifact-Centric Modeling; Guard-Stage-Milestone; Petri Nets; Process Mining

Fuzzy mining - Adaptive process simplification based on multi-perspective metrics Process Mining is a technique for extracting process models from execution logs. This is particularly useful in situations where people have an idealized view of reality. Real-life processes turn out to be less structured than people tend to believe. Unfortunately, traditional process mining approaches have problems dealing with unstructured processes. The discovered models are often "spaghetti-like", showing all details without distinguishing what is important and what is not. This paper proposes a new process mining approach to overcome this problem. The approach is configurable and allows for different faithfully simplified views of a particular process. To do this, the concept of a roadmap is used as a metaphor. Just like different roadmaps provide suitable abstractions of reality, process models should provide meaningful abstractions of operational processes encountered in domains ranging from healthcare and logistics to web services and public administration. © Springer-Verlag Berlin Heidelberg 2007. 

Generating event logs from non-process-aware systems enabling business process mining As information systems age they become legacy information systems (LISs), embedding business knowledge not present in other artefacts. LISs must be modernised when their maintainability falls below acceptable limits but the embedded business knowledge is valuable information that must be preserved to align the modernised versions of LISs with organisations' real-world business processes. Business process mining permits the discovery and preservation of all meaningful embedded business knowledge by using event logs, which represent the business activities executed by an information system. Event logs can be easily obtained through the execution of process-aware information systems (PAISs). However, several non-process-aware information systems also implicitly support organisations' business processes. This article presents a technique for obtaining event logs from traditional information systems (without any in-built logging functionality) by statically analysing and modifying LISs. The technique allows the modified systems to dynamically record event logs. The approach is validated with a case study involving a healthcare information system used in Austrian hospitals, which shows the technique obtains event logs that effectively and efficiently enable the discovery of embedded business processes. This implies the techniques provided within the process mining field, which are based on event logs, may also be applied to traditional information systems. © 2011 Taylor & Francis. Dynamic analysis; Event log; Legacy system; Modernisation; Process mining

Generating event logs with workload-dependent speeds from simulation models Both simulation and process mining can be used to analyze operational business processes. Simulation is model-driven and very useful because different scenarios can be explored by changing the model's parameters. Process mining is driven by event data. This allows detailed analysis of the observed behavior showing actual bottlenecks, deviations, and other performance-related problems. Both techniques tend to focus on the control-flow and do not analyze resource behavior in a detailed manner. In this paper, we focus on workload-dependent processing speeds because of the well-known phenomenon that people perform best at a certain stress level. For example, the "Yerkes-Dodson Law of Arousal" states that people will take more time to execute an activity if there is little work to do. This paper shows how workload-dependent processing speeds can be incorporated in a simulation model and learned from event logs. We also show how event logs with workload-dependent behavior can be generated through simulation. Experiments show that it is crucial to incorporate such phenomena. Moreover, we advocate an amalgamation of simulation and process mining techniques to better understand, model, and improve real-life business processes. © 2012 Springer-Verlag. 

Genetic process mining The topic of process mining has attracted the attention of both researchers and tool vendors in the Business Process Management (BPM) space. The goal of process mining is to discover process models from event logs, i.e., events logged by some information system are used to extract information about activities and their causal relations. Several algorithms have been proposed for process mining. Many of these algorithms cannot deal with concurrency. Other typical problems are the presence of duplicate activities, hidden activities, non-free-choice constructs, etc. In addition, real-life logs contain noise (e.g., exceptions or incorrectly logged events) and are typically incomplete (i.e., the event logs contain only a fragment of all possible behaviors). To tackle these problems we propose a completely new approach based on genetic algorithms. As can be expected, a genetic approach is able to deal with noise and incompleteness. However, it is not easy to represent processes properly in a genetic setting. In this paper, we show a genetic process mining approach using the so-called causal matrix as a representation for individuals. We elaborate on the relation between Petri nets and this representation and show that genetic algorithms can be used to discover Petri net models from event logs. © Springer-Verlag Berlin Heidelberg 2005. Business Activity Monitoring; Business Process Intelligence; Genetic Algorithms; Petri Nets; Process Discovery; Process Mining

Genetic process mining: A basic approach and its challenges One of the aims of process mining is to retrieve a process model from a given event log. However, current techniques have problems when mining processes that contain non-trivial constructs and/or when dealing with the presence of noise in the logs. To overcome these problems, we try to use genetic algorithms to mine process models. The non-trivial constructs are tackled by choosing an internal representation that supports them. The noise problem is naturally tackled by the genetic algorithm because, per definition, these algorithms are robust to noise. The definition of a good fitness measure is the most critical challenge in a genetic approach. This paper presents the current status of our research and the pros and cons of the fitness measure that we used so far. Experiments show that the fitness measure leads to the mining of process models that can reproduce all the behavior in the log, but these mined models may also allow for extra behavior. In short, the current version of the genetic algorithm can already be used to mine process models, but future research is necessary to always ensure that the mined models do not allow for extra behavior. Thus, this paper also discusses some ideas for future research that could ensure that the mined models will always only reflect the behavior in the log. © Springer-Verlag Berlin Heidelberg 2006. Genetic algorithms; Genetic mining; Petri nets; Process mining; Workflow Petri nets

Genetic process mining: An experimental evaluation One of the aims of process mining is to retrieve a process model from an event log. The discovered models can be used as objective starting points during the deployment of process-aware information systems (Dumas et al., eds., Process-Aware Information Systems: Bridging People and Software Through Process Technology. Wiley, New York, 2005) and/or as a feedback mechanism to check prescribed models against enacted ones. However, current techniques have problems when mining processes that contain non-trivial constructs and/or when dealing with the presence of noise in the logs. Most of the problems happen because many current techniques are based on local information in the event log. To overcome these problems, we try to use genetic algorithms to mine process models. The main motivation is to benefit from the global search performed by this kind of algorithms. The non-trivial constructs are tackled by choosing an internal representation that supports them. The problem of noise is naturally tackled by the genetic algorithm because, per definition, these algorithms are robust to noise. The main challenge in a genetic approach is the definition of a good fitness measure because it guides the global search performed by the genetic algorithm. This paper explains how the genetic algorithm works. Experiments with synthetic and real-life logs show that the fitness measure indeed leads to the mining of process models that are complete (can reproduce all the behavior in the log) and precise (do not allow for extra behavior that cannot be derived from the event log). The genetic algorithm is implemented as a plug-in in the ProM framework. © Springer Science+Business Media, LLC 2007. Genetic algorithms; Genetic mining; Petri nets; Process mining; Workflow nets

Genetic-based anomaly detection in logs of process aware systems Nowaday's, many organizations use systems that support business process as a whole or partially. However, in some application domains, like software development and health care processes, a normative Process Aware System (PAS) is not suitable, because a flexible support is needed to respond rapidly to new process models. On the other hand, a flexible Process Aware System may be vulnerable to undesirable and fraudulent executions, which imposes a tradeoff between flexibility and security. In order to make this tradeoff available, a genetic-based anomaly detection model for logs of Process Aware Systems is presented in this paper. The detection of an anomalous trace is based on discovering an appropriate process model by using genetic process mining and detecting traces that do not fit the appropriate model as anomalous trace; therefore, when used in PAS, this model is an automated solution that can support coexistence of flexibility and security. Anomaly detection; Genetic algorithm; Process aware systems; Process mining

Getting a grasp on clinical pathway data: An approach based on process mining Since healthcare processes are pre-eminently heterogeneous and multi-disciplinary, information systems supporting these processes face important challenges in terms of design, implementation and diagnosis. Nonetheless, streamlining clinical pathways with the purpose of delivering high quality care while at the same time reducing costs is a promising goal. In this paper, we propose a methodology founded on process mining for intelligent analysis of clinical pathway data. Process mining can be considered a valuable approach to obtain a better understanding about the actual way of working in human-centric processes such as clinical pathways by investigating the event data as recorded in healthcare information systems. However, capturing tangible knowledge from clinical processes with their ad hoc and complex nature proves difficult. Accordingly, this paper proposes a data analysis methodology focussing on the extraction of tangible insights from clinical pathway data by adopting both a drill up and a drill down perspective. © 2013 Springer-Verlag. clinical pathways; event logs; fuzzy miner; healthcare information systems; process mining

Grasping product pragmatics: A case with internet on TV With the emergence of highly interactive products in the domestic space, consumer electronics brands are facing an increasing challenge in predicting the way their products are being used and experienced. Unforeseen experiences relating to functional, emotional and social/contextual aspects of product use lead to a large and increasing share of field complaints that cannot be attributed to a violation of products' specifications. In a project called Soft Reliability, we are trying to develop a product evaluation ecology that enables the anticipation of product use by gathering behavioral and attitudinal data early in the product development process, through longitudinal field studies with working prototypes. This paper introduces a novel framework for behavioral and attitudinal data collection and analysis. The framework enables instrumentation that relies on the event-based experience sampling method, and as such deploys an analysis methodology that includes process mining techniques for the analysis of usage patterns, multivariate techniques for the analysis of longitudinal attitudinal data, and product quality analysis techniques for the analysis of combined information. We illustrate the value and applicability of this framework in practice, through the findings of an ongoing project concerning the conceptualization of an innovative Internet on TV product, which is being conducted in collaboration with Philips, a multi-national consumer electronics company. Copyright 2008 ACM. Product conceptualization; Product usage logs; Soft reliability; Subjective user feedback; User experience evaluation

Handling concept drift in process mining Operational processes need to change to adapt to changing circumstances, e.g., new legislation, extreme variations in supply and demand, seasonal effects, etc. While the topic of flexibility is well-researched in the BPM domain, contemporary process mining approaches assume the process to be in steady state. When discovering a process model from event logs, it is assumed that the process at the beginning of the recorded period is the same as the process at the end of the recorded period. Obviously, this is often not the case due to the phenomenon known as concept drift. While cases are being handled, the process itself may be changing. This paper presents an approach to analyze such second-order dynamics. The approach has been implemented in ProM and evaluated by analyzing an evolving process. © 2011 Springer-Verlag. change patterns; concept drift; flexibility; process mining

Handover optimization in business processes via prediction Purpose: Process mining provides a new means to improve processes in a variety of application domains. The purpose of this paper is to abstract a process model and then use the discovered models from process mining to make useful optimization via predictions. Design/methodology/approach: The paper divides the process model into a combination of "pair-adjacent activities" and "pair-adjacent persons" in the event logs. First, two new handover process models based on adjacency matrix are proposed. Second, by adding the stage, frequency, and time for every activity or person into the matrix, another two new handover prediction process models based on stage adjacency matrix are further proposed. Third, compute the conditional probability from every stage to next stage through the frequency. Finally, use real data to analyze and demonstrate the practicality and effectiveness of the proposed handover optimization process. Findings: The process model can be extended with information to predict what will actually happen, how possible to reach the next activity, who will do this activity, and the corresponding probability if there are several people executing the same activity, etc. Originality/value: The contribution of this paper is to predict what will actually happen, how possible it is to reach the following activities or persons in the next stage, how soon to reach the following activities or persons by calculating all the possible interval time via different traces, who will do this activity, and the corresponding probability if there are several people executing the same activity, etc. © Emerald Group Publishing Limited. Adjacency matrix; Handover optimization; Process mining; Time prediction

Hardware accelerated cognitively enhanced complex event processing architecture Agent-based decision aids can improve their performance by mining domain knowledge captured in cognitive domain ontologies (CDOs). This paper introduces a cognitively enhanced complex event processing (CECEP) architecture to enable enhanced agent-based decision making. Additionally the paper examines the parallelization and acceleration of a key knowledge mining process within the architecture on high performance computing platforms. Speedups of almost a 1000 times were seen using 8 NVIDIA Tesla C2070 GPGPUs over 1 Xeon X5650 processor core. Speedups of this level will allow more complex knowledge domains to be searched in real time on reactive agents and thus enable systems with enhanced intelligence to be designed. © 2013 IEEE. Agent based decision aides; GPGPU; knowledge mining; multicore; parallelization

Healthcare process mining with RFID The working environment in health care organizations is characterized by its demand for highly dynamic human resource management in which (a) medical personnel are generally associated with several disparate types of tasks, (b) service location and service personnel change frequently, (c) emergency issues could arise at any time, and (d) the stakes are high since invaluable human lives are involved. There is an urgent need from both researchers and health care organizations to develop mechanisms for maintaining a good balance between efficient management and superior medical service quality. We discuss the potential for real-time health care coordination and effective medical human resource management enabled by event-driven RFID item-level tracking/tracing identification technology. We explore the uniqueness of instance-level process mining and its application in health care environment. We propose an adaptive learning framework that supports real-time health care coordination. © 2010 Springer-Verlag. healthcare; process mining; RFID

Heuristic mining: Adaptive process simplification in education Process mining techniques allow for extracting information from event logs. For example, the audit trails of a workflow management system or the transaction logs of an enterprise resource planning system can be used to discover models describing processes, organizations, and products. ProM is a generic tool for implementing process mining tools in a standard environment. Prom aims at improving this by providing techniques and tools for discovering process, organizational, social, and performance information from event logs. In this paper we introduce the challenging process mining domain and discuss a heuristics driven process mining algorithm; the so-called 'Heuristics Miner' in detail. Heuristics Miner is an applied applicable mining algorithm that can deal with noise, and can be used to express the main behavior registered in an event log. In the 'case study' section of this paper, we used an students' registration event log consisted of 299 cases and 569 events. The data was received from one of the universities in Thailand. Finally, the HM algorithm focused on the control flow perspective and generated a process model in the form of a Heuristics Net for the given event log. © 2012 IEEE. causal dependency relationship; Heuristics Miner plugin; Process Mining; students' registration process; workflow model

Hierarchical colored petri nets based components for workflow systems Workflow systems have benefited the enterprise and customer in many aspects. But with the increasing complexity of the system, workflow design becomes a complicated and time-consuming process. In this paper, we model the system based on the Hierarchical Colored Petri Nets (HCPN) to avoid the complexity of the system, and the super nets of the model are abstracted as independent components to increase the flexibility, acceptability and maintainability of the system. Another important characteristic of this model is its convenience for reuse and workflow mining. The development process of the overhead traveling crane was given to demonstrate the proposed method. Component; Hierarchical colored petri nets; Workflow; Workflow mining

Hierarchical conformance checking of process models based on event logs Process mining techniques aim to extract knowledge from event logs. Conformance checking is one of the hard problems in process mining: it aims to diagnose and quantify the mismatch between observed and modeled behavior. Precise conformance checking implies solving complex optimization problems and is therefore computationally challenging for real-life event logs. In this paper a technique to apply hierarchical conformance checking is presented, based on a state-of-the-art algorithm for deriving the subprocesses structure underlying a process model. Hierarchical conformance checking allows us to decompose problems that would otherwise be intractable. Moreover, users can navigate through conformance results and zoom into parts of the model that have a poor conformance. The technique has been implemented as a ProM plugin and an experimental evaluation showing the significance of the approach is provided. © 2013 Springer-Verlag. Conformance Checking; Process Diagnosis; Process Mining

Historical map polygon and feature extractor Polygon and attribute data extraction from historical maps such as US insurance atlases from the 19th and early 20th centuries has so far been a manual task. The New York Public Library (NYPL) currently relies on staff and volunteer work to manually extract polygons and other attribute data from its collection to create new public data sets for the study of urban history. This is a time-intensive task requiring up to several minutes to trace a shapefile and transcribe attributes for a single building. In this paper we propose an approach to automatically extract such attribute data from historical maps. The approach makes use of multiple image processing and statistics utilities to produce desirable results in a fraction of the time required to do by hand. On average, a shapefile for an atlas sheet is generated in ~11.4 minutes for a total of 23.5 hours of processing time for a whole atlas that contains ~55,000 polygons; contrast this time frame to NYPL's current manual process that has taken three years to extract about 170,000 polygons across four New York City street atlases. Even with some error rate in the proposed approach, the most cumbersome, time-intensive work (manual polygon drawing) has been reduced to a fraction of its original scope. This new workflow has promising implications for historical GIS. Copyright is held by the owner/author(s). Alpha shapes; Attribute data extraction; Map image tracing

Host-based anomaly detection for pervasive medical systems Intrusion detection systems are deployed on hosts in a computing infrastructure to tackle undesired events in the course of usage of the systems. One of the promising domains of applying intrusion detection is the healthcare domain. A typical healthcare scenario is characterized by high degree of mobility, frequent interruptions and above all demands access to sensitive medical records by concerned stakeholders. Migrating this set of concerns in pervasive healthcare environments where the traditional characteristics are more intensified in terms of uncertainty, one ends up with more challenges on security due to nature of pervasive devices and wireless communication media along with classic security problems for desktop based systems. Despite evolution of automated healthcare services and sophistication of attacks against such services, there is a reasonable lack of techniques, tools and experimental setups for protecting hosts against intrusive actions. This paper presents a contribution to provide a host-based, anomaly modeling and detection approach based on data mining techniques for pervasive healthcare systems. The technique maintains normal usage profile of pervasive healthcare applications and inspects current workflow against normal usage profile so as to classify it as anomalous or normal. The technique is implemented as a prototype with sample data set and the results obtained revealed that the technique is able to perform classification of anomalous activities. © 2010 IEEE. Data Mining; Intrusion Detection Systems; Pervasive Medical Systems; Security

Hybrid genetic algorithm and association rules for mining workflow best practices Business workflow analysis has become crucial in strategizing how to create competitive edge. Consequently, deriving a series of positively correlated association rules from workflows is essential to identify strong relationships among key business activities. These rules can subsequently, serve as best practices. We have addressed this problem by hybridizing genetic algorithm with association rules. First, we used correlation to replace support-confidence in genetic algorithm to enable dynamic data-driven determination of support and confidence, i.e.; use correlation to optimize the derivation of positively correlated association rules. Second, we used correlation as fitness function to support upward closure in association rules (hitherto, association rules support only downward closure). The ability to support upward closure allows derivation of the most specific association rules (business model) from less specific association rules (business meta-model) and generic association rules (reference meta-model). Downward closure allows the opposite. Upward-downward closures allow the manager to drill-down and analyze based on the degree of dependency among business activities. Subsequently, association rules can be used to describe best practices at the model, meta-model and reference meta-model levels with the most general positively dependent association rules as reference meta-model. Experiments are based on an online hotel reservation system. © 2012 Elsevier Ltd. All rights reserved. Business intelligence; Development-methodology-business models; DSS development-functionality; E-commerce; Genetic algorithm; Performance measurement

Hybrid particle swarm optimization method for process mining This paper presents a bio-inspired hybrid method that extracts the optimal or a near-optimal business process model from an event log. The proposed method combines Particle Swarm Optimization with Simulated Annealing to optimize the mining process in terms of execution time and model quality. To evaluate a candidate business process model we use a fitness function that considers as evaluation criteria the model completeness and preciseness according to the cases in the event log. The bio-inspired hybrid method has been integrated in the PROM framework and evaluated on a set of event logs. © 2012 IEEE. 

Hybrid technique for user's web page access prediction based on Markov model Web Mining consists of three different categories, namely Web Content Mining, Web Structure Mining, and Web Usage Mining (is the process of discovering knowledge from the interaction generated by the users in the form of access logs, browser logs, proxy-server logs, user session data, cookies). This paper present mining process of web server log files in order to extract usage patterns to web link prediction with the help of proposed Markov Model. The approaches result in prediction of popular web page or stage and user navigation behavior. Proposed technique cluster user navigation based on their pair-wise similarity measure combined with markov model with the concept of apriori algorithm which is used for Web link prediction is the process to predict the Web pages to be visited by a user based on the Web pages previously visited by other user. So that Web pre-fetching techniques reduces the web latency & they predict the web object to be pre-fetched with high accuracy and good scalability also help to achieve better predictive accuracy among different log file The evolutionary approach helps to train the model to make predictions commensurate to current web browsing patterns. © 2013 IEEE. Apriori Algorithm; Clustering; Markov Model; Web Access prediction; Web Log Files

Identification of process-based fraud patterns in credit application Fraud detection has become an important research topic recently. In a credit application, fraud can occur in forgery of documents or business processes. Fraud on the business process is known as Process-based Fraud (PBF). Previous studies proposed several detection methods of fraud in the business process model. This fraud detection includes analysis methods and an identification process. However, none of them proposed PBF identification, particularly identification of PBF attributes and pattern clearly, so its accuracy still needs further improvement. As identification of PBF attributes and PBF pattern is very important for the accuracy of PBF detection, this paper proposes an identification method for PBF detection. This PBF identification process consists of some attributes, those are skip sequence, skip decision, throughput time minimum, throughput time maximum, wrong resource, wrong duty decision, wrong duty sequence, wrong duty combine, wrong pattern and wrong decision. In this paper, PBF pattern is combined with a fuzzy set which consists of low, middle and high categories. This fuzzy set is implemented in order to improve the accuracy of PBF determination. PBF attribute and its pattern contribute to the process mining for detecting PBF. Fraud detection; Fuzzy set; PBF attribut; PBF Pattern; Process-Bases Fraud

Identifying drivers of inefficiency in business processes: A DEA and Data Mining perspective Measuring the performance of business processes in the financial services sector can be tackled from different perspectives. The viewpoint of efficiency is one of them. This paper focuses on the analysis of process efficiency and proposes a new methodology for measuring process efficiency and for further identifying drivers of process inefficiency. It is suitable for a specific perspective on process efficiency. The methodology is based on Data Envelopment Analysis (DEA) and methods from Data Mining. It aims to find strong association rules between process transactions' characteristics and inefficiency values. This approach enables the identification of drivers of inefficiency from a (large) dataset of transactions without any prior assumptions about potential determinants of inefficiency. The methodology is applicable to business processes supported by workflow management systems and it can serve as the basis for an add-on system allowing structural analysis of process inefficiency and its drivers. © 2010 Springer-Verlag Berlin Heidelberg. Data Envelopment Analysis; Data mining; Efficiency drivers; Process efficiency

Identifying influential factors of business process performance using dependency analysis We present a comprehensive framework for identifying influential factors of business process performance. In particular, our approach combines monitoring of process events and Quality of Service (QoS) measurements with dependency analysis to effectively identify influential factors. The framework uses data mining techniques to construct tree structures to represent dependencies of a key performance indicator (KPI) on process and QoS metrics. These dependency trees allow business analysts to determine how process KPIs depend on lower-level process metrics and QoS characteristics of the IT infrastructure. The structure of the dependencies enables a drill-down analysis of single factors of influence to gain a deeper knowledge why certain KPI targets are not met. © 2011 Taylor & Francis. Data mining; Decision tree; KPI; Process performance monitoring; QoS; Service composition

Implementing organization-wide gemba using noninvasive process mining Lean promotes gemba, a Japanese term that means "go and see." Gemba represents the search for knowledge; it helps us understand the execution of processes, why certain activities take the time they take, who is involved in the activities, and so on. Gemba promotes a culture of measurement, a culture that wants to understand the best strategy to achieve a given goal. In this article, we describe how practitioners can use noninvasive (i.e., without human interaction) measurement in combination with process mining to understand the real process that is carried out as opposed to the documented, ideal process. Process mining implements "go and see" since it does not beautify the reality -- it shows it as it is. We will explore the question, "How can we exploit gemba, the discipline of getting and understanding data within the organization, on an holistic level?" 

Improved artificial negative event generation to enhance process event logs Process mining is the research area that is concerned with knowledge discovery from event logs. Process mining faces notable difficulties. One is that process mining is commonly limited to the harder setting of unsupervised learning, since negative information about state transitions that were prevented from taking place (i.e. negative events) is often unavailable in real-life event logs. We propose a method to enhance process event logs with artificially generated negative events, striving towards the induction of a set of negative examples that is both correct (containing no false negative events) and complete (containing all, non-trivial negative events). Such generated sets of negative events can advantageously be applied for discovery and evaluation purposes, and in auditing and compliance settings. © 2012 Springer-Verlag Berlin Heidelberg. event logs; negative events; process discovery; process mining

Improving business intelligence based on frequent itemsets using k-means clustering algorithm In this world, each and every activity is enriched with lot of information. Business and other organization needs information for better decision making. Business Intelligence is a set of methods, process and technologies that transform raw data into meaningful and useful information. Some of the functions of business intelligence technologies are reporting, Online Analytical Processing, Online Transaction processing, data mining, process mining, complex event processing, business performance management, benchmarking and text mining. The applications of business intelligence includes E-commerce recommender system, approval of bank loan, credit/debit card fraud detection etc., In order to obtain business intelligence from large dataset there many techniques are available in data mining such as characterization, discrimination, frequent itemset mining, outlier analysis, cluster analysis and so on. In this proposed algorithm frequent itemset mining and clustering algorithm is used to extract the information from the dataset in order to make the decision making process more efficient and to improve the business intelligence. © 2014 Springer International Publishing Switzerland. 

Improving business process decision making based on past experience Business processes entail a large number of decisions that affect their business performance. The criteria used in these decisions are not always formally specified and optimized. The paper develops a semi-automated approach that improves the business performance of processes by deriving decision criteria from the experience gained through past process executions. The premise that drives the approach is that it is possible to identify a process path that would yield best performance at a given context. The approach uses data mining techniques to identify the relationships between context, path decisions, and process outcomes, and derives decision rules from these relationships. It is evaluated using a simulation of a manufacturing process, whose results demonstrate the potential of improving the business performance through the rules generated by the approach. © 2013 Elsevier B.V. All rights reserved. Business process; Context; Decision making; Decision tree; Goal

Improving business process models with agent-based simulation and process mining Business processes are usually modeled at a high level of abstraction, while the analysis of their run-time behavior through process mining techniques is based on low-level events recorded in an event log. In this scenario, it is difficult to discover the relationship between the process model and the run-time behavior, and to check whether the model is actually a good representation for that behavior. In this work, we introduce an approach that is able to capture such relationship in a hierarchical model. In addition, through a combination of process mining and agent-based simulation, the approach supports the improvement of the process model so that it becomes a better representation for the behavior of agents in the process. For this purpose, the model is evaluated based on a set of metrics. We illustrate the approach in an application scenario involving a purchase process. © 2013 Springer-Verlag. 

Improving genetic process mining using Honey Bee algorithm Process mining refers to the extraction of process models from event logs. This paper presents a new process mining approach based on the combination of Honey Bee algorithm and Genetic Algorithm in which the benefits of Honey Bee algorithm is used where the concept of neighborhood search for a solution emerges from intelligent behavior of honeybee and the diversity of Genetic algorithm to find the global optimum. The new process mining approach presented in this paper is implemented as a plug-in in the process mining framework http://www.processmining.org. Computational experiments show that the process mining approach present in this paper gives a significant improvement over the basic Genetic algorithm. © 2013 IEEE. Data mining; Genetic Algorithm; Honey Bee Algorithm; Petri nets; Process Mining

Improving process models by mining mappings of low-level events to high-level activities While it is possible to analyze the run-time behavior of a business process through process mining techniques, in practice there is often a gap between the low-level nature of the events recorded in an event log and the high-level of abstraction at which the process is modeled. This makes it difficult to understand the recorded behavior in terms of the high-level activities in the process model. Also, it makes it difficult to improve the model based on run-time data about the process. In this work we present an approach to mine mappings between the events in the log and the activities in the model. These mappings can be used to generate suggestions of how the process model can be extended in order to capture the behavior recorded in the event log. Using a real-world and publicly available event log, we show how the approach can improve the model in a stepwise manner, until it covers all the behavior recorded in the event log. Business process modeling; Model enhancement; Process mining; Recommendation systems

Improving product usage monitoring and analysis with semantic concepts Nowadays, complex electronic products, such as DVD players or mobile phones, offer a huge number of functions. As a consequence of the complexity of the devices, customers often have problems to use such products effectively. For example, it has been observed that an increasing number of technically sound products is returned due to, e.g., interaction problems. One possible root cause of this problem is that most product development processes are still too technology-driven, i.e., potential users are brought into contact with the product only at a very late stage. If early consumer tests are carried out, then these typically aim at abstract market evaluations rather than formulating concrete requirements towards the functionality of the product. As a result, products often have little meaning or relevance to the customers. Therefore, we need better ways to involve users in the development of such products. This can be achieved by observing product usage in the field and incorporating the gained knowledge in the product creation process. This paper proposes an approach to build automatic observation modules into products, collect usage data, and analyze these data by means of process mining techniques exploiting a novel semantic link between observation and analysis. This link yields two main benefits: (i) it adds focus to the potential mass of captured data items; and (ii) it reduces the need for extensive post-processing of the collected data. Together with the framework's flexibility to change observation modules remotely on-the-fly, these benefits speed up the information feedback cycle towards development. © 2009 Springer Berlin Heidelberg. Log analysis; Ontologies; Process mining; Product monitoring; Semantic process mining

Improving structural medical process comparison by exploiting domain knowledge and mined information Objectives: Process model comparison and similar process retrieval is a key issue to be addressed in many real-world situations, and a particularly relevant one in medical applications, where similarity quantification can be exploited to accomplish goals such as conformance checking, local process adaptation analysis, and hospital ranking. In this paper, we present a framework that allows the user to: (i) mine the actual process model from a database of process execution traces available at a given hospital; and (ii) compare (mined) process models. The tool is currently being applied in stroke management. Methods: Our framework relies on process mining to extract process-related information (i.e., process models) from data. As for process comparison, we have modified a state-of-the-art structural similarity metric by exploiting: (i) domain knowledge; (ii) process mining outputs and statistical temporal information. These changes were meant to make the metric more suited to the medical domain. Results: Experimental results showed that our metric outperforms the original one, and generated output closer than that provided by a stroke management expert. In particular, our metric correctly rated 11 out of 15 mined hospital models with respect to a given query. On the other hand, the original metric correctly rated only 7 out of 15 models. The experiments also showed that the framework can support stroke management experts in answering key research questions: in particular, average patient improvement decreased as the distance (according to our metric) from the top level hospital process model increased. Conclusions: The paper shows that process mining and process comparison, through a similarity metric tailored to medical applications, can be applied successfully to clinical data to gain a better understanding of different medical processes adopted by different hospitals, and of their impact on clinical outcomes. In the future, we plan to make our metric even more general and efficient, by explicitly considering various methodological and technological extensions. We will also test the framework in different domains. © 2014 Elsevier B.V. All rights reserved. Graph edit distance; Process mining and comparison; Stroke management

Improving structure: Logical sequencing of mined process models The increasing availability of digital data offers new opportunities for analyzing business processes. Process aware information systems like Enterprise Resource Planning systems store data in the course of transaction processing. This data can be exploited by using process mining techniques. Process mining algorithms produce process models by analyzing recorded event logs. A fundamental challenge in process mining is the creation of purpose-oriented and useful process models. Process mining algorithms commonly refer to the temporal ordering of events for determining the control flow in reconstructed process models. We show how the logical sequence of events can be used instead of the temporal for reconstructing the control flow in mined process models. The exploitation of the logical structure of available event log records opens up new ways to receive purpose-oriented, less complex, and more informative process models. © 2014 IEEE. 

Improving the quality of the Heuristics Miner in ProM 6.2 Considering the presence of large amounts of data in organizations today, the need to transform this data into useful information and subsequently into knowledge, increasingly gains attention. Process discovery is a technique to automatically discover process models from data in event logs. Since process discovery is gaining attention among researchers as well as practitioners, the quality of the resulting process model must be assured. In this paper, the quality of the frequently used Heuristics Miner is improved as anomalies were found concerning the validity and completeness of the resulting process model. For this purpose, a new artifact called the Updated Heuristics Miner was constructed containing alterations to the tool and to the algorithm itself. Evaluations of this artifact resulted in the conclusion that the Updated Heuristics Miner indeed demonstrates higher validity and completeness. This study contributes to the body of knowledge first by improving the quality of the an often used research instrument and second by stating that there is a need for a systematic developing and evaluation method for process discovery techniques. © 2014 Elsevier Ltd. All rights reserved. Completeness; Heuristics Miner; Knowledge discovery; Process mining; Quality; Validity

Incorporating user behavior patterns to discover workflow models from event logs We propose a novel approach to discover workflow models from event logs. The proposed approach addresses two major limitations of current process mining approaches. First, they assume either a single workflow model for the entire event log or the availability of workflow ids that can be used to group logs associated with the same workflow model together. Nonetheless, these assumptions are oversimplified as a complex system typically runs multiple workflow models, all of which share the same log system. Second, existing process mining approaches do not consider the usage patterns of workflow users. Most systems support multi-users and each user is typically associated with (or use) certain number of operation sequences, which may all follow one or several workflow models. Hence, we propose to leverage User Behavior Patterns (or UBPs) to improve the outcome of process mining. In particular, we exploit machine learning techniques to incorporate UBPs into sequence clustering for workflow model discovery. We model a UBP as a probabilistic distribution on sequences, which allows to compute the distance between a UBP and any sequence. We apply three-way matrix factorization onto a UBP-sequence distance matrix to co-cluster users and sequences. In this way, users that share similar UBPs are grouped together while the clustering of similar sequences will lead to the discovery of workflow models. An comprehensive experimental study is conducted to demonstrate the effectiveness and efficiency of the proposed approach. © 2013 IEEE. co-clustering; probabilistic suffix tree; process mining; workflow model discovery

Incremental mining of processes with loops Currently most researches in process mining focus on discovering a workflow model from an entire log. In fact, the process designers may have a partially built model and their prior knowledge is also valuable information to process mining. Besides, the large volume of log data makes the process mining a time-consuming job. It is better that the process mining be done in an incremental way. There are only a few methods that can incrementally mine a model, but they have their limitations such as incapability in handling loops or being intolerant to noise. On the other hand, loop mining is a challenging problem in process mining because the repeatedly executed tasks add complexity to the search for task precedence. This paper studies the problem of handling loops in process mining and proposes an improved incremental process mining method which supports loops. Experiments in the end show the feasibility and validity of the proposed method. © 2011 World Scientific Publishing Company. incremental mining; loop; Process mining; workflow model

Incremental workflow mining based on document versioning information Current enterprises spend much effort to obtain precise models of their system engineering processes in order to improve the process capability of the organization. The manual design of workflow models is complicated, time-consuming and error-prone; capabilities of human beings in detecting discrepancies between the actual process and the process model are rather limited. Therefore, automatic techniques for deriving these models are becoming more and more important. In this paper, we present an idea that exploits the user interaction with a version management system for the incremental automatic derivation, refinement and analysis of process models. Though this idea is not fully worked out yet, we sketch the architecture of the solution and the algorithms, for the main steps of incremental automatic derivation of process models. © Springer-Verlag Berlin Heidelberg 2005. 

Incremental workflow mining with optional patterns For today's business organizations, workflow models play important roles in analyzing the productivity, evaluating the performances and costs, optimizing the business operations, and supporting evolving services and products. Workflow mining, the process of empirically extracting structured process descriptions from a set of real executions, thus has attracted a lot of attention recently. However, there are several challenges that have not been fully addressed in the previous research: i) How can we mine process models with optional tasks? ii) How can we efficiently use new available workflow log data to incrementally update pre-existing workflow models or to complete previous partial process models? iii) How can we compare two different workflow models of similar organizations? In this paper, we present our research efforts to address the above challenges. We present a workflow mining algorithm that is able to mine process models with optional tasks and propose an incremental workflow mining algorithm based on intermediate relationships such as ordering and independence. The intermediate relationships can also be used to facilitate the comparison of two process models. We illustrate our algorithms on example data derived from real world applications. © 2006 IEEE. 

Inducing declarative logic-based models from labeled traces In this work we propose an approach for the automatic discovery of logic-based models starting from a set of process execution traces. The approach is based on a modified Inductive Logic Programming algorithm, capable of learning a set of declarative rules. The advantage of using a declarative description is twofold. First, the process is represented in an intuitive and easily readable way; second, a family of proof procedures associated to the chosen language can be used to support the monitoring and management of processes (conformance testing, properties verification and interoperability checking, in particular). The approach consists in first learning integrity constraints expressed as logical formulas and then translating them into a declarative graphical language named DecSerFlow. We demonstrate the viability of the approach by applying it to a real dataset from a health case process and to an artificial dataset from an e-commerce protocol. © Springer-Verlag Berlin Heidelberg 2007. Careflow; DecSerFlow; Logic programming; Process mining; Process verification and validation

Industrial application of semantic process mining Process mining relates to the extraction of non-trivial and useful information from information system event logs. It is a new research discipline that has evolved significantly since the early work on idealistic process logs. Over the last years, process mining prototypes have incorporated elements from semantics and data mining and targeted visualisation techniques that are more user-friendly to business experts and process owners. In this article, we present a framework for evaluating different aspects of enterprise process flows and address practical challenges of state-of-the-art industrial process mining. We also explore the inherent strengths of the technology for more efficient process optimisation. © 2012 Copyright Taylor and Francis Group, LLC. business process intelligence; business process management; data mining; ontologies; process analysis; process mining; process models; semantics

Information and communication technology for process management in healthcare: A contribution to change the culture of blame Statistics on medical errors and their consequences has astonished, during the previous years, both healthcare professionals and ordinary people. Mass-media are becoming more and more sensitive to medical malpractices. This paper elaborates on the well-known resistance of the medical world to disclose actions and processes that could have caused some damages; it illustrates the possible causes of medical errors and, for some of them, it suggests solutions based on information and communication technology. In particular, careflow management systems and process mining techniques are proposed as a means to improve the healthcare delivery process: the former by facilitating task assignments and resource management, the latter by discovering not only individuals' errors, but also the chains of responsibilities concurring to produce errors in a complex patient's pathway. Both supervised and unsupervised process mining will be addressed. The former compares real processes with a known process model (e.g., a clinical practice guideline or a medical protocol), whereas the latter mines processes from raw data, without imposing any model. The potentiality of these techniques is illustrated by means of examples from stroke patient management. Copyright © 2010 John Wiley & Sons, Ltd. Careflow management systems; Clinical practice guidelines; Healthcare process management; Medical errors; Risk management

Information System Risk Auditing Model Based on Process Mining The basic function of audit is finding risk and preventing fraud from occurring as well as maintaining healthy, safe operation of enterprise and even the whole economy. By combining process mining techniques and risk management theory and using the technique of obtaining evidence on fraud risk as a trial, this paper takes business process risk auditing of process-aware information systems as its research goal. The paper aims to find out faults in the business process and audit evidence. It also aims to propose process mining-based risk auditing models of information systems from the perspective of workflow and in allusion to complicated business process. This paper identifies risk and implements continuous audit and monitor as well as searches risk auditing mechanisms and risk control method by using consistency analysis between actual business process and pre-designed business. continuous auditing; continuous monitoring; process mining; risk auditing mechanism

Insuring sensitive processes through process mining Any system, company or complex task is composed by processes, i.e., sequences of actions performed in some established order. Some of these processes are considered sensitive for the role they play within the system, or for the sensitive data they manage. In such cases, the trust in this processes is desirable, requiring their verification, monitoring, auditing, but also the possibility of being insured by a third party. In this approach we propose a schema for insuring sensitive process based on the use of formal models and Process Mining techniques (i.e. process management techniques that allows for the analysis of processes based on event logs). The experimental results presented show that this new approach could be useful in the context of insurance and analysis of processes. © 2012 IEEE. Accountability;; Insurance schema; Process mining; Risk; Trust model

Integrating computer log files for process mining: A genetic algorithm inspired technique Process mining techniques are applied to single computer log files. But many processes are supported by different software tools and are by consequence recorded into multiple log files. Therefore it would be interesting to find a way to automatically combine such a set of log files for one process. In this paper we describe a technique for merging log files based on a genetic algorithm. We show with a generated test case that this technique works and we give an extended overview of which research is needed to optimise and validate this technique. © 2011 Springer-Verlag. Business Process Modeling; Log File Merging; Process Discovery; Process Mining; Tool-Support for Modeling

Integrating event logs into KDM repositories Business knowledge embedded in legacy information systems is a valuable asset that must be recovered and preserved when these systems are modernized. Event logs register the execution of business activities supported by existing information systems, thus they entail a key artifact to be used for recovering the actual business processes. There exists a wide variety of techniques to discover business processes by reversing event logs. Unfortunately, event logs are typically represented with particular notations such as Mining XML (MXML) rather than the recent software modernization standard Knowledge Discovery Metamodel (KDM). Process mining techniques consequently cannot be effectively reused within software modernization projects. This paper proposes an automatic technique to transform MXML event logs into event models to be integrated into KDM repositories. Its main implication is the exploitation of valuable event logs by well-proven software modernization techniques. The model transformation has been validated through a case study involving several benchmark event logs. © 2012 ACM. business process; event logs; knowledge discovery metamodel; model-driven reengineering

Integration and reuse of data mining in business processes - A pattern-based approach Today's business applications demand high flexibility in processing information and extracting knowledge from data. Thus, data mining becomes more and more an integral part of operating a business. However, the integration of data mining into business processes still requires a lot of coordination and manual adjustment. This paper aims at reducing this effort by reusing successful data mining solutions. We describe a novel approach to facilitating the integration based on process patterns for data mining and demonstrate that these patterns allow for easy reuse and can significantly speed up the process of integration. We empirically evaluate our approach in a case study of fraud detection in the healthcare domain. Copyright © 2011 Inderscience Enterprises Ltd. BPM; Business processes; CRISP; Data mining patterns; Integration; Reuse

Intelligent mininig for capturing processes through event logs to represent workflows using FP tree Data mining applications require an ability to understand unfiltered data embedded in event logs. The scalability of the data, end-user comprehensibility of the results, non-presumption of any canonical data distribution, and insensitivity to the order of input records will determine efficiency of data mining. Contemporary workflow management systems are driven by explicit process models based on completely specified workflow designs. Creating a workflow design is a complicated time-consuming process and typically there are discrepancies between the actual workflow processes and the processes as perceived by the management. In this paper, we propose a Process Mining Architecture (PROARCH) model which involves capturing processes in a system through event logs containing information about the different processes under execution. We assume that events in logs bear timestamps. But these logs will also contain log of unformatted data which may be dirty data for our model. Hence this information needs to be filtered before further processing. After filtering, the clean data is represented in MXML format and will serve as input to our model. This MXML data is parsed into a Petri net representation. The nodes and transitions, are connected to form a workflow representation. Since the initial input logs are dirty we use FP tree approach to build our workflow model. ©2007 IEEE. Data mining; FP tree; Process mining; Workflows

Intentional process mining: Discovering and modeling the goals behind processes using supervised learning Understanding people's goals is a challenging issue that is met in many different areas such as security, sales, information retrieval, etc. Intention Mining aims at uncovering intentions from observations of actual activities. While most Intention Mining techniques proposed so far focus on mining individual intentions to analyze web engine queries, this paper proposes a generic technique to mine intentions from activity traces. The proposed technique relies on supervised learning and generates intentional models specified with the Map formalism. The originality of the contribution lies in the demonstration that it is actually possible to reverse engineer the underlying intentional plans built by people when in action, and specify them in models e.g. with intentions at different levels, dependencies, links with other concepts, etc. After an introduction on intention mining, the paper presents the Supervised Map Miner Method and reports two controlled experiments that were undertaken to evaluate precision, recall and F-Score. The results are promising since the authors were able to find the intentions underlying the activities as well as the corresponding map process model with satisfying accuracy, efficiency and performance. Event Log; Goal Modeling; Hidden Markov Model; Intention Mining; Supervised Learning; Trace

Interaction pattern detection in process oriented information systems Finding interaction patterns is a challenging problem, but this kind of information about processes or social networks might be useful for an organization's management to understand the role of specific persons in processes. Ad-hoc processes are of special interest, because they result from runtime-collaboration between the participants, not using predefined models specifying the persons responsibilities and the order of activities. Because social network analysis (SNA) is closely related to interaction pattern detection, we introduce it as a method to determine properties of social networks like project teams. In order to support the detection of these patterns, we discuss the necessity of additional semantic activity information, and we propose rules and an algorithm that allow detecting such patterns automatically. We apply our algorithm in a case study, using Caramba to perform an example ad-hoc process. © 2006 Elsevier B.V. All rights reserved. Caramba; Interaction patterns; Pattern finding process; Process mining; Social network analysis

Intra- and inter-organizational process mining: Discovering processes within and between organizations Due to the availability of more and more event data and mature process mining techniques, it has become possible to discover the actual processes within an organization. Process mining techniques use event logs to automatically construct process models that explain the behavior observed. Existing process models can be validated using conformance checking techniques. Moreover, the link between real-life events and model elements allows for the projection of additional information onto process models (e.g., showing bottlenecks and the flow of work within an organization). Although process mining has been mainly used within individual organizations, this new technology can also be applied in cross-organizational settings. In this paper, we identify such settings and highlight some of the challenges and opportunities. In particular, we show that cross-organizational processes can be partitioned along two orthogonal dimensions. This helps us to identify relevant process mining challenges involving multiple organizations. © 2011 IFIP International Federation for Information Processing. business process management; cross-organizational mining; process mining

Is my event log complete? - A probabilistic approach to process mining Process mining is a technique for extracting process models from event logs recorded by information systems. Process mining approaches normally rely on the assumption that the log to be mined is complete. Checking log completeness is known to be a difficult issue. Except for some trivial cases, checkable criteria for log completeness are not known. We overcome this problem by taking a probabilistic point of view. In this paper, we propose a method to compute the probability that the event log is complete. Our method provides a probabilistic lower bound for log completeness for three subclasses of Petri nets, namely, workflow nets, T-workflow nets, and S-workflow nets. Furthermore, based upon the complete log obtained by our methods, we propose two specialized mining algorithms to discover T-workflow nets and S-workflow nets, respectively. We back up our theoretical work with empirical studies that show that the probabilistic bounds computed by our method are reliable. © 2011 IEEE. event log; Petri nets; probabilistic analysis; process mining; workflow management

KNNI-SVM: A hybrid algorithm integrating imputation and support vector machine for real-time business process monitoring Inductive data mining based approaches to process monitoring aim at investigating historical process logs and classifying the result of executed process. However, they show some limitations when applied to real-time monitoring such as late warnings or no real-time feedback capabilities. In order to alleviate such limitations, we propose a novel approach to real-time business process monitoring using a hybrid algorithm integrating support vector machine with k nearest neighbor imputation. By the proposed algorithm, an ongoing process instance is monitored through generated attributes and the final result of the instance is predicted based on them, which is iterated periodically as the ongoing instance progresses. Therefore, we can predict probable outcomes probabilistically based on the current progress. © 2011 ISSN 1881-803X. Business process; Imputation; Real-time monitoring; Support vector machine

Knowledge management in health care: An architectural framework for clinical process management systems This work describes the architectural framework of a clinical process management system. It supports the extraction, from textual documents, of ontologies, clinical processes and guidelines and allows their formal description using ontology and workflow representation languages. Clinical processes and guidelines are stored in a knowledge base and classified w.r.t. the concepts contained in the ontologies. Starting from this process-centered vision of health care practices the system is able to enhance cost control and patient safety, reducing risks due to medical errors and adverse events. The main goal of the system is to assist in executing the clinical processes by providing intelligence functionalities, based on workflow mining techniques, and in monitoring processes during their execution. Furthermore, acquired process instances can be analyzed to identify main causes of risks, to control costs and, potentially, to suggest clinical process restructuring or improvement. © 2005 IEEE. 

Learning frequent behaviors of the users in intelligent environments Intelligent environments (IEs) are expected to support people in their daily lives. One of the hidden assumptions in IEs is that they propose a change of perspective in the relationships between humans and technology, shifting from a techno-centered perspective to a human-centered one. Unlike current computing systems where the user has to learn how to use the technology, an IE adapts its behavior to the users, even anticipating their needs, preferences, or habits. For this reason, the environment should learn how to react to the actions and needs of the users, and this should be achieved in an unobtrusive and transparent way. In order to provide personalized and adapted services, it is necessary to know the preferences and habits of users. Thus, the ability to learn patterns of behavior becomes an essential aspect for the successful implementation of IEs. This paper presents a system, learning frequent patterns of user behavior system (LFPUBS), that discovers users' frequent behaviors taking into consideration the specific features of IEs. The core of LFPUBS is the learning layer, which, unlike some other components, is independent of the particular environment in which the system is being applied. On one hand, it includes a language that allows the representation of discovered behaviors in a clear and unambiguous way. On the other hand, coupled with the language, an algorithm that discovers frequent behaviors has been designed and implemented. For this reason, it uses association, workflow mining, clustering, and classification techniques. LFPUBS was validated using data collected from two real environments. In MavPad environment, LFPUBS was tested with different confidence levels using data collected in three different trials, whereas in a WSU Smart Apartment environment LFPUBS was able to discover a predefined behavior. © 2013 IEEE. Ambient intelligence; Intelligent environments; Machine learning techniques; Pattern learning

Learning probabilistic real-time automata from multi-attribute event logs The growing number of time-labeled datasets in science and industry increases the need for algorithms that automatically induce process models. Existing methods are capable of identifying process models that typically only work on single attribute events. We propose a new model type to address the problem of mining multi-attribute events, meaning that each event is described by a vector of attributes. The model is based on timed automata, includes expressive descriptions of states and can be used for making predictions. A probabilistic real time automaton is created, where each state is annotated by a profile of events. To identify the states of the automaton, similar events are combined by a clustering approach. The method was implemented and tested on a synthetic, a medical and a biological dataset. Its prediction accuracy was evaluated on a medical dataset and compared to a combined logistic regression, which is considered a standard in this application domain. Moreover, the method was experimentally compared to Multi-Output HMMs and Petri nets learned by standard process mining algorithms. The experimental comparison suggests that the automaton-based approach performs favorably in several dimensions. Most importantly, we show that meaningful medical and biological process knowledge can be extracted from such automata. Automata induction; clustering; multivariate time series

Learning workflow Petri nets Workflow mining is the task of automatically producing a workflow model from a set of event logs recording sequences of workflow events; each sequence corresponds to a use case or workflow instance. Formal approaches to workflow mining assume that the event log is complete (contains enough information to infer the workflow) which is often not the case. We present a learning approach that relaxes this assumption: if the event log is incomplete, our learning algorithm automatically derives queries about the executability of some event sequences. If a teacher answers these queries, the algorithm is guaranteed to terminate with a correct model. We provide matching upper and lower bounds on the number of queries required by the algorithm, and report on the application of an implementation to some examples. 

Learning workflow petri nets Workflow mining is the task of automatically producing a workflow model from a set of event logs recording sequences of workflow events; each sequence corresponds to a use case or workflow instance. Formal approaches to workflow mining assume that the event log is complete (contains enough information to infer the workflow) which is often not the case. We present a learning approach that relaxes this assumption: if the event log is incomplete, our learning algorithm automatically derives queries about the executability of some event sequences. If a teacher answers these queries, the algorithm is guaranteed to terminate with a correct model. We provide matching upper and lower bounds on the number of queries required by the algorithm, and report on the application of an implementation to some examples. © 2010 Springer-Verlag. 

Left-right oscillate algorithm for community detection used in e-learning system Learning management systems are widely used as a support of distance learning. Recently, these systems successfully help in present education as well. Learning management systems store large amount of data based on the history of users' interactions with the system. Obtained information is commonly used for further course optimization, finding e-tutors in collaboration learning, analysis of students' behavior, or for other purposes. The partial goal of the paper is an analysis of students' behavior in a learning management system. Students' behavior is defined using selected methods from sequential and process mining with the focus to the reduction of large amount of extracted sequences. The main goal of the paper is description of our Left-Right Oscillate algorithm for community detection. The usage of this algorithm is presented on the extracted sequences from the learning management system. The core of this work is based on spectral ordering. Spectral ordering is the first part of an algorithm used to seek out communities within selected, evaluated networks. More precise designations for communities are then monitored using modularity. © 2012 IFIP International Federation for Information Processing. 

Leveraging process discovery with trace clustering and text mining for intelligent analysis of incident management processes Recent years have witnessed the ability to gather an enormous amount of data in a large number of domains. Also in the field of business process management, there exists an urgent need to beneficially use these data to retrieve actionable knowledge about the actual way of working in the context of a certain business process. The research field concerned is process mining, which can be defined as a whole family of analysis techniques for extracting knowledge from information system event logs. In this paper, we present a solution strategy to leverage traditional process discovery techniques in the flexible environment of incident management processes. In such environments, it is typically observed that single model discovery techniques are incapable of dealing with the large number of different types of execution traces. Accordingly, we propose a combination of trace clustering and text mining to enhance process discovery techniques with the purpose of retrieving more useful insights from process data. © 2012 IEEE. 

Log based business process engineering using fuzzy web service discovery Business process engineering and mining is a technique that allows discovery, analysis and modeling of possible Business Processes based on information gathered from enterprise information systems. Most of currently available business process engineering and mining techniques either focus on machine learning techniques to mine, discover and model any possible Business Processes from raw data, or use semantically-enabled process models and service descriptions to construct and represent complex Business Processes. However, in real-life scenario, all the required services are not always available and hence exact matching of the services in order to construct Business Process is not possible. In this paper, we present our approach of using fuzzy Web Service discovery to construct and represent Business Processes. It helps in relaxing the matching criteria of Web Services, and allows service consumers to specify business requirements in a more fuzzy way, and hence increases the possibility of finding required Web Services that could construct Business Processes. The paper presents the proposed solution then reports and discusses the evaluation. © 2014 Elsevier B.V. All rights reserved. 

Log-based transactional workflow mining A continuous evolution of business process parameters, constraints and needs, hardly foreseeable initially, requires a continuous design from the business process management systems. In this article we are interested in developing a reactive design through process log analysis ensuring process re-engineering and execution reliability. We propose to analyse workflow logs to discover workflow transactional behaviour and to subsequently improve and correct related recovery mechanisms. Our approach starts by collecting workflow logs. Then, we build, by statistical analysis techniques, an intermediate representation specifying elementary dependencies between activities. These dependencies are refined to mine the transactional workflow model. The analysis of the discrepancies between the discovered model and the initially designed model enables us to detect design gaps, concerning particularly the recovery mechanisms. Thus, based on this mining step, we apply a set of rules on the initially designed workflow to improve workflow reliability. © 2009 Springer Science+Business Media, LLC. Business process analysis; Business process intelligence; Correction; Execution reliability; Process mining; Process reengineering; Transactional workflow; Workflow logs; Workflow mining; Workflow patterns

Logic-based incremental process mining in smart environments Understanding what the user is doing in a Smart Environment is important not only for adapting the environment behavior, e.g. by providing the most appropriate combination of services for the recognized situation, but also for identifying situations that could be problematic for the user. Manually building models of the user processes is a complex, costly and error-prone engineering task. Hence, the interest in automatically learning them from examples of actual procedures. Incremental adaptation of the models, and the ability to express/learn complex conditions on the involved tasks, are also desirable. First-order logic provides a single comprehensive and powerful framework for supporting all of the above. This paper presents a First-Order Logic incremental method for inferring process models, and show its application to the user's daily routines, for predicting his needs and comparing the actual situation with the expected one. Promising results have been obtained with both controlled experiments that proved its efficiency and effectiveness, and with a domain-specific dataset. © 2013 Springer-Verlag. 

MailOfMine - Analyzing mail messages for mining artful collaborative processes Artful processes are informal processes typically carried out by those people whose work is mental rather than physical (managers, professors, researchers, engineers, etc.), the so called "knowledge workers". In this paper we propose the MailOfMine approach, to automatically build, on top of a collection of email messages, a set of workflow models that represent the artful processes laying behind the knowledge workers activities. © 2012 IFIP International Federation for Information Processing. artful processes; declarative workflows; email analysis; knowledge workers; object matching; process mining; visual representation of processes

MANA: Identifying and mining unstructured business processes The process mining field supports the discovery of process models using audit trails logged by information systems. Several mining techniques are able to deal with unstructured processes, mainly through cluster analysis. However, they assume the previous extraction of an event log containing related instances. This task is not trivial when the source system doesn't provide a reliable separation of its processes and allows the input of data through free text fields. The identification of related instances should, in this case, be explorative and integrated into the process mining tool used in later stages of the analyst's workflow. To this goal, the MANA approach was developed, allowing the explorative selection and grouping of instances through a canonical database. © 2013 Springer-Verlag Berlin Heidelberg. Business Process Management; Process Discovery; Process Mining; Unstructured Processes

Mashups by orchestration and widget-based personal environments: Key challenges, solution strategies, and an application Purpose: Mashups have been studied extensively in the literature; nevertheless, the large body of work in this area focuses on service/data level integration and leaves UI level integration, hence UI mashups, almost unexplored. The latter generates digital environments in which participating sources exist as individual entities; member applications and data sources share the same graphical space particularly in the form of widgets. However, the true integration can only be realized through enabling widgets to be responsive to the events happening in each other. The authors call such an integration "widget orchestration" and the resulting application "mashup by orchestration". This article aims to explore and address challenges regarding the realization of widget-based UI mashups and UI level integration, prominently in terms of widget orchestration, and to assess their suitability for building web-based personal environments. Design/methodology/approach: The authors provide a holistic view on mashups and a theoretical grounding for widget-based personal environments. The authors identify the following challenges: widget interoperability, end-user data mobility as a basis for manual widget orchestration, user behavior mining - for extracting behavioral patterns - as a basis for automated widget orchestration, and infrastructure. The authors introduce functional widget interfaces for application interoperability, exploit semantic web technologies for data interoperability, and realize end-user data mobility on top of this interoperability framework. The authors employ semantically enhanced workflow/process mining techniques, along with Petri nets as a formal ground, for user behavior mining. The authors outline a reference platform and architecture that is compliant with the authors' strategies, and extend W3C widget specification respectively - prominently with a communication channel - to foster standardization. The authors evaluate their solution approaches regarding interoperability and infrastructure through a qualitative comparison with respect to existing literature, and provide a computational evaluation of the behavior mining approach. The authors realize a prototype for a widget-based personal learning environment for foreign language learning to demonstrate the feasibility of their solution strategies. The prototype is also used as a basis for the end-user assessment of widget-based personal environments and widget orchestration. Findings: The evaluation results suggest that the interoperability framework, platform, and architecture have certain advantages over existing approaches, and the proposed behavior mining techniques are adequate for the extraction of behavioral patterns. User assessments show that widget-based UI mashups with orchestration (i.e. mashups by orchestration) are promising for the creation of personal environments as well as for an enhanced user experience. Originality/value: This article provides an extensive exploration of mashups by orchestration and their role in the creation of personal environments. Key challenges are described, along with novel solution strategies to meet them. © Emerald Group Publishing Limited. Behavioral patterns; Foreign language learning; Language; Mashups; Ontologies; Personal environments; Petri nets; RDFa; Semantics; Widget orchestration; Workflow mining

Matching heterogeneous event data Identifying duplicate events are essential to various business process applications such as provenance querying or process mining. Distinct features of heterogeneous events including opaque names, dislocated traces and composite events, prevent existing data integration from techniques performing well. To address these issues, in this paper, we propose an event similarity function by iteratively evaluating similar neighbors. We prove the convergence of iterative similarity computation, and propose several pruning and estimation methods. To efficiently support matching composite events, we devise upper bounds of event similarities. Experiments on real and synthetic datasets demonstrate that the proposed event matching approaches can achieve significantly higher accuracy than the state-of-the-art matching methods. © 2014 ACM. Event matching; Schema matching

Matching observed behavior and modeled behavior: An approach based on Petri nets and integer programming Inspired by the way SAP R/3 and other transactional information systems log events, we focus on the problem to decide whether a process model and a frequency profile "fit" together. The problem is formulated in terms of Petri nets and an approach based on integer programming is proposed to tackle the problem. The integer program provides necessary conditions and, as shown in this paper, for relevant subclasses these conditions are sufficient. Unlike traditional approaches, the approach allows for labeled Petri nets with "hidden transitions", noise, etc. © 2006 Elsevier B.V. All rights reserved. Conformance testing; Integer programming; Marking equation; Petri nets; Process mining; Reference models; SAP R/3

Measuring precision of modeled behavior Conformance checking techniques compare observed behavior (i.e., event logs) with modeled behavior for a variety of reasons. For example, discrepancies between a normative process model and recorded behavior may point to fraud or inefficiencies. The resulting diagnostics can be used for auditing and compliance management. Conformance checking can also be used to judge a process model automatically discovered from an event log. Models discovered using different process discovery techniques need to be compared objectively. These examples illustrate just a few of the many use cases for aligning observed and modeled behavior. Thus far, most conformance checking techniques focused on replay fitness, i.e., the ability to reproduce the event log. However, it is easy to construct models that allow for lots of behavior (including the observed behavior) without being precise. In this paper, we propose a method to measure precision of process models, given their event logs by first aligning the logs to the models. This way, the measurement is not sensitive to non-fitting executions and more accurate values can be obtained for non-fitting logs. Furthermore, we introduce several variants of the technique to deal better with incomplete logs and reduce possible bias due to behavioral property of process models. The approach has been implemented in the ProM 6 framework and tested against both artificial and real-life cases. Experiments show that the approach is robust to noise and applicable to handle logs and models of real-life complexity. © 2014 Springer-Verlag Berlin Heidelberg. Conformance checking; Log-model alignment; Precision measurement; Process mining

Merging computer log files for process mining: An artificial immune system technique Process mining techniques try to discover and analyse business processes from recorded process data. These data have to be structured in so called computer log files. If processes are supported by different computer systems, merging the recorded data into one log file can be challenging. In this paper we present a computational algorithm, based on the Artificial Immune SystEM (Expectation-maximization) algorithm, that we developed to automatically merge separate log files into one log file. We also describe our implementation of this technique, a proof of concept application and a real life test case with promising results. © 2012 Springer-Verlag. Business Process Modelling; Log File Merging; Process Discovery; Process Mining

Merging event logs for process mining: A rule based merging method and rule suggestion algorithm In an inter-organizational setting the manual construction of process models is challenging because the different people involved have to put together their partial knowledge about the overall process. Process mining, an automated technique to discover and analyze process models, can facilitate the construction of inter-organizational process models. This paper presents a technique to merge the input data of the different partners of an inter-organizational process in order to serve as input for process mining algorithms. The technique consists of a method for configuring and executing the merge and an algorithm that searches for links between the data of the different partners and that suggests rules to the user on how to merge the data. Tool support is provided in the open source process mining framework ProM. The method and the algorithm are tested using two artificial and three real life datasets that confirm their effectiveness and efficiency. © 2014 Elsevier Ltd. All rights reserved. Business process management; Event log merging; Inter-organizational process modeling; Process mining

Message classification as a basis for studying command and control communications - An evaluation of machine learning approaches In military command and control, success relies on being able to perform key functions such as communicating intent. Most staff functions are carried out using standard means of text communication. Exactly how members of staff perform their duties, who they communicate with and how, and how they could perform better, is an area of active research. In command and control research, there is not yet a single model which explains all actions undertaken by members of staff well enough to prescribe a set of procedures for how to perform functions in command and control. In this context, we have studied whether automated classification approaches can be applied to textual communication to assist researchers who study command teams and analyze their actions. Specifically, we report the results from evaluating machine leaning with respect to two metrics of classification performance: (1) the precision of finding a known transition between two activities in a work process, and (2) the precision of classifying messages similarly to human researchers that search for critical episodes in a workflow. The results indicate that classification based on text only provides higher precision results with respect to both metrics when compared to other machine learning approaches, and that the precision of classifying messages using text-based classification in already classified datasets was approximately 50%. We present the implications that these results have for the design of support systems based on machine learning, and outline how to practically use text classification for analyzing team communications by demonstrating a specific prototype support tool for workflow analysis. © Springer Science+Business Media, LLC 2011. Classification; Command and control; Exploratory sequential data analysis; Random indexing; Text clustering; Workflow mining

Methods and techniques for discovering taxonomies of behavioral process models Modeling behavioral aspects of business processes is a hard and costly task, which usually requires heavy intervention of business experts. This explains the increasing attention given to process mining techniques, which automatically extract behavioral process models from log data. In the case of complex processes, however, the models identified by classical process mining techniques are hardly useful to analyze business operations at a suitable abstraction level. In fact, the need of process abstraction emerged in several application scenarios, and abstraction methods are already supported in some business-management platforms, which allow users to manually define abstract views for the process at hand. Therefore, it comes with no surprise that process mining research recently considered the issue of mining processes at different abstraction levels, mainly in the form of a taxonomy of process models, as to overcome the drawbacks of traditional approaches. This paper presents a general framework for the discovery of such a taxonomy, and offers a survey of different kinds of basic techniques that can be exploited to this purpose: (1) workflow modeling and discovery techniques, (2) clustering techniques enabling the discovery of different behavioral process classes, and (3) activity abstraction techniques for associating a generalized process model with each higher level taxonomy node. © 2013 John Wiley & Sons, Inc. 

MindFlow: Intelligent workflow for clinical trials in mental healthcare The recruitment of human subjects for clinical trial research is an imperative step in the discovery of new cures for diseases. However, the current major recruitment methodologies are inherently inefficient. Intelligent workflow management has great potential for improving the clinical trial recruitment process and overcome some of the limitations. In this paper, we present an intelligent workflow system for clinical trials, called MindFlow as an alternative to the traditional workflow model for clinical trials. With an increasing capacity of analysis of clinical trial processes, this model can enhance the efficiency and quality of recruitment of patients with psychiatric disorders for clinical research. The MindFlow system is based on data mining approaches, ontology and visualization technologies. The MindFlow system offers a simulation of clinical trials workflow based on published outcomes and analysis/prediction with data mining and visualization of the processes involved. We believe that the system particularly valuable in enhancing recruitment for clinical trial studies for development of new drugs. © 2012 IEEE. 

Mining and checking web services behavior As an emerging paradigm for architecting, service-oriented computing plays a more and more important role in information technology. To ensure that web services are working according with the expectation, the research in service behavior about interactions between services is crucial to guarantee no deviation from specification. To detect these deviations, we propose a method to mine and check web service behavior. The method attempts to apply process mining to interactions between services in order to narrow the gap between service consumers and providers. By observing executions of services, we present three levels of abstraction on service behavior: internal behavior, external behavior and workflow behavior. Then we outline the approach to extract behavioral model that provides specification to the activity of service checking. Finally the framework of service behavior checking is presented. © 2012 IEEE. behavioral model; conformance checking; web service mining; web services

Mining and reasoning on workflows Today's workflow management systems represent a key technological infrastructure for advanced applications that is attracting a growing body of research, mainly focused in developing tools for workflow management, that allow users both to specify the "static" aspects, like preconditions, precedences among activities, and rules for exception handling, and to control its execution by scheduling the activities on the available resources. This paper deals with an aspect of workflows which has so far not received much attention even though it is crucial for the forthcoming scenarios of large scale applications on the Web: Providing facilities for the human system administrator for identifying the choices performed more frequently in the past that had lead to a desired final configuration. In this context, we formalize the problem of discovering the most frequent patterns of executions, i.e., the workflow substructures that have been scheduled more frequently by the system. We attacked the problem by developing two data mining algorithms on the basis of an intuitive and original graph formalization of a workflow schema and its occurrences. The model is used both to prove some intractability results that strongly motivate the use of data mining techniques and to derive interesting structural properties for reducing the search space for frequent patterns. Indeed, the experiments we have carried out show that our algorithms outperform standard data mining algorithms adapted to discover frequent patterns of workflow executions. © 2005 IEEE. Data mining; Workflow management

Mining and re-engineering transactional workflows for reliable executions A continuous evolution of business process parameters, constraints and needs, hardly foreseeable initially, requires from the business process management systems a continuous design and a reliable process model. In this paper, we are interested in developing a reactive design through a process log analysis ensuring process re-engineering and execution reliability. We propose to analyse workflow logs to discover workflow transactional behavior and to improve and correct related recovery mechanisms subsequently. Our approach starts by collecting workflow logs. Then, we build, by statistical analysis techniques, an intermediate representation specifying elementary dependencies between activities. These dependencies are refined to mine the transactional workflow model. The analysis of the discrepancies between the discovered model and the initially designed model enables us to detect design gaps, concerning particularly the recovery mechanisms. Thus, based on this mining step, we apply a set of rules on the initially designed workflow to improve workflow reliability. © Springer-Verlag Berlin Heidelberg 2007. 

Mining association rules for the quality improvement of the production process Academics and practitioners have a common interest in the continuing development of methods and computer applications that support or perform knowledge-intensive engineering tasks. Operations management dysfunctions and lost production time are problems of enormous magnitude that impact the performance and quality of industrial systems as well as their cost of production. Association rule mining is a data mining technique used to find out useful and invaluable information from huge databases. This work develops a better conceptual base for improving the application of association rule mining methods to extract knowledge on operations and information management. The emphasis of the paper is on the improvement of the operations processes. The application example details an industrial experiment in which association rule mining is used to analyze the manufacturing process of a fully integrated provider of drilling products. The study reports some new interesting results with data mining and knowledge discovery techniques applied to a drill production process. Experiment's results on real-life data sets show that the proposed approach is useful in finding effective knowledge associated to dysfunctions causes. © 2012 Elsevier Ltd. All rights reserved. 

Mining association rules from XML data with index table Mining XML association rule is confronted with more challenges due to the inherent flexibilities of XML in both structure and semantics. In order to make mining XML association rule efficiently, we give a new definition of transaction and item in XML context, then build transaction database based on an index table. Based on our definition and the index table used for XML searching, we can check the include relation between a transaction and an item quickly. A high adaptive mining technique is also described. By using it, we can process mining rules with no guidance of interest associations given by users and mining unknown rules. We demonstrate the effectiveness of these techniques through experiments on real-life data. © 2007 IEEE. Association rule; Include relation; Index table; XML mining

Mining association rules to support resource allocation in business process management Resource allocation is of great importance for business process management. In business process execution, a set of rules that specify resource allocation is always implied. Although many approaches have been offered to support resource allocation, they are not sufficient to derive interesting resource allocation rules which ensure that each activity is performed by suitable resource. Hence, this paper introduces an association rule mining based approach to mine interesting resource allocation rules from event log. The idea is to concern the ordered correlations between items in event log, and then to present two efficient algorithms to mine real "interesting" rules. The event log of radiology CT-scan examination process provided by the Chinese Huzhou hospital is used to verify the proposed approach. The evaluation results showed that the proposed approach not only is able to extract the rules more efficient and much faster, but also can discover more important resource allocation rules. © 2011 Published by Elsevier Ltd. Association rules; Business process management; Data mining; Resource allocation

Mining based on learning from process change logs In today's dynamic business world economic success of an enterprise increasingly depends on its ability to react to internal and external changes in a quick and flexible way. In response to this need, process-aware information systems (PAIS) emerged, which support the modeling, orchestration and monitoring of business processes. Recently, a new generation of flexible PAIS was introduced, which additionally allows for dynamic process changes. This, in turn, leads to a large number of process variants, which are created from the same original model, but might slightly differ from each other. This paper deals with issues related to the mining of such process variant collections. Our overall goal is to learn from process changes and to merge the resulting model variants into a generic process model in the best possible way. By adopting this generic process model in the PAIS, future costs of process change and need for process adaptations will decrease. We compare process variant mining with conventional process mining techniques, and show that it is additionally needed to learn from process changes. © 2009 Springer Berlin Heidelberg. 

Mining batch processing workflow models from event logs The employment of batch processing in workflow is to model and schedule activity instances in multiple workflow cases of the same workflow type to optimize business processes execution dynamically. Although our previous works have preliminarily investigated its model and implementation, it is still necessary to deal with its model design problem. Process mining techniques allow for the automated discovery of process models from event logs and have received notable attentions in researches recently. Following these researches, this paper proposes an approach to mine batch processing workflow models from event logs by considering the batch processing relations among activity instances in multiple workflow cases. The notion of batch processing feature and its corresponding mining algorithm are also presented for discovering the batch processing area in the model by using the input and output data information of activity instances in events. The algorithms presented in this paper can help to enhance the applicability of existing process mining approaches and broaden the process mining spectrum. Copyright © 2013 John Wiley & Sons, Ltd. batch processing; batch processing area; process mining; WF-net; workflow

Mining business process variants: Challenges, scenarios, algorithms During the last years a new generation of process-aware information systems has emerged, which enables process model configurations at buildtime as well as process instance changes during runtime. Respective model adaptations result in a large number of model variants that are derived from the same process model, but slightly differ in structure. Generally, such model variants are expensive to configure and maintain. In this paper we address two scenarios for learning from process model adaptations and for discovering a reference model out of which the variants can be configured with minimum efforts. The first one is characterized by a reference process model and a collection of related process variants. The goal is to improve the original reference process model such that it fits better to the variant models. The second scenario comprises a collection of process variants, while the original reference model is unknown; i.e., the goal is to "merge" these variants into a new reference process model. We suggest two algorithms that are applicable in both scenarios, but have their pros and cons. We provide a systematic comparison of the two algorithms and further contrast them with conventional process mining techniques. Comparison results indicate good performance of our algorithms and also show that specific techniques are needed for learning from process configurations and adaptations. Finally, we provide results from a case study in automotive industry in which we successfully applied our algorithms. (C) 2011 Elsevier B.V. All rights reserved. Process change; Process configuration; Process mining; Process variant

Mining configurable enterprise information systems Process mining aim at extracting a process model from system logs. These logs have to meet minimum requirements, i.e. each event should refer to a case and a task. Some system logs do not meet these requirements, and therefore it is not possible to use process mining for process optimization or delta analysis. This paper shows an alternative process mining procedure for logs containing only data on the number of times that process steps have been executed (i.e., frequencies). To be able to mine such logs we apply Configurable Event-driven Process Chains (C-EPCs). If a C-EPC is available, we propose a method to mine the process. If only a classical reference model (i.e., an EPC) is available, we propose a method to first derive the C-EPC through mining and then analyze the process. This approach enables us to do process mining in the context of ERP systems such as the SAP solutions. © 2005 Elsevier B.V. All rights reserved. Data and process re-engineering; Data mining; Enterprise information systems; Knowledge discovery; Reference models

Mining configurable process models from collections of event logs Existing process mining techniques are able to discover a specific process model for a given event log. In this paper, we aim to discover a configurable process model from a collection of event logs, i.e., the model should describe a family of process variants rather than one specific process. Consider for example the handling of building permits in different municipalities. Instead of discovering a process model per municipality, we want to discover one configurable process model showing commonalities and differences among the different variants. Although there are various techniques that merge individual process models into a configurable process model, there are no techniques that construct a configurable process model based on a collection of event logs. By extending our ETM genetic algorithm, we propose and compare four novel approaches to learn configurable process models from collections of event logs. We evaluate these four approaches using both a running example and a collection of real event logs. © 2013 Springer-Verlag. 

Mining constrained graphs: The case of workflow systems Constrained graphs are directed graphs describing the control flow of processes models. In such graphs, nodes represent activities involved in the process, and edges the precedence relationship among such activities. Typically, nodes and edges can specify some constraints, which control the interaction among the activities. Faced with the above features constrained graphs are widely used in the modelling and analysis of Workflow processes. In this paper we overview two mining problems related to the analysis of constrained graphs, namely the analysis of frequent patterns of execution, and the induction of a constrained graph from a set of execution traces. We discuss some complexity aspects related to the problem of reasoning and mining on constrained graphs, and overview two algorithms for the mentioned problems. © Springer-Verlag Berlin Heidelberg 2005. 

Mining constraints for artful processes Artful processes are informal processes typically carried out by those people whose work is mental rather than physical (managers, professors, researchers, engineers, etc.), the so called "knowledge workers". MailOfMine is a tool, the aim of which is to automatically build, on top of a collection of email messages, a set of workflow models that represent the artful processes laying behind the knowledge workers activities. After an outline of the approach and the tool, this paper focuses on the mining algorithm, able to efficiently compute the set of constraints describing the artful process. Finally, an experimental evaluation of it is reported. © 2012 Springer-Verlag. artful process; declarative workflow; email; process mining

Mining context-dependent and interactive business process maps using execution patterns Process mining techniques attempt to extract non-trivial knowledge and interesting insights from event logs. Process models can be seen as the "maps" describing the operational processes of organizations. Unfortunately, traditional process discovery algorithms have problems dealing with less-structured processes. Furthermore, existing discovery algorithms do not consider the analyst's context of analysis. As a result, the current models (i.e., "maps") are difficult to comprehend or even misleading. To address this problem, we propose a two-phase approach based on common execution patterns. First, the user selects relevant and context-dependent patterns. These patterns are used to obtain an event log at a higher abstraction level. Subsequently, the transformed log is used to create a hierarchical process map. The approach has been implemented in the context of ProM. Using a real-life log of a housing agency we demonstrate that we can use this approach to create maps that (i) depict desired traits, (ii) eliminate irrelevant details, (iii) reduce complexity, and (iv) improve comprehensibility. © 2011 Springer-Verlag. 

Mining decision activity logs This paper introduces our work regarding the mining of decision activity logs generated by the users of a decision support system-like environment. We will show that a DSS can be modified in order to become "decision-aware. If the system offers support for all the data and information needs of the decision maker, how the user interacts with the software can provide us with a new perspective over the implicit and explicit knowledge employed in the decision process, as well as the decision patterns and strategies used for that decisional situation. All this valuable information will be stored as activity logs. Those logs need to be mined in order to build a graphical representation of the decision process. As proof-of-concept we focus on the enterprise loan contracting decision situation. We will show some of the models we created using several process mining algorithms and our own approach. Based on those models, we argue the new insights we can provide into the decision making process and the knowledge that is now explained and depicted as diagrams. © 2010 Springer-Verlag Berlin Heidelberg. decision mining; decision reference model; mining algorithm; process mining; user activity log

Mining deviations from patient care pathways via electronic medical record system audits In electronic medical record (EMR) systems, administrators often provide EMR users with broad access privileges, which may leave the system vulnerable to misuse and abuse. Given that patient care is based on a coordinated workflow, we hypothesize that care pathways can be represented as the progression of a patient through a system and introduce a strategy to model the patient's flow as a sequence of accesses defined over a graph. Elements in the sequence correspond to features associated with the access transaction (e.g., reason for access). Based on this motivation, we model patterns of patient record usage, which may indicate deviations from care workflows. We evaluate our approach using several months of data from a large academic medical center. Empirical results show that this framework finds a small portion of accesses constitute outliers from such flows. We also observe that the violation patterns deviate for different types of medical services. Analysis of our results suggests greater deviation from normal access patterns by nonclinical users. We simulate anomalies in the context of real accesses to illustrate the efficiency of the proposed method for different medical services. As an illustration of the capabilities of our method, it was observed that the area under the receiver operating characteristic (ROC) curve for the Pediatrics service was found to be 0.9166. The results suggest that our approach is competitive with, and often better than, the existing state-of-the-art in its outlier detection performance. At the same time, our method is more efficient, by orders of magnitude, than previous approaches, allowing for detection of thousands of accesses in seconds. © 2013 ACM. Anomaly detection; Audit; Data mining; Electronic medical record systems; Graph-based analysis; Temporal systems

Mining E-contract documents to classify clauses E-contracts begin as legal documents and end up as processes that help organizations abide by legal rules while fulfilling contract terms. As contracts are complex, their deployment is predominantly established and fulfilled with significant human involvement. One of the key difficulties with any kind of contract processing is the legal ambiguity, which makes it difficult to address any violation of the contract terms. Thus, there is a need to track clauses for the contract activities under execution and violation of clauses. This necessitates deriving clause patterns from e-contract documents and map to their respective activities for further monitoring and fulfillment of e-contracts during their enactment. In this paper, we present a classification approach to extract clause patterns from e-contract documents. This is a challenging task as activities and clauses are mostly derived from both legal and business process driven contract knowledge. © 2010 ACM. Data mining; E-contracts; Text analytics

Mining e-mail messages: Uncovering interaction patterns and processes using e-mail logs Increasingly information systems log historic information in a systematic way. Workflow management systems, but also ERP, CRM, SCM, and B2B systems often provide a so-called "event log" (i.e., a log recording the execution of activities). Thus far, process mining has been mainly focusing on structured event logs resulting in powerful analysis techniques and tools for discovering process, control, data, organizational, and social structures from event logs. Unfortunately, many work processes are not supported by systems providing structured logs. Instead, very basic tools such as text editors, spreadsheets, and e-mail are used. This article explores the application of process mining to e-mail (i.e., unstructured or semi-structured e-mail messages are converted into event logs suitable for application of process mining tools). This article presents the tool EMailAnalyzer, embedded in the ProM process mining framework, which analyzes and transforms e-mail messages to a format that allows for analysis using our process mining techniques. The main innovative aspect of this work is that, unlike most other work in this area, our analysis is not restricted to social network analysis. Based on e-mail logs, we can also discover interaction patterns and processes. Copyright © 2008, IGI Global. Computer supported cooperative work; E-mail mining; Process mining; Social network analysis; Workflow management

Mining event logs to support workflow resource allocation Currently, workflow technology is widely used to facilitate the business process in enterprise information systems (EIS), and it has the potential to reduce design time, enhance product quality and decrease product cost. However, significant limitations still exist: as an important task in the context of workflow, many present resource allocation (also known as "staff assignment") operations are still performed manually, which are time-consuming. This paper presents a data mining approach to address the resource allocation problem (RAP) and improve the productivity of workflow resource management. Specifically, an Apriori-like algorithm is used to find the frequent patterns from the event log, and association rules are generated according to predefined resource allocation constraints. Subsequently, a correlation measure named lift is utilized to annotate the negatively correlated resource allocation rules for resource reservation. Finally, the rules are ranked using the confidence measures as resource allocation rules. Comparative experiments are performed using C4.5, SVM, ID3, Naïve Bayes and the presented approach, and the results show that the presented approach is effective in both accuracy and candidate resource recommendations. © 2012 Elsevier B.V. All rights reserved. Association rules; Data mining; Process mining; Resource allocation; Workflow

Mining for social processes in intelligence data streams This work introduces a robust method for identifying and tracking clandestinely operating sub-nets in an active social network. The methodology is based on the Process Query System (PQS) previously applied to process mining in various physical contexts. Given a collection of process descriptions encoding personal and/or coordinated behavior of social entities, we parse a network's transactional stream for instances of active processes and assign process states to events and functional entities based on a projection of the evidence onto the process models. Our goal is not only to define the social network, but also to identify and track the dynamic states of functionally coherent sub-networks. We apply our methodology to a real world security task- mining a collection of simulated HUMINT and SIGINT intelligence data (the Ali Baba simulated intelligence data set)- and demonstrate superior results both in partitioning and contextualizing the social network. social network analysis; SNA; process query system; PQS

Mining hierarchies of models: From abstract views to concrete specifications Process mining techniques have been receiving great attention in the literature for their ability to automatically support process (re)design. The output of these techniques is a concrete workflow schema that models all the possible execution scenarios registered in the logs, and that can be profitably used to support further-coming enactments. In this paper, we face process mining in a slightly different perspective. Indeed, we propose an approach to process mining that combines novel discovery strategies with abstraction methods, with the aim of producing hierarchical views of the process that satisfactorily capture its behavior at different level of details. Therefore, at the highest level of detail, the mined model can support the design of concrete workflows; at lower levels of detail, the views can be used in advanced business process platforms to support monitoring and analysis. Our approach consists of several algorithms which have been integrated into a systems architecture whose description is accounted for in the paper as well. © Springer-Verlag Berlin Heidelberg 2005. 

Mining high impact exceptional behavior patterns In the real world, exceptional behavior can be seen in many situations such as security-oriented fields. Such behavior is rare and dispersed, while some of them may be associated with significant impact on the society. A typical example is the event September 11. The key feature of the above rare but significant behavior is its high potential to be linked with some significant impact. Identifying such particular behavior before generating impact on the world is very important. In this paper, we develop several types of high impact exceptional behavior patterns. The patterns include frequent behavior patterns which are associated with either positive or negative impact, and frequent behavior patterns that lead to both positive and negative impact. Our experiments in mining debt-associated customer behavior in social-security areas show the above approaches are useful in identifying exceptional behavior to deeply understand customer behavior and streamline business process. © Springer-Verlag Berlin Heidelberg 2007. 

Mining inter-organizational business process models from EDI messages: A case study from the automotive sector Traditional standards for Electronic Data Interchange (EDI), such as EDIFACT and ANSI X12, have been employed in Business-to-Business (B2B) e-commerce for decades. Due to their wide industry coverage and long-standing establishment, they will presumably continue to play an important role for some time. EDI systems are typically not process-aware, i.e., messages are standardized but processes simply emerge. However, to improve performance and to enhance the control, it is important to understand and analyze the real processes supported by these systems. In the case study presented in this paper we uncover the inter-organizational business processes of an automotive supplier company by analyzing the EDIFACT messages that it receives from its business partners. We start by transforming a set of observed messages to an event log, which requires that the individual messages are correlated to process instances. Thereby, we make use of the specific structure of EDIFACT messages. Then we apply process mining techniques to uncover the inter-organizational business processes. Our results show that inter-organizational business process models can be derived by analyzing EDI messages that are exchanged in a network of organizations. © 2012 Springer-Verlag Berlin Heidelberg. BPM; EDI; event correlation; inter-organizational business processes; process mining

Mining invisible tasks from event logs Most existing process mining algorithms have problems in dealing with invisible tasks. In this paper, a new process mining algorithm named a# is proposed, which extends the mining capacity of the classical a algorithm by supporting the detection of invisible tasks from event logs. Invisible tasks are first divided into four types according to their functional features, i.e., SIDE, SKIP, REDO and SWITCH. After that, the new ordering relation for detecting mendacious dependencies between tasks that reflects invisible tasks is introduced. Then the construction algorithms for invisible tasks of SIDE and SKIP/REDO/SWITCH types are proposed respectively. Finally, the a# algorithm constructs the mined process models incorporating invisible tasks in WF-net. A lot of experiments are done to evaluate the mining quality of the proposed a# algorithm and the results are promising. © Springer-Verlag Berlin Heidelberg 2007. 

Mining knowledge flow for modeling the information needs of task-based groups Knowledge is the most important resource to create core competitive advantages for an organization. Such knowledge is circulated and accumulated by a knowledge flow (KF) in an organization to support worker's tasks. Workers may cooperate and participate in several task-based groups to fulfill their needs. In this paper, we propose a group-based knowledge flow mining algorithm which integrates information retrieval and data mining techniques for mining and constructing the group-based KF (GKF) for task-based groups. The GKF is expressed as a directed knowledge graph to represent the knowledge referencing behavior for a group of workers with similar task needs. The frequent knowledge referencing paths are identified from the knowledge graph to indicate the frequent knowledge flows of the workers. We also implement a prototype of GKF mining system to demonstrate the effectiveness of our proposed method. ©2008 IEEE. Data mining; Knowledge flow; Knowledge management; Process mining

Mining knowledge sharing processes in online discussion forums Online discussion forums have become a popular knowledge source for sharing information or solving problems. This study is an attempt to apply business process modeling and mining techniques to analyzing online knowledge sharing activities. Traditional process mining techniques have little consideration on social interactions, which are rich in online forums. We propose to complement traditional process mining with analyses on social interactions among discussion participants. Our experiments show that business process modeling and mining techniques can be used to model online knowledge sharing processes and identify patterns related to effective knowledge sharing. In addition, analyses on social interactions provide insights that verify and supplement the process mining results. © 2014 IEEE. 

Mining of ad-hoc business processes with TeamLog The design of workflows is a complicated task. In those cases where the control flow between activities cannot be modeled in advance but simply occurs during enactment time (run time), we speak of ad-hoc processes. Ad-hoc processes allow for the flexibility needed in real-life business processes. Since ad-hoc processes are highly dynamic, they represent one of the most difficult challenges, both, technically and conceptually. Caramba is one of the few process-aware collaboration systems allowing for ad-hoc processes. Unlike in classical workflow systems, the users are no longer restricted by the system. Therefore, it is interesting to study the actual way people and organizations work. In this paper, we propose process mining techniques and tools to analyze ad-hoc processes. We introduce process mining, discuss the concept of mining in the context of ad-hoc processes, and demonstrate a concrete application of the concept using Caramba, process mining tools such as EMiT and MinSoN, and a newly developed extraction tool named Teamlog. © 2005 Elsevier B.V. All rights reserved. Business process analysis; Business process management; Caramba; EMiT; MinSoN; Process mining; TeamLog; Workflow management

Mining periodic patterns from nested event logs Information about periodic computations of processes, events, and software components can be used to improve performance of software systems. This work investigates mining periodic patterns of events from historical information related to processes, events, and software components. We introduce a concept of a nested event log that generalizes historical information stored in the application traces, event logs and dynamic profiles. We show how a nested event log can be compressed into a reduced event table and later on converted into a workload histogram suitable for mining periodic patterns of events. The paper defines a concept of periodic pattern and its validation in a workload histogram. We propose two algorithms for mining periodic patterns and we define the quality indicators for the patterns found. We show, that a system of operations on periodic patterns introduced in this work can be used to derive new periodic patterns with some of the quality indicators better from the original ones. The paper is concluded with an algorithm for deriving periodic patterns with the given quality constraints. Nested events; Nested logs; Periodic patterns; Process mining

Mining Process Flowcharts from Business Data: An Evolutionary Approach The practice of process mining concerns the reconstruction of complete process flow diagrams from data logs. In an increasingly complex business environment, there is a need for managers to understand the processes they already have in place. Process mining facilitates the automatic reconstruction of a flowchart description based on a set of execution traces. The process mining approach featured in this paper utilises a Genetic Programming approach to process mining using a graph representation. The results from a number of experiments are detailed in this paper and point to its potential as a practical tool for use in industry. The principles investigated in this approach form a core component of future research by the authors in the area of process disparity identification. Business process mining; Data mining; Flowcharts; Genetic programming; Workflow mining

Mining process models from event logs in distributed bioinformatics workflows Designing a workflow is a complicated process, and there are discrepancies between the actual workflow processes and the ideal processes. So we have researched how to discover workflow models, and we have applied the techniques to distributed bioinformatics workflows. The source for such techniques is a "workflow log" containing information about the workflow process. We presented a new algorithm to extract a process model from such a log and represented it in terms of a Petri net. The algorithm can handle concurrence and recurrence of the distributed bioinformatics workflow processes that are the restrictions of other algorithms. The a algorithm can successfully mine any workflow represented by WF-net. © 2007 IEEE. Distributed bioinformatics workflow; Petri nets; Workflow log; Workflow nets; Workflow process mining

Mining process models with non-free-choice constructs Process mining aims at extracting information from event logs to capture the business process as it is being executed. Process mining is particularly useful in situations where events are recorded but there is no system enforcing people to work in a particular way. Consider for example a hospital where the diagnosis and treatment activities are recorded in the hospital information system, but where health-care professionals determine the "careflow." Many process mining approaches have been proposed in recent years. However, in spite of many researchers' persistent efforts, there are still several challenging problems to be solved. In this paper, we focus on mining non-free-choice constructs, i.e., situations where there is a mixture of choice and synchronization. Although most real-life processes exhibit non-free-choice behavior, existing algorithms are unable to adequately deal with such constructs. Using a Petri-net-based representation, we will show that there are two kinds of causal dependencies between tasks, i.e., explicit and implicit ones. We propose an algorithm that is able to deal with both kinds of dependencies. The algorithm has been implemented in the ProM framework and experimental results shows that the algorithm indeed significantly improves existing process mining techniques. © 2007 Springer Science+Business Media, LLC. Event log; Implicit dependency; Non-free-choice constructs; Process mining

Mining process models with prime invisible tasks Process mining is helpful for deploying new business processes as well as auditing, analyzing and improving the already enacted ones. Most of the existing process mining algorithms have some problems in dealing with invisible tasks, i.e., such tasks that exist in a process model but not in its event log. In this paper, a new process mining algorithm named alpha(#) is proposed, which extends the mining capability of the classical alpha algorithm by supporting the detection of prime invisible tasks from event logs. Prime invisible tasks are divided into five types according to their structural features, i.e., INITIALIZE, SKIP, REDO, SWITCH and FINALIZE. After that, a new ordering relation for detecting mendacious dependencies between tasks that reflects prime invisible tasks is introduced. A reduction rule for identifying redundant "mendacious" dependencies is also considered. The construction algorithm to insert prime invisible tasks of SKIP/REDO/SWITCH types is presented. The alpha(#) algorithm has been evaluated using both artificial and real-life logs and the results are promising. (C) 2010 Elsevier B.V. All rights reserved. Invisible tasks; Petri nets; Process mining; Workflow log

Mining program workflow from interleaved traces Successful software maintenance is becoming increasingly critical due to the increasing dependence of our society and economy on software systems. One key problem of software maintenance is the difficulty in understanding the evolving software systems. Program workflows can help system operators and administrators to understand system behaviors and verify system executions so as to greatly facilitate system maintenance. In this paper, we propose an algorithm to automatically discover program workflows from event traces that record system events during system execution. Different from existing workflow mining algorithms, our approach can construct concurrent workflows from traces of interleaved events. Our workflow mining approach is a three-step coarse-to-fine algorithm. At first, we mine temporal dependencies for each pair of events. Then, based on the mined pair-wise temporal dependencies, we construct a basic workflow model by a breadth-first path pruning algorithm. After that, we refine the workflow by verifying it with all training event traces. The refinement algorithm tries to find out a workflow that can interpret all event traces with minimal state transitions and threads. The results of both simulation data and real program data show that our algorithm is highly effective. © 2010 ACM. Graphical behavior models; Temporal properties; Workflow mining

Mining Reference Process Models and Their Configurations Reference process models are templates for common processes rim by many corporations. However, the individual needs among organizations on the execution of these processes usually vary. A process model can address these variations through control-flow choices. Thus, it can integrate the different process variants into one model. Through configuration parameters, a configurable reference models enables corporations to derive their individual process variant from such an integrated model. While this simplifies the adaptation process for the reference model user, the construction of a configurable model integrating several process variants is far more complex than the creation of a traditional reference model depicting a single best-practice variant. In this paper we therefore recommend the use of process mining techniques on log files of existing, well-running IT systems to help the reference model provider in creating such integrated process models. Afterwards, the same log files are used to derive Suggestions for common configurations that can serve as starting points for individual configurations. 

Mining sequences for patterns with non-repeating symbols Finding the case id in unlabeled event logs is arguably one of the hardest challenges in process mining research. While this problem can be addressed with greedy approaches, these usually converge to sub-optimal solutions. In this paper, we describe an approach to perform complete search over the search space. We formulate the problem as a matter of finding the minimal set of patterns contained in a sequence, where patterns can be interleaved but do not have repeating symbols. We show that for practical purposes it is possible to reduce the search space to maximal disjoint occurrences of these patterns. Experimental results suggest that, whenever this approach finds a solution, it usually finds a minimal one. © 2010 IEEE. 

Mining staff assignment rules from event-based data Process mining offers methods and techniques for capturing process behaviour from log data of past process executions. Although many promising approaches on mining the control flow have been published, no attempt has been made to mine the staff assignment situation of business processes. In this paper, we introduce the problem of mining staff assignment rules using history data and organisational information (e.g., an organisational model) as input. We show that this task can be considered an inductive learning problem and adapt a decision tree learning approach to derive staff assignment rules. In contrast to rules acquired by traditional techniques (e.g., questionnaires) the thus derived rules are objective and show the staff assignment situation at hand. Therefore, they can help to better understand the process. Moreover, the rules can be used as input for further analysis, e.g., workload balance analysis or delta analysis. This paper presents the current state of our work and points out some challenges for future research. © Springer-Verlag Berlin Heidelberg 2006. 

Mining student capstone projects with FRASR and ProM Capstone projects are commonly carried out at the end of an undergraduate program of study in software engineering or computer science. While traditionally such projects solely focussed on the software product to be developed, in more recent work importance of the development process has been stressed. Currently process quality assessment techniques are limited to review of intermediary artifacts, self- and peer evaluations. We advocate augmenting the assessment by mining software repositories used by the students during the development. We present the assessment methodology and illustrate it by applying to a number of software engineering capstone projects. 

Mining taxonomies of process models Process mining techniques have been receiving great attention in the literature for their ability to automatically support process (re)design. Typically, these techniques discover a concrete workflow schema modelling all possible execution patterns registered in a given log, which can be exploited subsequently to support further-coming enactments. In this paper, an approach to process mining is introduced that extends classical discovery mechanisms by means of an abstraction method aimed at producing a taxonomy of workflow models. The taxonomy is built to capture the process behavior at different levels of detail. Indeed, the most-detailed mined models, i.e., the leafs of the taxonomy, are meant to support the design of concrete workflows, as it happens with existing techniques in the literature. The other models, i.e., non-leaf nodes of the taxonomy, represent instead abstract views over the process behavior that can be used to support advanced monitoring and analysis tasks. All the techniques discussed in the paper have been implemented, tested, and made available as a plugin for a popular process mining framework (ProM). A series of tests, performed on different synthesized and real datasets, evidenced the capability of the approach to characterize the behavior encoded in input logs in a precise and complete way, achieving compelling conformance results even in the presence of complex behavior and noisy data. Moreover, encouraging results have been obtained in a real-life application scenario, where it is shown how the taxonomical view of the process can effectively support an explorative ex-post analysis, hinged on the different kinds of process execution discovered from the logs. © 2008 Elsevier B.V. All rights reserved. Abstraction; Knowledge discovery; Process mining; Workflow management

Mining the low-level behaviour of agents in high-level business processes Currently there is a gap between the high level of abstraction at which business processes are modelled and the low level nature of the events that are recorded during process execution. When applying process mining techniques, it is possible to discover the logic behind low-level events but it is difficult to determine the relationship between those low-level events and the high-level activities in a given process model. In this work, we introduce a hierarchical Markov model to capture both the high-level behaviour of activities and the low-level behaviour of events. We also develop an expectation-maximisation technique to discover that kind of hierarchical model from a given event log and a high-level description of the business process. We use this technique to understand the behaviour of agents in business processes, from the control-flow perspective and from the organisational perspective as well. Using an agent-based simulation platform (AOR), we implemented a purchasing process and generated an event log in order to illustrate the benefits of the proposed approach and to compare the results with existing process mining techniques, namely the ones that are available in the ProM framework. Copyright © 2013 Inderscience Enterprises Ltd. Agent-based simulation; Agent-object-relationship; AOR.; Expectationmaximisation; Hierarchical Markov model; Process mining

Mining the role-oriented process models based on genetic algorithm Traditional role-oriented process modeling seems to be subjective in identifying roles. To solve the problem, the similarity of activities is used in this paper. Sub-processes with high similarity are recognized as the process undertaken by a certain role. In this way, a relatively objective role identification approach is proposed, which determines the interaction between roles and establishes the role-activity diagram. Furthermore, by analyzing the interaction between roles, genetic algorithm is used to introduce multiple factors to optimize the identification. Therefore, an optimized role-oriented process modeling approach is established and an example is presented to show the feasibility of this approach. © 2012 Springer-Verlag. Genetic Algorithm; Process Mining; Role Identification; Role-Activity Diagram

Mining transportation logs for understanding the after-assembly block manufacturing process in the shipbuilding industry In the after-assembly block manufacturing process in the shipbuilding industry, domain experts or industrial managers have the following questions regarding the first step in terms of reducing the overhead transportation cost due to irregularities not defined in a process design: "What tasks are bottlenecks?" and "How long do the blocks remain waiting in stockyards?" We provide the answers to these two questions. In the process mining framework, we propose a method automatically extracting the most frequent task flows from transport usage histories. Considering characteristics of our application, we use a clustering technique to identify heterogeneous groups of process instances, and then derive a process model independently by group. Process models extracted from real-world transportation logs, are verified by domain experts and labelled based on their interpretations. Consequently, we conceptualize the "standard process" from one global process model. Moreover, local models derived from groups of process instances reflect unknown context regarding characteristics of blocks. Our proposed method can provide conceptualized process models and process (or waiting in stockyards) times as a performance indicator. Providing reasonable answers to their questions, it helps domain experts better understand and manage the actual process. With the extension of the conventional methodology for our application problem, the main contributions of this research are that our proposed approach provides insight into the after-assembly block manufacturing process, and describes the first step for reducing transportation costs. © 2012 Elsevier Ltd. All rights reserved. Manufacturing process; Process mining; Shipbuilding industry; Transportation; Workflow mining

Mining unconnected patterns in workflows General patterns of execution that have been frequently scheduled by a workflow management system provide the administrator with previously unknown, and potentially useful information, e.g., about the existence of unexpected causalities between subprocesses of a given workflow. This paper investigates the problem of mining unconnected patterns on the basis of some execution traces, i.e., of detecting sets of activities exhibiting no explicit dependency relationships that are frequently executed together. The problem is faced in the paper by proposing and analyzing two algorithms. One algorithm takes into account information about the structure of the control-flow graph only, while the other is a smart refinement where the knowledge of the frequencies of edges and activities in the traces at hand is also accounted for, by means of a sophisticated graphical analysis. Both algorithms have been implemented and integrated into a system prototype, which may profitably support the enactment phase of the workflow. The correctness of the two algorithms is formally proven, and several experiments are reported to evidence the ability of the graphical analysis to significantly improve the performances, by dramatically pruning the search space of candidate patterns. © 2006 Elsevier B.V. All rights reserved. Frequent patterns discovery; Graph mining; Workflow management

Mining workflow event log to facilitate parallel work item sharing among human resources In many workflow applications, actors are free to pick up work items in their work list. It is not unusual for an actor to start a work item before completing other previously accepted ones. Frequent occurrence of this behaviour implies potential patterns of work parallelism, which is useful for workflow scheduler to better dispatch ongoing work items. In this article, we apply association rule mining techniques to workflow event log to analyse various kinds of activity parallel execution patterns. When an actor accepts a new work item, the parallel execution rules mined from event log can help the workflow scheduler to find other work items that might be suitable to be undertaken by the same actor simultaneously. In the experiment on three vehicle manufacturing enterprises, we have found 32 strong rules of 40 different workflow activities. We describe our approach and report on the result of our experiment. © 2011 Taylor & Francis. data mining; human factors; work sharing; workflow resource management

Mining workflow outlier with a frequency-based algorithm Business Process includes workflows which integrated some critical activities among different departments. Workflow management is a quickly evolving technology that can assist business process reengineering and accomplish full or partial automatic processing of a business. Workflow plays a critical role in the ERP (Enterprise Resources Planning) system since it aims to achieve maximum satisfaction for both employee and customers. Any workflow that is irrationally and irregularly designed will not only lead to an ineffective operation of enterprise but also limit the implementation of an effective business strategy. The research proposes an algorithm which makes use of the workflow's executed frequency, the concept of distance-based outlier detection, empirical rules and Method of Exhaustion to mine three types of workflow outliers, including less-occurring workflow outliers of each process (abnormal workflow of each process), less-occurring workflow outliers of all processes (abnormal workflow of all processes) and never-occurring workflow outliers (redundant workflow). In addition, this research adopts real data to evaluate workflow mining feasibility. In terms of the management, it will assist managers and consultants in (1) controlling exceptions in the process of enterprise auditing, (2) simplifying the business process management by the integration of relevant processes and (3)persisting to improve the quality of business process and enhance enterprise performance. BPM; Data mining; ERP; Outlier detection; Workflow mining

Mining workflow patterns through event-data analysis It is obvious to notice that in collaborative applications, considerable processes are either implicit, or integrate existing processes. The discovery, and the explanation of these processes are a hot research topic. The work described in this paper is a contribution to these problems. Generally, workflow mining proposes techniques to acquire a workflow model from a workflow log. In this paper, we present a new workflow mining technique to discover workflow patterns. This technique combines complementary an algorithmic technique and a statistical analysis technique. This combination can deal with some ambiguities that the single use of the statistical analysis technique cannot resolve. © 2005 IEEE. Workflow mining; Workflow patterns; Workflow supported collaboration

Mining workflow processes from distributed workflow enactment event logs Workflow management systems help to execute, monitor and manage work process flow and execution. These systems, as they are executing, keep a record of who does what and when (e.g. log ofevents). The activity of using computer software to examine these records, and deriving various structural data results is called workflow mining. The workflow mining activity, in general, needs to encompass behavioral (process/control-flow), social, informational (data-flow), and organizational perspectives; as well as other perspectives, because workflow systems are "people systems" that must be designed, deployed, and understood within their social and organizational contexts. This paper particularly focuses on mining the behavioral aspect of workflows from XML-based workflow enactment event logs, which are vertically (semantic-driven distribution) or horizontally (syntactic-driven distribution) distributed over the networked workflow enactment components. That is, this paper proposes distributed workflow mining approaches that are able to rediscover ICN-based structured workflow process models through incrementally amalgamating a series of vertically or horizontally fragmented temporal workcases. And each of the approaches consists of a temporal fragment discovery algorithm, which is able to discover a set of temporal fragment models from the fragmented workflow enactment event logs, and a workflow process mining algorithm which rediscovers a structured workflow process model from the discovered temporal fragment models. Where, the temporal fragment model represents the concrete model of the XML-based distributedworkflow fragment events log. Distributed events log; Distributed workflow management system; Distributed workflow process mining; Workflow fragmentation

Mining workflow processes from xml-based distributed workflow event logs In this paper1, we particularly focus on mining the behavioral aspect of workflows from XML-based workflow enactment event logs, which are vertically (semantic-driven distribution) or horizontally (syntactic-driven distribution) distributed over the networked workflow enactment components. That is, this paper proposes a distributed workflow mining approach that is able to rediscover ICN-based structured workflow process models through incrementally amalgamating a series of vertically or horizontally fragmented temporal workcases. The approach has two essential algorithms; One is a temporal fragment discovery algorithm that is able to discover a set of temporal fragment models from the fragmented workflow enactment event logs, and the other is a workflow process mining algorithm that rediscovers a structured workflow process model from the discovered temporal fragment models. Where, the temporal fragment model represents the concrete model of the XML-based distributed workflow fragment events log. © 2009 IEEE. Distributed workflow management system; Events log; Horizontal fragment; Temporal fragment; Vertical fragment; Workflow fragmentation; Workflow process mining

Mining workflow recovery from event based logs Handling workflow transactional behavior remains a main problem to ensure a correct and reliable execution. It is obvious that the discovery, and the explanation of this behavior, would enable to better understand and control workflow recovery. Unfortunately, previous workflow mining works have concentrated their efforts on control flow aspects. Although powerful, these proposals are found lacking in functionalities and performance when used to discover workflow transactional behavior. In this paper, we describe mining techniques, which are able to discover a workflow model, and to improve its transactional behavior from event based logs. First, we propose an algorithm to discover workflow patterns. Then, we propose techniques to discover activities transactional dependencies that allow us to mine workflow recovery techniques. Finally, based on this mining step, we use a set of rules to improve workflow design. © Springer-Verlag Berlin Heidelberg 2005. Transactional workflows; Workflow mining; Workflow patterns; Workflow recovery

Model repair - aligning process models to reality Process mining techniques relate observed behavior (i.e., event logs) to modeled behavior (e.g., a BPMN model or a Petri net). Process models can be discovered from event logs and conformance checking techniques can be used to detect and diagnose differences between observed and modeled behavior. Existing process mining techniques can only uncover these differences, but the actual repair of the model is left to the user and is not supported. In this paper we investigate the problem of repairing a process model w.r.t. a log such that the resulting model can replay the log (i.e., conforms to it) and is as similar as possible to the original model. To solve the problem, we use an existing conformance checker that aligns the runs of the given process model to the traces in the log. Based on this information, we decompose the log into several sublogs of non-fitting subtraces. For each sublog, either a loop is discovered that can replay the sublog or a subprocess is derived that is then added to the original model at the appropriate location. The approach is implemented in the process mining toolkit ProM and has been validated on logs and models from several Dutch municipalities. © 2014 Elsevier Ltd. All rights reserved. 

Model-based business process mining As companies use enterprise resource planning (ERP) systems to support their business processes, they need to verity that the systems are configured appropriately and used in the most efficient way. This article describes the approach taken and results from a business process mining project at a midsized company in Norway. A newly released tool for analyzing ERP system logs is used to construct the underlying business flows and to provide new insights that can be used by the company to improve the procurement process. 

Model-based testing of service infrastructure components We present a methodology for testing service infrastructure components described in a high-level (UML-like) language. The technique of graph transformation is used to precisely capture the dynamic aspect of the protocols which is the basis of state space generation. Then we use model checking techniques to find adequate test sequences for a given requirement. To illustrate our approach, we present the case study of a fault tolerant service broker which implements a wellknown dependability pattern at the level of services. Finally, a compact Petri Net representation is derived by workflow mining techniques to generate faithful test cases in a non-deterministic, distributed environment. Note that our methodology is applicable at the architectural level rather than for testing individual service instances only. © IFIP- International Federation for Information Processing 2007. Fault-tolerant services; Graph transformation; Model checking; Model-based testing

Modeling and mining of learnflows This article transfers concepts and methods from business process modeling and workflow management to the field of learnflows, i.e. learning and teaching processes. It is first shown that these two areas have a lot of commonalities and similarities. On the other hand, there are also crucial specifics of learning processes that have to be taken into account additionally. We then introduce and discuss modeling languages for learnflows which are based on ideas from workflow modeling. Finally, we develop an approach to automatically generate learnflow models from log files of learning systems by adapting workflow mining methods. © 2012 Springer-Verlag. 

Modeling and verification of a protocol for operational support using coloured Petri nets In this paper, we describe the modeling and analysis of a protocol for operational support during workflow enactment. Operational support provides online replies to questions such as "is my execution valid?" and "how do I end the execution in the fastest/cheapest way?", and may be invoked multiple times for each execution. Multiple applications (operational support providers) may be able to answer such questions, so a protocol supporting this should be able to handle multiple providers, maintain data between queries about the same execution, and discard information when it is no longer needed. We present a coloured Petri net model of a protocol satisfying our requirements. The model is used both to make our requirements clear by building a model-based prototype before implementation and to verify that the devised protocol is correct. We present techniques to make analysis of the large state-space of the model possible, including modeling techniques and an improved state representation for coloured Petri nets allowing explicit representation of state spaces with more than 10 8 states on a normal PC. We briefly describe our implementation in the process mining tool ProM and how we have used it to improve an existing provider. © 2011 Springer-Verlag. 

Modelling and performance analysis of wireless sensor networks using process mining techniques: ContikiMAC use case In the current protocol stack for Internet of Things in general and wireless sensor network in particular, many devices rely on the Contiki MAC protocol at their MAC layer. This protocol is widely used and enabled by default for several industrial environments and time sensitive monitoring and control applications. However, few work exists regarding the performance of this protocol because it lacks of an underlying theoretical model for analysing its performance. In this paper, we propose a novel approach relying on process mining technique that aims to obtain a Markov chain model for networks running the Contiki MAC protocol. In particular, we present a comprehensive specification of the protocol and a Markov chain model obtained through the analysis and instrumentation of its reference implementation. We used the obtained Markov chain to analyze and estimate the end to end delay distribution for a multi-hops transmission with static routing. The approach can also be extended to a wide range of protocols. © 2014 IEEE. MAC Protocols; Markov chain; Network performance; Process Mining

Monitoring care processes in the gynecologic oncology department The care processes of healthcare providers are typically considered as human-centric, flexible, evolving, complex and multi-disciplinary. Consequently, acquiring an insight in the dynamics of these care processes can be an arduous task.A novel event log based approach for extracting valuable medical and organizational information on past executions of the care processes is presented in this study. Care processes are analyzed with the help of a preferential set of process mining techniques in order to discover recurring patterns, analyze and characterize process variants and identify adverse medical events. © 2013 Elsevier Ltd. Care processes; Clinical pathways; Health information systems; Healthcare quality; Medical informatics; Process mining

Net Components for the Integration of Process Mining into Agent-Oriented Software Engineering Process mining is increasingly used as an analysis technique to support the understanding of processes in software engineering. Due to the close relation to Petri nets as an underlying theory and representation technique, it can especially add to Petri net-based approaches. However, the complex analysis techniques are not straightforward to understand and handle for software developers with little data mining background. In this paper, we first discuss possibilities to integrate process mining into our Petri net-based agent-oriented software engineering approach. As the main contribution, we focus on enhancing its usability and introduce a technique and tool for visually modeling process mining algorithms with net components. These can be used to build new complex algorithms as a patch-work of existing procedures and new compositions. Furthermore, they allow for an easy integration with standard tools such as ProM. Petri nets; net components; process mining chains; modeling

New methodology for modeling large scale manufacturing process: Using process mining methods and experts' knowledge Modeling manufacturing process of complex products like electronic chips is crucial to maximize the quality of the production. This paper proposes a new methodology to model large scale manufacturing processes based on activity information as well as experts' knowledge. DEVS formalism is used for the final models because of its advantages as a formal formalism. This methodology helps to easily detect discrepancies between the actual implementation of processes with experts' definitions. It also helps to construct general models that could be used later for controlling processes. The idea of STMicroelectronics enterprise is to use these general models to implement an alarm system. The idea is to alert engineers about risky modifications done over STMicroelectronics manufacturing processes. The state of our work towards to model STMicroelectronics' production processes is presented at the end of this paper. © 2011 IEEE. 

New region-based algorithms for deriving bounded petri nets The theory of regions was introduced in the early nineties as a method to bridge state and event-based models. This paper tackles the problem of deriving a Petri net from a state-based model, using the theory of regions. Some of the restrictions required in the traditional approach are dropped in this paper, together with significant extensions that make the approach applicable in new scenarios. One of these scenarios is Process Mining, where accepting (discovering) additional behavior in the synthesized Petri net is sometimes valued. The algorithmic emphasis used in this paper contributes to the demystification of the theory of regions as been only a good theoretical exercise, opening the door for its application in the industrial domain. © 2010 IEEE. Bisimulation.; Petri nets; Process mining; Synthesis; Theory of regions; Transition systems

Nirikshan: Mining bug report history for discovering process maps, inefficiencies and inconsistencies Issue tracking systems such as Bugzilla, Mantis and JIRA are Process Aware Information Systems to support business process of issue (defect and feature enhancement) reporting and resolution. The process of issue reporting to resolution consists of several steps or activities performed by various roles (bug reporter, bug triager, bug fixer, developers, and quality assurance manager) within the software maintenance team. Project teams define a workflow or a business process (design time process model and guidelines) to streamline and structure the issue management activities. However, the runtime process (reality) may not conform to the design time model and can have imperfections or inefficiencies. We apply business process mining tools and techniques to analyze the event log data (bug report history) generated by an issue tracking system with the objective of discovering runtime process maps, inefficiencies and inconsistencies. We conduct a case-study on data extracted from Bugzilla issue tracking system of the popular open-source Firefox browser project. We present and implement a process mining framework, Nirikshan, consisting of various steps: data extraction, data transformation, process discovery, performance analysis and conformance checking. We conduct a series of process mining experiments to study self-loops, back-andforth, issue reopen, unique traces, event frequency, activity frequency, bottlenecks and present an algorithm and metrics to compute the degree of conformance between the design time and the runtime process. Copyright 2014 ACM. Empirical software engineering and measurements; Issue tracking system; Mining software repositories; Open-Source software; Process mining; Software maintenance

Obtaining thresholds for the effectiveness of business process mining Business process mining is a powerful tool to retrieve the valuable business knowledge embedded in existing information systems. The effectiveness of this kind of proposal is usually evaluated using recall and precision, which respectively measure the completeness and exactness of the retrieved business processes. Since the effectiveness assessment of business process mining is a difficult and error-prone activity, the main hypothesis of this work studies the possibility of obtaining thresholds to determine when recall and precision values are appropriate. The business process mining technique under study is MARBLE, a model-driven framework to retrieve business processes from existing information systems. The Bender method was applied to obtain the thresholds of the recall and precision measures. The experimental data used as input were obtained from a set of 44 business processes retrieved with MARBLE through a family of case studies carried out over the last two years. The study provides thresholds for recall and precision measures, which facilitates the interpretation of their values by means of five linguistic labels that range from low to very high. As a result, recall must be high (with at least a medium precision above 0.56), and precision must also be high (with at least a low recall of 0.70) to ensure that business processes were recovered (by using MARBLE) with an effectiveness value above 0.65. The thresholds allowed us to ascertain with more confidence whether MARBLE can effectively mine business processes from existing information systems. In addition, the provided results can be used as reference values to compare MARBLE with other similar business process mining techniques. © 2011 IEEE. Bender method; Business process; Case study; Process mining; Thresholds

On analyzing process compliance in skin cancer treatment: An experience report from the evidence-based medical compliance cluster (EBMC 2) Process mining has proven itself as a promising analysis technique for processes in the health care domain. The goal of the EBMC 2 project is to analyze skin cancer treatment processes regarding their compliance with relevant guidelines. For this, first of all, the actual treatment processes have to be discovered from the available data sources. In general, the L * life cycle model has been suggested as structured methodology for process mining projects. In this experience paper, we describe the challenges and lessons learned when realizing the L * life cycle model in the EBMC 2 context. Specifically, we provide and discuss different approaches to empower data of low maturity levels, i.e., data that is not already available in temporally ordered event logs, including a prototype for structured data acquisition. Further, first results on how process mining techniques can be utilized for data screening are presented. © 2012 Springer-Verlag Berlin Heidelberg. Data Quality; Healthcare Processes; Process Mining; Process Modeling

On integrating data mining into business processes Integrating data mining into business processes becomes crucial for business today.Modern business process management frameworks provide great support for flexible design, deployment and management of business processes. However, integrating complex data mining services into such frameworks is not trivial due to unclear definitions of user roles and missing flexible data mining services as well as missing standards and methods for the deployment of data mining solutions. This work contributes an integrated view on the definition of user roles for business, IT and data mining and discusses the integration of data mining in business processes and its evaluation in the context of BPR. © 2010 Springer-Verlag Berlin Heidelberg. BPM; Business processes; CRISP; Data mining; Integration

On mining clinical pathway patterns from medical behaviors Objective: Clinical pathway analysis, as a pivotal issue in ensuring specialized, standardized, normalized and sophisticated therapy procedures, is receiving increasing attention in the field of medical informatics. Clinical pathway pattern mining is one of the most important components of clinical pathway analysis and aims to discover which medical behaviors are essential/critical for clinical pathways, and also where temporal orders of these medical behaviors are quantified with numerical bounds. Even though existing clinical pathway pattern mining techniques can tell us which medical behaviors are frequently performed and in which order, they seldom precisely provide quantified temporal order information of critical medical behaviors in clinical pathways. Methods: This study adopts process mining to analyze clinical pathways. The key contribution of the paper is to develop a new process mining approach to find a set of clinical pathway patterns given a specific clinical workflow log and minimum support threshold. The proposed approach not only discovers which critical medical behaviors are performed and in which order, but also provides comprehensive knowledge about quantified temporal orders of medical behaviors in clinical pathways. Results: The proposed approach is evaluated via real-world data-sets, which are extracted from Zhejiang Huzhou Central hospital of China with regard to six specific diseases, i.e., bronchial lung cancer, gastric cancer, cerebral hemorrhage, breast cancer, infarction, and colon cancer, in two years (2007.08-2009.09). As compared to the general sequence pattern mining algorithm, the proposed approach consumes less processing time, generates quite a smaller number of clinical pathway patterns, and has a linear scalability in terms of execution time against the increasing size of data sets. Conclusion: The experimental results indicate the applicability of the proposed approach, based on which it is possible to discover clinical pathway patterns that can cover most frequent medical behaviors that are most regularly encountered in clinical practice. Therefore, it holds significant promise in research efforts related to the analysis of clinical pathways. © 2012 Elsevier B.V. Clinical pathway analysis; Clinical workflow log; Pattern mining; Process mining

On process mining in health care With the increasing demand for health care, hospitals are looking for ways to optimize their care processes in order to increase efficiency, while guaranteeing the quality of the care. Process modeling is a crucial step for process improvement, since it provides a process model that can be analyzed and optimized. Process mining is a recent promising methodology to discover process models based on data from event logs. However, early applications of process mining to health care has produced overly complex models, which have been attributed to the complexity of the health care domain. In this paper, we argue that existing process mining methods fail to identify good process models, even for well-defined clinical processes. We identify a number of reasons for this shortcoming and discuss a few directions for extending process mining methods in order to make them more suitable for the clinical domain. © 2012 IEEE. clinical processes; Healthcare; process mining

On recommendation of process mining algorithms While many process mining algorithms have been proposed recently, there does not exist a widely-accepted benchmark to evaluate and compare these process mining algorithms. As a result, it can be difficult to choose a suitable process mining algorithm for a given enterprise or application domain. Some recent benchmark systems have been developed and proposed to address this issue. However, evaluating available process mining algorithms against a large set of business models (e.g., in a large enterprise) can be computationally expensive, tedious and time-consuming. This paper proposes a novel framework that can efficiently select the process mining algorithms that are most suitable for a given model set. In particular, it attemptsto investigate how we can avoid evaluating numerous process mining algorithms on all given process models. © 2012 IEEE. benchmarking; Business process mining; evaluation

On reusing data mining in business processes - A pattern-based approach Today's business applications demand high flexibility in processing information and extracting knowledge from data. Thus, data mining becomes more and more an integral part of operating a business. However, the integration of data mining into business processes still requires a lot of coordination and manual adjustment. This paper aims at reducing this effort by reusing successful data mining solutions. We describe a novel approach on facilitating the integration based on process patterns for data mining and demonstrate that these patterns allow for easy reuse and can significantly speed up the process of integration. We empirically evaluate our approach in a case study of fraud detection in the health care domain. © 2011 Springer-Verlag. BPM; Business Processes; CRISP; Data Mining Patterns; Reuse and Integration

On the distinction between truthful, invisible, false and unobserved events: An event existence classification framework and the impact on business process analytics related research areas In this paper we present an event existence classification framework based on five business criteria. As a result we are able to distinguish thirteen event types distributed over four categories, i.e. truthful, invisible, false and unobserved events. Currently, several of these event types are not commonly dealt with in business process analytics research. Based on the proposed framework we situate the different business process analytics research areas and indicate the potential issues for each field. A real world case will be elaborated to demonstrate the relevance of the event classification framework. © (2012) by the AIS/ICIS Administrative Office All rights reserved. Artificial event generation; Compliance checking; Event-based information systems; Information systems auditing; Process mining

On the exploitation of process mining for security audits: The conformance checking case Process mining stands for a set of techniques to analyze business process models and logs. However, the extent to which it can be used for security auditing has not been investigated. Focusing on conformance checking and its support in ProM, this paper reports on a case-study in the financial sector applying this technology for the auditing of relevant security requirements. Although the vast majority of requirements could be verified, we notice a large manual effort to carry out the analysis. Moreover, we identify a class of security requirements that demands process discovery for analysis, and elaborate on ways in which process mining could be extended to better suit security analyses. © 2012 ACM. business process security audit; conformance checking; information flow analysis; process mining

On the performance of workflow processes with distributed actors: Does place matter? Current workflow technology offers rich features to manage and enact business processes. In principle, the technology enables actors to cooperate in the execution of business processes regardless of their geographical location. Furthermore, the technology is considered as an efficient means to reduce processing times. In this paper, we evaluate the effects on the performance of a workflow process in an organizational setting where actors are geographically distributed. The studied process is exceptional, because equivalent tasks can be performed at different locations. We have analyzed a large workflow process log with state-of-the art mining tools associated with the ProM framework. Our analysis leads to the conclusion that there is a positive effect on process performance when workflow actors are geographically close. © Springer-Verlag Berlin Heidelberg 2007. Case study; Performance evaluation; Process mining; Workflow management

On the use of side information for mining text data In many text mining applications, side-information is available along with the text documents. Such side-information may be of different kinds, such as document provenance information, the links in the document, user-access behavior from web logs, or other non-textual attributes which are embedded into the text document. Such attributes may contain a tremendous amount of information for clustering purposes. However, the relative importance of this side-information may be difficult to estimate, especially when some of the information is noisy. In such cases, it can be risky to incorporate side-information into the mining process, because it can either improve the quality of the representation for the mining process, or can add noise to the process. Therefore, we need a principled way to perform the mining process, so as to maximize the advantages from using this side information. In this paper, we design an algorithm which combines classical partitioning algorithms with probabilistic models in order to create an effective clustering approach. We then show how to extend the approach to the classification problem. We present experimental results on a number of real data sets in order to illustrate the advantages of using such an approach. © 1989-2012 IEEE. clustering; text mining

On the a-reconstructibility of workflow nets The process mining algorithm a was introduced by van der Aalst et al. for the discovery of workflow nets from event logs. This algorithm was presented in the context of structured workflow nets even though it was recognized that more wokflow nets should be reconstructible. In this paper we assess a algorithm and provide a more precise description of the class of workflow nets reconstructible by a. © 2012 Springer-Verlag. Net Synthesis; Process Mining; Workflows

On web services workflow mining With the ever growing importance of the service-oriented paradigm in system architectures more and more (business) processes will be executed using service-oriented systems. Therefore, we believe that the ability to discover processes in loosely-coupled systems is essential in system optimization. Firstly, we briefly describe our previously introduced idea of Web Services Interaction Mining (WSIM) and then direct our attention on mining for workflows in logs provided by SOA. We thoroughly examine strategies in other fields of mining for their applicability in SOA. After that, we discuss logging possibilities in service-oriented systems and analyze mining opportunities with regards to the provided logs. As a case study we present a service-oriented system and its logging features. We conclude with a demonstration of how we successfully applied existing process mining strategies on this system's logs and present the results of that mining in the form of workflow models. © Springer-Verlag Berlin Heidelberg 2006. 

Online techniques for dealing with concept drift in process mining Concept drift is an important concern for any data analysis scenario involving temporally ordered data. In the last decade Process mining arose as a discipline that uses the logs of information systems in order to mine, analyze and enhance the process dimension. There is very little work dealing with concept drift in process mining. In this paper we present the first online mechanism for detecting and managing concept drift, which is based on abstract interpretation and sequential sampling, together with recent learning techniques on data streams. © Springer-Verlag Berlin Heidelberg 2012. 

Ontological approach to enhance results of business process mining and analysis Purpose: The purpose of this paper is to propose a solution to the problem of a lack of machine processable semantics in business process management. Design/methodology/approach: The paper introduces a methodology that combines domain and company-specific ontologies and databases to obtain multiple levels of abstraction for process mining and analysis. The authors valuated this approach with a real case study from the apparel domain, using a prototype system and techniques developed in the Process Mining Framework (ProM). The results of this approach are compared with similar research. Findings: Semantically enriching process execution data can successfully raise analysis from the syntactic to the semantic level, and enable multiple perspectives of analysis on business processes. Combining this approach with complementary research in semantic business process management (SBPM) can provide results comparable to multidimensional analysis in data warehouse and on line analytical processing (OLAP) technologies. Originality/value: The approach and prototype described in this paper improve the richness of semantics available for open-source process mining and analysis tools like ProM, and the richness and detail of the resulting analysis. © Emerald Group Publishing Limited. Business process; Multi-perspective process analysis; Multidimensional analysis; Ontological approach; Ontology layers; Ontology-database mapping; Process analysis; Process mining and analysis; Semantic annotation log; Semantic business process management; Semantic enhancement; Semantic process mining and analysis; Semantics

Optimization of service delivery through continual process improvement: A case study In order to deliver services of high quality in a cost-effective manner, processes and their support through information technology (IT) play an increasingly significant role. We present an approach, which allows optimizing the service delivery through continual process improvement. This approach combines the 7-step improvement process recommended by ITIL with process mining. On the basis of suggestions derived from process mining, performance indicators of different services are determined and subsequently compared as part of an internal benchmark. The approach, which will be trialed in practice, enables the optimization of service delivery certainly, but it is also concerned with the most effective utilization of limited resources in terms of people and tools. 

Organizational modeling from event logs Many process mining approaches have been published, which would be helpful to process modeling, but little attempt has been made for role mining used for organizational modeling. In this paper, a method of role mining using event logs as input is introduced. We adopt cosine metrics as the similarity measurement to deduce flat organizational model by clustering people base on their similar skills. In contrast to traditional techniques (e.g., questionnaire), our approach is objective and efficient. This paper also points out some challenges for future research. ©2007 IEEE. 

Organizational structure mining based on workflow logs In order to mining the organizational setting and interactions among coworkers from workflow logs, we define metrics to establish the relationships among originators by analyzing the information in the workflow logs. Three methods for mining organizational structure from workflow logs are presented in this paper, default mining, mining based on the similarity of activities and mining based on the similarity of cases. By applying these methods, we can construct the corresponding organizational network which reflects the organizational entities involved in the workflow process and corrects presented the organizational structure. In the end of the paper, we give an example to explain it. © 2009 IEEE. Organizational network; Organizational structure mining; Process mining; Workflow logs

Outlier detection techniques for process mining applications Classical outlier detection approaches may hardly fit process mining applications, since in these settings anomalies emerge not only as deviations from the sequence of events most often registered in the log, but also as deviations from the behavior prescribed by some (possibly unknown) process model. These issues have been faced in the paper via an approach for singling out anomalous evolutions within a set of process traces, which takes into account both statistical properties of the log and the constraints associated with the process model. The approach combines the discovery of frequent execution patterns with a cluster-based anomaly detection procedure; notably, this procedure is suited to deal with categorical data and is, hence, interesting in its own, given that outlier detection has mainly been studied on numerical domains in the literature. All the algorithms presented in the paper have been implemented and integrated into a system prototype that has been thoroughly tested to assess its scalability and effectiveness. © 2008 Springer-Verlag Berlin Heidelberg. 

Pattern discovery from innovation processes Innovation management and promotion has become one of the most important topics in the Literature about business and executive decision support. In particular, the relationship between innovation and collaboration, both intra- and inter-organization, is gaining an increasing attention in many works, for example in the Open Innovation research field [2]. Innovation activities, especially those that involve collaboration, are typically not structured; they don't follow a predefined scheme or procedure and are influenced by multiple factors, for instance the individual behaviour, that makes it difficult to apply classical methods of process analysis. In this paper we describe a methodology to discover significant and recurrent patterns in innovation activities, that can be used to support and improve such kind of processes. To evaluate our approach we conducted a set of experiments on a synthetic dataset, which contains a set of traces of innovation activities generated from some abstract templates, drew with the aim to model the typical ways in which innovation is carried on. © 2013 IEEE. clustering; collaboration analysis; open innovation; pattern discovery; process mining

Pattern mining in system logs: Opportunities for process improvement Enterprise systems implementations are often accompanied by changes in the business processes of the organizations in which they take place. However, not all the changes are desirable. In "vanilla" implementations it is possible that the newly operational business process requires many additional steps as "workarounds" of the system limitations, and is hence performed in an inefficient manner. Such inefficiencies are reflected in the event log of the system as recurring patterns of log entries. Once identified, they can be resolved over time by modifications to the enterprise system. Addressing this situation, the paper proposes an approach for identifying inefficient workarounds by mining the related patterns in an event log. The paper characterizes such patterns, proposes a mining algorithm, and rules for prioritizing the required process improvements. © 2009 Springer Berlin Heidelberg. Enterprise systems; Event log; Process mining

PCorral - Interactive mining of protein interactions from MEDLINE The extraction of information from the scientific literature is a complex task - for researchers doing manual curation and for automatic text processing solutions. The identification of protein-protein interactions (PPIs) requires the extraction of protein named entities and their relations. Semi-automatic interactive support is one approach to combine both solutions for efficient working processes to generate reliable database content. In principle, the extraction of PPIs can be achieved with different methods that can be combined to deliver high precision and/or high recall results in different combinations at the same time. Interactive use can be achieved, if the analytical methods are fast enough to process the retrieved documents. PCorral provides interactive mining of PPIs from the scientific literature allowing curators to skim MEDLINE for PPIs at low overheads. The keyword query to PCorral steers the selection of documents, and the subsequent text analysis generates high recall and high precision results for the curator. The underlying components of PCorral process the documents on-the-fly and are available, as well, as web service from the Whatizit infrastructure. The human interface summarizes the identified PPI results, and the involved entities are linked to relevant resources and databases. Altogether, PCorral serves curator at both the beginning and the end of the curation workflow for information retrieval and information extraction. © The Author(s) 2013. Published by Oxford University Press. 

Performance analysis of GRID middleware using process mining Performance analysis of the GRID middleware used in a production setting can give valuable information to both GRID users and developers. A new approach to this issue is to use the process mining techniques. Analyzing logs of the middleware activities, performed on the SEE-GRID pilot production Grid infrastructure, objective qualitative and quantitative information on what actually happens can be obtained. Using the appropriate tools like ProM to apply the process mining algorithms, many interesting findings and conclusions can be drawn. In this paper we describe our approach and show some of our conclusions. © 2008 Springer-Verlag Berlin Heidelberg. Grid; Middleware; Performances; Process mining

Performative-based mining of workflow organizational structures Continuous and unforeseeable evolution of business rules, processing logics, and organizational structures within enterprises, require from business process management systems to integrate continuous design. Supporting business process rediscovery based on workflow logs analysis, workflow mining gathers retroactive (re)design techniques necessary to understand business process execution reality. Most of the work in this area focus on the control-flow perspective, while very few of them address the organizational aspect. In this paper, we propose to enrich workflow logs using a performative-based agent communication language in order to integrate conversations among workflow performers. Thereafter, we present innovative mining algorithms in order to discover organizational workflow structures based on the enriched logs. Those algorithms have been implemented as new plug-ins in ProM framework. © 2012 Springer-Verlag. Organizational mining; Performatives; Process mining

PETRA: Process Evolution using a TRAce-based system on a maintenance platform To meet increasing needs in the field of maintenance, we studied the dynamic aspect of process and services on a maintenance platform, a major challenge in process mining and knowledge engineering. Hence, we propose a dynamic experience feedback approach to exploit maintenance process behaviors in real execution of the maintenance platform. An active learning process exploiting event log is introduced by taking into account the dynamic aspect of knowledge using trace engineering. Our proposal makes explicit the underlying knowledge of platform users by means of a trace-based system called "PETRA". The goal of this system is to extract new knowledge rules about transitions and activities in maintenance processes from previous platform executions as well as its user (i.e. maintenance operators) interactions. While following a Knowledge Traces Discovery process and handling the maintenance ontology IMAMO, "PETRA" is composed of three main subsystems: tracking, learning and knowledge capitalization. The capitalized rules are shared in the platform knowledge base in order to be reused in future process executions. The feasibility of this method is proven through concrete use cases involving four maintenance processes and their simulation. © 2014 Elsevier B.V. All rights reserved. Experience reuse; Process extension; Process mining; s-Maintenance platform; Trace-based systems

Petri-net integration - An approach to support multi-agent process mining During the developing phase of a multi-agent system (MAS), it is necessary to simulate the system feasibility before the formal implementation. Petri-net (PN) is the most popular tool used in MAS system simulation. However, most of the PN models were developed according to the investigation of the MAS behaviors. There lacked a bridge to directly link MAS development tool and the PN simulator. This research proposed a PN integration approach to support multi-agent process mining. A process mining technique (a algorithm) would be used to investigate the log file generated by each agent system and then to create the PN based process models. In the next stage, an approach was proposed to integrate the PN of each agent. This method would construct the incoming and outgoing places of each agent's PN according to inter-agent communication behaviors showed in the logs. These incoming and outgoing places would be merged into communication places representing the inter-relationship between agent's PN models. Finally, the multi-agent PN model would be simulated and the results showed that the agent interaction behaviors are consistent with the information shown in their log files. © 2010 Elsevier Ltd. All rights reserved. Multi-agent systems; Petri-net; Process mining

Predicting deadline transgressions using event logs Effective risk management is crucial for any organisation. One of its key steps is risk identification, but few tools exist to support this process. Here we present a method for the automatic discovery of a particular type of process-related risk, the danger of deadline transgressions or overruns, based on the analysis of event logs. We define a set of time-related process risk indicators, i.e., patterns observable in event logs that highlight the likelihood of an overrun, and then show how instances of these patterns can be identified automatically using statistical principles. To demonstrate its feasibility, the approach has been implemented as a plug-in module to the process mining framework ProM and tested using an event log from a Dutch financial institution. © 2013 Springer-Verlag Berlin Heidelberg. 

Preprocessing support for large scale process mining of SAP transactions Since ERP systems, like SAP, support the backbone operations of companies, their transaction logs provide valuable insight into the companies' business processes. In SAP every transaction is stored and linked to relevant documents, organizational structures and other process-relevant information. However, the complexities and size of SAP logs make it hard to analyze the business processes directly with current process mining tools. This paper describes an ERP log analysis system that allows the users to define at a meta level how events, resources and their inter-relations are stored and transformed for use in process mining. We show how the system is applied to extract and transform related SAP transaction data for the ProM process mining tool. © 2008 Springer-Verlag Berlin Heidelberg. 

Probabilistic workflow mining In several organizations, it has become increasingly popular to document and log the steps that makeup a typical business process. In some situations, a normative workflow model of such processes is developed, and it becomes important to know if such a model is actually being followed by analyzing the available activity logs. In other scenarios, no model is available and, with the purpose of evaluating cases or creating new production policies, one is interested in learning a workflow representation of such activities. In either case, machine learning tools that can mine workflow models are of great interest and still relatively unexplored. We present here a probabilistic workflow model and a corresponding learning algorithm that runs in polynomial time. We illustrate the algorithm on example data derived from a real world workflow. Copyright 2005 ACM. Causal models; Graphical models; Workflow mining

Process aware host-based intrusion detection model Nowadays, many organizations use Process Aware Information Systems (PAISs) to automate their business process. As any other information systems, security plays a major role in PAIS to provide a secure state and maintain the system in it. In order to provide security in a PAIS, a Process Aware Host-based Intrusion Detection (PAHID) model is proposed in this paper. The model detects host-based intrusions in a PAIS using process mining techniques. The proposed model uses both anomaly detection and misuse detection techniques for more efficiency, and organizational perspective of process mining is considered (rather than control-flow perspective) to detect more attack types. The model is automated and can deal with large logs and is suitable for flexible application domains. The PAHID model is implemented by the use of ProM framework and Java programming. It is evaluated by using a simulated log based on a real-world organization information system. Results demonstrate that the model provides high accuracy and low false positive rate. Anomaly detection; Host-based Intrusion Detection; Misuse detection.; Process aware information system; Process mining

Process design selection using proximity score measurement Recently, business environments have become exceedingly dynamic and competitive. In this situation, many enterprises strive to attract customers by constructing multiple business process (BP) variants. Variances within a single process model are created by a process designer to comply with customers' needs. However, customers are rarely involved in the design phase. In the near future, a customer-centric system will request more flexibility in design customization. The advantages from the establishment of a user analysis tool will be necessary to any organization. This paper presents an analysis technique for measuring the proximity among processes. The proposed proximity score follows the concept of workflow mining in observing the closeness of the relationships among all activities within process variants. The method enables a process modeler to generate a proximity score directly once a user starts to design. A higher proximity score for a new process design emphasizes a closer relationship with the existing activities among process variants. A simple case study is presented to demonstrate the idea of proximity score in the BP design environment. © 2010 Springer-Verlag. process design; process variant; proximity score; Workflow mining

Process diagnostics using trace alignment: Opportunities, issues, and challenges Business processes leave trails in a variety of data sources (e.g., audit trails, databases, and transaction logs). Hence, every process instance can be described by a trace, i.e., a sequence of events. Process mining techniques are able to extract knowledge from such traces and provide a welcome extension to the repertoire of business process analysis techniques. Recently, process mining techniques have been adopted in various commercial BPM systems (e.g., BPM|one, Futura Reflect, ARIS PPM, Fujitsu Interstage, Businesscape, Iontas PDF, and QPR PA). Unfortunately, traditional process discovery algorithms have problems dealing with less structured processes. The resulting models are difficult to comprehend or even misleading. Therefore, we propose a new approach based on trace alignment. The goal is to align traces in such a way that event logs can be explored easily. Trace alignment can be used to explore the process in the early stages of analysis and to answer specific questions in later stages of analysis. Hence, it complements existing process mining techniques focusing on discovery and conformance checking. The proposed techniques have been implemented as plugins in the ProM framework. We report the results of trace alignment on one synthetic and two real-life event logs, and show that trace alignment has significant promise in process diagnostic efforts. © 2011 Elsevier Ltd. All Rights Reserved. Alignment; Conformance; Diagnostics; Execution patterns; Process mining

Process diagnostics: A method based on process mining As organizations change, their information systems can evolve from simple systems to complex systems, which are hard to understand, and therefore hard to maintain or extend. Process mining can help organizations in trying to understand the information systems by analyzing the system. In this paper we propose a methodology to perform process diagnostics, based on process mining. Given an event log of an information system within an organization, process diagnostics gives a broad overview of the organization's process(es) within a short period of time. In the process diagnostics methodology, several perspectives of the process are highlighted. The outcome covers the control flow perspective, the performance perspective and the organizational perspective. We used the methodology on a case study for a Dutch governmental organization. Index Terms-process management, process analysis, process mining, information system design © 2009 IEEE. 

Process discovery and conformance checking using passages The two most prominent process mining tasks are process discovery (i.e., learning a process model from an event log) and conformance checking (i.e., diagnosing and quantifying differences between observed and modeled behavior). The increasing availability of event data makes these tasks highly relevant for process analysis and improvement. Therefore, process mining is considered to be one of the key technologies for Business Process Management (BPM). However, as event logs and process models grow, process mining becomes more challenging. Therefore, we propose an approach to decompose process mining problems into smaller problems using the notion of passages. A passage is a pair of two non-empty sets of activities (X, Y) such that the set of direct successors of X is Y and the set of direct predecessors of Y is X. Any Petri net can be partitioned using passages. Moreover, process discovery and conformance checking can be done per passage and the results can be aggregated. This has advantages in terms of efficiency and diagnostics. Moreover, passages can be used to distribute process mining problems over a network of computers. Passages are supported through ProM plug-ins that automatically decompose process discovery and conformance checking tasks. business process management; conformance checking; distributed computing; process discovery; Process mining

Process discovery and Petri nets The aim of the research domain known as process mining is to use process discovery to construct a process model as an abstract representation of event logs. The goal is to build a model (in terms of a Petri net) that can reproduce the logs under consideration, and does not allow different behaviours compared with those shown in the logs. In particular, process mining aims to verify the accuracy of the model design (represented as a Petri net), basically checking whether the same net can be rediscovered. However, the main mining methods proposed in the literature have some drawbacks: the classical -algorithm is unable to rediscover various nets, while the region-based approach, which can mine them correctly, is too complex. In this paper, we compare different approaches and propose some ideas to counter the weaknesses of the region-based approach. © 2009 Cambridge University Press. 

Process Discovery by Synthesizing Activity Proximity and User's Domain Knowledge Process mining techniques assist users to automatically infer process models from event logs. However, the result of process model driven by traditional process mining technique may conflict with the knowledge of users due to some real conditions, i.e. alternative activity is selected due to equipment breakdown. First, the use of heuristics may detect inconsistencies caused by bad guess. Second, extraction of all possible ordering of events reflects historical observation that sometimes hinders users to obtain an ideal process model since the activity has some event types. Yet, the current process mining approach is not totally compatible with some aspects such as extra logs behavior and soundness of process model when the process model changes according to user requirements. This paper presents a method for synthesizing activity proximity from event logs in the area of process mining. The method derives a bounded graph that covers the extra-behavior of an event log according to user's domain knowledge. Another important property is that it produces a graph with considering the proximity among activities that still contains the original behavior of the event log based on event types. The methods described in this paper have been implemented in ProM framework and tested on a set of real process examples. process mining; business process; proximity score; user's knowledge; integer linear programming

Process discovery from the log of business rule engine Process/workflow mining aims at discovering the underlying processes to help in improving or rebuilding business processes. Most of the current practices of process mining are based on event logs from Transactional Information Systems (TIS) (such as WFM, ERP, CRM, SCM and B2B systems). However, with the popular deployment and use of business rule engine with TIS, a great number of rule logs are generated, but they are rarely utilized for discovering processes. This paper intends to propose a different perspective for process discovery as compared with the traditional way based on the event logs. Firstly, it illustrates a motivation scenario about process mining from rule logs and then brings forward a framework for process discovery based on rule logs. After that, the mining algorithm called Alpha-r with a case study is introduced to discover a process through mining the relations of traces in rule flow log. Finally, some experiments show the effectiveness and performance of the method. © 2012 ICIC International. Business rule engine; Log; Process/Workflow mining; Rule flow

Process discovery in event logs: An application in the telecom industry The abundant availability of data is typical for information-intensive organizations. Usually, discerning knowledge from vast amounts of data is a challenge. Similarly, discovering business process models from information system event logs is definitely non-trivial. Within the analysis of event logs, process discovery, which can be defined as the automated construction of structured process models from such event logs, is an important learning task. However, the discovery of these processes poses many challenges. First of all, human-centric processes are likely to contain a lot of noise as people deviate from standard procedures. Other challenges are the discovery of so-called non-local, non-free choice constructs, duplicate activities, incomplete event logs and the inclusion of prior knowledge. In this paper, we present an empirical evaluation of three state-of-the-art process discovery techniques: Genetic Miner, AGNEs and HeuristicsMiner. Although the detailed empirical evaluation is the main contribution of this paper to the literature, an in-depth discussion of a number of different evaluation metrics for process discovery techniques and a thorough discussion of the validity issue are key contributions as well. © 2010 Elsevier B.V. All rights reserved. AGNEs; Data mining; Event logs; Genetic Miner; HeuristicsMiner; Process discovery; Workflow management systems (WfMS)

Process discovery using ant colony optimization This paper proposes ACO BP Miner, a novel method used to discover business process models from event logs using an Ant Colony Optimization (ACO) algorithm. ACO concepts are mapped to process model elements for enabling artificial ants to discover business process models that correctly correspond to the event logs. The process model discovered by ACO BP Miner is represented as a BPMN diagram [12]. The results are presented as a side by side comparison between the ACO BP Miner and the Genetic Miner [10]. © 2013 IEEE. ant colony optimization; artificial ant; BPMN; business process discovery; business process mining; event logs; Genetic Miner

Process discovery via precedence constraints A key task in process mining consists of building a graph of causal dependencies over process activities, which can then be used to derive more expressive models in some high-level modeling language. An approach to accomplish this task is presented where the learning process can exploit the background knowledge that, in many cases, is available to the analysts taking care of the process (re-)design. The method is based on encoding the information gathered from the log and the (possibly) given background knowledge in terms of precedence constraints, i.e., constraints over the topology of the graphs. Learning algorithms are eventually formulated in terms of reasoning problems over precedence constraints, and the computational complexity of such problems is thoroughly analyzed by tracing their tractability frontier. The whole approach has been implemented in a prototype system leveraging a solid constraint programming platform, and results of experimental activity are reported. © 2012 The Author(s). 

Process discovery: Capturing the invisible Processes are everywhere. Organizations have business processes to manufacture products, provide services, purchase goods, handle applications, etc. Also in our daily lives we are involved in a variety of processes, for example when we use our car or when we book a trip via the Internet. Although such operational processes are omnipresent, they are at the same time intangible. Unlike a product or a piece of data, processes are less concrete because of their dynamic nature. However, more and more information about these processes is captured in the form of event logs. Contemporary systems ranging from copiers and medical devices to enterprise information systems and cloud infrastructures record events. These events can be used to make processes visible. Using process mining techniques it is possible to discover processes. This provides the insights necessary to manage, control, and improve processes. Process mining has been successfully applied in a variety of domains ranging from healthcare and e-business to high-tech systems and auditing. Despite these successes, there are still many challenges as process discovery shows that the real processes are more "spaghetti-like" than people like to think. It is still very difficult to capture the complex reality in a suitable model. Given the nature of these challenges, techniques originating from Computational Intelligence may assist in the discovery of complex processes. © 2006 IEEE. 

Process management in health care: A system for preventing risks and medical errors This work describes the architecture of a clinical processes management system aimed to support a process-centered vision of health care practices. At the heart of the system there is a formalism well suited for representation of both processes and related domain knowledge. This language allows the semantic description of clinical processes using ontology and workflow representation formalisms. The main goal of the system is to assist in executing the clinical processes by providing intelligence functionalities, based on workflow mining techniques, and in monitoring processes during their execution. Acquired process instances can be analyzed to identify main causes of medical errors and high costs and, potentially, to suggest clinical processes restructuring or improvement able to enhance cost control and patient safety. © Springer-Verlag Berlin Heidelberg 2005. 

Process Mining alpha-Algorithm as a Tool (A Case Study of Student Registration) The alpha-algorithm is an algorithm used in process mining, aimed at reconstructing causality from a set of sequences of events. In this paper we used alpha algorithm in order to focus on the control flow perspective of students' registration process model in one of the universities in Thailand. The event log consisted of 299 cases and 569 events. Initially the data was received in form of MS Access Database but later using PromImport platform, the data was converted into MXML, a format that commonly is used in Prom. Though the paper applies the alpha-algorithm in presented case study, yet the alpha-algorithm could not adequately deal with loops and concurrency of process models. Therefore the alpha-algorithm should not be seen as a very practical mining technique as it has its own problems with noise, infrequent/incomplete behavior, and complex routing constructs. Nevertheless, we used the algorithm as a baseline for discussing the challenges related to model discovery of registration process in an academic environment. process mining; alpha-algorithm; workflow mining; Petri nets; workflow Petri nets; students' registration process

Process mining analysis of conceptual modeling behavior of novices - Empirical study using JMermaid modeling and experimental logging environment Previous studies on learning challenges in the field of modeling focus on cognitive perspectives, such as model understanding, modeling language knowledge and perceptual properties of graphical notation by novice business analysts as major sources affecting model quality. In the educational context outcome feedback is usually applied to improve learning achievements. However, not many research publications have been written observing the characteristics of a modeling process itself that can be associated with better/worse learning outcomes, nor have any empirically validated results been reported on the observations of modeling activities in the educational context. This paper attempts to cover this gap for conceptual modeling. We analyze modeling behavior (conceptual modeling event data of 20 cases, 10.000 events in total) using experimental logging functionality of the JMermaid modeling tool and process mining techniques. The outcomes of the work include modeling patterns that are indicative for worse/better learning performance. The results contribute to (1) improving teaching guidance for conceptual modeling targeted at process-oriented feedback, (2) providing recommendations on the type of data that can be useful in observing a modeling behavior from the perspective of learning outcomes. In addition, the study provides first insights for learning analytics research in the domain of conceptual modeling. Conceptual modeling pattern; Information systems education; Learning data analytics; Process mining; Process-oriented feedback; Teaching/learning conceptual modeling

Process mining and petri net synthesis The theory of regions and the algorithms for synthesizing a Petri net model from a transition system, which are based on this theory, have interesting practical applications - in particular in the design of electronic circuits. In this paper, we show that this theory can be also applied for mining the underlying process from the user interactions with a document management system. To this end, we combine an algorithm that we called activity mining with such Petri net synthesis algorithms. We present the basic idea of this approach, show some first results, and compare them with classical process mining techniques. The main benefit is that, in combination, the activity mining algorithm and the synthesis algorithms do not need a log of the activities, which is not available when the processes are supported by a document management system only. © Springer-Verlag Berlin Heidelberg 2006. 

Process mining and security: Detecting anomalous process executions and checking process conformance One approach to secure systems is through the analysis of audit trails. An audit trail is a record of all events that take place in a system and across a network, i.e., it provides a trace of user/system actions so that security events can be related to the actions of a specific individual or system component. Audit trails can be inspected for the presence or absence of certain patterns. This paper advocates the use of process mining techniques to analyze audit trails for security violations. It is shown how a specific algorithm, called the a-algorithm, can be used to support security efforts at various levels ranging from low-level intrusion detection to high-level fraud prevention. © 2005 Elsevier B.V. Audit trails; Data mining; Pattern discovery; Petri nets; Process mining; Security

Process mining and security: Visualization in database intrusion detection Nowadays, more and more organizations keep their valuable and sensitive data in Database Management Systems (DBMSs). The traditional database security mechanisms such as access control mechanisms, authentication, data encryption technologies do not offer a strong enough protection against the exploitation of vulnerabilities (e.g. intrusions) in DBMSs from insiders. Intrusion detection systems recently proposed in the literature focus on statistical approaches, which are not intuitive. Our research is the first ever effort to use process mining modeling low-level event logs for database intrusion detection. We have proposed a novel approach for visualizing database intrusion detection using process mining techniques. Our experiments showed that intrusion detection visualization will be able to help security officers who might not know deeply the complex system, identify the true positive detection and eliminate the false positive results. © 2012 Springer-Verlag. conformance; database intrusion detection; event log; intrusion detection; intrusion detection visualization; Process mining; security

Process mining and verification of properties: An approach based on temporal logic Information systems are facing conflicting requirements. On the one hand, systems need to be adaptive and self-managing to deal with rapidly changing circumstances. On the other hand, legislation such as the Sarbanes-Oxley Act, is putting increasing demands on monitoring activities and processes. As processes and systems become more flexible, both the need for, and the complexity of monitoring increases. Our earlier work on process mining has primarily focused on process discovery, i.e., automatically constructing models describing knowledge extracted from event logs. In this paper, we focus on a different problem complementing process discovery. Given an event log and some property, we want to verify whether the property holds. For this purpose we have developed a new language based on Linear Temporal Logic (LTL) and we combine this with a standard XML format to store event logs. Given an event log and an LTL property, our LTL Checker verifies whether the observed behavior matches the (un)expected/(un)desirable behavior. © Springer-Verlag Berlin Heidelberg 2005. Business process management; Data mining; Petri nets; Process mining; Temporal logic; Workflow management

Process mining applied to the test process of wafer scanners in ASML Process mining techniques attempt to extract nontrivial and useful information from event logs. For example, there are many process mining techniques to automatically discover a process model describing the causal dependencies between activities. Several successful case studies have been reported in literature, all demonstrating the applicability of process mining. However, these case studies refer to rather structured administrative processes. In this paper, we investigate the applicability of process mining to less structured processes. We report on a case study where the process mining (ProM) framework has been applied to the test processes of ASML (the leading manufacturer of wafer scanners in the world).This case study provides many interesting insights. On the one hand, process mining is also applicable to the less structured processes of ASML. On the other hand, the case study also shows the need for alternative mining approaches. © 2009 IEEE. Case study; Process mining; Test process optimization

Process mining approach for traffic analysis in wireless mesh networks Short-time traffic flow prediction in particular systems will expedite discovering of an optimal path for packet transmitting in dynamic wireless networks. The main goal is to predict traffic overload while changing a network topology. Machine learning techniques and process mining can help analyze traffic produced by several moving nodes. Several related approaches are observed. Research framework structure is presented. The idea of process mining approach is proposed. © 2012 Springer-Verlag. adaptive routing; power aware metric; process mining; traffic hotspots; Wireless mesh networks

Process mining approach to promote business intelligence in Iranian detectives' police Most of business processes leave their "footprints" in transactional information systems, i.e., business process events are recorded in so-called event logs on Enterprise systems. These systems can be used as a lead in police investigation. This paper field is in providing techniques and tools for discovering process, control, data, organizational, and social structures from event logs as the goal of process mining and the basic idea of process mining is to diagnose business processes to promote Detectives' Police knowledge in computer crimes. In this paper we focus on the potential use of process mining techniques to enable Iranian Detectives' Police for discovering grounds of crime. This application is an approach that provides new view in police investigation. This paper explains process mining how can assist the monitoring enterprise systems. © 2010 Springer-Verlag. Business Intelligence; Detective police; Evaluation; Process mining

Process mining approaches to detect organizational properties in cyber-physical systems Cyber-physical systems (CPS) are service systems that connect physical and cyber elements through global networks. CPS put upon sensors and actuators as well as omnipresent status data of smart products in order to facilitate the design of innovative service offerings. CPS typically require the cooperation of several actors such as manufacturers of smart products and service providers. Organizational mining uses event log data produced by information systems to explore organizational structures and to analyze social networks representing communication structures. Hence, organizational mining is a promising approach for changing the organization of several actors in a CPS for the better and for improving the delivery of innovative CPS service offerings. However, approaches of this kind so far have not been discussed with regard to CPS. From a review of the literature on organizational mining this article therefore identifies 18 different approaches, and it discusses their requirements and possible challenges and obstacles of using them in a CPS. The main results from the analysis include that organizational mining may generally be well applicable to CPS while some serious challenges related to CPS characteristics such as distribution in space, different levels of granularity, and time issues require for further research. Cyber-physical systems; Organizational mining; Process mining; Role mining

Process mining as first-order classification learning on logs with negative events Process mining is the automated construction of process models from information system event logs. In this paper we identify three fundamental difficulties related to process mining: the lack of negative information, the presence of history-dependent behavior and the presence of noise. These difficulties can elegantly dealt with when process mining is represented as first-order classification learning on event logs supplemented with negative events. A first set of process discovery experiments indicates the feasibility of this learning technique. © 2008 Springer-Verlag Berlin Heidelberg. 

Process mining based modeling and analysis of workflows in clinical care - A case study in a chicago outpatient clinic The United States currently spends over 17% of its gross domestic product on healthcare and this expenditure will continue to rise in the next few decades. Improving the performance and the efficiency of the United States healthcare system is of practical value to lowering such expenditure. Discrete event modeling, which can capture the complex behaviors of healthcare systems and provide statistical estimations of 'what if' scenarios, is one of the most powerful and cost-effective methods for healthcare system improvement. It involves creating an abstract-level workflow model with an accurate view of the patient flow while considering the dynamic nature of healthcare processes. In this paper, an outpatient clinic in Chicago, Illinois, USA, is used as a case study to illustrate a process mining based method for healthcare processes management and improvement. This method is able to discover meaningful knowledge, i.e., the workflow, of the clinical care processes by mining event logs. Based on the results from process mining, a discrete event simulation model is proposed to quantitatively analyze the clinical center. Sensitivity analyses have also been carried out to investigate the care activities with limited resources such as doctors and nurses. The results suggest that this methodology is a useful and flexible tool for healthcare process performance improvement. © 2014 IEEE. discrete event simulation; healthcare; outpatient clinic; patient flow; process mining

Process mining based on clustering: A quest for precision Process mining techniques attempt to extract non-trivial and useful information from event logs recorded by information systems. For example, there are many process mining techniques to automatically discover a process model based on some event log. Most of these algorithms perform well on structured processes with little disturbances. However, in reality it is difficult to determine the scope of a process and typically there are all kinds of disturbances. As a result, process mining techniques produce spaghetti-like models that are difficult to read and that attempt to merge unrelated cases. To address these problems, we use an approach where the event log is clustered iteratively such that each of the resulting clusters corresponds to a coherent set of cases that can be adequately represented by a process model. The approach allows for different clustering and process discovery algorithms. In this paper, we provide a particular clustering algorithm that avoids over-generalization and a process discovery algorithm that is much more robust than the algorithms described in literature [1]. The whole approach has been implemented in ProM. © 2008 Springer-Verlag Berlin Heidelberg. Disjunctive workflow schema; Process discovery; Process mining; ProM framework; Workflow mining

Process mining by measuring process block similarity Mining, discovering, and integrating process-oriented services has attracted growing attention in the recent years. Workflow precedence graph and workflow block structures are two important factors for comparing and mining processes based on distance similarity measure. Some existing work has done on comparing workflow designs based on their precedence graphs. However, there lacks of standard distance metrics for comparing workflows that contain complex block structures such as parallel OR, parallel AND. In this paper we present a quantitative approach to modeling and capturing the similarity and dissimilarity between different workflow designs, focusing on similarity and dissimilarity between the block structures of different workflow designs. We derive the distance-based similarity measures by analyzing the workflow block structure of the participating workflow processes in four consecutive phases. We first convert each workflow dependency graph into a block tree by using our block detection algorithm. Second, we transform the block tree into a binary tree to provide a normalized reference structure for distance based similarity analysis. Third, we construct a binary branch vector by encoding the binary tree. Finally, we calculate the distance metric between two binary branch vectors. © Springer-Verlag Berlin Heidelberg 2006. 

Process mining can be applied to software too! Modern information systems produce tremendous amounts of event data. The area of process mining deals with extracting knowledge from this data. Real-life processes can be effectively discovered, analyzed and optimized with the help of mature process mining techniques. There is a variety of process mining case studies and experience reports from such business areas as healthcare, public, transportation and education. Although nowadays, these techniques are mostly used for discovering business processes. The goal of this industrial paper is to show that process mining can be applied to software too. Here we present and analyze our experiences on applying process mining in different productive software systems used in the touristic domain. Process models and user interface workflows underlie the functional specifications of the systems we experiment with. When the systems are utilized, user interaction is recorded in event logs. After applying process mining methods to these logs, process and user interface flow models are automatically derived. These resulting models provide insight regarding the real usage of the software, motivate the changes in the functional specifications, enable usability improvements and software redesign. Thus, with the help of our examples we demonstrate that process mining facilitates new forms of software analysis. The user interaction with almost every software system can be mined in order to improve the software and to monitor and measure its real usage. client technology; process mining; software process mining; user interface design

Process mining for electronic data interchange Choreography modeling and service integration received a lot of attention in the last decade. However, most real-world implementations of inter-organizational systems are still realized by traditional Electronic Data Interchange (EDI) standards. In traditional EDI standards, the notion of process or choreography is not explicitly specified. Rather, every business document exchange stands for its own. This lack of process awareness in traditional EDI systems hinders organizations from applying Business Process Management (BPM) methods in such settings. To address this shortcoming, we seek to derive choreographies from EDI message exchanges. Thereby, we employ and extend process mining techniques, which have so far concentrated on business processes within single organizations. We discover the interaction sequences between the partners as well as the business information conveyed in the exchanged documents, which goes beyond the state-of-the-art in process mining. As a result, we lift the information gained on the IT level to the business level. This enables us to derive new insights that help organizations to improve their performance, e.g., an organization may get insights into the value of its business partnerships to support an efficient decision making process. This way we hope to bring the merits of BPM to inter-organizational systems realized by traditional EDI standards. © 2011 Springer-Verlag. EDI; EDIFACT; inter-organizational business processes; process mining

Process mining for job nets in integrated enterprise systems Batch jobs such as shell scripts are used to process large amounts of data in large scale enterprise systems. They are cascaded via certain signals or files to process their data in the proper order. Such cascaded jobs are called "job nets". In many cases, it is difficult to understand the execution order of batch jobs in a job net because of the complexity of their relationships or because of lack of information. However, without understanding the behavior of batch jobs, we cannot achieve reliable system management. In this paper, we propose a method to derive the execution pattern of the job net from its execution logs. We developed a process mining method which takes into account the concurrency of batch job executions in large scale systems, and evaluated its accuracy by a conformance check method using job net logs obtained from an actual large scale supply chain management system. © 2011 Springer-Verlag Berlin Heidelberg. Batch job; Behavior analysis; Integrated enterprise system; Job net; Process mining

Process mining for semantic business process modeling Business processes are captured by models that serve as a basis for communication and training purposes, but this modeling is still a time consuming manual job. Semantic annotation of process models in combination with AI planning approaches can contribute to solve this drawback enabling an automatic creation of process models. But the semantic annotated process fragments necessary for starting the planning are often missing at all or not up-to-date anymore. Therefore, this work describes an approach for the semantic annotation and semantic-based planning of process models and introduces Cystid, an integration of Process Mining algorithms and semantic-based planning. ©2009 IEEE. Process mining; Process models; SBPM

Process Mining for the multi-faceted analysis of business processes - A case study in a financial services organization Most organizations have some kind of process-oriented information system that keeps track of business events. Process Mining starts from event logs extracted from these systems in order to discover, analyze, diagnose and improve processes, organizational, social and data structures. Notwithstanding the large number of contributions to the process mining literature over the last decade, the number of studies actually demonstrating the applicability and value of these techniques in practice has been limited. As a consequence, there is a need for real-life case studies suggesting methodologies to conduct process mining analysis and to show the benefits of its application in real-life environments. In this paper we present a methodological framework for a multi-faceted analysis of real-life event logs based on Process Mining. As such, we demonstrate the usefulness and flexibility of process mining techniques to expose organizational inefficiencies in a real-life case study that is centered on the back office process of a large Belgian insurance company. Our analysis shows that process mining techniques constitute an ideal means to tackle organizational challenges by suggesting process improvements and creating a company-wide process awareness. © 2012 Elsevier B.V. All rights reserved. Event log analysis; Financial services industry; Process Mining; Real-life application

Process mining framework for software processes Software development processes are often not explicitly modelled and sometimes even chaotic. In order to keep track of the involved documents and files, engineers use Software Configuration Management (SCM) systems. Along the way, those systems collect and store information on the software process itself. Thus, SCM information can be used for constructing explicit process models, which is called software process mining. In this paper we show that (1) a Process Mining Framework can be used for obtaining software process models as well as for analysing and optimising them; (2) an algorithmic approach, which arose from our research on software processes, is integrated in the framework. © Springer-Verlag Berlin Heidelberg 2007. Software process mining and management

Process mining from a basis of state regions A central problem in the area of Process Mining is to obtain a formal model that represents selected behavior of a system. The theory of regions has been applied to address this problem, enabling the derivation of a Petri net whose language includes a set of traces. However, when dealing with real-life systems, the available tool support for performing such task is unsatisfactory, due to the complex algorithms that are required. In this paper, the theory of regions is revisited to devise a novel technique that explores the space of regions by combining the elements of a region basis. Due to its light space requirements, the approach can represent an important step for bridging the gap between the theory of regions and its industrial application. Experimental results improve in orders of magnitude state-of-the-art tools for the same task. © 2010 Springer-Verlag. 

Process mining in knowledge maintenance a case study The quality of knowledge in the knowledge repository determines the effects of knowledge reusing and sharing. In knowledge management systems (KMS), knowledge maintenance events are recorded in process logs. In order to take knowledge maintenance process logs to discover process, control, organizational, and social structure and construct a more appropriate knowledge maintenance process model, process mining is applied to the knowledge maintenance. The paper demonstrates the applicability of process mining using a real case of a knowledge maintenance process in an aviation design institute. In this paper, we analyzed the knowledge maintenance from two different perspectives: (1) the process perspective, which is used to find a good characterization of knowledge maintenance tasks and paths and (2) the organizational perspective which is used to find relations between individual performers. The results show that process mining can be used to provide new insights that facilitate the improvement of existing knowledge maintenance process. Knowledge maintenance; Knowledge management; Process mining; Workflow mining

Process mining meets abstract interpretation The discovery of process models out of system traces is a problem that has received significant attention in the last years. In this work, a theory for the derivation of a Petri net from a set of traces is presented. The method is based on the theory of abstract interpretation, which has been applied successfully in other areas. The principal application of this theory is Process Mining, an area that tries to incorporate the use of formal models both in the design and use of information systems. © 2010 Springer-Verlag Berlin Heidelberg. 

Process mining of RFID-based supply chains Process mining facilitates the analysis of business processes by extracting a process model from event logs. Most mining algorithms perform well on single-system event logs that explicitly refer to a process instance or case. However, in many operational environments such case identifiers are not directly recorded. In supply chain processes there are even further challenges, since different identification numbers and numerous aggregation steps prevent individual work items to become traceable as a case. In this paper, we investigate how the EPCglobal standard for processing Radio Frequency Identification (RFID) events can make supply chain data accessible for process mining. Our contribution is an algorithm that is able to deal with challenges of case identification and focus shifts. We present a prototypical implementation and use a process based on the Supply Chain Operations Reference (SCOR) Model to evaluate our implementation. © 2009 IEEE. EPCglobal; Process mining; RFID; Supply chain

Process mining of train describer event data and automatic conflict identification Data records from train describer systems are a valuable source of information for analysing railway operations performance and assessing railway timetable quality. This paper presents a process mining tool based on event data records from the Dutch train describer system TROTS, including algorithms developed for the automatic identification of route conflicts with conflicting trains, arrival and departure times/delays at stations, and train paths on track section and blocking time level. Visualisations of the time-distance diagrams and blocking time diagrams support the analysis of incidents, track obstructions, disruptions, and structural errors in the timetable design. © 2012 WIT Press. Blocking time diagram; Delay; Operations performance analysis; Realisation data; Route conflict; Timetable quality; Train describers

Process mining online assessment data Traditional data mining techniques have been extensively applied to find interesting patterns, build descriptive and predictive models from large volumes of data accumulated through the use of different information systems. The results of data mining can be used for getting a better understanding of the underlying educational processes, for generating recommendations and advice to students, for improving management of learning objects, etc. However, most of the traditional data mining techniques focus on data dependencies or simple patterns and do not provide a visual representation of the complete educational (assessment) process ready to be analyzed. To allow for these types of analysis (in which the process plays the central role), a new line of data-mining research, called process mining, has been initiated. Process mining focuses on the development of a set of intelligent tools and techniques aimed at extracting process-related knowledge from event logs recorded by an information system. In this paper we demonstrate the applicability of process mining, and the ProM framework in particular, to educational data mining context. We analyze assessment data from recently organized online multiple choice tests and demonstrate the use of process discovery, conformance checking and performance analysis techniques. 

Process mining software repositories Software developers' activities are in general recorded in software repositories such as version control systems, bug trackers and mail archives. While abundant information is usually present in such repositories, successful information extraction is often challenged by the necessity to simultaneously analyze different repositories and to combine the information obtained. We propose to apply process mining techniques, originally developed for business process analysis, to address this challenge. However, in order for process mining to become applicable, different software repositories should be combined, and "related" software development events should be matched: e.g., mails sent about a file, modifications of the file and bug reports that can be traced back to it. The combination and matching of events has been implemented in FRASR (FRamework for Analyzing Software Repositories), augmenting the process mining framework ProM. FRASR has been successfully applied in a series of case studies addressing such aspects of the development process as roles of different developers and the way bug reports are handled. © 2011 IEEE. Process mining; Software repositories

Process mining software repositories from student projects in an undergraduate software engineering course An undergraduate level Software Engineering courses generally consists of a team-based semester long project and emphasizes on both technical and managerial skills. Software Engineering is a practice-oriented and applied discipline and hence there is an emphasis on hands-on development, process, usage of tools in addition to theory and basic concepts. We present an approach for mining the process data (process mining) from software repositories archiving data generated as a result of constructing software by student teams in an educational setting. We present an application of mining three software repositories: team wiki (used during requirement engineering), version control system (development and maintenance) and issue tracking system (corrective and adaptive maintenance) in the context of an undergraduate Software Engineering course. We propose visualizations, metrics and algorithms to provide an insight into practices and procedures followed during various phases of a software development life-cycle. The proposed visualizations and metrics (learning analytics) provide a multi-faceted view to the instructor serving as a feedback tool on development process and quality by students. We mine the event logs produced by software repositories and derive insights such as degree of individual contributions in a team, quality of commit messages, intensity and consistency of commit activities, bug fixing process trend and quality, component and developer entropy, process compliance and verification. We present our empirical analysis on a software repository dataset consisting of 19 teams of 5 members each and discuss challenges, limitations and recommendations. Copyright © 2014 ACM. Education data mining; Learning analytic; Mining software repositories; Process mining; Software engineering education

Process mining techniques: An application to stroke care In a competitive health-care market, hospitals have to focus on ways to streamline their processes in order to deliver high quality care while at the same time reducing costs. To accomplish this goal, hospital managers need a thorough understanding of the actual processes. Diffusion of Information and Communication Technology tools within hospitals, such as electronic clinical charts, computerized guidelines and, more generally, decision support systems, make huge collections of data available, not only for data analysis, but also for process analysis. Process mining can be used to extract process related information (e.g., process models) from data, i.e., process mining describes a family of a-posteriori analysis techniques exploiting the information recorded in the event logs. This process information can be used to understand and redesign processes to become efficient high quality processes. In this paper, we apply process mining on two datasets for stroke patients and present the most interesting results. Above all, the paper demonstrates the applicability of process mining in the health-care domain. © Organizing Committee of MIE 2008. All rights reserved. Data analysis-extraction tools; Event-based systems; Process

Process mining to support students' collaborative writing Writing, particularly collaborative writing is a commonly needed skill. Investigating how ideas and concepts are developed during the process of writing can be used to improve not only the quality of the written documents but more importantly the writing skills of those involved. In this paper, process mining is used to analyze the process that groups of writers follow, and how the process correlates to the quality and semantic features of the final product. Particularly, we developed heuristics to extract the semantic nature of text changes during writing. These semantic changes were then used to identify writing activities in writing processes. We conducted a pilot study using documents collected from groups of undergraduate students writing collaboratively in order to evaluate the proposed heuristics and illustrate the applicability of process mining techniques in analyzing the process of writing. 

Process mining using a-algorithm as a tool (A case study of student registration) The a-algorithm is an algorithm used in process mining, aimed at reconstructing causality from a set of sequences of events. In this paper we used alpha algorithm in order to focus on the control flow perspective of students' registration process model in one of the universities in Thailand. The event log consisted of 299 cases and 569 events. Initially the data was received in form of MS Access Database but later using PromImport platform, the data was converted into MXML, a format that commonly is used in Prom. Though the paper applies the a-algorithm in presented case study, yet the a-algorithm could not adequately deal with loops and concurrency of process models. Therefore, the a-algorithm should not be seen as a very practical mining technique as it has its own problems with noise, infrequent/incomplete behavior, and complex routing constructs. Nevertheless, we used the algorithm as a baseline for discussing the challenges related to model discovery of registration process in an academic environment. © 2012 IEEE. a-algorithm; Petri nets; process mining; students' registration process; workflow mining; workflow Petri nets

Process mining, discovery, and integration using distance measures Business processes continue to play an important role in today's service-oriented enterprise computing systems. Mining, discovering, and integrating processoriented services has attracted growing attention in the recent year. In this paper we present a quantitative approach to modeling and capturing the similarity and dissimilarity between different process designs. We derive the similarity measures by analyzing the process dependency graphs of the participating workflow processes. We first convert each process dependency graph into a normalized process matrix. Then we calculate the metric space distance between the normalized matrices. This distance measure can be used as a quantitative and qualitative tool in process mining, process merging, and process clustering, and ultimately it can reduce or minimize the costs involved in design, analysis, and evolution of workflow systems. © 2006 IEEE. 

Process mining: A two-step approach to balance between underfitting and overfitting Process mining includes the automated discovery of processes from event logs. Based on observed events (e.g., activities being executed or messages being exchanged) a process model is constructed. One of the essential problems in process mining is that one cannot assume to have seen all possible behavior. At best, one has seen a representative subset. Therefore, classical synthesis techniques are not suitable as they aim at finding a model that is able to exactly reproduce the log. Existing process mining techniques try to avoid such "overfitting" by generalizing the model to allow for more behavior. This generalization is often driven by the representation language and very crude assumptions about completeness. As a result, parts of the model are "overfitting" (allow only for what has actually been observed) while other parts may be "underfitting" (allow for much more behavior without strong support for it). None of the existing techniques enables the user to control the balance between "overfitting" and " underfitting". To address this, we propose a two-step approach. First, using a configurable approach, a transition system is constructed. Then, using the "theory of regions", the model is synthesized. The approach has been implemented in the context of ProM and overcomes many of the limitations of traditional approaches. 

Process mining: algorithm for S-Coverable workflow nets To discover process models from event logs has recently aroused many researchers' interest in the area of process mining. Notwithstanding the interest and related efforts, existing algorithms are far from being satisfactory. For example, some researchers have proved that a-algorithm is capable of discovering the processes of the so-called SWF-nets without short loops; however, a-algorithm has been found to contain some severe limitations. This paper is therefore to introduce the notation of S-Coverable workflow nets, to reach theorems about the characteristics of Sound S-Coverable Workflow Nets, and to develop a new process mining algorithm, namely, algorithm S. On such basis, suggested in the paper is a new approach to dealing with the problem of hidden transition discovering, an approach that, by means of the pretreatment of such hidden tasks, allows algorithm S to discover process models that will help preserve better structures. Theorems thus reached are applicable not only to process mining, but also to process modeling and process model checking. © 2009 IEEE. Business process analysis; Data mining; Process mining; S-Coverable workflow net; Workflow mining

Process Mining: Extending alpha-Algorithm to Mine Duplicate Tasks in Process Logs Process mining is a new technology which can distill workflow models from a set of real executions. However, the present research in process mining stilt meets many challenges. The problem of duplicate tasks is one of them, which refers to the situation that the same task can appear multiple times in one workflow model. The "alpha-algorithm" is proved to mine sound Structured Workflow nets without task duplication. In this paper, basing on the "alpha-algorithm", a new algorithm (the "alpha*-algorithm") is presented to deal with duplicate tasks and has been implemented in a research prototype. In eight scenarios, the "alpha*-algorithm" is evaluated experimentally to show its validity. Process mining; workflow mining; duplicate tasks; Petri nets; workflow nets

Process mining: Fuzzy clustering and performance visualization The goal of performance analysis of business processes is to gain insights into operational processes, for the purpose of optimizing them. To intuitively show which parts of the process might be improved, performance analysis results can be projected onto process models. This way, bottlenecks can quickly be identified and resolved. Unfortunately, for many operational processes, good models, describing the process accurately and intuitively are unavailable. Process mining, or more precisely, process discovery, aims at deriving such models from events logged by information systems. However many mining techniques assume that all events in an event log are logged at the same level of abstraction, which in practice is often not the case. Furthermore, many mining algorithms produce results that are hard to understand by process specialists. In this paper, we propose a simple clustering algorithm to derive a model from an event log, such that this model only contains a limited set of nodes and edges. Each node represents a set of activities performed in the process, but many nodes can refer to many activities and vice versa. Using the discovered model, which represents the process at a potentially high level of abstraction, we present two different ways to project performance information onto it. Using these performance projections, process owners can gain insights into the process under consideration in an intuitive way. To validate our approach, we apply our work to a real-life case from a Dutch municipality. © 2010 Springer-Verlag. 

Process mining: Matrix representation for bloc discovery Modeling is practically time-consuming and error-prone task. To help making process modeling easier, the use of process discovery is considered to be an efficient way to create a fitting process model. In this paper, we propose a new method for process discovery based on a process matrix representation to reduce the complexity of discovered processes. © 2013 IEEE. Bloc Discovery; Petri Nets; Process Discovery; Process Mining; Workflow Mining

Process optimization of candy production based on data mining There are complicated correlations between process parameters and quality indicators in candy manufacturing. The objective of this work is to develop an optimization system of candy production process to improve final candy quality and to increase production efficiency. The study is conducted by using an artificial neural network data mining method to obtain optimization knowledge of process parameters from large amount of saved process data. The software platform including data processing, statistic analysis, data mining and graphical display module was developed and the quality forecasting models for typical processing operations were discussed. Experiments indicated that the system can optimize and predict the quality of candy production process effectively. © (2011) Trans Tech Publications. 

Process Prediction in Noisy Data Sets: A Case Study in a Dutch Hospital Predicting the amount of money that can be claimed is critical to the effective running of an Hospital. In this paper we describe a case study of a Dutch Hospital where we use process mining to predict the cash flow of the Hospital. In order to predict the cost of a treatment, we use different data mining techniques to predict the sequence of treatments administered, the duration and the final "care product" or diagnosis of the patient. While performing the data analysis we encountered three specific kinds of noise that we call sequence noise, human noise and duration noise. Studies in the past have discussed ways to reduce the noise in process data. However, it is not very clear what effect the noise has to different kinds of process analysis. In this paper we describe the combined effect of sequence noise, human noise and duration noise on the analysis of process data, by comparing the performance of several mining techniques on the data. © International Federation for Information Processing 2013. case study; cash flow prediction; classification; data noise; process mining; process prediction

Process socio space discovery based on semantic logs While the cyber physical society (CPS) describes the future environment of collaboration and coordination between the cyber space and the socio space, nowadays, business process management systems (BPMS) are coined to specify how the computational resources can coordinate and collaborate by aligning all aspects of an organization through a set of activities, performed by their relevant collaborators, to purposefully achieve a common business goal. Generally, cyber physical systems promise a tight integration between the cyber space and the socio space in their interactions. In this paper, we focus on how leveraging existing BPMS for achieving this integration by discovering process socio space based on log analysis. Concretely, we propose an Organizational Ontology specifying the organizational socio space model. This ontology is used to semantically annotate logs and establish a knowledge base that will be used to semantically discover relationships between performers in the process socio space. Our approach has been implemented within the ProM framework. Process log analysis; Process mining; Socio space organizational ontology

Process-driven approaches to knowledge transformation In this paper we focus on specific approaches to knowledge transformation within the educational domain. Our approaches can be briefly characterized as process-driven, because the core concepts are educational processes and semantic representations of them. In this paper we present two alternative ways of using process models for knowledge transfer in educational domain. First one is deductive approach, or top-down approach, where knowledge is captured from the very beginning and continuously upgraded with the repeated runs of educational processes. The second one is inductive approach, or bottom-up approach, where process logs are analyzed with the aim to derive useful knowledge patterns. We build on our experiences from more research and educational projects, where we have designed and developed information systems and services supporting these types of knowledge transformation. Knowledge transformation; Ontology; Process mining; Process model

Process-Mining-Based Workflow Model Fragmentation for Distributed Execution A complex workflow is often executed by geographically dispersed partners or different organizations. As a solution for dealing with the decentralized nature of workflow applications, a workflow can be fragmented into small pieces and scheduled to different servers for its execution. An important challenge in distributed workflows is to optimize the fragmentation and distribution to achieve efficiency with respect to time and server resources. To tackle this challenge, we propose the application of process mining to the fragmentation of a workflow for distributed execution. The workflow model discovered through process mining records the actual execution of a workflow and allows in-depth analysis of its temporal behavior. Based on examination of the model resulting from process mining, we demonstrate how to determine the minimum time to finish a workflow and how to partition the workflow in order to achieve efficient server usage. Distributed workflow; Petri net; Process mining; Task assignment; Workflow management; Workflow model fragmentation

ProcMiner: Advancing process analysis and management This paper contributes both to research and practice on process mining. Previous research on process mining has focused on mining patterns from event log files to generate process models. The process mining approach adopted in this paper is focused on producing patterns about process models, not the models themselves. The approach is demonstrated by ProcMiner - an explorative research prototype for management, consolidating, publishing, retrieving, and analyzing process models. Content-based document clustering is applied to process models represented as XML database in order to find topical groups from models. In practice, organizations face numerous challenges in managing their process models. The models may be heterogeneous or ambiguous. The modeling software may change over time or due to differences in departmental purchases. ProcMiner was used in quality system development initiative at the University of Jyväskylä. The findings support previous model engineering research, showing that multiple actions are needed to ensure consistency of process models, and to make them efficiently manageable. © 2007 IEEE. 

Profiling event logs to configure risk indicators for process delays Risk identification is one of the most challenging stages in the risk management process. Conventional risk management approaches provide little guidance and companies often rely on the knowledge of experts for risk identification. In this paper we demonstrate how risk indicators can be used to predict process delays via a method for configuring so-called Process Risk Indicators (PRIs). The method learns suitable configurations from past process behaviour recorded in event logs. To validate the approach we have implemented it as a plug-in of the ProM process mining framework and have conducted experiments using various data sets from a major insurance company. © 2013 Springer-Verlag. process mining; process risk indicators; risk identification

Projection approaches to process mining using region-based techniques Traces are everywhere from information systems that store their continuous executions, to any type of health care applications that record each patient's history. The transformation of a set of traces into a mathematical model that can be used for a formal reasoning is therefore of great value. The discovery of process models out of traces is an interesting problem that has received significant attention in the last years. This is a central problem in Process Mining, a novel area which tries to close the cycle between system design and validation, by resorting on methods for the automated discovery, analysis and extension of process models. In this work, algorithms for the derivation of a Petri net from a set of traces are presented. The methods are grounded on the theory of regions, which maps a model in the state-based domain (e.g., an automata) into a model in the event-based domain (e.g., a Petri net). When dealing with large examples, a direct application of the theory of regions will suffer from two problems: one is the state-explosion problem, i.e., the resources required by algorithms that work at the state-level are sometimes prohibitive. This paper introduces decomposition and projection techniques to alleviate the complexity of the region-based algorithms for Petri net discovery, thus extending its applicability to handle large inputs. A second problem is known as the overfitting problem for region-based approaches, which informally means that, in order to represent with high accuracy the trace set, the models obtained are often spaghetti-like. By focusing on special type of processes called conservative and for which an elegant theory and efficient algorithms can be devised, the techniques presented in this paper alleviate the overfitting problem and moreover incorporate structure into the models generated. © 2011 The Author(s). Petri nets; Process mining; Theory of regions

Prom: Analysis of Social Network in students registration system The work presented in this paper applies the results from sociometry, and Social Network Analysis in particular, to an event log. The paper used various metrics in order to build a social network in terms of three types of metrics, namely as: [a] Handover of Work metric (this metric determines who passes work to whom.), [b] Working Together metric (this technique counts how frequently individuals work in the same case.), and [c] Similar Tasks metric (this technique determines who performs the same type of activities.). In addition, our aim was to evaluate the role of each individual through the registration process within a private university in Thailand. Thus, in 'case study' section of the paper, we focused on the mining of organizational relations (roles) showing which relations can be derived from our event log. In other words, organization model derived from the dendogram. Ovals and the pentagons represent actors/originators and organizational entities in charge of students' registration process at university. The event log contained information about 299 cases and 569 activities. For each case, the performed tasks - in regard to students' registration process - and the moment of completion were recorded. © 2012 IEEE. Process Discovery; Process Mining; Prom; Social Network Miner; Sociometry

Pseudo-parallel genetic algorithm in process mining Process mining is helpful for deploying new business processes as well as auditing, analyzing and improving the already enacted ones. An improved pseudo-parallel genetic algorithm is proposed with an asexual reproduction for avoiding crossover operators' breach to nice gene patterns. The initial population is produced by greedy algorithm in order to enhance convergence velocity. Information exchange between subgroups employs island model in pseudo-parallel genetic algorithm. These measures are of great significance on reducing complexities and enhancing convergence velocity, as well as increasing global searching ability of the algorithm. © 2012 IEEE. 

Quality management process continuous improvement based on workflow mining This paper presents an approach to diagnose and improve the quality management process based on workflow mining technology. In order to inspect each improvement stage in the PDCA lifecycle, an adaptive process mining method is proposed to reconstruct the workflow models from logs. In this method, a sliding window is defined on the process audit streams, and the sliding window size and process schedule method are continuously adjusted by the updating rules to adaptively find various stages of the process changes implied in the workflow log. Case study and comparisons are used to illustrate the accuracy and high performance of this algorithm in the end. © (2011) Trans Tech Publications. Adaptive mining method; Continuous improvement; Quality management process; Workflow mining

Quantifying process equivalence based on observed behavior In various application domains there is a desire to compare process models, e.g., to relate an organization-specific process model to a reference model, to find a web service matching some desired service description, or to compare some normative process model with a process model discovered using process mining techniques. Although many researchers have worked on different notions of equivalence (e.g., trace equivalence, bisimulation, branching bisimulation, etc.), most of the existing notions are not very useful in this context. First of all, most equivalence notions result in a binary answer (i.e., two processes are equivalent or not). This is not very helpful because, in real-life applications, one needs to differentiate between slightly different models and completely different models. Second, not all parts of a process model are equally important. There may be parts of the process model that are rarely activated (i.e., "process veins") while other parts are executed for most process instances (i.e., the "process arteries"). Clearly, differences in some veins of a process are less important than differences in the main arteries of a process. To address the problem, this paper proposes a completely new way of comparing process models. Rather than directly comparing two models, the process models are compared with respect to some typical behavior. This way, we are able to avoid the two problems just mentioned. The approach has been implemented and has been used in the context of genetic process mining. Although the results are presented in the context of Petri nets, the approach can be applied to any process modeling language with executable semantics. © 2007 Elsevier B.V. All rights reserved. Business process intelligence; Genetic algorithms; Petri nets; Process discovery; Process equivalence; Process mining

Reality Mining Via Process Mining Reality mining project work on Ubiquitous Mobile Systems (UMSs) that allow for automated capturing of events. Reality Mining demonstrates the power of collecting not only communication information but also location and proximity data from mobile phones over an extended period. On the other hand Process mining aims at extracting information from event logs to capture the process as it is being executed. Process mining also supports analysis of the performance of processes including Qualitative and Quantitative analysis for captured process model. This paper introduces process mining to modeling and analyzing reality mining dataset. Process mining; workflow mining; reality mining; ubiquitous computing; Complex social systems; User modeling; social network analysis

Recognize contextual situation in pervasive environments using process mining techniques Research in pervasive computing and ambience intelligence aims to enable users to interact with the environment in a context-aware way. To achieve this, a complex set of features describing different aspects of the environment has to be captured and processed; in other words situation-awareness is needed. This article notes uniquely three points when modelling situations. Firstly, unlike most existing approaches, context information history should be considered when modelling the situations. We argue here that the current state cannot be understood in isolation from the previous states. Secondly, in order to track user's behaviour there is a need to consider the context information available in the different domains the user visits. Thirdly, to identify situations it can be problematic to define situation patterns and looking for an exact match as most of the approaches does. We found that the combination of the flexibility of the user behaviour and automated capture of context events provide a very effective solution for contextual situation recognition. In this article we first provide a formalization of the situation recognition problem and then we focus on the potential use of process mining techniques for measuring situation alignment, i.e., comparing the real situations of users with the expected situations. To this end, we propose two ways to create and/or maintain the fit between them: linear temporal logic (LTL) analysis and conformance testing. We evaluate the effectiveness of the framework using a third party published smart home dataset. Our experiments prove the effectiveness of applying the proposed approach to recognizing situations in the flow of context information. © Springer-Verlag 2010. Context-awareness; Pervasive applications; Process mining; Situation recognition

Recommendation of optimized information seeking process based on the similarity of user access behavior patterns Differing from many studies of recommendation that provided the final results directly, our study focuses on providing an optimized process of information seeking to users. Based on process mining, we propose an integrated adaptive framework to support and facilitate individualized recommendation based on the gradual adaptation model that gradually adapts to a target user's transition of needs and behaviors of information access, including various search-related activities, over different time spans. In detail, successful information seeking processes are extracted from the information seeking histories of users. Furthermore, these successful information seeking processes are optimized as a series of action units to support the target users whose information access behavior patterns are similar to the reference users. Based on these, the optimized information seeking processes are navigated to the target users according to their transitions of interest focus. In addition to describing some definitions and measures introduced, we go further to present an optimized process recommendation model and show the system architecture. Finally, we discuss the simulation and scenario for the proposed system. © 2012 Springer-Verlag London Limited. Behavior patterns; Information seeking process; Personalized recommendation

Reconstructing meaningful workflow from transaction logs Enterprises today rely on workflow more and more to accomplish business goals. A well designed process can contribute to better business operation and working efficiency. In practice, however, most organizations have no efficient workflow, either there is not at all from the very beginning, or lack domain experts who equip with the comprehensive landscape about the business. In order to conduct business more effectively, it is necessary to reconstruct workflows from transaction logs, and further, optimize the business via meaningful representations of these workflows. In this paper, we propose a method and corresponding toolbox to mine the workflows and vital patterns. Domain experts can use them in an interactive way to reconstruct meaningful business processes. We got very promising experimental results on two real applications datasets © 2010 IEEE. GSP; Meaningful workflow; Process mining; Sequence mining

RECYCLE: Learning looping workflows from annotated traces A workflow is a model of a process that systematically describes patterns of activity. Workflows capture a sequence of operations, their enablement conditions, and data flow dependencies among them. It is hard to design a complete and correct workflow from scratch, while it is much easier for humans to demonstrate the solution than to state the solution declaratively. This article presents RECYCLE, our approach to learning workflow models from example demonstration traces. RECYCLE captures control flow, data flow, and enablement conditions of an underlying workflow process. Unlike prior work from workflow mining and AI planning literature, (1) RECYCLE can learn from a single demonstration trace with loops, (2) RECYCLE learns both loop and conditional branch structure, and (3) RECYCLE handles data flow among actions. In this article, we describe the phases of RECYCLE's learning algorithm: substructure analysis and node abstraction. To ground the discussion, we present a simplified flight reservation system with some of the important characteristics of the real domains we worked with. We present some results from a patient transport domain. © 2011 ACM. Hierarchical Task Network learning; Learning from demonstration; Learning from traces; Process mining; Workflow learning

Redesigning business processes: A methodology based on simulation and process mining techniques Nowadays, organizations have to adjust their business processes along with the changing environment in order to maintain a competitive advantage. Changing a part of the system to support the business process implies changing the entire system, which leads to complex redesign activities. In this paper, a bottom-up process mining and simulation-based methodology is proposed to be employed in redesign activities. The methodology starts with identifying relevant performance issues, which are used as basis for redesign. A process model is "mined" and simulated as a representation of the existing situation, followed by the simulation of the redesigned process model as prediction of the future scenario. Finally, the performance criteria of the current business process model and the redesigned business process model are compared such that the potential performance gains of the redesign can be predicted. We illustrate the methodology with three case studies from three different domains: gas industry, government institution and agriculture. CPN Tools; Process mining; Process redesigning; Simulation

Rediscovery of government process model in E-government The normal running of electronic government depends on government process models. The traditional government process is static. With the development of government, government processes become changeful. Unfortunately, traditional modeling approaches have some limitations to meet these demands due to their inherent static properties. Therefore this paper researches an automatic government process remodeling approach. The core of the method is process remodeling algorithm. In the algorithm a markov transition matrix is set up based on process logs in BPMS. And according to the matrix the eight remodeling rules of process logical relations are designed. The remodeling method can not only automatically remodel the various government processes, but also greatly enhance the process modeling efficiency. © 2009 IEEE. Business process management system; Government process; Process log, electronic government; Process mining, markov transition matrix

Re-examining information systems user performance: Using data mining to identify properties of IS that lead to highest levels of user performance As competitive pressures increase, managers try to realize every bit of productivity from people, business processes and new information technologies (IT). This leads one to ask, how can managers configure information systems to achieve higher levels of performance from end users? In this regard, managers continually seek advice on how to meet the promises and expectations of continued increases in productivity through the use of IT. However, results from research on how to achieve higher performance through the use of IT in organizations has been mixed. Consequently, it has been difficult for IS researchers to give managers any advice on investing in specific aspects of IS that would lead to the highest performance possible. We focus on this question in this research. We use a data mining approach to tease out information about specific characteristics of IS that managers can manipulate to achieve desired outcomes with regards to individual performance. Our findings offer both researchers and managers significant new knowledge that can make a difference to IT user performance research theory and the practice of user performance management. Further, our research method offers a novel approach to linking theory and practice in IS research, a problem that is of great concern to many IS researchers. The approach is generalized and can be implemented by academic or industry researchers who are interested in generating hypotheses from data for the purpose of theoretical or applied research. © 2010 Elsevier Ltd. All rights reserved. Data mining; Decision tree; End-user performance; Information systems

Region-based foldings in process discovery A central problem in the area of Process Mining is to obtain a formal model that represents the processes that are conducted in a system. If realized, this simple motivation allows for powerful techniques that can be used to formally analyze and optimize a system, without the need to resort to its semiformal and sometimes inaccurate specification. The problem addressed in this paper is known as Process Discovery: to obtain a formal model from a set of system executions. The theory of regions is a valuable tool in process discovery: it aims at learning a formal model (Petri nets) from a set of traces. On its genuine form, the theory is applied on an automaton and therefore one should convert the traces into an acyclic automaton in order to apply these techniques. Given that the complexity of the region-based techniques depends on the size of the input automata, revealing the underlying cycles and folding the initial automaton can incur in a significant complexity alleviation of the region-based techniques. In this paper, we follow this idea by incorporating region information in the cycle detection algorithm, enabling the identification of complex cycles that cannot be obtained efficiently with state-of-the-art techniques. The experimental results obtained by the devised tool suggest that the techniques presented in this paper are a big step into widening the application of the theory of regions in Process Mining for industrial scenarios. © 1989-2012 IEEE. Process discovery; region theory; transition system folding

Re-learning of Business Process Models from Legacy System Using Incremental Process Mining Several approaches have already been proposed to extract both business processes and business rules from a legacy source code. These approaches usually consider static and dynamic source code analysis for relearning of these models. However, business processes have components that cannot be directly extracted by static analysis (i.e., process participants and concurrent tasks). Moreover, most of well-known process mining algorithms used in dynamic analysis do not support all required operations of incremental extraction. Re-learning of large legacy systems can benefit from an incremental analysis strategy in order to provide iterative extraction of process models. This paper discusses an approach for business knowledge extraction from legacy systems through incremental process mining. Discovery results can be used in various ways by business analysts and software architects, e.g. documentation of legacy systems or for re-engineering purposes. Incremental process mining; Legacy systems; Process mining

Repairing process models to reflect reality Process mining techniques relate observed behavior (i.e., event logs) to modeled behavior (e.g., a BPMN model or a Petri net). Processes models can be discovered from event logs and conformance checking techniques can be used to detect and diagnose differences between observed and modeled behavior. Existing process mining techniques can only uncover these differences, but the actual repair of the model is left to the user and is not supported. In this paper we investigate the problem of repairing a process model w.r.t. a log such that the resulting model can replay the log (i.e., conforms to it) and is as similar as possible to the original model. To solve the problem, we use an existing conformance checker that aligns the runs of the given process model to the traces in the log. Based on this information, we decompose the log into several sublogs of non-fitting subtraces. For each sublog, a subprocess is derived that is then added to the original model at the appropriate location. The approach is implemented in the process mining toolkit ProM and has been validated on logs and models from Dutch municipalities. © 2012 Springer-Verlag. conformance checking; model repair; Petri nets; process mining

Representing and visualizing mined artful processes in MailOfMine Artful processes are informal processes typically carried out by those people whose work is mental rather than physical (managers, professors, researchers, engineers, etc.), the so called "knowledge workers". mailofmine is a tool, the aim of which is to automatically build, on top of a collection of e-mail messages, a set of workflow models that represent the artful processes laying behind the knowledge workers activities. This paper presents its innovative graphical syntax proposal and the interface for representing and showing such mined processes to users. © 2011 Springer-Verlag Berlin. artful process; process mining; process visualization

Research on reengineering of ERP system based on data mining and MAS The flexibility has been a primary focus in the development of Enterprise Resource Planning (ERP) system. To improve the flexibility of ERP system and achieve a high level of success, this paper put forward methods for business process decompose and design of workflow log, and a data mining algorithm based on XML for reengineering of ERP is proposed. Thus we realize standardization of business process, function units and system structure of information system for production management, and achieve the automatic mining of bottlenecks in the process of production. Then an adaptive reengineering method of information system is brought forward for production management based on Multi-Agent, and the reengineering and flexibility of information system is realized. Those methods above implement the rapid acquirement of enterprise business model and optimization and configuration of information system. The validity of this mining algorithm and the feasibility of this technique structure are proved by the simulation with Petri net and its application in enterprises. © 2008 IEEE. 

Research on web log mining The article introduces each stage of Web Log Mining process in detail, including data preprocessing, user recognition calculation and user clustering method. We aimed at specifying the inevitable steps that are required for obtaining valid data from the log file. The proposed methodology is applied to the Web log files; especially, we focused on improving the user identification heuristic rules of data mining, which allows accurate identification of the user. On the selection of timeout, used Advance prediction for it, which can represent the web users' behavior patterns better? The experiment results indicate that the mining efficiency and the quality of those association rules obtained by improved genetic algorithm have significantly improved. © 2013 Springer-Verlag. Data mining; Data preprocessing; Web Log Mining

Resource behavior measure and application in business process management Efficient resource behavior measure in business process management is a real and challenging problem. It reflects the actual situations in business process execution from resource perspective and is highly relevant for the business process performance. This paper presents an approach of measuring resource behavior from four important perspectives, i.e.; preference, availability, competence and cooperation, based on process mining. Furthermore, this paper shows how business process management can benefit from resource behavior measure. In particular, four applications are addressed to demonstrate the applicability of resource behavior measure in business process management. The presented approach is evaluated based on a proof-of-concept implementation and its application to a real case form health-care. The results show that the proposed approach is possible to improve current state of business process management. © 2011 Elsevier Ltd. All rights reserved. Availability; Business process management; Competence; Cooperation; Preference; Resource behavior

Results from Data Mining in a Radiology Department: The Relevance of Data Quality This work is part of an ongoing effort to examine and improve clinical workflows in radiology Classical workflow analysis is time consuming and expensive. Here we present a purely data-driven approach using data mining techniques to detect causes for poor data quality and areas with poor workflow performance. Data has been taken from a operational RIS system. We defined a set of four key indicators for both data quality and workflow performance. Using several mining techniques such as cluster analysis and correlation tests we were able to detect interesting effects regarding data quality and an abnormality in the workflow for some organizational units of the examined radiology departments. We conclude that data-driven data mining approaches may act as a valuable tool to support workflow analysis and can narrow down the problem space for a manual on-site workflow analysis. This can save time and effort and leads to less strait? for clinicians and workflow analysts during interviews. data mining; data quality; radiology; workflow

Retrieval and clustering for business process monitoring: Results and improvements Business process monitoring is a set of activities for organizing process instance logs and for highlighting non-compliances and adaptations with respect to the default process schema. Such activities typically serve as the starting point for a-posteriori log analyses. In recent years, we have implemented a tool for supporting business process monitoring, which allows to retrieve traces of process execution similar to the current one. Moreover, it supports an automatic organization of the trace database content through the application of clustering techniques. Retrieval and clustering rely on a distance definition able to take into account temporal information in traces. In this paper, we report on such a tool, and present the newest experimental results. Moreover, we introduce our recent research directions, that aim at improving the tool performances, usability and visibility with respect to the scientific community. Specifically, we propose a methodology for avoiding exhaustive search in the trace database, by identifying promising regions of the search space, in order to reduce computation time. Moreover, we describe how our work is being incorporated as a plug-in in ProM, an open source framework for process mining and process analysis. © 2012 Springer-Verlag. 

Role-activity diagrams modeling based on workflow mining Role-activity diagram (RAD) is a basic role-oriented process model, but there lacks of an objective role identification method during RAD modeling. By means of the analysis of workflow logs - workflow mining, the ratio of activities performed by actors is used to describe their work. The role is, therefore, identified by regarding actors with similar activities, who undertaking the same responsibility. On the basis of role identification, social network diagrams among actors are analyzed by considering activity dependence between them and their interactions are discussed. In this way, we can get role-activity diagrams. Experiments show that the proposed method is viable. © 2008 IEEE. 

Root cause analysis with enriched process logs In the field of process mining, the use of event logs for the purpose of root cause analysis is increasingly studied. In such an analysis, the availability of attributes/features that may explain the root cause of some phenomena is crucial. Currently, the process of obtaining these attributes from raw event logs is performed more or less on a case-by-case basis: there is still a lack of generalized systematic approach that captures this process. This paper proposes a systematic approach to enrich and transform event logs in order to obtain the required attributes for root cause analysis using classical data mining techniques, the classification techniques. This approach is formalized and its applicability has been validated using both self-generated and publicly-available logs. © 2013 Springer-Verlag Berlin Heidelberg.ok event logs; process mining; root cause analysis

Rule-based business process mining: Applications for management The abundance of available event data, originating from process-aware information systems, creates opportunities for enterprise risk management applications at the intersection of the business & management, artificial intelligence and knowledge representation research fields. This paper proposes a rule-based process mining approach for dealing with uncertainty and risk. The applicability of the approach is demonstrated using the updating and debugging process of a social security service provider. © 2012 Springer-Verlag. 

Scalable dynamic business process discovery with the constructs competition miner Since the environment for businesses is becoming more competitive by the day, business organizations have to be more adaptive to environmental changes and are constantly in a process of optimization. Fundamental parts of these organizations are their business processes. Discovering and understanding the actual execution flow of the processes deployed in organizations is an important enabler for the management, analysis, and optimization of both, the processes and the business. This has become increasingly difficult since business processes are now often dynamically changing and may produce hundreds of events per second. The basis for this paper is the Constructs Competition Miner (CCM): A divide-and-conquer algorithm which discovers block-structured processes from event logs possibly consisting of exceptional behaviour. In this paper we propose a set of modifications for the CCM to enable scalable dynamic business process discovery of a run-time process model from a stream of events. We describe the different modifications and carry out an evaluation, investigating the behaviour of the algorithm on event streams of dynamically changing processes. Big data; Business process management; Complex event processing; Event streaming; Process mining; Run-time models

Scenario-based method for business process analysis and improvement in SOA Business Process Management is often associated with software to manage, control, and support operational processes. And in order to meet dynamic and new business needs with flexible information technology solutions, more and more enterprises intend to build their own IT infrastructure under Service Oriented Architecture. Currently analyzing and refining the existing business process models for configuring enterprise information system is a hot area of research. In our approach, we apply the process mining technology to the event logs to discover the scenarios, each of which mainly consists of task originators, sub-process (ordering of service invocations) and business objects. Based on composition of these scenarios, the enterprise is able to redesign the process models and combine closely the business process with the services provided by different application systems in SOA. When new business requirements emerge, solution designers can devise a flexibly composite process that makes the best use of existing scenarios and glue the scenarios together with least augmentation or modification. business process model; process mining; scenario discovery; SOA

Semantic process mining tools: Core building blocks Process mining aims at discovering new knowledge based on information hidden in event logs. Two important enablers for such analysis are powerful process mining techniques and the omnipresence of event logs in today's information systems. Most information systems supporting (structured) business processes (e.g. ERP, CRM, and workflow systems) record events in some form (e.g. transaction logs, audit trails, and database tables). Process mining techniques use event logs for all kinds of analysis, e.g., auditing, performance analysis, process discovery, etc. Although current process mining techniques/tools are quite mature, the analysis they support is somewhat limited because it is purely based on labels in logs. This means that these techniques cannot benefit from the actual semantics behind these labels which could cater for more accurate and robust analysis techniques. Existing analysis techniques are purely syntax oriented, i.e., much time is spent on filtering, translating, interpreting, and modifying event logs given a particular question. This paper presents the core building blocks necessary to enable semantic process mining techniques/tools. Although the approach is highly generic, we focus on a particular process mining technique and show how this technique can be extended and implemented in the ProM framework tool. Semantic auditing; Semantic business process management; Semantic process mining; Semantics-supported business intelligence

Semi-automatic acquisition of Semantic descriptions of processes in the Web Most of today's business processes are complex and consist of more than one party or single step procedures. In the Web, this is reflected by the existence of billions of Web sites, which may be regarded as complex processes, and on the other side only a few thousands of publicly available WSDL files that present single services. The availability of semantic descriptions of services and processes in the Web facilitates their discovery, as well as their composition into more complex workflows. It also facilitates the automatic execution of such workflows despite their heterogeneity. However, the deficit of semantic descriptions of Web processes deprives the users from using such sophisticated automatic techniques. The scope of our research is to fill this gap by providing semiautomatic techniques for the acquisition of a large number of semantic process descriptions on the (deep) Web. We model the data found in the online sources using ontologies, mine the process a user follows through the Web forms and generate a semantic description of this process. We present in this paper the implementation of our algorithms for the acquisition of process descriptions. We also provide a Web-based editor for manual annotation of new processes and refinement of the automatically-generated descriptions. © 2010 IEEE. Deep web; Process mining; Semantic process description; Semantic web; Web process

SePMa: An algorithm that mining sequential processes from hybrid log To accommodate ourselves to the changeful and complex business environment, we should be able adjust the business processes within the enterprise whenever changes happen. However, the work to design and redesign the processes is far from trivial, the designers are required to have deep knowledge of the business processes at hand, in traditional approaches it means long term investigation and high cost. To automate the procedure of process discovery, process mining is introduced. Process mining takes the run-time log generated by the process management system as its input, and outputs the process models defined for the system. Unfortunately, current work on process mining often assumes that the input log is generated by the same process, but in many occasions this requisition is hard to be satisfied. In this paper, we propose SePMa, an algorithm that mining sequential processes from hybrid log. SePMa aims at discovering sequential processes from log generated by multiple processes, both of theoretical analysis and experimental results show that SePMa has very high efficiency and effectiveness. © Springer-Verlag Berlin Heidelberg 2007. 

Sequence partitioning for process mining with unlabeled event logs Finding the case id in unlabeled event logs is arguably one of the hardest challenges in process mining research. While this problem has been addressed with greedy approaches, these usually converge to sub-optimal solutions. In this work, we describe an approach to perform complete search over the search space. We formulate the problem as a matter of finding the minimal set of patterns contained in a sequence, where patterns can be interleaved but do not have repeating symbols. This represents a new problem that has not been previously addressed in the literature, with NP-hard variants and conjectured NP-completeness. We solve it in a stepwise manner, by generating and verifying a list of candidate solutions. The techniques, introduced to address various subtasks, can be applied independently for solving more specific problems. The approach has been implemented and applied in a case study with real data from a business process supported in a software application. (C) 2011 Elsevier B.V. All rights reserved. Combinatorics on words; Process mining; Sequence partitioning; Sequential pattern mining

Service mining: Using process mining to discover, check, and improve service behavior Web services are an emerging technology to implement and integrate business processes within and across enterprises. Service orientation can be used to decompose complex systems into loosely coupled software components that may run remotely. However, the distributed nature of services complicates the design and analysis of service-oriented systems that support end-to-end business processes. Fortunately, services leave trails in so-called event logs and recent breakthroughs in process mining research make it possible to discover, analyze, and improve business processes based on such logs. Recently, the task force on process mining released the process mining manifesto. This manifesto is supported by 53 organizations and 77 process mining experts contributed to it. The active participation from end-users, tool vendors, consultants, analysts, and researchers illustrate the growing significance of process mining as a bridge between data mining and business process modeling. In this paper, we focus on the opportunities and challenges for service mining, i.e., applying process mining techniques to services. We discuss the guiding principles and challenges listed in the process mining manifesto and also highlight challenges specific for service-orientated systems. © 2008-2012 IEEE. business process management; conformance checking; Process mining; service discovery

Service pattern discovery of web service mining in Web service registry-repository This paper presents and elaborates the concept of Web service usage patterns and pattern discovery through service mining. We define three different levels of service usage data: i) user request level, ii) template level and iii) instance level. At each level, we investigate patterns of service usage data and the discovery of these patterns. An algorithm for service pattern discovery at the template level is presented. We show the system architecture of a service-mining enabled service registry repository. Web service patterns, pattern discovery and pattern mining supports the discovery and composition of complex services, which in tum supports the application of web services to increasingly complex business processes and applications. © 2006 IEEE. 

Service-oriented distributed data mining Data mining research currently faces two great challenges: how to embrace data mining services with just-in-time and autonomous properties and how to mine distributed and privacy-protected data. To address these problems, the authors adopt the Business Process Execution Language for Web Services in a serviceoriented distributed data mining (DDM) platform to choreograph DDM component services and fulfill global data mining requirements. They also use the learning-from-abstraction methodology to achieve privacy-preserving DDM. Finally,they illustrate how localized autonomy on privacy-policy enforcement plus a bidding process can help the service-oriented system self-organize. © 2006 IEEE. 

sigma-algorithm: Structured workflow process mining through amalgamating temporal workcases Workflow Management Systems help to execute, monitor and manage work process flow and execution. These systems, as they are executing, keep a record of who does what and when (e.g. log of events). The activity of using computer software to examine these records, and deriving various structural data results is called workfiow mining. The workflow mining activity, in general, needs to encompass behavioral (process/control-flow), social, informational (data-flow), and organizational perspectives; as well as other perspectives, because workflow systems are "people systems" that must be designed, deployed, and understood within their social and organizational contexts. In this paper we especially focus on the behavioral perspective of a structured workflow model that preserves the proper nesting and the matched pair properties. That is, this paper proposes an ICN-based mining algorithm that rediscovers a structured workflow process model. We name it sigma-Algorithm, because it is incrementally amalgamating a series of temporal workcases (workflow traces) according to three types of basic merging principles conceived in this paper. Where, a temporal workcase is a temporally ordered set of activity execution event logs. We also gives an example to show that how the algorithm works with the temporal workcases. workflow management system; events log; workflow mining; process rediscovery; temporal workcase; workflow process mining framework

Simplified business process model mining based on Structuredness Metric Process mining is the automated acquisition of process models from event logs. Although many process mining techniques have been developed, most of them focus on mining models from the prospective of control flow while ignoring the structure of mined models. This directly impacts the understandability and quality of mined models. To address the problem, we have proposed a genetic programming (GP) approach to mining simplified process models. Herein, genetic programming is applied to simplify the complex structure of process models using a tree-based individual representation. In addition, the fitness function derived from process complexity metric provides a guideline for discovering low complexity process models. Finally, initial experiments are performed to evaluate the effectiveness of the method. © 2011 IEEE. Genetic programming; Process complexity metric; Process mining; Structuredness Metric

Simplified Process Model Discovery Based on Role-Oriented Genetic Mining Process mining is automated acquisition of process models from event logs. Although many process mining techniques have been developed, most of them are based on control flow. Meanwhile, the existing role-oriented process mining methods focus on correctness and integrity of roles while ignoring role complexity of the process model, which directly impacts understandability and quality of the model. To address these problems, we propose a genetic programming approach to mine the simplified process model. Using a new metric of process complexity in terms of roles as the fitness function, we can find simpler process models. The new role complexity metric of process models is designed from role cohesion and coupling, and applied to discover roles in process models. Moreover, the higher fitness derived from role complexity metric also provides a guideline for redesigning process models. Finally, we conduct case study and experiments to show that the proposed method is more effective for streamlining the process by comparing with related studies. 

Simplifying discovered process models in a controlled manner Process models discovered from a process log using process mining tend to be complex and have problems balancing between overfitting and underfitting. An overfitting model allows for too little behavior as it just permits the traces in the log and no other trace. An underfitting model allows for too much behavior as it permits traces that are significantly different from the behavior seen in the log. This paper presents a post-processing approach to simplify discovered process models while controlling the balance between overfitting and underfitting. The discovered process model, expressed in terms of a Petri net, is unfolded into a branching process using the event log. Subsequently, the resulting branching process is folded into a simpler process model capturing the desired behavior. © 2012 Elsevier Ltd. All rights reserved. Branching processes; Model simplification; Petri nets; Process mining

Simplifying mined process models: An approach based on unfoldings Process models discovered using process mining tend to be complex and have problems balancing between overfitting and underfitting. Overfitting models are not general enough while underfitting models allow for too much behavior. This paper presents a post-processing approach to simplify discovered process models while controlling the balance between overfitting and underfitting. The discovered process model, expressed in terms of a Petri net, is unfolded into a branching process using the event log. Subsequently, the resulting branching process is folded into a simpler process model capturing the desired behavior. © 2011 Springer-Verlag. branching processes; model simplification; Petri nets; process mining

Single-Entry Single-Exit decomposed conformance checking An exponential growth of event data can be witnessed across all industries. Devices connected to the internet (internet of things), social interaction, mobile computing, and cloud computing provide new sources of event data and this trend will continue. The omnipresence of large amounts of event data is an important enabler for process mining. Process mining techniques can be used to discover, monitor and improve real processes by extracting knowledge from observed behavior. However, unprecedented volumes of event data also provide new challenges and often state-of-the-art process mining techniques cannot cope. This paper focuses on "conformance checking in the large" and presents a novel decomposition technique that partitions larger process models and event logs into smaller parts that can be analyzed independently. The so-called Single-Entry Single-Exit (SESE) decomposition not only helps to speed up conformance checking, but also provides improved diagnostics. The analyst can zoom in on the problematic parts of the process. Importantly, the conditions under which the conformance of the whole can be assessed by verifying the conformance of the SESE parts are described, which enables the decomposition and distribution of large conformance checking problems. All the techniques have been implemented in ProM, and experimental results are provided. © 2014 Elsevier Ltd. Conformance checking; Decomposition; Process diagnosis; Process mining

Skeletal Algorithms in Process Mining This paper(1) studies sample applications of skeletal algorithm to process mining and automata discovery. The basic idea behind the skeletal algorithm is to express a problem in terms of congruences on a structure, build an initial set of congruences, and improve it by taking limited unions/intersections, until a suitable condition is reached. Skeletal algorithms naturally arise in the context of process minig and automata discovery, where the skeleton is the "free" structure on initial data and a congruence corresponds to similarities in data. In such a context, skeletal algorithms come equipped with fitness functions measuring the complexity of a model. We examine two fitness functions for our sample problem - one based on Minimum Description Length Principle, and the other based on Bayesian Interpretation. 

SLA-Driven Business Process Distribution Service Oriented Architecture (SOA) includes several building blocks among which orchestration engine demands special attention. Although, there are a number of centralized orchestration engines to execute business processes described by BPEL language in SOA, you may find several decentralized orchestration engines and their purpose is to decompose a BPEL process to several software agents to improve some quality factors. On one hand, choosing a suitable method of process distribution may result in better adaptability of process with run-time environment. On the other hand, in the new generation of Service Oriented Architecture (SOA), Service Level Agreements (SLAs) are of paramount important. We need to have an adaptable business process with SLAs requirements and in this paper we are going to study business process distribution methods from an SLA point of view. To reach this goal, firstly, we introduce an intelligent method of using process mining for business process distribution (IPD). Secondly, we compare different methods of processes distribution including Fully, Semi and Intelligent Process Distribution methods. We also show the comparison of these methods considering quality factors such as Total Execution Time, Band Width Usage, Agent Granularity, Resource Adaptability, Memory Usage of Agents, Number of Produced Agents and Total System Adaptability. Thirdly, we consider all of the distribution methods from an SLA view through which users can determine their requirements of executing business processes to be mapped to run-time environment © 2009 IEEE. Adaptive Systems; BPEL; Business Process Mining; Distributed Orchestrate Engine; Mobile Agents; Service Level Agreement (SLA); Service Oriented Architecture; Workflow

Source code partitioning using process mining Software maintenance of business application software such as adding new functions and anti-aging should be performed cost-effectively. Information such as grouping of business activities that are executed as a unit, source code which corresponds to the activities, and the execution volume of the activities is useful for deciding on what areas of business application software to invest in, and prioritizing maintenance requests. We propose a new method which extracts such information using the BPM-E process mining tool we have developed. The method was applied to in-house business systems; the results showed that the method successfully extracted the grouping of events, but that there are accuracy issues in associating events with source code. © 2011 Springer-Verlag. business application maintenance; process mining; source code analysis

Start time and duration distribution estimation in semi-structured processes Semi-structured processes are business workflows, where the execution of the workflow is not completely controlled by a workflow engine, i.e., an implementation of a formal workflow model. Examples are workflows where actors potentially have interaction with customers reporting the result of the interaction in a process aware information system. Building a performance model for resource management in these processes is difficult since the required information is only partially recorded. In this paper we propose a systematic approach for the creation of an event log that is suitable for available process mining tools. This event log is created by an incrementally cleansing of data. The proposed approach is evaluated in an experiment. Copyright 2013 ACM. 

Statistical process monitoring by using process mining There is well known: Whether the advantage of using a normal process model to monitor the stability of a manufacturing process can be gained lies in the model's ability used to realize its conformance to the manufacturing process trend. In other words, whether a manufacturing process can be stabilized depends on how much is about the conformance level between its processing trend and the norm regulated in the process model. Once there are differences between a normalized process model and a manufacturing process, it will have some interesting situations that are worthy to be investigated. In this paper, a process conformance technique discussed in process mining field will be newly applied to accomplish such the investigation. This technique will consider statistical process control (SPC) trending charts as the norms of normalized processes so to experimentally estimate and examine the conformance level between the SPC norms and a statistically generated manufacture running process, hereby to see how the proposed process conformance approach is to the stability of the simulated manufacturing process. © 2013 IEEE. process conformance; process mining; process quality control; SPC charts; statistical process control

Statistical sequence analysis for business process mining and organizational routines Analyzing discrete event sequences has become a popular field in recent years. In the area of business process mining, numerous techniques have been developed to discover the structure of business processes by means of traces they leave behind in information systems. In organizational routines literature, these traces have been identified as a valuable source of information to investigate the dynamics of routines and how they evolve over time. However, both areas have been discussed in separation only. But in both areas alike the fundamental problem is to acquire knowledge about regularities in sequences of events based on observations thereof, and thus, we argue that process mining has the potential to advance research on organizational routines. As with any data analysis problem, one has to deal with problems due to noisy data and small samples. Thus, we show in this paper how to apply simple statistical tools to pattern detection in sequences. Subsequently, we integrate this into the popular -algorithm. This paves the way for statistically controlling the risk of falling for erroneous results. To the best of our knowledge, no process mining algorithm is capable of doing this. We are convinced that this will facilitate applicability in organizational routines studies. Business Process Mining; Organizational Genetics; Organizational Routines; Sequence Analysis.

Studies on the discovery of declarative control flows from error-prone data The declarative modeling of workflows has been introduced to cope with flexibility in processes. Its rationale is based on the idea of stating some basic rules (named constraints), tying the execution of some activities to the enabling, requiring or disabling of other activities. What is not explicitly prohibited by such constraints is implicitly considered legal, w.r.t. the specification of the process. Declarative models for workflows are based on a taxonomy of constraint templates. Constraints are thus instances of constraint templates, applied to specific activities. Many algorithms for the automated discovery of declarative workflows associate to each constraint a support. The support is a statistical measure assessing to what extent a constraint was respected during the enactment(s) of the process. In current state-of-the-art literature, constraints having a support below a user-defined threshold are considered not valid for the process. Thresholds are useful for filtering out guesses based on possible misleading events, reported in logs either because of errors in the execution, unlikely process deviations, or wrong recordings in logs. The latter circumstance can be considered extremely relevant when logs are not written down directly by machines reporting their work, but extracted from other source of information. Here, we present an insight on the actual capacity of filtering constraints by modifying the threshold for support, on the basis of real data. Then, taking a cue from the results performed on such analysis, we consider the trend of support when controlled errors are injected into the log, w.r.t. individual constraint templates. Through these tests, we demonstrate by experiment that each constraint template reveal to be less or more robust to different kinds of error, according to its nature. Artful process; Declarative workflow; Noisy event log; Process mining

Study of the process modeling based on petri net Process mining is one key technology in PASI, it can extract the relevant knowledge according to the event log information recorded in the information system, then restructure a process instance model and makes all the information track in the event log can meet the process model. In this paper, based on a algorithm of process mining, we propose the process mining ? algorithm which can discover the cycle activities and the activities with duplicate name in event log. Finally, we validates the correctness and effectivity of the ? algorithm in the process mining framework ProM5.2. © 2012 IEEE. algorithm; PASI Net; process mining; process modeling

Sub-process discovery: Opportunities for process diagnostics Most business processes in real life are not strictly ruled by the information systems that support them. This behavior is reflected in the traces stored by information systems. It is useful to diagnose in early stages of business process analysis. Process diagnostics is part of the process mining and it encompasses process performance analysis, anomaly detection, and inspection of interesting patterns.The techniques developed in this area have problems to detect sub-processes associated with the analyzed process and framing anomalies and significant patterns in the detected sub-processes. This proposal allows to segment the aligned traces and to form representative groups of sub-processes that compose the process analyzed. The tree of building blocks obtained reflects the hierarchical organization that is established between the sub-processes, considering main execution patterns. The proposal allows greater accuracy in the diagnosis. Based on the findings, implications for theory and practice are discussed. © 2013 IFIP International Federation for Information Processing. Business process; process diagnostics; process mining; trace alignment

SubSift web services and workflows for profiling and comparing scientists and their published works Scientific researchers, laboratories and organisations can be profiled and compared by analysing their published works, including documents ranging from academic papers to web sites, blog posts and Twitter feeds. This paper describes how the vector space model from information retrieval, more normally associated with full text search, has been employed in the open source SubSift software to support work-flows to profile and compare such collections of documents. SubSift was originally designed to match submitted conference or journal papers to potential peer reviewers based on the similarity between the paper's abstract and the reviewer's publications as found in online bibliographic databases. The software is implemented as a family of RESTful web services that, composed into a re-usable workflow, have already been used to support several major data mining conferences. Alternative workflows and service compositions are now enabling other interesting applications. © 2010 IEEE. 

Summarizing clinical pathways from event logs Objective: Clinical pathway analysis, as a pivotal issue in ensuring specialized, standardized, normalized and sophisticated therapy procedures, is receiving increasing attention in the field of medical informatics. Research in clinical pathway analysis has so far mostly focused on looking at aggregated data seen from an external perspective, and only provide very limited insight into the pathways. In some recent work, process mining techniques have been studied in discovering clinical pathway models from data. While it is interesting, discovered models may provide too much detail to give a comprehensive summary of the pathway. Moreover, the number of patterns discovered can be large. Alternatively, this article presents a new approach to build a concise and comprehensive summary that describes the entire structure of a clinical pathway, while revealing essential/critical medical behaviors in specific time intervals over the whole time period of the pathway. Methods: The presented approach summarizes a clinical pathway from the collected clinical event log, which regularly records all kinds of patient therapy and treatment activities in clinical workflow by various hospital information systems. The proposed approach formally defines the clinical pathway summarization problem as an optimization problem that can be solved in polynomial time by using a dynamic-programming algorithm. More specifically, given an input event log, the presented approach summarizes the pathway by segmenting the observed time period of the pathway into continuous and overlapping time intervals, and discovering frequent medical behavior patterns in each specific time interval from the log. Results: The proposed approach is evaluated via real-world data-sets, which are extracted from Zhejiang Huzhou Central hospital of China with regard to four specific diseases, i.e., bronchial lung cancer, colon cancer, gastric cancer, and cerebral infarction, in two years (2007.08-2009.09). Although the medical behaviors contained in these logs are very diverse and heterogeneous, experimental results indicates that the presented approach is feasible to construct condensed clinical pathway summaries in polynomial time from the collected logs, and have a linear scalability against the increasing size of the logs. Conclusion: Experiments on real data-sets illustrate that the presented approach is efficient and discovers high-quality results: the observed time period of a clinical pathway is correctly segmented into a set of continuous and overlapping time intervals, in which essential/critical medical behaviors are well discovered from the event log to form the backbone of a clinical pathway. The experimental results indicate that the generated clinical pathway summary not only reveals the global structure of a pathway, but also provides a thorough understanding of the way in which actual medical behaviors are practiced in specific time intervals, which might be essential from the perspectives of clinical pathway analysis and improvement. © 2012 Elsevier Inc. Clinical event log; Clinical pathway analysis; Clinical pathway summarization; Frequent pattern mining; Log segmentation; Process mining

Supervised intentional process models discovery using Hidden Markov models Since several decades, discovering process models is a subject of interest in the Information System (IS) community. Approaches have been proposed to recover process models, based on the recorded sequential tasks (traces) done by IS's actors. However, these approaches only focused on activities and the process models identified are, in consequence, activity-oriented. Intentional process models focus on the intentions underlying activities rather than activities, in order to offer a better guidance through the processes. Unfortunately, the existing process-mining approaches do not take into account the hidden aspect of the intentions behind the recorded user activities. We think that we can discover the intentional process models underlying user activities by using Intention mining techniques. The aim of this paper is to propose the use of probabilistic models to evaluate the most likely intentions behind traces of activities, namely Hidden Markov Models (HMMs). We focus on this paper on a supervised approach that allows discovering the intentions behind the user activities traces and to compare them to the prescribed intentional process model. © 2013 IEEE. intention mining; process discovery; process modeling; supervised learning

Supporting collaborative work by learning process models and patterns from cases Recent work shows an increasing interest of the Business Process Management (BPM) community in unstructured, so-called "human-centric" processes. Case Management (CM) is a new trend that focuses on the support of collaborative human-centric processes. Although CM provides concepts that support human-centric work, processes have to be modelled beforehand in order to be supported by IT systems. Hence, a problem that arises when applying CM is that when organisations begin to formalize CM practice, it is often difficult to express rules controlling the applicability of tasks. Furthermore, fundamental complexity challenges arise when applying CM in practice. In this contribution, we provide a solution to these two issues. We propose that managing human-centric processes should start with model skeletons that serve as a lattice where initial process execution can lean against. Additionally, by tracking different process cases, substantial process knowledge is recorded. Exploring process history might reveal certain recurring patterns that serve as dynamic guidance enhancement for CM systems. In this way, process models might evolve over time, become more and more complete and better reflect operational reality. © 2013 ICST. Adaptive Case Management; Association Rule Mining; Business Process Management; Process Mining; Process Observation

Surgical workflow monitoring based on trajectory data mining This research aims at investigating intermediate-scale workflows using the surgical staff's movement pattern. In this study, we have introduced an ultrasonic location aware system to monitor intraoperative movement trajectories on surgical staffs for the workflow analysis. And we developed trajectory data mining for surgical workflow segmentation, and analyzed trajectory data with multiple cases. As a result, in 77.18% of total time, a kind of current operation stage could be correctly estimated. With high accuracy 85.96%, the estimation using trajectory data was able to distinguish whether a current 5 minutes was transition time from one stage to another stage or not.. Based on these results, we are implementing the surgery safe support system that promotes safe & efficient surgical operations. © 2011 Springer-Verlag. Surgical Management; Surgical Workflow; Trajectory Analysis

Techniques for a posteriori analysis of declarative processes The increasing availability of event data recorded by information systems, electronic devices, web services and sensor networks provides detailed information about the actual processes in systems and organizations. Process mining techniques can use such event data to discover processes and check the conformance of process models. For conformance checking, we need to analyze whether the observed behavior matches the modeled behavior. In such settings, it is often desirable to specify the expected behavior in terms of a declarative process model rather than of a detailed procedural model. However, declarative models do not have an explicit notion of state, thus making it more difficult to pinpoint deviations and to explain and quantify discrepancies. This paper focuses on providing high-quality and understandable diagnostics. The notion of activation plays a key role in determining the effect of individual events on a given constraint. Using this notion, we are able to show cause-and-effect relations and measure the healthiness of the process. © 2012 IEEE. conformance checking; Declare; process mining; temporal logic

Temporal mining for interactive workflow data analysis In the past few years there has been an increasing interest in the analysis of process logs. Several proposed techniques, such as workflow mining, are aimed at automatically deriving the underlying workflow models. However, current approaches only pay little attention on an important piece of information contained in process logs: the timestamps, which are used to define a sequential ordering of the performed tasks. In this work we try to overcome these limitations by explicitly including time in the extracted knowledge, thus making the temporal information a first-class citizen of the analysis process. This makes it possible to discern between apparently identical process executions that are performed with different transition times between consecutive tasks. This paper proposes a framework for the user-interactive exploration of a condensed representation of groups of executions of a given process. The framework is based on the use of an existing mining paradigm: Temporally-Annotated Sequences (TAS). These are aimed at extracting sequential patterns where each transition between two events is annotated with a typical transition time that emerges from input data. With the extracted TAS, which represent sets of possible frequent executions with their typical transition times, a few factorizing operators are built. These operators condense such executions according to possible parallel or possible mutual exclusive executions. Lastly, such condensed representation is rendered to the user via the exploration graph, namely the Temporally-Annotated Graph (TAG). The user, the domain expert, is allowed to explore the different and alternative factorizations corresponding to different interpretations of the actual executions. According to the user choices, the system discards or retains certain hypotheses on actual executions and shows the consequent scenarios resulting from the coresponding re-aggregation of the actual data. Copyright 2009 ACM. Temporal sequence mining; Workflow mining

The behavior trustworthiness analysis methods of composite web services based on process mining At present, the behavior trustworthiness of the composite Web service was very important. The soundness of the composite Web service model was the core of the behavior trustworthiness of the service composition, which includes two steps, one was to determine whether or not the composite model satisfied the behavior relativity, in order to analyze the function predictability; the other was to compare the behavior conformance for analyzing the influence of external factors . But the proposed judging algorithm of behavior relativity was feasible only in the case that T-invariant of Petri net model exists, and the behavior conformance was also difficult to handle. In the paper, firstly, in order to analyze the behavior relativity between theWeb services, an algorithm for determining the behavior weak soundness of the composite service was presented based on the theory of the service tree. Then, we present an effective analysis method of behavior conformance based on process mining. Finally, we develop plug-ins and test our methods in large benchmarks, and compare our methods with genetic process mining methods. The theoretical analysis and experimental results indicate that this method can realize the predictable behavior of software well, and satisfy the behavior trustworthiness requirements of software. © 2013 NSP Natural Sciences Publishing Cor. Behavior relativity; Behavior trustworthiness; Open petri net; Process mining; Web service

The minadept clustering approach for discovering reference process models out of process variants During the last years a new generation of adaptive Process-Aware Information Systems (PAIS) has emerged, which enables dynamic process changes at runtime, while preserving PAIS robustness and consistency. Such adaptive PAIS allow authorized users to add new process activities, to delete existing activities, or to change pre-defined activity sequences during runtime. Both this runtime flexibility and process configurations at build-time, lead to a large number of process variants being derived from the same process model, but slightly differing in structure due to the applied changes. Generally, process variants are expensive to configure and difficult to maintain. This paper presents selected results from our MinAdept project. In particular, we provide a clustering algorithm that fosters learning from past process changes by mining a collection of process variants. As mining result we obtain a process model for which average distance to the process variant models becomes minimal. By adopting this process model as reference model in the PAIS, need for future process configuration and adaptation decreases. We have validated our clustering algorithm by means of a case study as well as comprehensive simulations. Altogether, our vision is to enable full process lifecycle support in adaptive PAIS. © 2010 World Scientific Publishing Company. process change; process learning; process mining; process variants; Process-aware information system

The proposition of a framework for semantic process mining As one of the hot topics in Business Process Management (BPM), process mining aims at constructing models to explain what is actually happening from different perspectives based on the process-related information that automatically extracted from event logs. Because the semantics of the data that recorded in event logs are not usually explicit, current mining approaches are somewhat limited. A number of studies have been carried out in the combination use of formalized semantic models and process mining technologies to obtain the semantic mining capability. However, among these researches, there is lack of a guideline that can clearly illustrate different stages during the semantic process mining. The objective of this study is to present a general framework, which unambiguously expresses the main stages of the semantic process mining. Based on this framework, an example about carbon footprint analysis is used to show the possibility of obtaining advantages from semantic process mining. Carbon footprint analysis; Knowledge formalization; Knowledge injection; Process mining; Semantic annotation; Semantic discovery

The research of process mining assessment used in business intelligence In order to do process mining better in the Business Intelligence environment, the proper process mining model and the right evaluation method to assess the mining results become the key issues. This paper is based on both theoretical and technological achievements in process mining area, putting forward a process mining model under event log mode, providing the analysis process of selecting evaluation indicators by AHP, and gives out a set of formulas for assessing process instance combined with the vector model. For illustration, a case recorded by an insurance company handling claims lodged over the phone is utilized to show the feasibility of the given model and the formulas in solving assessment problems. Empirical results is presented as numerical data by formula assessing effectively to the new process records under specific target, it can be displayed directly for its consequence; process screening and classification, including excavation work for the follow-up by the threshold value setting can evaluate the process improvement and provide basis for decision making in further process mining work. © 2012 IEEE. AHP; Assessment; Process mining; Vector model; WPPDD

The research on the usage of business process mining in the implementation of BPR As an important approach of enterprise improvement, Business Process Re-engineering (BPR) has become the basis of enterprise information, organization change, etc. Great changes are difficult to be obtained only by experts' subjective decision-making, and efficient decision-making support tools are lack at the moment. Business process mining (BPM) does well in knowledge management and decision-making support. It is significant for successful implementation if BPM could be introduced into BPR projects. This paper describes the current implementation framework of the BPR, the development of the BPM and the research on usage of business Process Mining in the implementation of BPR Projects. At the end of paper propose the implementation framework of BPR based on the BPM. © 2007 IEEE. BPR; Business process mining (BPM); Petri net; Process reengineering life cycle

The Trustworthiness Analyzing of Interacting Business Process Based on the Induction Information Under the open environments, it is very difficult to guarantee the trustworthiness of interacting business process using traditional software engineering methods, at the same time, for dealing with the influence of external factors, some proposed business process mining methods are only effective 1-bounded business process, and some behavior dependent relationships are ignore. A behavior trustworthiness analysis method of business process based on induction information is presented in the paper. Firstly, aimed to the internal factors, we analyze the consistent behavior relativity to guarantee the predictable function. Then, for the external factors, in order to analyze the behavior change of business process, we propose a process mining methods based on induction information. Finally, experiment simulation is given out, and compares our method with genetic process mining methods. Theoretical analysis and experimental results indicate that our method is better than the genetic process mining method. trustworthiness; consistent behavior relativity; business process; process mining

The use of intelligent systems for planning and scheduling of product development projects The paper investigates the use of intelligent systems to identify the factors that significantly influence the duration of new product development. These factors are identified on the basis of an internal database of a production enterprise and further used to estimate the duration of phases in product development projects. In the paper, some models and methodologies of the knowledge discovery process are compared and a method of knowledge acquisition from an internal database is proposed. The presented approach is dedicated to industrial enterprises that develop modifications of previous products and are interested in obtaining more precise estimates for project planning and scheduling. The example contains four stages of the knowledge discovery process including data selection, data transformation, data mining, and interpretation of patterns. The example also presents a performance comparison of intelligent systems in the context of variable reduction and preprocessing. Among data mining techniques, artificial neural networks and the fuzzy neural system are chosen to seek relationships between the duration of project phase and other data stored in the information system of an enterprise. (C) 2014 The Authors. Published by Elsevier B.V. 

Thinking Out of the Box: Discovering the Relevance of External Context to Business Processes Successful organizations are those able to identify and respond appropriately to changes in their internal and external environments. The search for flexibility is linked to the need for the organization to adapt to frequent and exceptional changes in scenarios imposed to them. Those disruptions in routine should be reflected in business processes, in a sense that processes must be adjusted to such variations, taking into account both internal and external variables, typically referred in the literature as the context of the process. In particular, defining the relevance of external context for the execution of a process is still an open research issue. We propose a method to identify and prioritize external variables that impact the execution of specific activities of a process, applying competitive intelligence concepts and data mining techniques. We have evaluated the method in a case study, which showed how the discovered variables influenced specific activities of the process. © Springer-Verlag Berlin Heidelberg 2013. Business Process; Competitive Intelligence; External Context; KDD; Knowledge Management

Time prediction based on process mining Process mining allows for the automated discovery of process models from event logs. These models provide insights and enable various types of model-based analysis. This paper demonstrates that the discovered process models can be extended with information to predict the completion time of running instances. There are many scenarios where it is useful to have reliable time predictions. For example, when a customer phones her insurance company for information about her insurance claim, she can be given an estimate for the remaining processing time. In order to do this, we provide a configurable approach to construct a process model, augment this model with time information learned from earlier instances, and use this to predict e.g., the completion time. To provide meaningful time predictions we use a configurable set of abstractions that allow for a good balance between "overfitting" and "underfitting". The approach has been implemented in ProM and through several experiments using real-life event logs we demonstrate its applicability. © 2010 Elsevier B.V. All rights reserved. Business intelligence; Business process management; Performance analysis; Process mining; Time prediction

Time prediction based on process mining taking concept drift into consideration Process mining allows for the automated discovery of process models from event logs. These models provide insights and enable various types of model-based analysis. Now many scholars have made a great contribution on predicting the completion time of running instances and a lot of algorithms have been proposed, but they mostly ignored concept drift which means the influence of the external factors. In order to improve the accuracy of the prediction, we take the concept drift into account. We do cluster analysis on the annotated transition system. Experiments show that our algorithm has a considerable degree of improvement over the previous. © (2014) Trans Tech Publications, Switzerland. Cluster analysis; Concept drift; Process mining; Time prediction

Time-interval process model discovery and validation-a genetic process mining approach A process management technique, called process mining, received much attention recently. Process mining can extract organizational or social structures from event logs recorded in an information system. However, when constructing process models, most process mining searches consider only the topology information among events, but do not include the time information. To overcome the drawbacks, a time-interval genetic process mining framework is proposed. First, time-intervals between events are derived for all event sequences. A discretization procedure is then developed to transform time-interval data from continues type to categorical type. Second, the genetic process mining method which is based on global search strategy is applied to generate time-interval process models. Finally, a precision measure is defined to evaluate the quality of the generated models. With the measure, managers can select the best process model among a set of candidate models without human involvement. © 2010 Springer Science+Business Media, LLC. Genetic algorithms; Model quality; Process mining; Time-interval

Topological pattern discovery and feature extraction for fraudulent financial reporting Fraudulent financial reporting (FFR) involves conscious efforts to mislead others regarding the financial condition of a business. It usually consists of deliberate actions to deceive regulators, investors or the general public that also hinder systematic approaches from effective detection. The challenge comes from distinguishing dichotomous samples that have their major attributes falling in the same distribution. This study pioneers a novel dual GHSOM (Growing Hierarchical Self-Organizing Map) approach to discover the topological patterns of FFR, achieving effective FFR detection and feature extraction. Specifically, the proposed approach uses fraudulent samples and non-fraudulent samples to train a pair of dual GHSOMs under the same training parameters and examines the hypotheses for counterpart relationships among their subgroups taking advantage of unsupervised learning nature and growing hierarchical structures from GHSOMs. This study further presents (1) an effective classification rule to detect FFR based on the topological patterns and (2) an expert-competitive feature extraction mechanism to capture the salient characteristics of fraud behaviors. The experimental results against 762 annual financial statements from 144 public-traded companies in Taiwan (out of which 72 are fraudulent and 72 are non-fraudulent) reveal that the topological pattern of FFR follows the non-fraud-central spatial relationship, as well as shows the promise of using the topological patterns for FFR detection and feature extraction. (C) 2014 Elsevier Ltd. All rights reserved. 

Toward objective software process information: Experiences from a case study A critical problem in software development is the monitoring, control and improvement in the processes of software developers. Software processes are often not explicitly modeled, and manuals to support the development work contain abstract guidelines and procedures. Consequently, there are huge differences between 'actual' and 'official' processes: "the actual process is what you do, with all its omissions, mistakes, and oversights. The official process is what the book, i. e., a quality manual, says you are supposed to do" (Humphrey in A discipline for software engineering. Addison-Wesley, New York, 1995). Software developers lack support to identify, analyze and better understand their processes. Consequently, process improvements are often not based on an in-depth understanding of the 'actual' processes, but on organization-wide improvement programs or ad hoc initiatives of individual developers. In this paper, we show that, based on particular data from software development projects, the underlying software development processes can be extracted and that automatically more realistic process models can be constructed. This is called software process mining (Rubin et al. in Process mining framework for software processes. Software process dynamics and agility. Springer Berlin, Heidelberg, 2007). The goal of process mining is to better understand the development processes, to compare constructed process models with the 'official' guidelines and procedures in quality manuals and, subsequently, to improve development processes. This paper reports on process mining case studies in a large industrial company in The Netherlands. The subject of the process mining is a particular process: the change control board (CCB) process. The results of process mining are fed back to practice in order to subsequently improve the CCB process. © 2010 The Author(s). Configuration management data; Software process mining

Towards a Detective Approach to Business Process-Centered Resilience Protection of today's interconnected and complex information infrastructures is of high priority. Traditionally, protection means robustness: preventively identify the threats to business processes and propose countermeasures within the context of a risk analysis. This, however, only covers known risks having punctual effects upon the IT infrastructure. In contrast, the notion of resilience, as a refinement of trustworthiness, is getting attention both in academia and within organizations as a denominator to move beyond survival and even prosper in the face of adverse conditions. This paper reports on ongoing work towards the development of PREDEC, a detective framework to realize resilience in the context of business processes. Specifically, it firstly motivates the need for operational resilience and corresponding tool support at the level of processes. Secondly, it sketches the operation and building blocks of PREDEC, which currently employs process mining techniques to analyze process event logs to assess systems' resilience. Finally, it describes the intended evaluation steps to be undertaken once PREDEC is completely implemented. Operational Resilience; Automated Detection; Process Intelligence; Resilient BPM

Towards a framework for the agile mining of business processes In order to support business processes effectively, their implementation by a process management systems (PMS) must be as close to the real world's processes as possible. Generally, it is not sufficient to analyze and model a business process only once, and then to handle respective business cases according to the defined model for a long period of time. Instead, process implementations must be quickly adaptable to changing needs. A PMS should enable process instance changes and provide facilities for analyzing these instance-specific changes in order to derive optimized process models. In this paper we introduce a framework for the agile mining of business processes which supports the whole process life cycle in an integrated way. Our framework is based on process mining techniques, adaptive process management, and conversational case-based reasoning. On the one hand, it allows annotating execution and change logs with semantical information to gather information about the reasons for ad-hoc deviations, which can then be analyzed by the process engineer (with support from the PMS). On the other hand, it enables the process engineer to adapt process models based on the outcome of these analyses and to migrate related process instances to the new model. © Springer-Verlag Berlin Heidelberg 2006. 

Towards a goal recognition model for the organizational memory Automatically building a model of the different goals underlying a workflow is very important for an organization's memory since we will be able to capture the implicit knowledge that is hosted in the employees. The automatic recognition of the goal that motivates an employee to execute a particular sequence of tasks is crucial to determine what tasks are expected to be performed next in order to achieve that goal within the dynamics of the organization. Furthermore, an early recognition of the employee's goal can also prevent deviations in his/her behavior from the expected behavior by providing personalized assistance. In this article we propose a model to capture regularities in the activities carried out by employees of an organization when they are pursuing different goals. An experimental evaluation was conducted in order to determine the validity of our approach and promising results are reported. © 2012 Springer-Verlag. goal recognition; organizational memory; process mining

Towards a method to retrieving business process model from source code Understanding and keeping track of business processes is one of the most important tasks in development of business software. However, any documentation other than source code cannot be completely reliable. On the other hand, source code is rather unreadable by non-developers and can be challenging to determine business processes distributed among many files and layers. This paper introduces a methodology for extracting business process model from source code by identifying topics from object model, analysing application architecture dependency and developing a graph data structure to store information regarding semantic relationships within source code. © 2014 AISTI. business process model; metadata; object oriented model

Towards a performance estimate in semi-structured processes Semi-structured processes are business workflows, where the execution of the workflow is not completely controlled by a workflow engine, i.e., an implementation of a formal workflow model. Examples are workflows where actors potentially have interaction with customers reporting the result of the interaction in a process aware information system. Building a performance model for resource management in these processes is difficult since the information required for a performance model is only partially recorded. In this paper we propose a systematic approach for the creation of an event log that is suitable for available process mining tools. This event log is created by an incremental cleansing of data. The proposed approach is evaluated in a case study where the quality of the derived event log i assessed by domain experts. © 2011 IEEE. 

Towards comprehensive support for organizational mining Process mining has emerged as a way to analyze processes based on the event logs of the systems that support them. Today's information systems (e.g., ERP systems) log all kinds of events. Moreover, also embedded systems (e.g., medical equipment, copiers, and other high-tech systems) start producing detailed event logs. The omnipresence of event logs is an important enabler for process mining. The primary goal of process mining is to extract knowledge from these logs and use it for a detailed analysis of reality. Lion's share of the efforts in this domain has been devoted to control-flow discovery. Many algorithms have been proposed to construct a process model based on an analysis of the event sequences observed in the log. As a result, other aspects have been neglected, e.g., the organizational setting and interactions among coworkers. Therefore, we focus on organizational mining. We will present techniques to discover organizational models and social networks and show how these models can assist in improving the underlying processes. To do this, we present new process mining techniques but also use existing techniques in an innovative manner. The approach has been implemented in the context of the ProM framework and has been applied in various case studies. In this paper, we demonstrate the applicability of our techniques by analyzing the logs of a municipality in the Netherlands. © 2008 Elsevier B.V. All rights reserved. Business process management; Data mining; Petri nets; Process mining; Social network analysis; Workflow management

Towards improving the representational bias of process mining Process mining techniques are able to extract knowledge from event logs commonly available in today's information systems. These techniques provide new means to discover, monitor, and improve processes in a variety of application domains. Process discovery-discovering a process model from example behavior recorded in an event log-is one of the most challenging tasks in process mining. A variety of process discovery techniques have been proposed. Most techniques suffer from the problem that often the discovered model is internally inconsistent (i.e., the model has deadlocks, livelocks or other behavioral anomalies). This suggests that the search space should be limited to sound models. In this paper, we propose a tree representation that ensures soundness. We evaluate the impact of the search space reduction by implementing a simple genetic algorithm that discovers such process trees. Although the result can be translated to conventional languages, we ensure the internal consistency of the resulting model while mining, thus reducing the search space and allowing for more efficient algorithms. © 2012 IFIP International Federation for Information Processing. 

Towards mining structural workflow patterns Collaborative information systems are becoming more and more complex, involving numerous interacting business objects within considerable processes. Analysing the interaction structure of those complex systems will enable them to be well understood and controlled. The work described in this paper is a contribution to these problems for workflow based process applications. In fact, we discover workflow patterns from traces of workflow events based on a workflow mining technique. Workflow mining proposes techniques to acquire a workflow model from a workflow log. Mining of workflow patterns is done by a statistical analysis of log-based event. Our approach is characterised by a "local" workflow patterns discovery that allows to cover partial results and a dynamic technique dealing with concurrency. © Springer-Verlag Berlin Heidelberg 2005. Business process reengineering; Workflow mining; Workflow patterns

Towards performance analysis of wireless sensor networks using Process Mining Techniques Performance analysis of wireless sensor networks is a difficult task because of the high dynamic of networks and the use of duty-cycled MAC protocols. Markov-based modelling is an interesting approach to deal with this problem. However, existing Markov-based analytic models, being MAC protocol-centric rather than network-centric, work under strong assumptions and do not allow to encompassing important network parameters like radio channel fading and capture effect, or actual implementation optimizations (not always specified in the protocol description). In this paper we propose a novel approach to obtain a Markov chain model for networks running different MAC protocols by means of Process Mining Techniques. We present the main aspects of our approach together with the results obtained for the standard IEEE 802.15.4. The obtained Markov model can be used to evaluate various performance parameters. The approach can also be extended to a wider range of protocols. MAC Protocols; Markov chain; Network performance; Process Mining

Towards robust conformance checking The growing complexity of processes in many organizations stimulates the adoption of business process management (BPM) techniques. Process models typically lie at the basis of these techniques and generally, the assumption is made that the operational business processes as they are taking place in practice conform to these models. However, recent experience has shown that this often isn't the case. Therefore, the problem of checking to what extent the operational process conforms to the process model is increasingly important. In this paper, we present a robust approach to get insights into the conformance of an operational process to a given process model. We use logs that carry information about which activities have being performed, in which order and we compare these logs to an abstract model. We do not only provide several different conformance metrics, but we show an efficient implementation for the calculation of these metrics. Our approach has been implemented in the ProM framework, evaluated using simulated event logs and compared against an existing conformance technique based on Petri nets. © 2011 Springer-Verlag. conformance; process analysis; Process mining

Trace alignment in process mining: Opportunities for process diagnostics Process mining techniques attempt to extract non-trivial knowledge and interesting insights from event logs. Process mining provides a welcome extension of the repertoire of business process analysis techniques and has been adopted in various commercial BPM systems (BPM/one, Futura Reflect, ARIS PPM, Fujitsu, etc.). Unfortunately, traditional process discovery algorithms have problems dealing with less-structured processes. The resulting models are difficult to comprehend or even misleading. Therefore, we propose a new approach based on trace alignment. The goal is to align traces in a way that event logs can be explored easily. Trace alignment can be used in a preprocessing phase where the event log is investigated or filtered and in later phases where detailed questions need to be answered. Hence, it complements existing process mining techniques focusing on discovery and conformance checking. © 2010 Springer-Verlag Berlin Heidelberg. 

Trace clustering based on conserved patterns: Towards achieving better process models Process mining refers to the extraction of process models from event logs. Real-life processes tend to be less structured and more flexible. Traditional process mining algorithms have problems dealing with such unstructured processes and generate "spaghetti-like" process models that are hard to comprehend. An approach to overcome this is to cluster process instances such that each of the resulting clusters correspond to coherent sets of process instances that can each be adequately represented by a process model. In this paper, we present multiple feature sets based on conserved patterns and show that the proposed feature sets have a better performance than contemporary approaches. We evaluate the goodness of the formed clusters using established fitness and comprehensibility metrics defined in the context of process mining. The proposed approach is able to generate clusters such that the process models mined from the clustered traces show a high degree of fitness and comprehensibility. Further, the proposed feature sets can be easily discovered in linear time making it amenable to real-time analysis of large data sets. © 2010 Springer-Verlag. case similarity; Clustering; fitness; process discovery; process mining

Translating Message Sequence Charts to other Process Languages Using Process Mining Message Sequence Charts (MSCs) are often used by software analysts When discussing the behavior of a system with different stake-holders. Often such discussions lead to more complete behavioral models in the form of, e.g., Event-driven Process Chains (EPCs), Unified Modeling Language (UML), activity diagrams, Business Process Modeling Notation (BPMN) models, Petri acts, etc. Process mining oil the. other hand, deals with the problem of constructing complete behavioral models by analyzing event logs of information systems. In contrast to existing process mining techniques, where logs are assumed to only contain implicit information, the approach presented in this paper combines the explicit knowledge captured in individual MSCs and the techniques and tools available in the process mining domain. This combination allows us to discover high-quality process models. To constructively add to the existing work on process mining, our approach has been implemented in the process mining framework ProM (www.processmining.org). message sequence charts; process mining; synthesis of scenarios-based models

Turning event logs into process movies: animating what has really happened Todays information systems log vast amounts of data. These collections of data (implicitly) describe events (e.g. placing an order or taking a blood test) and, hence, provide information on the actual execution of business processes. The analysis of such data provides an excellent starting point for business process improvement. This is the realm of process mining, an area which has provided a repertoire of many analysis techniques. Despite the impressive capabilities of existing process mining algorithms, dealing with the abundance of data recorded by contemporary systems and devices remains a challenge. Of particular importance is the capability to guide the meaningful interpretation of oceans of data by process analysts. To this end, insights from the field of visual analytics can be leveraged. This article proposes an approach where process states are reconstructed from event logs and visualised in succession, leading to an animated history of a process. This approach is customisable in how a process state, partially defined through a collection of activity instances, is visualised: one can select a map and specify a projection of events on this map based on the properties of the events. This paper describes a comprehensive implementation of the proposal. It was realised using the open-source process mining framework ProM. Moreover, this paper also reports on an evaluation of the approach conducted with Suncorp, one of Australias largest insurance companies. 

Turning points in business process orientation maturity model: An East European survey Companies worldwide are embracing Business Process Orientation (BPO) in order to improve their overall performance. Over the past few years methodologies for analyzing maturity state of BPO have been developed. Maturity model consists of a number of stages through which companies evolve as they increase the adoption of process oriented practices. Understanding the transition between different stages of BPO is of utmost importance for enabling governance and superior execution of these processes. In this paper we present the investigation of turning points between different stages of BPO in the business setting in transitional economies of East European countries, specifically Croatia and Slovenia. Using an acknowledged data mining technique of classification and regression trees (C&RT) turning points are detected based on survey results obtained in 2008. These findings present invaluable guidelines for any business that strives to achieve more efficient business processes. 

UMFP: Update Mining Frequency Paths in RFID system Radio Frequency Identification (RFID) technology is fast becoming an important tool for tracking commodities in supply chain management applications. The movement of commodities through the supply chain forms a gigantic workflow which can be mined for the discovery of moving trends that in turn will be valuable in understanding and optimizing business processes. There are some methods dealing with mining frequency paths in static RFID database. But like data stream, RFID system also collects tracking data for moving objects continually. The current mining methods are not created for mining frequency paths in incremental RFID database. In this paper, we propose a method called UMFP to mine frequency paths in incremental RFID database. The method uses existing frequency path mining algorithms to mine frequency paths in each update batch, then merges the results together and returns the frequency paths to users. In our method, the whole RFID data will be mined only once when update batch generated, it will combine the existing data mining results and the last update batch data mining results. The UMFP uses path tree to store mining results. The mining threshold we used in our method is smaller than minimum support threshold which defined by users. By this strategy, UMFP will mine all the potentially frequency paths, ensure that all truly frequency paths will be output when the users request. At last, experiments will show the performances about UMFP. © 2009 IEEE. 

Understanding process behaviours in a large insurance company in Australia: A case study Having a reliable understanding about the behaviours, problems, and performance of existing processes is important in enabling a targeted process improvement initiative. Recently, there has been an increase in the application of innovative process mining techniques to facilitate evidence-based understanding about organizations' business processes. Nevertheless, the application of these techniques in the domain of finance in Australia is, at best, scarce. This paper details a 6-month case study on the application of process mining in one of the largest insurance companies in Australia. In particular, the challenges encountered, the lessons learned, and the results obtained from this case study are detailed. Through this case study, we not only validated existing 'lessons learned' from other similar case studies, but also added new insights that can be beneficial to other practitioners in applying process mining in their respective fields. © 2013 Springer-Verlag. business process management; case study; process mining

Understanding service quality and customer churn by process discovery for a multi-national banking contact center Churning of the customer base is always a top issue in Banking. It is directly related to recurrent revenue, and the ever increasing acquisition costs for new customers. In a first approach, this issue is related to both the quality of service (which is mainly in the front-office, say the contact center) and the speed of service, which is mainly in the back-office. Many studies published to date on this required manual data collection. This creates in general two concerns: worker behavior may change under observation, and manual data collection is expensive and often error prone. In this paper it is shown by means of a case study for a Multi-National Bank (with 5000 employees in the back office) how automated Business Process Discovery, which is an advanced type of process mining, makes it possible to handle the above concerns. The automated data collection and the analysis, in terms of Hidden Markov Models, are key elements. Several results regarding the quality and speed of service have been obtained. Most interesting was the discovery of deeper root causes for customer attrition. Once the deficiencies in the processes are identified, appropriate process improvements can be designed and simulated based on the models emerging from process discovery. In this case study, significant quality and speed improvements as well as customer churn reductions have been obtained. © 2013 IEEE. Custumer churn; Process discovery; Process improvement; Quality of service

Understanding spaghetti models with sequence clustering for ProM The goal of process mining is to discover process models from event logs. However, for processes that are not well structured and have a lot of diverse behavior, existing process mining techniques generate highly complex models that are often difficult to understand; these are called spaghetti models. One way to try to understand these models is to divide the log into clusters in order to analyze reduced sets of cases. However, the amount of noise and ad-hoc behavior present in real-world logs still poses a problem, as this type of behavior interferes with the clustering and complicates the models of the generated clusters, affecting the discovery of patterns. In this paper we present an approach that aims at overcoming these difficulties by extracting only the useful data and presenting it in an understandable manner. The solution has been implemented in ProM and is divided in two stages: preprocessing and sequence clustering. We illustrate the approach in a case study where it becomes possible to identify behavioral patterns even in the presence of very diverse and confusing behavior. © 2010 Springer-Verlag. Event Logs; Hierarchical Clustering; Markov Chains; Preprocessing; Process Mining; Process Models; ProM; Sequence Clustering

User-guided discovery of declarative process models Process mining techniques can be used to effectively discover process models from logs with example behaviour. Cross-correlating a discovered model with information in the log can be used to improve the underlying process. However, existing process discovery techniques have two important drawbacks. The produced models tend to be large and complex, especially in flexible environments where process executions involve multiple alternatives. This overload of information is caused by the fact that traditional discovery techniques construct procedural models explicitly showing all possible behaviours. Moreover, existing techniques offer limited possibilities to guide the mining process towards specific properties of interest. These problems can be solved by discovering declarative models. Using a declarative model, the discovered process behaviour is described as a (compact) set of rules. Moreover, the discovery of such models can easily be guided in terms of rule templates. This paper uses DECLARE, a declarative language that provides more flexibility than conventional procedural notations such as BPMN, Petri nets, UML ADs, EPCs and BPEL. We present an approach to automatically discover DECLARE models. This has been implemented in the process mining tool ProM. Our approach and toolset have been applied to a case study provided by the company Thales in the domain of maritime safety and security. © 2011 IEEE. 

Using ADMIRE data mining and integration tools in hydrological forecast use case This paper presents successful use of the data mining and integration (DMI) tools created by the EU ADMIRE project in the data mining based hydrological forecast use case. We present general architecture and tools of the ADMIRE framework, DISPEL language for description of distributed workflows, Eclipse based workbench for DMI workflow construction and execution and user portal. Then we describe the hydrological forecast use case, its implementation using the tools of ADMIRE project and share some thoughts on advantages of the framework described. © 2011 IEEE. 

Using AI for e-Government automatic assessment of immigration application forms This paper describes an e-Government AI project that provides a range of intelligent AI services to support automated assessment of various types of applications submitted to an immigration agency. The "AI Module" is integrated into the agency's next generation application form processing system which includes a workflow and document management system. AI services provided include rule-based assessment, workflow processing, schema-based suggestions, data mining, case-based reasoning, and machine learning. The objective is to use AI to provide faster and higher quality service to millions of citizens and visitors in processing their requests. The AI Module streamlines processes and workflows while at the same time ensuring all applications are processed fairly and accurately and that all relevant laws and regulations have been considered. It greatly shortens turnaround time and indirectly helps facilitate economic growth of the city. This is probably the first time any immigration agency in the world is using AI for automatic application assessment in such a large and broad scale. Copyright © 2007, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. 

Using business process models to retrieve information from governing documents Governing documents are long textual documents containing information about how different operations are to be carried out in a business. The information spans from overall policies and standards to detailed guidelines, and the amount of such documents in larger corporations tend to be substantial. In business process models the aim is to model the same domain from a process perspective. In this project work we investigate the potential of utilizing text mining technologies together with a standard information retrieval system to link these two sources of information in a dynamic way. To test out the concepts we employ business process models and governing documents from Statoil ASA, a Norwegian oil and gas company. 

Using classification methods to label tasks in process mining We investigate a method designed to improve the accuracy of process mining in scenarios where the identification of task labels for log events is uncertain. Such situations are prevalent in business processes where events consist of communications between people, such as email messages. We examine how the accuracy of an independent task identifier, such as a classification or clustering engine, can be improved by examining the currently mined process model. First, a classification scheme based on identifying the keywords in each message is presented to provide an initial labeling. We then demonstrate how these labels can be refined by considering the likelihood that the event represents a particular task as obtained via an analysis of the current representation of the process model. This process is then repeated a number of times until the model is sufficiently refined. Results show that both keyword classification and the current process model analysis can be significantly effective on their own, and when combined have the potential to correct virtually all errors when noise is low (less than 20%), and can reduce the error rate by about 85% when noise is in the 30-40% range. Copyright © 2010 Crown in the right of Canada. Bayesian classification; Process mining; Task labeling; Workflow

Using Datamining Methodology for Detecting Turning Points in Business Process Orientation Maturity Models Data mining is an approach to detecting meaningful new correlations, patterns and trends by applying pattern recognition techniques as well as statistical and mathematical methods to large datasets. Data mining methodology has proven to provide invaluable intrinsic information from datasets in a number of application areas. In this paper we argue that the research in business and management can also benefit from the introduction of data mining techniques. For this purpose selected data mining technique is used to analyze the maturity state of Business Process Orientation (BPO) of companies in Central and Eastern Europe. In order to determine the expansion of process oriented practices in companies a survey was conducted in 2008. Data was used for building a data mining model that revealed knowledge about conditions of business process organization and management for transition between different stages of the BPO Maturity Model. These findings present invaluable guidelines for any business that strives to achieve more efficient business processes. Business Process Orientation; Maturity Models; Turning Points; Datamining; Decision Trees

Using genetic process mining technology to construct a time-interval process model To understand process executed in many activities, process mining technologies are now extensively studied. However, three major problems in the current process mining techniques are identified. First, most process mining techniques mainly use local search strategy to generate process models. Second, time intervals between two actives are not considered so that patterns that are different in view of time are regarded as the same behaviors. Third, no precision evaluation measure is defined to evaluate the quality of process models. To solve these difficulties, this research proposes a time-interval process mining method. A genetic process mining algorithm with time-interval consideration is developed. Then, a precision evaluation measure is defined to evaluate the quality of the generated process models. Finally, the best process model with highest precision value is reported. © 2009 Springer Berlin Heidelberg. Genetic Algorithm; Process Mining; Time-interval

Using graph aggregation for service interaction message correlation Discovering the behavior of services and their interactions in an enterprise requires the ability to correlate service interaction messages into process instances. The service interaction logic (or process model) is then discovered from the set of process instances that are the result of a given way of correlating messages. However, sometimes, the Correlation Conditions (CC) allowing to identify correlations of messages from a service interaction log are not known. In such cases, and with a large number of message's correlator attributes, we are facing a large space of possible ways messages may be correlated which makes identifying process instances difficult. In this paper, we propose an approach based on message indexation and aggregation to generate a size-efficient Aggregated Correlation Graph (ACG) that exhibits all the ways messages correlate in a service interaction log not only for disparate pairs of messages but also for sequences of messages corresponding to process instances. Adapted filtering techniques based on user defined heuristics are then applied on such a graph to help the analysts efficiently identify the most frequently executed processes from their sequences of CCs. The approach has been implemented and experiments show its effectiveness to identify relevant sequences of CCs from large service interaction logs. © 2011 Springer-Verlag. Aggregation; Correlation; Process mining; SOA

Using inductive reasoning to find the cause of process delays Delays in business processes can have negative consequences for organizations, such as extra costs, missed deadlines, poor service, etc. Although they are easy to detect, it may be hard to find the actual reason for such delays. In this work we develop an approach to find the cause of delays based on the information recorded in an event log. The approach is based on a logic representation of the event log and on the application of decision tree induction to separate process instances according to their duration. In this decision tree, the delayed instances immediately stand out, and by following the path in the tree it is possible to extract a rule that characterizes those instances and therefore provides a possible explanation for the delay. We illustrate the approach in a set of experiments with event logs that are generated by simulation of a purchase process. In each experiment, there is a different cause of delay, and the approach succeeds in finding that cause. Additional experiments show that the approach is scalable and tolerant to noise. © 2013 IEEE. Decision Trees; Inductive Logic Programming; Process Mining

Using minimum description length for process mining In the field of process mining, the goal is to automatically extract process models from event logs. Recently, many algorithms have been proposed for this task. For comparing these models, different quality measures have been proposed. Most of these measures, however, have several disadvantages; they are model-dependent, assume that the model that generated the log is known, or need negative examples of event sequences. In this paper we propose a new measure, based on the minimal description length principle, to evaluate the quality of process models that does not have these disadvantages. To illustrate the properties of the new measure we conduct experiments and discuss the trade-off between model complexity and compression. Copyright 2009 ACM. 

Using process mining in software development process management: A case study In this paper we describe the application of process mining techniques to analyze a software development process. Software engineering practitioners often conduct quality auditing of the development process to assure conformance with organizational standards. Despite some works have explored process mining techniques for the conformance analysis of general business processes, it is not of our knowledge any study that applies process mining to conformance checking of software development processes. Under a practical perspective, this paper explores a real database with event logs generated in the past five years of execution of a software development process. The database was gently provided by a Brazilian software house with annual revenue of more than US$ 500 million and includes more than 2,000 cases (process instances). The results show that process mining can be effectively employed as a supporting tool for the management of software development processes and for the improvement of the maturity level of software engineering organizations. © 2011 IEEE. conformance checking; process mining; software development process

Using process mining to business process distribution Service Oriented Architecture (SOA) is by far the most pervasive architecture which includes several building blocks among which orchestration engine is under special focus. Although, there are a number of centralized orchestration engines to execute business processes described by BPEL language in SOA, you may find several decentralized orchestration engines and their purpose is decomposing a BPEL process to several software agents to improve quality factors such as adaptability, performance and so forth. As these process distribution methods break a BPEL process to its building activities and encapsulate each activity in one agent, it results in producing a lot of agents whose interactions and resource usage would degrade the run-time environment. This paper proposes an intelligent process distribution (IPD) based on a process mining approach in which the selection of activities that should be encapsulated in agents, depends on the previous behavior of process instances. The recommended IPD approach will improve three aspects of system quality. First; is the amelioration of business process adaptability with run-time environment, second; choosing the best agent granularity based on detecting most relevant activities and encapsulating them in agents and third; is decreasing of resource usage due to reduced and improved number of produced agents and messages. Furthermore, we proved our method using a mathematical approach. Copyright 2009 ACM. Adaptive systems; BPEL; Business process mining; Distributed orchestrate engine; Mobile agents; Service oriented architecture; Workflow

Using process mining to identify coordination patterns in IT service management We empirically analyze the database used in the help desk process between a national US public agency and its global outsourcing provider. We considered the question of whether the database might reveal a deeper level of knowledge than was apparent from direct inspection. Our results reveal that four constructs underlie this process. Three are confirmed through covariance-based structural equation modeling and a fourth is implied through existing data. Our results suggest refinement in service level agreements to create a different type of governance coordination to assist in aligning the outsourcing provider's execution more closely with the client's needs. © 2010 Elsevier B.V. All rights reserved. Adaptive structuration; Coordination theory; Covariance-based Structural Equation Modeling (SEM); EQS; Help desk; IT service management

Using process mining to identify models of group decision making in chat data This paper introduces process modeling and mining as an approach to process analysis for CSCL. This approach is particularly relevant for collaborative learning that takes a project-based form, and is applied in this study to online chat data from teams working on a complex task. The groups differed in terms of the number of members and the amount of scaffolding aimed at group processes and task requirements. The models, produced using the HeuristicsMiner algorithm, showed that the group with fewer members that received more instruction in the task requirements had a more linear decision-making process than the group that received instruction in group processes, however neither were an example of a linear, unitary phase model. This approach has relevance both for CSCL research methods and for providing feedback to students on their decision-making processes. © ISLS. 

Using process mining to learn from process changes in evolutionary systems Traditional information systems struggle with the requirement to provide flexibility and process support while still enforcing some degree of control. Accordingly, adaptive Process Management Systems (PMSs) have emerged that provide some flexibility by enabling dynamic process changes during runtime. Based on the assumption that these process changes are recorded explicitly, we present two techniques for mining change logs in adaptive PMSs; that is, we do not only analyse the execution logs of the operational processes, but also consider the adaptations made at the process instance level. The change processes discovered through process mining provide an aggregated overview of all changes that happened so far. Using process mining as an analysis tool we show in this paper how better support can be provided for truly flexible processes by understanding when and why process changes become necessary. © 2008, Inderscience Publishers. Change mining; Process mining; Process-aware information systems

Using Provenance to Improve Workflow Design With the popularity of scientific workflow management systems (WfMS), workflow specifications are becoming available. Provenance support in WfMS can help reusing third party code. Browsing can be done through queries instead of ad-hoc search on the Web. Finding dependencies among programs or services through provenance queries, without tool support, is not a trivial task. Due to the huge number of program versions available and their configuration parameters, this task may be heavily error prone and counterproductive. In this work we propose a recommendation service that aims at suggesting frequent combinations of scientific programs for reuse. Our recommendation service is designed to work over WfMS that provide provenance on workflow specification and execution logs. We have based our service on software components reuse and data mining techniques, and implemented a prototype with Vistrails WfMS. 

Using semantic lifting for improving process mining: A data loss prevention system case study Process mining is a process management technique to extract knowledge from the event logs recorded by an information system. We show how applying an appropriate semantic lifting to the event and workflow log may help to discover the process that is actually being executed. In particular, we show how it is possible to extract not only knowledge about the structure of the process, but also to verify if some non-functional properties, such as security properties, hold during the process execution. 

Using suffix-tree to identify patterns and cluster traces from event log Process mining refers to the extraction process models from event logs. Traditional process mining algorithms have problems dealing with event logs that are produced from unstructured real-life processes and generate spaghetti-like and incomprehensible process models. One means making traces more structural is to extract commonly used process model constructs (common patterns) in the event log and transform traces basing on such constructs. Another way of pre-processing traces is to categorize traces in event log into clusters such that process traces in each cluster can be adequately represented by a process model. Nevertheless, current approaches for trace clustering have many problems such as ignoring context process and huge computational overhead. In this paper, suffix-tree is firstly utilized for discovering common patterns. The traces in event log are transformed with common patterns. Thereafter suffix-trees are applied to categorize transformed traces. The trace clustering algorithm has a linear-time computational complexity. The process models mined from the clustered traces show a high degree of fitness and comprehensibility. © 2012 ICST Institute for Computer Science, Social Informatics and Telecommunications Engineering. Process mining; Suffix tree; Trace clustering

Verification of the SAP reference models using EPC reduction, state-space analysis, and invariants A reference model is a generic conceptual model that formalizes recommended practices for a certain domain. Today, the SAP reference models are among the most comprehensive reference models, including over 4000 entity types and covering over 1000 business processes and inter-organizational scenarios. The SAP reference models use Event-driven Process Chains (EPCs) to model these processes and scenarios. Like other informal languages, EPCs are intended to support the transition from a business model to an executable model. For this reason, researchers have tried to formalize the semantics of EPCs. However, in their approaches, they fail to acknowledge the fact that in EPCs constructs exist that require human judgment to assess correctness. This paper aims to acknowledge this fact by introducing a two-step approach. First, the EPC is reduced using universally accepted reduction rules. Second, the reduced EPC is analyzed using a mixture of state-space analysis, invariants, and human judgment. This approach has been implemented in a tool, and applying this tool to the SAP reference models showed that these contain errors, which clearly shows the added value of this verification approach. © 2007 Elsevier B.V. All rights reserved. Event-driven Process Chains; Petri nets; Process mining; SAP R/3 reference models; Verification

Web process and workflow path mining using the Multimethod approach Workflow Management Systems (WfMS) provide a fundamental technological infrastructure to define and manage business processes efficiently. WfMS logs contain valuable data that can be used to discover and extract knowledge about the execution of workflows and processes. One piece of important and useful information that can be discovered is related to the prediction of the path that will be followed during the execution of a workflow. We call this type of discovery, path mining. In this paper, we present and describe how path mining can be achieved using different data mining techniques including the Multimethod approach. Copyright © 2006 Inderscience Enterprises Ltd. Business process management systems; Data mining; Multimethod approach; Path mining; Quality of service; Web processes; Workflows

Web service community discovery based on spectrum clustering More and more web services are emerging in the Internet with development of service computing over the past decade. The web service in SOA system naturally forms into some service community during execution process. Mining and analysis web service community will help design SOA system and support web service application effectively. This article addresses the problem of how to discovering web services community formed by closely interactive web services. We propose a novel approach which construct web service execution network from logs and clustering it using spectrum clustering. Generally, the web services belong to same cluster have strong relative to same task object and we call it web service community. The approach has been implemented in an experience system for web services dynamic composition and mining. © 2009 IEEE. Community mining; Spectrum clustering; Web services

Web service composition based on QoS rules For workflow-based service composition approach, the relations between the Web service QoS and environments are usually not considered, so that the information about QoS for composite service selection is inaccurate. It makes the selected composite service inefficient, or even unexecutable. To address this problem, a novel service composition approach based on production QoS rules is proposed in this paper. Generally, it is very difficult to directly analyze how different kinds of environment factors influence the Web service QoS. We adopt "black-box" analysis method of optimizing composite services, discovering the knowledge such as "the QoS of one Web service will be higher in specific environments". In our approach, the execution information of the composite service is recorded into a log first, which will be taken as the basis of the subsequent statistical analysis and data mining. Then, the timely QoS values of the Web services are estimated and the production QoS rules being used to qualitatively express the different performances of the Web service QoS in different environments are mined. At last, we employ the mined QoS knowledge of the Web services to optimize the composite service selection. Extensive experimental results show that our approach can improve the performance of selected composite services on the premise of assuring the selecting computation cost. © 2010 Springer Science+Business Media, LLC & Science Press, China. data mining; production rules; QoS; service composition; service selection

Web service mining and verification of properties: An approach based on event calculus Web services are becoming more and more complex, involving numerous interacting business objects within complex distributed processes. In order to fully explore Web service business opportunities, while ensuring a correct and reliable execution, analyzing and tracking Web services interactions will enable them to be well understood and controlled. The work described in this paper is a contribution to these issues for Web services based process applications. This article describes a novel way of applying process mining techniques to Web services logs in order to enable "Web service intelligence". Our work attempts to apply Web service log-based analysis and process mining techniques in order to provide semantical knowledge about the context of and the reasons for discrepancies between process models and related instances. © Springer-Verlag Berlin Heidelberg 2006. 

Weighted subgraph mining technology to knowledge discovery Currently there is such an increasing interest in discovering important patterns from graph data. A significant number of applications require effective and efficient manipulation of graph mining, such as being: (i) analysis of microarray data in bioinformatics, (ii) pattern discovery in a large graph representing a social network, (iii) analysis of transportation networks, (iv) community discovery in Web data. This paper concerned with subgraph discovery from weighted graph data that came from the educational context. The non-linear correlation technology was introduced and used in the mining process in the whole knowledge achieved. At last we have applied these methods in real course management datasets and found correspondent results for the educators. © (2010) Trans Tech Publications. Graph mining; Non-linear correlation; Weighted graph

Where did I misbehave? Diagnostic information in compliance checking Compliance checking is gaining importance as today's organizations need to show that operational processes are executed in a controlled manner while satisfying predefined (legal) requirements. Deviations may be costly and expose the organization to severe risks. Compliance checking is of growing importance for the business process management and auditing communities. This paper presents a comprehensive compliance checking approach based on Petri-net patterns and alignments. 55 control flow oriented compliance rules, distributed over 15 categories, have been formalized in terms of Petri-net patterns describing the compliant behavior. To check compliance with respect to a rule, the event log describing the observed behavior is aligned with the corresponding pattern. The approach is flexible (easy to add new patterns), robust (the selected alignment between log and pattern is guaranteed to be optimal), and allows for both a quantification of compliance and intuitive diagnostics explaining deviations at the level of alignments. The approach can also handle resource-based and data-based compliance rules and is supported by ProM plug-ins. The applicability of the approach has been evaluated using various real-life event logs. © 2012 Springer-Verlag. compliance checking; conformance checking; Petri-nets; process mining

Workflow analysis based on estimate of fuzzy and statistical data In general, an execution duration or constraints of the workflow activity may be created manually (empirical temporal information) or can be derived through process mining techniques from execution logs (statistical information). Those will induce inevitably complexity of time representation and analysis in a workflow model. The focus of this work is to deal with the time analysis of workflow where fuzzy and statistical temporal information coexist. Combining formal language with the definition of workflow net, a fuzzy estimate workflow nets is introduced to analyze workflow model, which can solve the situation, where fuzzy and statistical data coexisted, to realize efficient workflow management and meet time critical business services. © 2006 IEEE. 

Workflow clustering method based on process similarity Process-centric information systems have been accumulating a mount of process models. Process designers continue to create new process models and they long for process analysis tools in various viewpoints. This paper proposes a novel approach of process analysis. Workflow clustering facilitates to analyze accumulated workflow process models and classify them into characteristic groups. The framework consists of two phases: domain classification and pattern analysis. Domain classification exploits an activity similarity measure, while pattern analysis does a transition similarity measure. Process models are represented as weighted complete dependency graphs, and then similarities among their graph vectors are estimated in consideration of relative frequency of each activity and transition. Finally, the models are clustered based on the similarities by a hierarchical clustering algorithm. We implemented the methodology and experimented sets of synthetic processes. Workflow clustering is adaptable to various process analyses, such as workflow recommendation, workflow mining, and process patterns analysis. © Springer-Verlag Berlin Heidelberg 2006. 

Workflow Management Architecture Based on Data Mining This paper probed into workflow technology applied in Business Process Reengineering and analyzed workflow model, workflow management process and workflow implementing process. Process definition and tool of management monitoring were extended locally in workflow model combining with data mining technology. Static data mining was added in the front-end of workflow process definition to extract rule database; dynamic data mining was added in the back-end of workflow management and monitoring tool for record database to bring strategy data base. Workflow management architecture will be put forward based on data mining. Further key technology has been put forward to actualize that static and dynamic data mining applied in the architecture combining with coal and gas outburst prediction of safety workflow management system. Business Process Reengineering; Workflow; Static Data Mining; Dynamic Data Mining

Workflow mining and outlier detection from clinical activity logs Purpose: The purpose of this study is twofold: (1) to derive a workflow consensus from multiple clinical activity logs and (2) to detect workflow outliers automatically and without prior knowledge from experts. Methods: Workflow mining is used in this paper to derive consensus workflow from multiple surgical activity logs using tree-guided multiple sequence alignment. To detect outliers, a global pair-wise sequence alignment (Needleman-Wunsch) algorithm is used. The proposed method is validated for Laparoscopic Cholecystectomy (LAPCHOL). Results: An activity log is directly derived for each LAPCHOL surgery from laparoscopic video using an already developed instrument tracking tool. We showed that a generic consensus can be derived from surgical activity logs using multi-alignment. In total 26 surgery logs are used to derive the consensus for laparoscopic cholecystectomy. The derived consensus conforms to the main steps of laparoscopic cholecystectomy as described in best practices. Using global pair-wise alignment, we showed that outliers can be detected from surgeries using the consensus and the surgical activity log. Conclusion: Alignment techniques can be used to derive consensus and to detect outliers from clinical activity logs. Detecting outliers particularly in surgery is a main step to automatically mine and analyse the underlying cause of these outliers and improve surgical practices. © 2012 Elsevier Inc. Laparoscopic surgery; Medical environment; Outlier detection; Surgical consensus; Surgical workflow

Workflow mining: Discovering process patterns & data analysis from MXML logs Contemporary workflow management systems are determined by precise process models, i.e., a totally specific workflow design is necessary so as to discover a given workflow process. Creating a workflow design is a complex time-consuming process and characteristically there are conflicts and discrepancies between the real-time workflow processes and the processes as professed by the management. Consequently, we recommend a method for process mining. This method employs workflow logs to determine the workflow process as it is truly being implemented. The process mining method proposed in this paper can cope with noise and can also be exercised to authorize workflow processes by revealing and measuring the discrepancies between prescriptive models and factual process executions. © 2013 IEEE. Business Process; Model Discovery; MXML; Pattern Analysis; Process Mining; Workflow

Workflow mining: Extending the a-algorithm to mine duplicate tasks Designing a workflow model is a complicated, time-consuming and error-prone process. A possible solution is workflow mining which extracts workflow models from workflow logs. Considerable researches have been done to develop heuristics to mine event-data logs in order to make a workflow model. However, if there are cyclic tasks in workflow traces, the current research in workflow mining still has problems in mining duplicate tasks. Based on the a-algorithm, an improved workflow mining algorithm called a1-algorithm is presented. The complete experiments have been done to evaluate the proposed algorithm. © 2008 IEEE. Cyclic tasks; Duplicate tasks; Workflow mining; Workflow model

Workflow reduction for reachable-path rediscovery in workflow mining This paper3 newly defines a workflow reduction mechanism that formally and automatically reduces an original workflow process to a minimal set of activities, which is called minimal-workflowmodel in this paper. It also describes about the implications of the minimal-workflow model on workflow mining that is a newly emerging research issue for rediscovering and reengineering workflow models from workflow logs containing workflow enactment and audit information gathered being executed on workflow engine. In principle, the minimal-workflow model is reduced from the original workflow processby analyzing dependencies among its activities. Its main purpose is to minimize discrepancies between the modeled workflow process and the enacted workflow process as it is actually being executed. That is, we can get a complete set of activity firing sequences (all reachable-pathsfrom the start to the end activity on a workflow process) on buildtime. Besides, we can discover from workflow logsthat which path out of all reachable paths a workcase (instance of workflow process) has actually followed through on runtime. These are very important information gain acquiring the runtime statistical significance and knowledge for redesigning and reengineering the workflow process. The minimal-workflow model presented in this paper is used to be a decision tree induction technique for mining and discovering a reachable-path of workcase from workflow logs. In a consequence, workflow miningmethodologies and systems are rapidly growing and coping with a wide diversity of domains in terms of their applications and working environments. So, the literature needs various, advanced, and specialized workflow mining techniques and architectures that are used for finally feed-backing their analysis results to the redesign and reengineering phase of the existingworkflow and business © 2006 Springer-Verlag Berlin/Heidelberg. 

Workflow similarity measure for process clustering in grid In grid environment, workflow process can be seen as not only cooperative approach of grid services and resources, but also reusable and sharable knowledge to settle specific problem. The research of grid workflow process clustering can promote knowledge discovery and reuse in grid. In this paper, we put forward a grid workflow process design method using EventCondition-Action (ECA) rule, and propose a new process similarity measure approach. Then, we use a case to prove the feasibility of the approach and show how to revise present clustering algorithm with the similarity measure approach briefly. © 2007 IEEE. 

Workflow simulation for operational decision support Simulation is widely used as a tool for analyzing business processes but is mostly focused on examining abstract steady-state situations. Such analyses are helpful for the initial design of a business process but are less suitable for operational decision making and continuous improvement. Here we describe a simulation system for operational decision support in the context of workflow management. To do this we exploit not only the workflow's design, but also use logged data describing the system's observed historic behavior, and incorporate information extracted about the current state of the workflow. Making use of actual data capturing the current state and historic information allows our simulations to accurately predict potential near-future behaviors for different scenarios. The approach is supported by a practical toolset which combines and extends the workflow management system YAWL and the process mining framework ProM. (C) 2009 Elsevier B.V. All rights reserved. Process mining; Short-term simulation; Workflow management

Workflow simulation for operational decision support using event graph through process mining It is increasingly common to see computer-based simulation being used as a vehicle to model and analyze business processes in relation to process management and improvement. While there are a number of business process management (BPM) and business process simulation (BPS) methodologies, approaches and tools available, it is more desirable to have a systemic BPS approach for operational decision support, from constructing process models based on historical data to simulating processes for typical and common problems. In this paper, we have proposed a generic approach of BPS for operational decision support which includes business processes modeling and workflow simulation with the models generated. Processes are modeled with event graphs through process mining from workflow logs that have integrated comprehensive information about the control-flow, data and resource aspects of a business process. A case study of a credit card application is presented to illustrate the steps involved in constructing an event graph. The evaluation detail is also given in terms of precision, generalization and robustness. Based on the event graph model constructed, we simulate the process under different scenarios and analyze the simulation logs for three generic problems in the case study: 1) suitable resource allocation plan for different case arrival rates; 2) teamwork performance under different case arrival rates; and 3) evaluation and prediction for personal performances. Our experimental results show that the proposed approach is able to model business processes using event graphs and simulate the processes for common operational decision support which collectively play an important role in process management and improvement. © 2011 Elsevier B.V. All rights reserved. Business process management; Business process simulation; Event graph; Process mining

Workflow trees for representation and mining of implicitly concurrent business processes We propose a novel representation of business processes called workflow trees that facilitates the mining of process models where the parallel execution of two or more sub-processes has not been recorded explicitly in workflow logs. Based on the provable property of workflow trees that a pair of tasks are siblings in the tree if and only if they have identical respective workflow-log relations with each and every remaining third task in the process, we describe an efficient business process mining algorithm of complexity only cubic in the number of process tasks, and analyze the class of processes that can be identified and reconstructed by it. Business process management; Petri nets; Process mining

XES, XESame, and ProM 6 Process mining has emerged as a new way to analyze business processes based on event logs. These events logs need to be extracted from operational systems and can subsequently be used to discover or check the conformance of processes. ProM is a widely used tool for process mining. In earlier versions of ProM, MXML was used as an input format. In future releases of ProM, a new logging format will be used: the eXtensible Event Stream (XES) format. This format has several advantages over MXML. The paper presents two tools that use this format - XESame and ProM 6 - and highlights the main innovations and the role of XES. XESame enables domain experts to specify how the event log should be extracted from existing systems and converted to XES. ProM 6 is a completely new process mining framework based on XES and enabling innovative process mining functionality. © 2011 Springer-Verlag Berlin Heidelberg. 

s-Algorithm: Structured workflow process mining through amalgamating temporal workcases Workflow Management Systems help to execute, monitor and manage work process flow and execution. These systems, as they are executing, keep a record of who does what and when (e.g. log of events). The activity of using computer software to examine these records, and deriving various structural data results is called workflow mining. The workflow mining activity, in general, needs to encompass behavioral (process/control-flow), social, informational (data-flow), and organizational perspectives; as well as other perspectives, because workflow systems are "people systems" that must be designed, deployed, and understood within their social and organizational contexts. In this paper 1, we especially focus on the behavioral perspective of a structured workflow model that preserves the proper nesting and the matched pair properties. That is, this paper proposes an ICN-based mining algorithm that rediscovers a structured workflow process model. We name it s-Algorithm, because it is incrementally amalgamating a series of temporal workcases (workflow traces) according to three types of basic merging principles conceived in this paper. Where, a temporal workcase is a temporally ordered set of activity execution event logs. We also gives an example to show that how the algorithm works with the temporal workcases. © Springer-Verlag Berlin Heidelberg 2007. Events log; Process rediscovery; Temporal workcase; Workflow Management System; Workflow mining; Workflow process mining framework

Conversion of real data from production process of automotive company for process mining analysis The aim of this paper is to convert the real data from the raw format from different information systems (log files) to the format, which is suitable for process mining analysis of a production process in a large automotive company. The conversion process will start with the import from several relational databases. The motivation is to use the DISCO tool for importing real pre-processed data and to conduct process mining analysis of a production process. DISCO generates process models from imported data in a comprehensive graphical form and provides different statistical features to analyse the process. This makes it possible to examine the production process in detail, identify bottlenecks, and streamline the process. The paper firstly presents a brief introduction of a manufacturing process in a company. Secondly, it provides a description of a conversion and pre-processing of chosen real data structures for the DISCO import. Then, it briefly describes the DISCO tool and proper format of pre-processed log file, which serves as desired input data. This data will be the main source for all consecutive operations in generated process map. Finally, it provides a sample analysis description with emphasis on one production process (process map and few statistics). To conclude, the results obtained show high demands on pre-processing of real data for suitable import format into DISCO tool and vital possibilities of process mining methods to optimize a production process in an automotive company.  Springer International Publishing AG 2018. Data cleaning; Data cleaning tools; DISCO; Process mining

Semantic-based model analysis towards enhancing information values of process mining: Case study of learning process domain Process mining results can be enhanced by adding semantic knowledge to the derived models. Information discovered due to semantic enrichment of the deployed process models can be used to lift process analysis from syntactic level to a more conceptual level. The work in this paper corroborates that semantic-based process mining is a useful technique towards improving the information value of derived models from the large volume of event logs about any process domain. We use a case study of learning process to illustrate this notion. Our goal is to extract streams of event logs from a learning execution environment and describe formats that allows for mining and improved process analysis of the captured data. The approach involves mapping of the resulting learning model derived from mining event data about a learning process by semantically annotating the process elements with concepts they represent in real time using process descriptions languages, and linking them to an ontology specifically designed for representing learning processes. The semantic analysis allows the meaning of the learning objects to be enhanced through the use of property characteristics and classification of discoverable entities, to generate inference knowledge which are used to determine useful learning patterns by means of the Semantic Learning Process Mining (SLPM) algorithm - technically described as Semantic-Fuzzy Miner. To this end, we show how data from learning processes are being extracted, semantically prepared, and transformed into mining executable formats to enable prediction of individual learning patterns through further semantic analysis of the discovered models.  Springer International Publishing AG 2018. Event logs; Knowledge discovery; Learning process; Ontology; Process mining; Semantic annotation

Towards a data science toolbox for industrial analytics applications Manufacturing companies today have access to a vast number of data sources providing gigantic amounts of process and status data. Consequently, the need for analytical information systems is ever-growing to guide corporate decision-making. However, decision-makers in production environments are still very much focused on static, explanatory modeling provided by business intelligence suites instead of embracing the opportunities offered by predictive analytics. We develop a data science toolbox for manufacturing prediction tasks to bridge the gap between machine learning research and concrete practical needs. We provide guidelines and best practices for modeling, feature engineering and interpretation. To this end, we leverage tools from business information systems as well as machine learning. We illustrate the usage of this toolbox by means of a real-world manufacturing defect prediction case study. Thereby, we seek to enhance the understanding of predictive modeling. In particular, we want to emphasize that simply dumping data into smart algorithms is not the silver bullet. Instead, constant refinement and consolidation are required to improve the predictive power of a business analytics solution.  2017 Elsevier B.V. Manufacturing; Predictive analytics; Process mining

Run-time prediction of business process indicators using evolutionary decision rules Predictive monitoring of business processes is a challenging topic of process mining which is concerned with the prediction of process indicators of running process instances. The main value of predictive monitoring is to provide information in order to take proactive and corrective actions to improve process performance and mitigate risks in real time. In this paper, we present an approach for predictive monitoring based on the use of evolutionary algorithms. Our method provides a novel event window-based encoding and generates a set of decision rules for the run-time prediction of process indicators according to event log properties. These rules can be interpreted by users to extract further insight of the business processes while keeping a high level of accuracy. Furthermore, a full software stack consisting of a tool to support the training phase and a framework that enables the integration of run-time predictions with business process management systems, has been developed. Obtained results show the validity of our proposal for two large real-life datasets: BPI Challenge 2013 and IT Department of Andalusian Health Service (SAS).  2017 Elsevier Ltd Business process indicator; Business process management; Evolutionary algorithm; Predictive monitoring; Process mining

Merging event logs: Combining granularity levels for process flow analysis Process mining techniques enable the discovery and analysis of business processes and the identification of opportunities for improvement. Processes often comprise separately managed procedures documented in separate log files, which are impossible to mine in an integrative manner as the complete end-to-end process flow is obscure. These procedures can have simple (one-to-one) or complex (many-to-one or many-to-many) relationships among them. When complex relationships exist, typically different granularity levels are involved. In this paper, we present a merging algorithm that results in a comprehensive merged log that can handle all kinds of relationships between the procedures. Addressing differences in the granularity levels, it offers two views of the end-to-end process: a case view and an instance view. This enables the identification of process flow problems that could not be detected by previous techniques. The unified log can be used by process mining techniques to identify flow problems, particularly at the point of integration between the processes under consideration. The procedure proposed in this paper has been implemented and evaluated using both synthetic and real-life logs.  2017 Elsevier Ltd Abstraction level; End-to-end process flow; Merging logs; Multiple instances; Process mining

Process mining using BPMN: relating event logs and process models Process-aware information systems (PAIS) are systems relying on processes, which involve human and software resources to achieve concrete goals. There is a need to develop approaches for modeling, analysis, improvement and monitoring processes within PAIS. These approaches include process mining techniques used to discover process models from event logs, find log and model deviations, and analyze performance characteristics of processes. The representational bias (a way to model processes) plays an important role in process mining. The BPMN 2.0 (Business Process Model and Notation) standard is widely used and allows to build conventional and understandable process models. In addition to the flat control flow perspective, subprocesses, data flows, resources can be integrated within one BPMN diagram. This makes BPMN very attractive for both process miners and business users, since the control flow perspective can be integrated with data and resource perspectives discovered from event logs. In this paper, we describe and justify robust control flow conversion algorithms, which provide the basis for more advanced BPMN-based discovery and conformance checking algorithms. Thus, on the basis of these conversion algorithms low-level models (such as Petri nets, causal nets and process trees) discovered from event logs using existing approaches can be represented in terms of BPMN. Moreover, we establish behavioral relations between Petri nets and BPMN models and use them to adopt existing conformance checking and performance analysis techniques in order to visualize conformance and performance information within a BPMN diagram. We believe that the results presented in this paper can be used for a wide variety of BPMN mining and conformance checking algorithms. We also provide metrics for the processes discovered before and after the conversion to BPMN structures. Cases for which conversion algorithms produce more compact or more complicated BPMN models in comparison with the initial models are identified.  2015, Springer-Verlag Berlin Heidelberg. Bisimulation; BPMN (Business Process Model and Notation); Conformance checking; Petri nets; Process discovery; Process mining

Aligning Real Process Executions and Prescriptive Process Models through Automated Planning Modern organizations execute processes to deliver product and services, whose enactment needs to adhere to laws, regulations and standards. Conformance checking is the problem of pinpointing where deviations are observed. This paper shows how instances of the conformance checking problem can be represented as planning problems in PDDL (Planning Domain Definition Language) for which planners can find a correct solution in a finite amount of time. If conformance checking problems are converted into planning problems, one can seamlessly update to the recent versions of the best performing automated planners, with evident advantages in term of versatility and customization. The paper also reports on results of experiments conducted on two real-life case studies and on eight larger synthetic ones, mainly using the FAST-DOWNWARD planner framework to solve the planning problems due to its performances. Some experiments were also repeated though other planners to concretely showcase the versatility of our approach. The results show that, when process models and event logs are of considerable size, our approach outperforms existing ones even by several orders of magnitude. Even more remarkably, when process models are extremely large and event log traces very long, the existing approaches are unable to terminate because they run out of memory, while our approach is able to properly complete the alignment task.  2017 Elsevier Ltd Automated planning; Business process management; Conformance checking; Process mining

Aligning observed and modelled behaviour based on workflow decomposition When business processes are mostly supported by information systems, the availability of event logs generated from these systems, as well as the requirement of appropriate process models are increasing. Business processes can be discovered, monitored and enhanced by extracting process-related information. However, some events cannot be correctly identified because of the explosion of the amount of event logs. Therefore, a new process mining technique is proposed based on a workflow decomposition method in this paper. Petri nets (PNs) are used to describe business processes, and then conformance checking of event logs and process models is investigated. A decomposition approach is proposed to divide large process models and event logs into several separate parts that can be analysed independently; while an alignment approach based on a state equation method in PN theory enhances the performance of conformance checking. Both approaches are implemented in programmable read-only memory (ProM). The correctness and effectiveness of the proposed methods are illustrated through experiments.  2016 Informa UK Limited, trading as Taylor & Francis Group. alignment; conformance checking; Petri nets; Process mining; workflow decomposition

Model mining: Integrating data analytics, modelling and verification Process mining techniques have been developed in the ambit of business process management to extract information from event logs consisting of activities and then produce a graphical representation of the process control flow, detect relations between components involved in the process and infer data dependencies between process activities. These process characterisations allow the analyst to discover an annotated visual representation of the conceptual model or the performance model of the process, check conformance with an a priori model to detect deviations and extend the a priori model with quantitative information such as frequencies and performance data. However, a process model yielded by process mining techniques is more similar to a representation of the process behaviour rather than an actual model of the process: it often consists of a huge number of states and interconnections between them, thus resulting in a spaghetti-like net which is hard to interpret or even read. In this paper we propose a novel technique, which we call model mining, to derive an abstract but concise and functionally structured model from event logs. Such a model is not a representation of the unfolded behaviour, but comprises, instead, a set of formal rules for generating the system behaviour, thus supporting more powerful predictive capabilities. The set of rules can be either inferred directly from the events logs (constructive mining) or refined by sifting a plausible a priori model using the event logs as a sieve until a reasonably concise model is achieved (refinement mining). We use rewriting logic as the formal framework in which to perform model mining and implement our framework using the Maude rewrite system. Once the final formal model is attained, it can be used, within the same rewriting logic framework, to predict future evolutions of the behaviour through simulation, to carry out further validation or to analyse properties through model checking. Finally, we illustrate our approach on two case studies from two different application fields, ecology and collaborative learning.  2017 Springer Science+Business Media, LLC Application to ecosystem modelling; Application to social network analysis; Formal methods; Model-driven approaches; Process mining; Rewrite systems

Guided interaction exploration in artifact-centric process models Artifact-centric process models aim to describe complex processes as a collection of interacting artifacts. Recent development in process mining allow for the discovery of such models. However, the focus is often on the representation of the individual artifacts rather than their interactions. Based on event data we can automatically discover composite state machines representing artifact-centric processes. Moreover, we provide ways of visualizing and quantifying interactions among different artifacts. For example, we are able to highlight strongly correlated behaviours in different artifacts. The approach has been fully implemented as a ProM plug-in; the CSM Miner provides an interactive artifact-centric process discovery tool focussing on interactions. The approach has been evaluated using real life data sets, including the personal loan and overdraft process of a Dutch financial institution.  2017 IEEE. Artifact-centric Processes; Measures of Interestingness; Process mining

Discovering work prioritisation patterns from event logs Business process improvement initiatives typically employ various process analysis techniques, including evidence-based analysis techniques such as process mining, to identify new ways to streamline current business processes. While plenty of process mining techniques have been proposed to extract insights about the way in which activities within processes are conducted, techniques to understand resource behaviour are limited. At the same time, an understanding of resources behaviour is critical to enable intelligent and effective resource management - an important factor which can significantly impact overall process performance. The presence of detailed records kept by today's organisations, including data about who, how, what, and when various activities were carried out by resources, open up the possibility for real behaviours of resources to be studied. This paper proposes an approach to analyse one aspect of resource behaviour: the manner in which a resource prioritises his/her work. The proposed approach has been formalised, implemented, and evaluated using a number of synthetic and real datasets.  2017 Elsevier B.V. Process mining; Queuing; Resource behaviour mining

Fodina: A robust and flexible heuristic process discovery technique In this paper, we present Fodina, a process discovery technique with a strong focus on robustness and flexibility. To do so, we improve upon and extend an existing process discovery algorithm, namely Heuristics Miner. We have identified several drawbacks which impact the reliability of existing heuristic-based process discovery techniques and therefore propose a new algorithm which is shown to be better performing in terms of process model quality, adds the ability to mine duplicate tasks, and allows for flexible configuration options.  2017 Elsevier B.V. Event logs; Process discovery; Process mining

Retrieving batch organisation of work insights from event logs Resources can organise their work in batches, i.e. perform activities on multiple cases simultaneously, concurrently or intentionally defer activity execution to handle multiple cases (quasi-) sequentially. As batching behaviour influences process performance, efforts to gain insight on this matter are valuable. In this respect, this paper uses event logs, data files containing process execution information, as an information source. More specifically, this work (i) identifies and formalises three batch processing types, (ii) presents a resource-activity centered approach to identify batching behaviour in an event log and (iii) introduces batch processing metrics to acquire knowledge on batch characteristics and its influence on process execution. These contributions are integrated in the Batch Organisation of Work Identification algorithm (BOWI), which is evaluated on both artificial and real-life data.  2017 Elsevier B.V. Batch processing; Business process management; Event log; Event log insights; Process metrics; Process mining

ProcessProfiler3D: A visualisation framework for log-based process performance comparison An organisation can significantly improve its performance by observing how their business operations are currently being carried out. A great way to derive evidence-based process improvement insights is to compare the behaviour and performance of processes for different process cohorts by utilising the information recorded in event logs. A process cohort is a coherent group of process instances that has one or more shared characteristics. Such process performance comparisons can highlight positive or negative variations that can be evident in a particular cohort, thus enabling a tailored approach to process improvement. Although existing process mining techniques can be used to calculate various statistics from event logs for performance analysis, most techniques calculate and display the statistics for each cohort separately. Furthermore, the numerical statistics and simple visualisations may not be intuitive enough to allow users to compare the performance of various cohorts efficiently and effectively. We developed a novel visualisation framework for log-based process performance comparison to address these issues. It enables analysts to quickly identify the performance differences between cohorts. The framework supports the selection of cohorts and a three-dimensional visualisation to compare the cohorts using a variety of performance metrics. The approach has been implemented as a set of plug-ins within the open source process mining framework ProM and has been evaluated using two real-life datasets from the insurance domain to assess the usefulness of such a tool. This paper also derives a set of design principles from our approach which provide guidance for the development of new approaches to process cohort performance comparison.  2017 Elsevier B.V. Performance analysis; Process analysis; Process mining; Visualisation

Tour Miner: Mining system of tour plans from SNS:-Smelting function from travel records to tour routes- We have been developing a system, called Tour Miner, which mines tour plans from SNS. It consists of two functions: mining and smelting. The mining function searches SNS for a given keyword and discovers travel records related to the keyword. The smelting function combines the travel records and extracts tour plans from the combination. In this paper, we elucidate the implementation of the smelting function. It first converts the travel records into a graph by process mining technique, and then gives each path of the graph as a tour route. We also illustrate its usefulness with an application example.  2017 IEEE. 

Analyzing the waiting time of patients in hospital by applying heuristics process miner Health care sectors are continuously research new and advanced way to improve serviceable productivities. This research study find potential efficiency gains in health care sectors by considering the factors like time, cost and resource utilization and demonstrates the applicability of process mining using a real data set of hospital with the help of enterprise resource planning (ERP) package. The precision of the calculated performance, e.g., waiting time, depends on firstly transactional information secondly the ability to differentiate between subtle controls flow aspects. The aim of the system is to propose effective process models by applying data set for each model which discovers the deviation from the actual process with the help of ProM tool. Several Magnetic Resonance Image (MRI) tests are considered as the baseline scenario wherein actual process models are produced and check for the fitness using Heuristics Miner. In this paper by applying the existing Heuristics Miner algorithm for similar operation, uncommon behavior and incompleteness. The fitness of the process model can be interpreted by utilizing event log with Petrinet called conformance checking by understanding the deviations, time intervals and propose an best fit model for the future execution in an hospital for giving best and efficient utilization of the physical resources and seek to bring down the waiting time of the patient.  2017 IEEE. Conformance analysis; Heuristic miner algorithm; Petrinets; Process mining; ProM

The best fit process model for the utilization of the physical resources in hospitals by applying inductive visual miner The main aim of a hospital is to provide an effective and efficient environment for the patient which supports effective utilization of resources for the diagnostic center which reduces the complexity of diagnosis process. In order to do so it is necessary to have an accurate view of care flows under consideration. In this paper we apply process mining techniques to obtain meaningful knowledge about this flows, e.g., to discover typical paths proceeded by particular group of symptoms that create a disease of a patient. In this paper lab test dataset is considered as a baseline scenario where in productive process models are created and checked for the efficiency using inductive visual miner algorithm. In order to do so we extracted relevant event logs from hospital information system in that we have taken diagnosis of lab test logs using ProM framework. Using inductive visual miner we are able to generate a soundness model for a health sector. The result shows how the process mining can be used to provide new insight that simplifies upgrading of existing health care flows and give insight about how it can be improved.  2017 IEEE. Healthcare process; Inductive visual miner; Process discovery; Process enhancement; Process mining; ProM

Efficient event correlation over distributed systems Event correlation is a cornerstone for process discovery over event logs crossing multiple data sources. The computed correlation rules and process instances will greatly help us to unleash the power of process mining. However, exploring all possible event correlations over a log could be time consuming, especially when the log is large. State-of-The-Art methods based on MapReduce designed to handle this challenge have offered significant performance improvements over standalone implementations. However, all existing techniques are still based on a conventional generating-And-pruning scheme. Therefore, event partitioning across multiple machines is often inefficient. In this paper, following the principle of filtering-And-verification, we propose a new algorithm, called RF-GraP, which provides a more efficient correlation over distributed systems. We present the detailed implementation of our approach and conduct a quantitative evaluation using the Spark platform. Experimental results demonstrate that the proposed method is indeed efficient. Compared to the state-of-The-Art, we are able to achieve significant performance speedups with obviously less network communication.  2017 IEEE. Big Data; Data Partitioning; Data-Intensive Computing; Event Correlation; Process Mining; Service Computing

Holistic Approach for Process Model Discovery Process discovery techniques aim at extracting a process model from an event log designed as a data structure that minimally contains a multi-set of event sequences. This paper studies the implications of applying newly developed methods and techniques in the field of process mining to reallife scenarios. The main problem consists in processing the collected data in order to use it for discovering the model of the observed process. The analysis of this problem revealed three main aspects: the need to properly represent the event data, to associate events to process instances and to determine the highlevel actions corresponding to the observed events. Each of these aspects has been investigated and a system architecture has been proposed based on their solution.  2017 IEEE. Cyber-Physical Systems; Process Mining

Mining collaboration patterns of software development processes based on trace alignment Developing large-scale software usually involves the interaction of a great number of engineers over a long period. To discover the collaboration patterns from developing logs helps improve the software development processes. Traditional techniques of process mining can be employed to identify such patterns. Unfortunately, due to the high uncertainty of software development process, they tend to obtain spaghetti models which are difficult to comprehend or even misleading. As a remedy, in this paper we propose an approach to the discovery of collaboration patterns existing in software development process by aligning development logs. It considers not only the sequence of activities, but also the collaboration of actors who perform activities. Instead of using time-consuming graph mining techniques, it employs the trace alignment, which is much more straightforward. Moreover, unlike some traditional approaches, the discovered patterns are determined because we do not depend on the mined process model that is usually uncertain due to the unstructured nature of software development process. The experimental results based on a large dataset generated from CPNTools demonstrate the effectiveness of our approach.  2017 ACM. Activities; Actors; Collaboration Patterns; Process Mining; Software Development Process; Trace Alignment

White-box prediction of process performance indicators via flow analysis Predictive business process monitoring methods exploit historical process execution logs to provide predictions about running instances of a process, which enable process workers and managers to preempt performance issues or compliance violations. A number of approaches have been proposed to predict quantitative process performance indicators, such as remaining cycle time, cost, or probability of deadline violation. However, these approaches adopt a black-box approach, insofar as they predict a single scalar value without decomposing this prediction into more elementary components. In this paper, we propose a white-box approach to predict performance indicators of running process instances. The key idea is to first predict the performance indicator at the level of activities, and then to aggregate these predictions at the level of a process instance by means of flow analysis techniques. The paper specifically develops this idea in the context of predicting the remaining cycle time of ongoing process instances. The proposed approach has been evaluated on four real-life event logs and compared against several baselines.  2017 ACM. Flow analysis; Predictive Process Monitoring; Process Mining

Linguistic summarization of event logs  A practical approach The amount of data that is generated during the execution of a business process is growing. As a consequence it is increasingly hard to extract useful information from the large amount of data that is produced. Linguistic summarization helps to point business analysts in the direction of useful information, by verbalizing interesting patterns that exist in the data. In previous work we showed how linguistic summarization can be used to automatically generate diagnostic statements about event logs, such as for most cases that contained the sequence ABC, the throughput time was long. However, we also showed that our technique produced too many of these statements to be useful in a practical setting. Therefore this paper presents a novel technique for linguistic summarization of event logs, which generates linguistic summaries that are concise enough to be used in a practical setting, while at the same time enriching the summaries that are produced by also enabling conjunctive statements. The improved technique is based on pruning and clustering of linguistic summaries. We show that it can be used to reduce the number of summary statements 80100% compared to previous work. In a survey among 51 practitioners, we found that practitioners consider linguistic summarization useful and easy to use and intend to use it if it were commercially available.  2017 Elsevier Ltd Business process; Data mining; Event log; Linguistic summarization; Similarity clustering

An insider threat detection method based on business process mining Current intrusion detection systems are mostly for detecting external attacks, but the "Prism Door" and other similar events indicate that internal staff may bring greater harm to organizations in information security. Traditional insider threat detection methods only consider the audit records of personal behavior and failed to combine it with business activities, which may miss the insider threat happened during a business process. The authors consider operators' behavior and correctness and performance of the business activities, propose a business process mining based insider threat detection system. The system firstly establishes the normal profiles of business activities and the operators by mining the business log, and then detects specific anomalies by comparing the content of real-time log with the corresponding normal profile in order to find out the insiders and the threats they have brought. The relating anomalies are defined and the corresponding detection algorithms are presented. The authors have performed experimentation using the ProM framework and Java programming, with five synthetic business cases, and found that the system can effectively identify anomalies of both operators and business activities that may be indicative of potential insider threat. Copyright  2017, IGI Global. Anomaly detection; Insider threat; Process mining

Applying process mining techniques in software process appraisals Context Process assessments are performed to identify the current maturity of organizations in relation to best practices. Existing process assessment methods, although widely used, have limitations such as: dependence on the competencies of appraisers; high amount of effort and resources required; subjectivity to analyze data and to judge on the implementation of practices; low confidence in sampling and its representativeness. Currently, due to the increasing use of information systems to support process execution, detailed information on the implementation of processes are recorded as event logs, transaction logs, etc. This fact enables the usage of process mining techniques as a powerful tool for process analysis. It allows using a significant amount of data with agility and reliability for process assessments. Objective The objective of this paper is to present the development and application of a feasible, usable and useful method, which reduces the limitations of current SCAMPI method and defines how to apply process mining techniques in SCAMPI-based process appraisals. Method Research method comprises nine steps that were performed in a manner that raised questions in the first four steps were answered by the last four steps of the research design. Results The method Process Mining Extension to SCAMPI was designed, developed, applied in two cases and submitted for review by experts who judged it viable, usable, and useful. Conclusions As per this research, process mining techniques are suitable to be applied in software process assessments since they are aligned with the purposes of data collection and analysis tasks. In addition to that, the resulting method was judged by experts as something that reduces identified limitations of one of the most used process assessment method.  2017 Data collection and analysis; Process mining; Process Mining Extension to SCAMPI; SCAMPI; Software process assessment

Using process mining and model-driven engineering to enhance security of web information systems Due to the development of Smart Cities and Internet of Things, there has been an increasing interest in the use of Web information systems in different areas and domains. Besides, the number of attacks received by this kind of systems is increasing continuously. Therefore, there is a need to strengthen their protection and security. In this paper, we propose a method based on Process Mining and Model-Driven Engineering to improve the security of Web information systems. Besides, this method has been applied to the SID Digital Library case study and some preliminary results to improve the security of this system are described.  2017 IEEE. Model-driven engineering; Process mining; Security; Web information systems

Detecting Sudden and Gradual Drifts in Business Processes from Execution Traces Business processes are prone to unexpected changes, as process workers may suddenly or gradually start executing a process differently in order to adjust to changes in workload, season or other external factors. Early detection of business process changes enables managers to identify and act upon changes that may otherwise affect process performance. Business process drift detection refers to a family of methods to detect changes in a business process by analyzing event logs (or event streams) extracted from the systems that support the execution of the process. Existing methods in this area are based on an explorative analysis of a potentially large feature space and in some cases they require users to manually identify specific features that characterize the drift. Depending on the explored feature space, these methods miss various types of changes. Moreover, they are either designed to detect sudden drifts or gradual drifts but not both. This paper proposes an automated and statistically grounded method for detecting sudden and gradual business process drifts under a unified framework. An empirical evaluation shows that the method detects typical change patterns with significantly higher accuracy and lower detection delay than existing methods, while accurately distinguishing between sudden and gradual drifts. IEEE Business process management; change detection; concept drift; Delays; Feature extraction; Insurance; process mining; Scalability; Space exploration

Multi-level clustering for extracting process-related information from email logs Emails represent a valuable source of information that can be harvested for understanding undocumented business processes of institutions. Towards this aim, a few researchers investigated the problem of extracting process oriented information from email logs to make benefit of the many available process mining techniques. In this work, we go further in this direction, by proposing a new method for mining process models from email logs that leverages unsupervised machine learning techniques. Moreover, our method allows to label emails with activity names, that can be used for activity recognition in new incoming emails. A use case illustrates the usefulness of the proposed solution.  2017 IEEE. Clustering; Email Analysis; Process Information; Process Mining; Process Model

Supporting modelers with model qualities and patterns Modelers face multiple challenges in their work. In this paper, we focus on two of them. First, multiple modeling methods and tools are currently available. Modelers are sometimes limited by their tools or paradigms. Second, when multiple models are proposed for the same case, a decision maker needs criteria to decide which model to choose for his/her objective. This Ph.D thesis aims to explore designer questions for creating the best model. For the first steps, a case study on design patterns applied to modeling process will be made, and a BPMN concepts related comparison function will be proposed.  2017 IEEE. Model Patterns; Model Semantic; Modeling Process; Models; Models Comparison; Process Mining; Quality of Model

CEFOP: A method for the Continual Evolution of Organisational Processes This paper presents CEFOP (Continual Evolution For Organisational Processes), a method for analysing, diagnosing and evolving the organisational processes. The dynamicity of the business environment requires from organisations to evolve their processes for maintaining their competitive advantage, but this can be time and cost consuming and cause great internal resistance. CEFOP method aims to limit these obstacles by introducing a continual evolution of the process managed in an autonomous way by the actors of the organisation. This approach is particularly crucial for SMEs, which have no internal skills to lead the necessary process evolutions. The CEFOP method adopts the AS-IS/AS-IF approach which allows going out of the project notion by proposing strategies to analyse, diagnose and improve the organisational processes in a continual way. This article focuses on the analysis strategy illustrated with a case study on a ticket support providing process. The case study is provided by Net Invaders, a juvenile French Startup, which is collaborating with us on this project.  2017 IEEE. business process management; business process mining; Continual evolution; method

Students' careers analysis: A process mining approach University degrees are typically organized in courses with prerequisites among them. If prerequisite are not mandatory, students are left free to attend courses and take exams in almost any order. While favoring flexible organization of the work by students, this practice can also lead to unstructured learning practices and to performance issues. In this paper we propose to take a process-oriented view of students' careers and analyze them by process mining techniques. Results provide us with some evidence of typical patterns followed by students and of the advantages of adopting structured learning practices.  2017 ACM. Educational mining; Process mining; Students' career analysis

A process mining oriented approach to improve process models analysis in developing countries As a result of the independence and the colonization endured by developing countries, most of their administrative procedures have been inherited from the colonial era. These procedures adapted to the colonizing countries, are complex for the African context. People in charge of their processing are not able to master it, take too much time to put them in practice and consider it as heavy for the administration. Sometimes, some misbehaviors are introduced in the execution of processes to accelerate it; this causes many troubles and incomprehension in their analysis, leading to bad decisions-making within the organization; It is therefore imperative to detect and solve these misbehaviors. The resulting challenge is to improve the comprehension of descriptive process models executed within information systems of developing countries by reducing their structural complexity and detecting anomalies in their execution. A substantial amount of literature has been devoted to this topic, and classified it among the set of problems solved by process mining techniques. Process mining is a research discipline interested in the proposal of methods for extracting descriptive business process models incomprehensible by users. Several techniques have been proposed for this purpose among which the a-algorithm, central for this work. The aim of this paper is to propose a refinement of this algorithm in order to generate a less structurally complex and more understandable descriptive process from execution logs within an information system. This refinement is essentially based on splitting the process into sub-processes according to the set of roles involved in the business process execution. The proposed model is experimented on a gynecological oncology workflow log and, it is shown how the whole process is split into sub-processes leading to a saving of execution time equivalent to half the execution time of the basic model.  2016 IEEE. Descriptive process; Developing countries; Event log; Normative process; Process discovery; Process mining; a-algorithm

A review on knowledge extraction for Business operations using data mining The Knowledge Economy is of great importance in various business fields which had resulted in increased demand for the people having high order thinking skills and unpredicted-problem-solving at workplace. Every organization has a Knowledge Management (KM) department as Knowledge itself is a precious resource of the organization. The latest trends in KM include Customer and Vendor knowledge, Mobile Applications for KM, Collaborative Knowledge Management System (KMS) and Social intranet which can be integrated with business processes. The knowledge extracted can be stored and processed to enhance business intelligence. KM works with various business fields like Marketing, Sales, Human Resource, Operations, Supply Chain, etc. Due to frequent changes in operation of processes and Quality policies, the knowledge extracted from these processes can play a vital role in enhancing business processes. In this paper we had proposed various models of KM & Business Operations and the need of data mining technique which can be used to deliver appropriate knowledge to the user.  2017 IEEE. Business Intelligence; Knowledge Management; Operations Management

Correlation Miner: Mining Business Process Models and Event Correlations Without Case Identifiers Process discovery algorithms aim to capture process models from event logs. These algorithms have been designed for logs in which the events that belong to the same case are related to each other - and to that case - by means of a unique case identifier. However, in service-oriented systems, these case identifiers are rarely stored beyond request-response pairs, which makes it hard to relate events that belong to the same case. This is known as the correlation challenge. This paper addresses the correlation challenge by introducing a technique, called the correlation miner, that facilitates discovery of business process models when events are not associated with a case identifier. It extends previous work on the correlation miner, by not only enabling the discovery of the process model, but also detecting which events belong to the same case. Experiments performed on both synthetic and real-world event logs show the applicability of the correlation miner. The resulting technique enables us to observe a service-oriented system and determine - with high accuracy - which request-response pairs sent by different communicating parties are related to each other.  2017 World Scientific Publishing Company. business process intelligence (BPI); business process management (BPM); event correlation; process discovery; Process mining

A Recommendation System to Facilitate Business Process Modeling This paper presents a system that utilizes process recommendation technology to help design new business processes from scratch in an efficient and accurate way. The proposed system consists of two phases: 1) offline mining and 2) online recommendation. At the first phase, it mines relations among activity nodes from existing processes in repository, and then stores the extracted relations as patterns in a database. At the second phase, it compares the new process under construction with the premined patterns, and recommends proper activity nodes of the most matching patterns to help build a new process. Specifically, there are three different online recommendation strategies in this system. Experiments on both real and synthetic datasets are conducted to compare the proposed approaches with the other state-of-the-art ones, and the results show that the proposed approaches outperform them in terms of accuracy and efficiency.  2013 IEEE. Pattern extraction; process mining; process modeling; process recommendation

Matching events and activities by integrating behavioral aspects and label analysis Nowadays, business processes are increasingly supported by IT services that produce massive amounts of event data during the execution of a process. These event data can be used to analyze the process using process mining techniques to discover the real process, measure conformance to a given process model, or to enhance existing models with performance information. Mapping the produced events to activities of a given process model is essential for conformance checking, annotation and understanding of process mining results. In order to accomplish this mapping with low manual effort, we developed a semi-automatic approach that maps events to activities using insights from behavioral analysis and label analysis. The approach extracts Declare constraints from both the log and the model to build matching constraints to efficiently reduce the number of possible mappings. These mappings are further reduced using techniques from natural language processing, which allow for a matching based on labels and external knowledge sources. The evaluation with synthetic and real-life data demonstrates the effectiveness of the approach and its robustness toward non-conforming execution logs.  2017 The Author(s) Business process intelligence; Constraint satisfaction; Declare; Event mapping; Natural language processing; Process mining

Overcoming challenges to air force satellite ground control automation US Air Force satellite ground stations require significant manpower to operate. To improve operating efficiencies, the Air Force seeks to incorporate more automation into routine satellite operations. Interaction with autonomous systems includes not only daily operations, but also the development, maintainability, and the extensibility of such systems. This paper presents challenges to Air Force satellite automation: 1) existing architecture of legacy systems, 2) space segment diversity, and 3) unclear definition and scoping of the term 'automation.' Using a qualitative case study approach, we survey comparable non-satellite operation domains (Industrial Control Automation and Software Testing) that have successfully integrated automation, and other satellite operation enterprises (NASA Goddard, Naval Research Laboratory, European Ground Station National Institute for Space Research in Brazil) to identify common themes and best practices. From this insight, we recommend that future satellite operation ground stations encourage the use of layered architectures, abstract satellite operation processes, and integrate simulators in future systems as concrete implementations of this common operating platform.  2017 IEEE. automation; case study; ground control; process mining; satellite; simulation

Event stream-based process discovery using abstract representations The aim of process discovery, originating from the area of process mining, is to discover a process model based on business process execution data. A majority of process discovery techniques relies on an event log as an input. An event log is a static source of historical data capturing the execution of a business process. In this paper, we focus on process discovery relying on online streams of business process execution events. Learning process models from event streams poses both challenges and opportunities, i.e. we need to handle unlimited amounts of data using finite memory and, preferably, constant time. We propose a generic architecture that allows for adopting several classes of existing process discovery techniques in context of event streams. Moreover, we provide several instantiations of the architecture, accompanied by implementations in the process mining toolkit ProM (http://promtools.org). Using these instantiations, we evaluate several dimensions of stream-based process discovery. The evaluation shows that the proposed architecture allows us to lift process discovery to the streaming domain.  2017 The Author(s) Abstract representations; Event streams; Process discovery; Process mining

Process Mining to Discover Shoppers' Pathways at a Fashion Retail Store Using a WiFi-Base Indoor Positioning System We present a preliminary report of a customer pathway analysis in an off-line store. Smart phone WiFi-based positioning technology is used to identify each customer's pathway behavior. The log data containing the space-time information are analyzed using process mining, a tool that provides a comprehensive view of an entire process. The main benefit of process mining is that it provides the topological structure of the processes. We installed a WiFi signal-capturing device in a retail store of a fashion brand in South Korea and collected data over a two-month period. Halfway through the experimental period, we swapped a set of mannequins displayed at the entrance to the store with an item stand. We then compared the customers' pathway behavior before and after the change. Through an analysis based on process mining, we observed a change in the topological structure of the pathway behavior following the change in the display setting. This paper demonstrates the possibilities of analyzing customer behavior using WiFi-based technology and the process mining technique. 

Middleware adaptation through process mining The development of adaptive middleware systems is a complex task due to the difficulty of dealing with adaptation issues, such as 'how' to implement the adaptation mechanism, 'where' to insert the adaptive code into the middleware, and 'when' the adaptive code is composed with the middleware logic. Existing solutions to build adaptive middleware usually concentrate on the use of software technologies like aspect oriented programming and computational reflection to face with the how issue. In this paper, we propose a solution to build middleware that is adapted at runtime 'when', whose adaptation decisions and actions are moved from the middleware to an external component 'where' and whose adaptation makes use of process mining techniques and software architecture 'how'. The adaptation process is triggered based on the verification of the middleware event log. In order to evaluate the proposed approach, we carried an experimental evaluation to check the quality of the mined middleware model and the verification overhead.  2017 IEEE. Adaptive middleware; Process mining; Software architecture

The digital future has many names - How business process management drives the digital transformation Process orientation of companies in combination with intelligent IT systems often forms the basis for many modern tendencies such as digitalization. This article analyses current BPM trends in a qualitative study and classifies them into three basic directions. There are technology-driven and human-driven BPM trends, both still follow the classical paradigm. However, optimization of workflows can be done bottom-up under involvement of data from IT systems or with collaboration of company employees. Different case-driven trends use the same sources for improvement but deviate from the traditional BPM paradigm in their fundamental methodical approach.  2017 IEEE. business process management; case management; intelligent BPM; process mining; social BPM; trend study

Generating event logs for high-level process models Business Process Model and Notation (BPMN) is a de-facto standard for practitioners working in the Business Process Management (BPM) field. The BPMN standard [1] offers high-level modeling constructs, such as subprocesses, events, data and message flows, lanes, and is widely used to model processes in various domains. Recently several BPMN-based process mining techniques [2, 3, 4] were introduced. These techniques allow representing processes, discovered from the event logs of process-aware information systems, in a convenient way, using the BPMN standard. To test these mining approaches an appropriate tool for the generation of event logs from BPMN models is needed. In this work we suggest such a tool. We propose a formal token-based executable BPMN semantics, which takes into account BPMN 2.0 with its expressive constructs. The developed tool is based on these semantics and allows simulation of hierarchical process models (including models with cancellations), models with data flows and pools, and models interacting through message flows. To manage the control flow, script-based gateways and choice preferences are implemented as well. The proposed simulation technique was implemented on top of existing plug-ins for ProM (Process Mining Framework) [5], and was verified on models created by practitioners from various domains.  2017 Elsevier B.V. BPMN (Business process model and notation); Business process simulation; Event log generation; Process mining

Financial process mining - Accounting data structure dependent control flow inference The increasing integration of computer technology for the processing of business transactions and the growing amount of financially relevant data in organizations create new challenges for external auditors. The availability of digital data opens up new opportunities for innovative audit procedures. Process mining can be used as a novel data analysis technique to support auditors in this context. Process mining algorithms produce process models by analyzing recorded event logs. Contemporary general purpose mining algorithms commonly use the temporal order of recorded events for determining the control flow in mined process models. The presented research shows how data dependencies related to the accounting structure of recorded events can be used as an alternative to the temporal order of events for discovering the control flow. The generated models provide accurate information on the control flow from an accounting perspective and show a lower complexity compared to those generated using timestamp dependencies. The presented research follows a design science research approach and uses three different real world data sets for evaluation purposes.  2017 Elsevier Inc. Business process intelligence; Business process modeling; Control flow inference; Design science research; Enterprise resource planning systems; Financial audits; Journal entries; Process mining

Fraud detection on event logs of goods and services procurement business process using Heuristics Miner algorithm Event logs are history records that contain sequence data for the activity of a case that has been executed by an information system. Event logs can be valuable information with a technique called mining process. With this technique, cheating on the business processes of an enterprise can be detected early on. Thus, the company can commit further examination of business processes, especially the business process of procurement of goods and services to achieve business process is expected.[8] In this study, management data of event log obtained from log data at each event transaction procurement and services. The event log data is then analyzed using a heuristic miner algorithm. Heuristics miner algorithm chosen because it has advantages that are not owned by Alpha++ algorithm that this algorithm can calculate the frequency relation between activities in the log to determine the causal dependency. Heuristic Miner can be used to determine the predominant process of thousands of logs and detect behaviors that are not common in a process.[11] This study aims to detect anomalies on business processes that occur during the process of procurement of goods and services by calculating the fitness value of the event log into the system. Heuristic miner algorithm using the results obtained identification accuracy of 0.88%.  2016 IEEE. event logs; fraud; heuristic miner; process mining; procurement

Business Process model similarity analysis using hybrid PLSA and WDAG methods Business process modeling means to describe the set of activities either within the companies or organizations. A variety of approaches used and the level of complexity is a problem that often occurs within applicability therefore needed a way to measure the degree of correspondence between the model of Business Process. By measuring the level of compatibility model in Business Process expected company can be easier to analyze. The need in the analysis of business process models are expected of a company or organization can understand the business processes that are running and can be used as a tool to help companies in the face of change and development so as to facilitate in making policies that are needed quickly. In this paper would propose merging structural analysis with semantic analysis where semantic analysis performed using Probabilistic Latent Semantic Analysis (PLSA), and then every method both structural and semantic analysis will be represented into Weighted Directed Acyclic Graph (WDAG) and to calculate, a combined with the aim to generating methods of measuring the degree of correspondence between business process models are better than just using structural analysis.  2016 IEEE. probabilistic latent semantic analysis; reusable process; similarity process model; topic mining; weighted directed acyclic graph

Mining method of business process models based on configuration The process mining technology is a kind of method, which can construct the process models from the event data of Information System, and has the vital significance for the analysis of the behavior of the business process model and the consistency test and so on. The existing mining technology can mine the general process model with all actions in the event log. However, for silent transitions in behavior constraints problems, the existing mining technologies have limitations. The mining method of configurable process model based on order relation of the event log and configuration constraints is proposed. Firstly, a mining method of the general process model is given relying on log order relation and two kinds of measurement, and then a mining method of the configurable process model is proposed on the basis of the configuration constraints. Finally an example is used to prove the feasibility of the mining method. Configuration Information; Event Logs; Process Mining; Process Models

Test Case Generation and Prioritization: A Process-Mining Approach Test cases are an essential tool in software quality assurance: they ensure that code behaves as specified in the requirement. However, writing test cases does not have only benefits, it comes with a cost: the programmer has to formulate the test cases and maintain them when the tested source code changes. Particularly for start-ups or small enterprises such costs become prohibitive, which often prefer to invest their time into the development of new functionalities instead of testing. This paper explores the use of process-mining as an approach to create a model of how users interact with a system to a) generate test cases and b) prioritize them. Using process-mining, it is possible to mine from the user behaviour which parts of the system are the most used, in which order they are executed, generate test cases repeating user input, and prioritizing test cases.  2017 IEEE. Process mining; Test case generation; Test case prioritization

Incorporating domain knowledge into clinical goal discovering for clinical pathway mining Clinical pathway is a crucial tool for care quality improvement and expense control. Compared to expertdesigned clinical pathway, the topic-based clinical pathway mined from history data is more dynamic and adaptive for real-world application. In this approach, the latent topics discovered by topic modeling are treated as the clinical goals, so that each patient trace is converted to a topic-based sequence. Process mining is used to generate a concise process model on these sequences. However, there is a common problem about the topic modeling that the redundancy between different topics is considerable. It means that some clinical activities strongly correlate to many topics, which has a significant impact on the ability of representing clinical goals of the topics. This paper proposed a novel topic modeling method for clinical goal discovering. Domain knowledge is incorporated to limit the available topic size for each clinical activity. Experiments demonstrate the effectiveness of our approach in discovering quality topics as the clinical goals for clinical pathway mining.  2017 IEEE. 

Process model extension using heuristics miner: Case study: Incident management of Volvo IT Belgium VINST is a system used to record all activities related to the incident and problem management in Volvo IT Belgium. In this VINST system, activities recorded in several attributes, such as serial number, change date and time, status, and any other attributes needed, which is stored in the event log. In these sequenced activities, there are some specific knowledge that is not explicitly described in the event log. To find some of the necessary knowledge, this study extracts knowledge from the event log, by using process mining. Heuristic miner algorithm was implemented in this study, because this algorithm has advantages compared to other methods, such as the ability to calculate the frequency of the process, to handle noise, and to combine the frequency between events and trace in the event log to build a process model. The steps being taken in this study began with the discovery process, followed by conformance checking, and completed with process model extension in enhancement step, which was finding knowledge based on analysing process model and event log. This study was using a specifically designed program to achieve the goals of this study. This study used VINST incident records with 149 cases consisting of 2.771 events. By applying heuristics miner, a process model discovered with precision, recall, and f-measure more than 96%. Knowledge gained from this process model extension were the analysis of time and organizational perspectives in forms of timestamp-impact attribute relation and originator-impact attribute relation.  2016 IEEE. heuristic miner; knowledge extraction; process mining; process model extension; VINST

Declarative process mining for DCR graphs We investigate process mining for the declarative Dynamic Condition Response (DCR) graphs process modelling language. We contribute (a) a process mining algorithm for DCR graphs, (b) a proposal for a set of metrics quantifying output model quality, and (c) a preliminary example-based comparison with the Declare Maps Miner. The algorithm takes a contradiction-based approach, that is, we initially assume that all possible constraints hold, subsequently removing constraints as they are observed to be violated by traces in the input log.  2017 Copyright held by the owner/author(s). DCR graphs; Declarative process mining

A descriptive clustering approach to the analysis of quantitative business-process deviances Increasing attention has been paid to the problem of explaining and analyzing "deviant cases" generated by a business process, i.e. instances of the process that diverged from prescribed/expected behavior (e.g. frauds, faults, SLA violations). In many real settings, such cases are labelled with a numerical deviance measure, and the analyst wants to obtain a fine grain unsupervised classification of them, which will help her recognize and explain different deviance scenarios. Unfortunately, current approaches rely on preliminary labelling all the cases, stored in some an execution log, as either deviant or non-deviant, and then inducing a rule-based classifier for discriminating among the two classes. By contrast, we here propose a method that discovers accurate and readable devianceaware clusters (of cases) defined in terms of descriptive rules over both properties and behavioral aspects of the cases. Each cluster is also equipped with summary information that allows to derive effective distribution charts and a high-level process map, both emphasizing the distinctive features of the cluster. Tests on a real-life log confirmed the ability of the approach to find easily-interpretable clustering models capturing relevant deviance scenarios. Copyright 2017 ACM. Clustering; Deviance explanation; Process mining

Parallel distributed patterns mining using hadoop mapreduce framework The treatment of large data is proving more difficult in different axes, but the arrival of the framework MapReduce is a solution of this problem. With it we can analyze and process vast amounts of data. It does this by distributing the computational work across a cluster of virtual servers running in a cloud or large set of machines while process mining provides an important bridge between data mining and business process analysis. The process mining techniques allow for extracting information from event logs. In general, there are two steps in process mining: correlation definition or discovery and process inference or composition. Firstly, the authors' work consists to mine small patterns from a log traces. Those patterns are the representation of the traces execution from a log file of a business process. In this step, they use existing techniques. The patterns are represented by finite state automaton or their regular expression. The final model is the combination of only two types of small patterns whom are represented by the regular expressions (ab)*and (ab*c)*. Secondly, the authors compute these patterns in parallel, and then combine those small patterns using the MapReduce framework. They have two parties: The first is the Map Step in which they mine patterns from execution traces; the second is the combination of these small patterns as reduce step. The authors' results are promising in that they show that their approach is scalable, general, and precise. It minimizes the execution time by the use of the MapReduce framework. Copyright  2017, IGI Global. Business Process; MapReduce; Patterns; Process Mining, Traces

Facilitating enhanced decision support Using a Social norms approach Social norms constrain behavior of individuals either through obligating or prohibiting certain types of behavior. Norm-based mechanisms have only recently found applications in enhancing decisions of knowledge workers in an automated business process management context. The norms inferred in the context of business process executions are then recommended to users so as to enable them to make informed decisions. The previous work on prohibition norm inference focused on identifying failure cases, which is now complemented by first inferring norms from the successful process execution cases and then inferring prohibition norms. This approach based on considering social feedback (i.e. inferring what is obliged and prohibited from history logs of process execution) shows encouraging results under uncertain business environments. Using simulation results the paper demonstrates that using the norm based mechanism results in reduced failure rates in the decision making of a knowledge worker while still providing maximum flexibility for the user to choose from a range of actions to execute.  2017, IGI Global. Decision support; Human interaction; Norm inference; Process automation; Process mining

Detecting concept drift in processes using graph metrics on process graphs Work in organisations is often structured into business processes, implemented using process-aware information systems (PAISs). These systems aim to enforce employees to perform work in a certain way executing tasks in a specified order. However, the execution strategy may change over time, leading to expected and unexpected changes in the overall process. Especially the unexpected changes may manifest without notice, which can have a big impact on the performance, costs, and compliance. Thus it is important to detect these hidden changes early in order to prevent monetary consequences. Traditional process mining techniques are unable to identify these execution changes because they usually generalise without considering time as an extra dimension, and assume stable processes. Most algorithms only produce a single process model, reflecting the behaviour of the complete analysis scope. Small changes cannot be identified as they only occur in a small part of the event log. This paper proposes a method to detect process drifts by performing statistical tests on graph metrics calculated from discovered process models. Using process models allows to additionally gather details about the structure of the drift to answer the question which changes were made to the process.  2017 Copyright held by the owner/author(s). Change point detection; Concept drift; Process drift; Process dynamics; Process mining

Recommending an alternative path of execution using an online decision support system Prediction of disease severity is highly essential for understanding the progression of disease and initiating an alternative path of execution, which is priceless in treatment planning. An online decision support system (ODeSS) is proposed here for stratification of the patients who may need Endoscopic Retrograde CholangioPancreatography (ERCP) and recommend an alternate path of execution. By this an immediate intervention can be avoided. In this study gallstone disease (GSD) whose prevalence is increasing in India is considered. ODeSS is a versatile non-linear information model which clustered the traces based on the duration of its completion. This is a Retrospective analyses of 575 traces. ODeSS applied the technique of longest common subsequence for identifying the sequence of an online execution and discovering to which cluster of variants it may belong. This discovery assist in taking appropriate clinical decision by recommending an alternative path of execution for such cases which may need emergency interventions. ODeSS performance was evaluated using area under receiver operating characteristic curve (area under ROC curve). This showed an accuracy of 0.9653 in prediction. The proposed model was validated using ROC curve in k-fold cross validation. Hence the proposed ODeSS can be used to conduct a non-linear statistical analysis since, the relationships between the predictive variables are not linear. It can be used as a clinical practice to recommend the path of execution. This would assist in better treatment planning, avoiding future complications.  2017 ACM. Cascade neural network; Clustering; Least mean square; Neural network; Process mining; Trace matching

Distilling lasagna from spaghetti processes If the operational process is flexible, control flow discovery methods in process mining tend to produce Spaghetti (unstructured) models. Spaghetti models generally consist of large number of activities and paths. These models are unstructured, incomprehensible difficult to analyse, impossible to use during operational support and enhancement. Due The structural complexity of Spaghetti processes majority of techniques in process mining can not be applied on them. There is a at most necessity to design and develop methods for simplifying the structure of Spaghetti process to make them easily understandable and reusable. The methods proposed in this paper concentrates on offering the tools and techniques for analysing the Spaghetti process. The problems addressed in this paper are 1) converting the unstructured Spaghetti to structured and simplified Lasagna process, 2) identifying the list of possible, significant, and impossible paths of execution in Lasagna process. The proposed technique is verified and validated on real-life road traffic fine management event-log taken from standard repository.  2017 ACM. Control-flow; Lasagna process; Process mining; Spaghetti process

Automatic discovering success factor relationship entities in articles using named entity recognition An understanding of success factor relationships in the context of business-to-business where Inter-organizational Relationship (IORs) between organizations is crucial for effective strategic management to accomplish marketing goals. Several studies regarding those success factors and their influences have been conducted and published as articles. We apply the technique of Named Entity Recognition and find a suitable model for extracting the entities of success factors. The appropriate model needs only 60 research abstracts and the performance as high as 0.9 is achievable. Furthermore, we find that there is no significant improvement affected by applying sentence normalization.  2017 IEEE. Business Process; Corpus; Named Entities Recognition; Success factor; Text mining

Large scale predictive process mining and analytics of university degree course data For students, in particular freshmen, the degree pathway from semester to semester is not that transparent, although students have a reasonable idea what courses are expected to be taken each semester. An often-pondered question by students is: "what can I expect in the next semester?" More precisely, given the commitment and engagement I presented in this particular course and the respective performance I achieved, can I expect a similar outcome in the next semester in the particular course I selected? Are the demands and expectations in this course much higher so that I need to adjust my commitment and engagement and overall workload if I expect a similar outcome? Is it better to drop a course to manage expectations rather than to (predictably) fail, and perhaps have to leave the degree altogether? Degree and course advisors and student support units find it challenging to provide evidence based advise to students. This paper presents research into educational process mining and student data analytics in a whole university scale approach with the aim of providing insight into the degree pathway questions raised above. The beta-version of our course level degree pathway tool has been used to shed light for university staff and students alike into our university's 1,300 degrees and associated 6 million course enrolments over the past 20 years.  2017 ACM. Educational data mining, educational process visualization; Learning analytics; Predictive modeling; Process mining

Towards mining sequences and dispersion of rhetorical moves in student written texts There is an increasing interest in the analysis of both student's writing and the temporal aspects of learning data. The analysis of higher-level learning features in writing contexts requires analyses of data that could be characterised in terms of the sequences and processes of textual features present. This paper (1) discusses the extant literature on sequential and process analyses of writing; and, based on this and our own first-hand experience on sequential analysis, (2) proposes a number of approaches to both pre-process and analyse sequences in whole-texts. We illustrate how the approaches could be applied to examples drawn from our own datasets of 'rhetorical moves' in written texts, and the potential each approach holds for providing insight into that data. Work is in progress to apply this model to provide empirical insights. Although, similar sequence or process mining techniques have not yet been applied to student writing, techniques applied to event data could readily be operationalised to undercover patterns in texts.  2017 ACM. Academic writing; Learning analytics; Process mining; Rhetorical moves; Sequence mining; Temporal analysis; Text mining; Writing analytics

Understanding student interactions in capstone courses to improve learning experiences Project-based courses can provide valuable learning experiences for computing majors as well as for faculty and community partners. However, proper coordination between students, stakeholders and the academic team is very difficult to achieve. We present an integral study consisting of a twofold approach. First, we propose a proven capstone course framework implementation in conjunction with an educational software tool to support and ensure proper fulfillment of most academic and engineering needs. Second, we propose an approach for mining process data from the information generated by this tool as a way of understanding these courses and improving software engineering education. Moreover, we propose visualizations, metrics and algorithms using Process Mining to provide an insight into practices and procedures followed during various phases of a software development life cycle. We mine the event logs produced by the educational software tool and derive aspects such as cooperative behaviors in a team, component and student entropy, process compliance and verification. The proposed visualizations and metrics (learning analytics) provide a multi-faceted view to the academic team serving as a tool for feedback on development process and quality by students.  2017 ACM. Capstone; Cloud-based mobile system; Computing majors; Data science; Education; Empirical software engineering; Process mining; Project-based learning

A big data analytics framework for enterprise service ecosystems in an e-Governance scenario In the recent times we have been seeing a fundamental shift from Enterprise Applications towards large scale Enterprise Service Ecosystems. Enterprise Service Ecosystems are developed by modularizing and bundling of individual business rules and functions in the form of services. These services are loosely coupled, distributed and heterogeneous components which orchestrate amongst themselves in a seamless manner. Ecosystem components record the events that are related to the activities performed by them. These components could span across Data Centre, Cloud Infrastructure and Internet of Things. Aadhaar Authentication Ecosystem and e-Governance Service Exchange are examples of Enterprise Service Ecosystems which recently emerged in national e-Governance scenario. A Big Data Analytics Framework for comprehensive mining and analyzing event data of Enterprise Service Ecosystems is proposed in this paper. The offered framework facilitates interesting real time analytics (e.g. Process Conformance Checking, Bottleneck Detection) as well as performing offline analytics (e.g. Process Discovery). The application of the proposed framework for real time analytics is explained using Aadhaar (Unique Identity) Authentication Ecosystem case study.  2017 ACM. Aadhaar authentication ecosystem; Big data analytics; Complex event processing; E-Governance; Enterprise service ecosystem; Event data; Graph analytics; Process mining

Event log imperfection patterns for process mining: Towards a systematic approach to cleaning event logs Process-oriented data mining (process mining) uses algorithms and data (in the form of event logs) to construct models that aim to provide insights into organisational processes. The quality of the data (both form and content) presented to the modeling algorithms is critical to the success of the process mining exercise. Cleaning event logs to address quality issues prior to conducting a process mining analysis is a necessary, but generally tedious and ad hoc task. In this paper we describe a set of data quality issues, distilled from our experiences in conducting process mining analyses, commonly found in process mining event logs or encountered while preparing event logs from raw data sources. We show that patterns are used in a variety of domains as a means for describing commonly encountered problems and solutions. The main contributions of this article are in showing that a patterns-based approach is applicable to documenting commonly encountered event log quality issues, the formulation of a set of components for describing event log quality issues as patterns, and the description of a collection of 11 event log imperfection patterns distilled from our experiences in preparing event logs. We postulate that a systematic approach to using such a pattern repository to identify and repair event log quality issues benefits both the process of preparing an event log and the quality of the resulting event log. The relevance of the pattern-based approach is illustrated via application of the patterns in a case study and through an evaluation by researchers and practitioners in the field.  2016 Elsevier Ltd Data mining; Data quality; Event log preparation; Event log quality; Patterns; Process mining; Systematic data pre-processing

Resolving inconsistencies and redundancies in declarative process models Declarative process models define the behaviour of business processes as a set of constraints. Declarative process discovery aims at inferring such constraints from event logs. Existing discovery techniques verify the satisfaction of candidate constraints over the log, but completely neglect their interactions. As a result, the inferred constraints can be mutually contradicting and their interplay may lead to an inconsistent process model that does not accept any trace. In such a case, the output turns out to be unusable for enactment, simulation or verification purposes. In addition, the discovered model contains, in general, redundancies that are due to complex interactions of several constraints and that cannot be cured using existing pruning approaches. We address these problems by proposing a technique that automatically resolves conflicts within the discovered models and is more powerful than existing pruning techniques to eliminate redundancies. First, we formally define the problems of constraint redundancy and conflict resolution. Second, we introduce techniques based on the notion of automata-product monoid, which guarantees the consistency of the discovered models and, at the same time, keeps the most interesting constraints in the pruned set. The level of interestingness is dictated by user-specified prioritisation criteria. We evaluate the devised techniques on a set of real-world event logs.  2016 Elsevier Ltd Conflict Resolution; Declarative Process; Process Mining; Redundant Constraints

Towards mining the organizational structure of a dynamic event scenario The increasing volume and value of data is an important enabler for data science. In this study, we consider the event data, i.e. information on things that happen in organizations, machines, systems and peoples lives. Each event refers to a well-defined activity in a certain business process execution, the resource (i.e. person or device) executing or initiating the activity, the timestamp of the event, as well as to various data elements recorded with the event (e.g. the geo-location of an activity). Process mining aims to analyze event data, in order to mine knowledge that can contribute to improving a business process behavior. In particular, the focus of this study is on organizational mining, that is a sub-field of process mining that aims at understanding the life cycle of a dynamic organizational structure (i.e. a configuration of organization units) and the interactions among co-workers (resources) arising from the analysis of real-world event logs. The innovative contribution of this study is that the organizational mining goal is here achieved by combining concepts from process mining, stream mining and social network analysis. This combination is an original contribution of this study, not still explored in organizational mining field. In an assessment, benchmark event data are explored, in order to understand how the presented solution allows us to identify the life cycle a dynamic organizational structure.  2017 Springer Science+Business Media New York Internet of events; Organizational mining; Process mining; Social network analysis

Implementing heuristic miner for information system audit based on DSS01 COBIT5 (Case study: CV Narnia distribution) Information systems are able to support the operational activities and provide useful information for users. In fact almost every large companies implementing information systems, but controlling the information system needs additional efforts, one of which is the audit of information systems. Audit is believed to be able to identify risks and evaluate the adequacy of the important controls on information systems. Audits are generally examining data or document but the modern companies stored more detailed information in event logs, transaction logs, databases, data warehouses etc. In this research, COBIT 5 framework is offered as part of the assessment process improvement initiative or part of a capability determination approach. This research aims to renew two important steps in the assessment process, namely the data collection and validation, using a process mining approach. Thus the information systems audit uses process mining to extract knowledge from event logs into useful information for audit purposes. The output of this study is the finding of how process mining can be combined with other data collection methods to improve the results of the assessment program.  2016 IEEE. audit; COBIT 5; event logs; process assessment; process mining

Towards a better assessment of event logs quality It is widely observed that the poor event logs quality poses a significant challenge to the process mining project both in terms of choice of process mining algorithms and in terms of the quality of the discovered process model. Therefore, it is important to control the quality of event logs prior to conducting a process mining analysis. In this paper, we propose a qualitative model which aims to assess the quality of event logs before applying process mining algorithms. Our ultimate goal is to give process mining practitioners an overview of the quality of event logs which can help to indicate whether the event log quality is good enough to proceed to process mining and in this case, to suggest both the needed preprocessing steps and the process mining algorithm that is most tailored under such a circumstance. The qualitative model has been evaluated using both artificial and real-life case studies.  2016 IEEE. event logs; process mining; process mining algorithms; qualitative model

Analyzing Machine Performance Using Data Mining This paper focuses on analysis of machine performance in a manufacturing company. Machine behavior can be complex, because it usually consists of many tasks. Performance of these tasks depends on product attributes, worker's speed, and therefore, analysis is not simple. Performance analysis results can be used for different purposes. Prediction and description are typical products of data mining. Prediction should be used for online monitoring of the manufactory process and as an input for a scheduler. Description can serve as information for managers to know which attributes of products cause problems more frequently. However manufacturing processes are complex, every process is quite unique. Our long term goal is to generalize the most common patterns to build general analyzer. This task is not simple because the lack of real word data and information. Therefore this work may contribute to the other researchers in their understanding of real world manufacturing problems.  2016 IEEE. association rules; data mining; manufacturing; performance analysis; prediction; Process mining; scheduling; simulation

Component behavior discovery from software execution data Tremendous amounts of data can be recorded during software execution. This provides valuable information on software runtime analysis. Many crashes and exceptions may occur, and it is a real challenge to understand how software is behaving. Software is usually composed of various components. A component is a nearly independent part of software that full-fills a clear function. Process mining aims to discover, monitor and improve real processes by extracting knowledge from event logs. This paper presents an approach to utilize process mining as a tool to discover the real behavior of software and analyze it. The unstructured software execution data may be too complex, involving multiple interleaved components, etc. Applying existing process mining techniques results in spaghetti-like models with no clear structure and no valuable information that can be easily understood by end. In this paper, we start with the observation that software is composed of components and we use this information to decompose the problem into smaller independent ones by discovering a behavioral model per component. Through experimental analysis, we illustrate that the proposed approach facilitates the discovery of more understandable software models. All proposed approaches have been implemented in the open-source process mining toolkit ProM.  2016 IEEE. 

Software cybernetics in BPM: Modeling software behavior as feedback for evolution by a novel discovery method based on augmented event logs Business Process Management (BPM) is a quickly developing management theory in recent years. The goal of BPM is to improve corporate performance by managing and optimizing the businesses process in and among enterprises. The goal is easier to achieve with the closed-loop feedback mechanism from business process execution to redesign in BPM life cycle, where the business process itself and the set of activities in BPM are viewed as a controlled object and a controller respectively. In this feedback control system, process mining plays an important role in generating feedback of process execution for redesign. However, the existing discovery methods cannot mine certain special structures from execution logs (e.g., implicit dependency, implicit place and short loops) correctly and their mining efficiencies cannot meet the requirements of online process mining. In this paper, we propose a novel discovery method to overcome these challenges based on a kind of augmented event log that will also bring new research directions for process discovery. A case study is presented for introducing how the mined model can be used in business process evolution. Results of experiments are described to show the improvements of the proposed algorithm compared with others.  2016 Petri nets; Process discovery; Software cybernetics

Filtering Out Infrequent Behavior from Business Process Event Logs In the era of "big data", one of the key challenges is to analyze large amounts of data collected in meaningful and scalable ways. The field of process mining is concerned with the analysis of data that is of a particular nature, namely data that results from the execution of business processes. The analysis of such data can be negatively influenced by the presence of outliers, which reflect infrequent behavior or "noise". In process discovery, where the objective is to automatically extract a process model from the data, this may result in rarely travelled pathways that clutter the process model. This paper presents an automated technique to the removal of infrequent behavior from event logs. The proposed technique is evaluated in detail and it is shown that its application in conjunction with certain existing process discovery algorithms significantly improves the quality of the discovered process models and that it scales well to large datasets.  2016 IEEE. Business process management; infrequent behavior; process mining

Temporal Data Mining on the Stay Time of Outpatients and Treatment Processes In this paper, we attempt to analyze the relationships between the stay time of outpatients and treatment processes they received based on the temporal pattern mining algorithm proposed by Batal et al. We could observe MPTPs (Minimal Predictive Temporal Patterns) of treatment processes containing 'co-occur' relations as well as injections in the classes where the patients spent long time in receiving outpatient services. It suggested that a visit needs long time if treatments or examinations should be executed during the consultation, or if injections such as intravenous drips were involved in the process.  2016 IEEE. Medical data mining; Process mining; Service science

Process discovery from event stream data in the cloud - A scalable, distributed implementation of the flexible heuristics miner on the amazon kinesis cloud infrastructure Cloud computing offers readily available, scalable infrastructure to tackle problems involving high data volume and velocity. Discovering processes from event streams, especially when the business processes execute in a cloud environment, is such a problem. Event stream data is generated rapidly with varying volume and must be processed on-the-fly, making stream processing an important use case for cloud computing. This paper describes a distributed, streaming implementation of the flexible heuristics miner on Amazon Kinesis, a cloud-based event stream infrastructure, showing how mining methods can scale effortlessly to tens of millions of events per minute.  2016 IEEE. big data; cloud computing; distributed processing; event stream processing; flexible heuristics miner; Process mining

Evaluation of discovered clinical pathways using process mining and joint agent-based discrete-event simulation The analysis of clinical pathways from event logs provides new insights about care processes. In this paper, we propose a new methodology to automatically perform simulation analysis of patients' clinical pathways based on a national hospital database. Process mining is used to build highly representative causal nets, which are then converted to state charts in order to be executed. A joint multi-Agent discrete-event simulation approach is used to implement models. A practical case study on patients having cardiovascular diseases and eligible to receive an implantable defibrillator is provided. A design of experiments has been proposed to study the impact of medical decisions, such as implanting or not a defibrillator, on the relapse rate, the death rate and the cost. This approach has proven to be an innovative way to extract knowledge from an existing hospital database through simulation, allowing the design and test of new scenarios.  2016 IEEE. 

Process mining meets malware evolution: A study of the behavior of malicious code Mobile phones are more and more used for sensitive resources exchange and access, becoming target for possible malware attacks. These attacks are still increasing with the birth of new and sophisticated malware that make the existing malware detection approaches often inadequate. Since the majority of new malware are generated using existing malicious code, it becomes very important tracking the mobile malware phylogeny. In this work, a Process Mining (PM) approach for building a malware phylogeny model using information contained in system calls traces, is proposed. The adoption of a declarative Process Mining technique allows to mine a constraint-based model that can be effectively used as a malware fingerprint expressing relationships and recurring execution patterns among system calls in the execution flows. The model characterizes the behavior of malware applications allowing the identification of similarities across malware families and among malware variants belonging to the same family. The proposed approach is evaluated using a dataset of more than 700 infected applications across seven malware families obtaining very encouraging results.  2016 IEEE. Declare; Linear temporal logic; Malware evolution; Malware phylogeny; Process mining; Security

Process-Based Habit Mining: Experiments and Techniques Independently of the specific task to be enacted in a smart space, it is always crucial to mine a set of models representing environmental dynamics and, noteworthy, user habits, desires. Many different formalisms have been proposed to model human habits, but the vast majority of them are either difficult to read, evaluate or their definition requires a huge amount of work from either experts or users. In this paper we propose to employ process mining techniques in order to model human habits, we experimentally evaluate such an approach on a dataset built adopting the Smart-Home-in-a-Box toolkit with real users.  2016 IEEE. Habit mining; Process mining; Smart home

Method for Applying Process Mining to the Distribution of Non-alcoholic Beverages Non-alcoholic beverage companies store a significant amount of data in their systems. However, by failing to convert this data into useful information for decision-making. Process mining aims to discover, monitor, and improve real processes by extracting knowledge from event logs available in current systems. This study provides a method for applying process mining to the distribution of non-alcoholic beverages, aiming to increase the quality of service delivered to customers by making the process more transparent. The method provides an orderly and practical guide of much of the knowledge that has been generated in the field of process mining. It allows for a comprehensive analysis by perspectives of process mining - control-flow, organizational, cases, and performance - following the L* life-cycle model stages. Additionally, it proposes recommendations and best practices in order to reduce the difficulty and costs, and improve the understanding of non-experts. The method is applied to the distribution process of a company in the non-alcoholic beverage bottling industry.  2015 IEEE. business process management; distribution process; non-alcoholic beverage industry; Process mining

Software development process mining: Discovery, conformance checking and enhancement Software development has become a fundamental process on any business or organization. As a consequence, together with other emergent technologies, new development platforms (IDEs) are being created, mainly in the cloud (e.g., Eclipse Orion, Cloud9, Codio), requiring different approaches on the way software development can be studied. Empirical studies on software development most often are based on data taken from software configuration management repositories, source code management systems and issue tracking tools, but not from the IDEs themselves, because they do not record data publically regarding developers' activities. We aim to bring forward new insights on the software development process by analyzing how developers use their IDE. Based upon process mining techniques such as process discovery and conformance checking, this missing perspective will hopefully allow the discovery of coding patterns, the search for programmer behaviors and the detection of deviations from prescribed processes. Finally, we expect to provide advice for individual software process enhancement.  2016 IEEE. pattern discovery; process mining; software development; software engineering; software process

On business process redesign and configuration: Leveraging data mining classification & outliers and artifact-centric process modeling In today's e-business, data increasingly capture many behavioral aspects of our daily life, e.g. operational patterns in production lines, human shopping habit, medical treatment, supply-chain management. We formally define the behavior of tasks (of the business process in question) in connection with conceptually described business artifacts that are manipulated by the tasks. We relate this representation to data mining and nonfunctional requirements to better define the context for process redesign (i.e, design-time changes) and process configuration (i.e, run-time changes). Furthermore, we propose algorithms for business-process redesign and configuration based on the above context. Our research is positioned in the field of business process flexibility-a term coined by van der Aalst [1] in his thorough literature survey on business processes. We validate our framework using real-life data provided by our industrial partners.  2016 IEEE. Artifact-centric process modeling; Data mining; Process configuration; Process redesign

Process mining for healthcare process analytics Process mining (PM) as applied in different industrial settings is considered as an effective technique for business process analytics. In healthcare domain, applications of this technique are yet limited but emerging. Process conformance verification, which is applied to measure differences between process model specification and process enactments, is one of the basic reasons to use the PM technique. The differences highlight the gaps to improve the process model specification by using the information gained from the process enactments. This paper first provides an overview of the studies that use the PM technique for conformance verification of healthcare processes as elicited from a systematic mapping study. It then describes the features of a tool that will use the PM technique to carry out process analytics in an intensive care unit of a university hospital.  2016 IEEE. Conformance verification; Healthcare; Process analytics; Process mining; Systematic mapping

Process mining on medical treatment history using conformance checking This research applies conformance checking algorithm to monitor and evaluate the process sequence that occurred in the medical treatment event log history by building a corresponding model on which the training and testing were conducted. The comparison results depicted whether or not the defined workflow is consistent with the actual one recorded in the log files. Thus, the performance was evaluated based the token (or state) behavior, e.g., missing tokens, remaining tokens, left-over tokens and error tokens, in each of the processing steps. The resulting findings can be further used to improve and optimize the overall performance of the designated system.  2016 IEEE. Alpha Algorithm; Conformance Checking; Petri Net; Process Mining; Tokens

Using transition systems and regions to analyze and monitor admission procedures of a hospital This research provides topological discovery process that took place and recorded in the log file history. The event log contains information of patient, date/time of the treatment, medical procedures, responsible staff, and case IDs. The goal of this research to verify the conformity of the desinated process workflow using Mine Transition Systems by comparing it with the actual activities recorded in the log file. By using a generated model (Petri Net), a guideline can be developed and used to improve the overall performance of the medical process. The inconsistency between the anticipated workflow and the extracted one from the log file history were found in this study. The main issue was an extensive delay in waiting time for treatment and for payment (prior to medication dispense). These results and findings can be presented to the people that are in charge and hence be used to solve this issue towards better service performance of the hospital.  2016 IEEE. Mine Transition System; Process Mining; ProM

Improving organizational process of a hospital through Petri-net based repair models The main emphasis of the study was to detect and discover bottlenecks of an admission procedures process in a hospital in Thailand during (or after the end of the) treatment process of the patients. Applying a Petri-net based repair model techniques enabled the administrators of the hospital to improve and benchmark the overall workflow of tasks from both administrative and client/customer points of view. Cause some small step process. Accordingly, by following the proposed approach, the quality of the offered service was significantly increased and boosted leading to the higher extent of customer/patient satisfaction, retention and loyalty toward the treatment process service. In addition, the developed system enabled the administrators and managers of the different hospital (treatment and healthcare) wards to better monitor, evaluate and asses the performance of the staff. Comparing the original/master model with real/authenticate data (event logs) eventually enhanced the efficiency and effectiveness of the offered service within the less duration of the treatment time. This research provides groundwork for the future and further studies in the areas of organizational structure management, bottleneck mining, process management and etc.  2016 IEEE. bottleneck Mining; Hospital Management; Organizational Structure Benchmarking; Petri Nets; Process Mining; Repair Model

Development of a process-aware instructor-aware multi-tabletop collaborative learning environment Unlike individual learning, collaborative learning using a computer is based on the idea that knowledge can be created within small groups of students where members actively participate and interact by sharing experiences and skills. However, in authentic classrooms, instructors have limited time and inadequate resources to monitor and investigate all group activities of students with respect to the whole knowledge creation process. This paper is divided into two main parts. Firstly, we designed implemented and evaluated novel technical infrastructure that can automatically and unobtrusively capture, collect and format the students' individual and collaborative activities in terms of datasets. Secondly, we conducted an empirical research to analyze these data with data mining and process mining techniques. Accordingly, the main objective of the study was to provide support to instructors by increasing their awareness toward students' collaboration process.  2016 IEEE. Computer-Supported Collaborative Learning; Concept Mapping; Interaction Behaviors; Patterns of Collaborative Process; Process Mining; Sequential Pattern Mining; SMART Tables

Performance analysis of a bank call canter customer service using Fuzzy Miner technique This research applies a process mining process discovery algorithm called Fuzzy Miner on a data previously collected from customers of call center of a bank in Thailand. The main purpose of applying this technique is to know what procedures in the customer service campaign are interrelated with each other and what the existing (potential) problems are in the developed system. Accordingly, the proposed technique enabled us to detect and reveal the potential bottlenecks of the call center service process as well as the identification of the correlation between the tasks and activities. The results of the study can be used to improve the quality of the offered service making the bank possible to better deal with the income complaints, problems and suggestions leading to increased customer satisfaction and added value.  2016 IEEE. Bank Customer Service Campaign; Call Center Data; Fuzzy Miner Algorithm; Process Mining

A study to investigate time durations of a call center customer service using transition systems This research study applied process mining transition systems and regions technique in order to better discover, investigate and analyze the customer service procedures of a Call Center in a bank regarding credit card problems, issues, inquiries and etc. Using the appropriate algorithm via ProM process mining tool enabled us to simulate and generate the resulting graphs in terms of Transition System models. Moreover, using the Disco Fluxicon process mining platform made possible having a look at the collected event logs from different perspectives and dimensions including the standard deviation analysis and investigation of the frequency of data at each stage and so on. The approach applied in this study and the proposed techniques can provide groundwork for future and further studies in different situations and scenarios. Accordingly, the findings of the study helped the administrators and managers of the call center company to improve and enhance the quality of their service with respect to bank credit service as well as being able to better benchmark and detect the potential or existing problems, discrepancies and noises within the available system.  2016 IEEE. Analyze Transition System; Disco; Fuzzy; Process Mining; ProM

Applying inductive Visual Miner technique to analyze and detect problems in procedures of a hospital in Thailand Operative medical procedure is a critical task which requires an immediate attention. Every second can determine a future of a patient. This research aims to apply a process mining technique called 'Mine with Inductive Visual Miner' with the purpose of detecting potential problems/discrepancies within the collected data and improving the quality of service in the surgical procedure department of a hospital in Thailand. The main objective of the study is to identify the existing problems and make recommendations to resolve the bottlenecks and/or repetition based on the generated process graphs.  2016 IEEE. Hospital; Mine with Inductive Visual Miner; Process Mining; surgical procedure

Towards the development of semantically enabled flexible process monitoring systems In current business and enterprise environment, the most common processes are structured and well-documented, but there is another important category of processes, also referred to as being flexible or less-structured, because their execution is not strictly enforced by an external system. The main objective of this article is the design of a semantically enabled system capable of monitoring and analysing flexible or transient processes that typically occur in enterprise environments, in which the human factor plays a very important role in the execution and planning of activities. In order to facilitate the development of such a system, we provide a framework for the management of processes that also involve physical activities thus extending the scope of business process management into physical systems. This undertaking involves the integration of results from the emerging Cyber Physical Systems (CPS) research field and from several other areas of research such as the area of and activity recognition, plan recognition, process mining, etc.  2015 Informa UK Limited, trading as Taylor & Francis Group. Cyber Physical Systems; Factories of the Future; information systems; process mining

Stage-based business process mining Evidence-based BPM has gained significant momentum in recent years, thanks to the widespread adoption of enterprise systems that store detailed business process execution data in event logs. Techniques for analyzing business processes using event logs are termed "process mining" techniques. Their objective is to aid business analysts in improving business processes by learning knowledge from massive data. To date, techniques for process mining abound. For example, one can measure processing time and waiting time, diagnose process delays and quality issues, and replay an entire event log over a process model discovered from the log itself. However, these techniques often suffer from limited applicability, particularly when used on top of unpredictable processes such as patient treatment processes in healthcare as opposed to predictable processes such as a car manufacturing process. They failed to extract a highly fit process model, awkward in measuring process performance, and inaccurate in predictive monitoring. In addition, they are confused at how to divide the problem into sub-problems for better solutions. This research aims at designing a novel set of techniques based on a notion of business process stages which can improve over existing process mining techniques. Copyright 2017 for this paper by its authors. Business process management; Decomposition; Multistage; Process mining; Stage-based

Business process reporting using process mining, analytic workflows and process cubes: A case study in education Business Process Intelligence (BPI) is an emerging topic that has gained popularity in the last decade. It is driven by the need for analysis techniques that allow businesses to understand and improve their processes. One of the most common applications of BPI is reporting, which consists on the structured generation of information (i.e., reports) from raw data. In this article, state-of-the-art process mining techniques are used to periodically produce automated reports that relate the actual performance of students of a Dutch University to their studying behavior. To avoid the tedious manual repetition of the same process mining procedure for each course, we have designed a workflow calling various process mining techniques using RapidProM. To ensure that the actual students behavior is related to their actual performance (i.e., grades for courses), our analytic workflows approach leverages on process cubes, which enable the dataset to be sliced and diced based on courses and grades. The article discusses how the approach has been operationalized and what is the structure and concrete results of the reports that have been automatically generated. Two evaluations were performed with lecturers using the real reports. During the second evaluation round, the reports were restructured based on the feedback from the first evaluation round. Also, we analyzed an example report to show the range of insights that they provide.  IFIP International Federation for Information Processing 2017. Analytic workflows; Business process reporting; Education; Process cubes; Process mining

Building business process ontology based on concept hierarchy model The agility and efficiency of business processes have great influence on the company's competitiveness. However, current detection of business process management system reveals the problem that it does not satisfy the customer requirements, because there is a lack of sufficient semantic information between business process. This paper proposes an approach for ontology extraction on business process by incorporating concept hierarchy as background knowledge. Incorporating the background knowledge in procedure of the process ontology has two main advantages: 1) background knowledge accelerates the building process, thereby minimising the conversion cost; 2) background knowledge guides the extraction of knowledge, which hides in database. To validate the method given in this paper, we use part of the sales order processes from SAP reference process models to construct business process ontology. The gold standard experiments show using this method can correct an effective construct process ontology. Copyright  2017 Inderscience Enterprises Ltd. Business process; Concept hierarch model; Process ontology; Statistical modelling ontology

Simulation of multi-perspective declarative process models Flexible business processes can often be represented more easily using a declarative process modeling language (DPML) rather than an imperative language. Process mining techniques can be used to automate the discovery of process models. One way to evaluate process mining techniques is to synthesize event logs from a source model via simulation techniques and to compare the discovered model with the source model. Though there are several declarative process mining techniques, there is a lack of simulation approaches. Process models also involve multiple aspects, like the flow of activities and resource assignment constraints. The simulation approach at hand automatically synthesizes event logs that conform to a given model specified in the multi-perspective, declarative language DPIL. Our technique translates DPIL constraints to a logic language called Alloy. A formula-analysis step is the actual log generation. We evaluate our technique with a concise example and describe an alternative configuration to simulate event logs based on an assumed partial execution as well as on properties that are intended to be checked. We complement the quality evaluation by a performance analysis.  Springer International Publishing AG 2017. Multi-perspective process mining; Predictive analytics; Simulation of business processes

Towards managing key performance indicators for measuring business process performance Organizations always need to continually improve and review their critical business processes (BP), especially in the healthcare field. This improvement requires an efficient mean to support the management and the analysis of healthcare processes, to collect all relevant indicators designed for both effective management and process improvement and to understand all interesting results based on data instance logs that reflect the performance of business processes. In order to meet these challenges, we propose a novel approach for managing business process performance enabling the evaluation and optimization of BPs. This approach is illustrated through a real case study in the emergency department of Farhat Hached hospital in Sousse (Tunisia).  Springer International Publishing AG 2017. Association rules; Business process; Business process management (BPM); Data mining; Emergency department; Health care process; Key performance indicators (KPI); Ontology; Performance measurement

Uncovering the runtime enterprise architecture of a large distributed organisation a process mining-oriented approach Process mining mainly focuses on analyzing a single process that runs through an organization. Often organisations consist of multiple departments that need to work together to deliver a process. Archi-Mate introduced the Business Process Cooperation Viewpoint for this. However, such models tend to focus on modeling design time, and not the runtime behavior. Additionally, many approaches exist to analyze multiple departments in isolation, or the social network they form, but the cooperation between processes received little attention. In this paper we take a different approach by analyzing the runtime execution data to create a new visualization technique to uncover cooperation between departments by means of the Runtime Enterprise Architecture using process mining techniques. By means of a real-life case study at a large logistic organization, we apply the presented approach.  Springer International Publishing AG 2017. Business analytics; Data analytics; Enterprise architecture; Process mining; Runtime enterprise architecture

The application of business process mining to improving a physical asset management process: A case study Business process planning and control is important for effectively managing and improving processes relating to the management of physical assets. This is especially true when processes affect the uptime and value creation by physical assets. This article presents a case study where an asset management process is analysed using a technique called process mining, with which it is possible to investigate the process as it is being performed in the real world. By applying process mining instead of a traditional mathematical approach, real-world issues can be identified and corrected to improve the effectiveness of the given process. A process model is first constructed to investigate process execution patterns, after which dotted charts are used to identify problem areas within the process and to propose possible areas for improvement.  2017, South African Institute of Industrial Engineering. All rights reserved. 

Detecting changes in process behavior using comparative case clustering Real-life business processes are complex and often exhibit a high degree of variability. Additionally, due to changing conditions and circumstances, these processes continuously evolve over time. For example, in the healthcare domain, advances in medicine trigger changes in diagnoses and treatment processes. Case data (e.g. treating physician, patient age) also influence how processes are executed. Existing process mining techniques assume processes to be static and therefore are less suited for the analysis of contemporary, flexible business processes. This paper presents a novel comparative case clustering approach that is able to expose changes in behavior. Valuable insights can be gained and process improvements can be made by finding those points in time where behavior changed and the reasons why. Evaluation using both synthetic and real-life event data shows our technique can provide these insights.  IFIP International Federation for Information Processing 2017. Concept drift; Process comparison; Process mining; Trace clustering

A Process Mining Based Service Composition Approach for Mobile Information Systems Due to the growing trend in applying big data and cloud computing technologies in information systems, it is becoming an important issue to handle the connection between large scale of data and the associated business processes in the Internet of Everything (IoE) environment. Service composition as a widely used phase in system development has some limits when the complexity of relationship among data increases. Considering the expanding scale and the variety of devices in mobile information systems, a process mining based service composition approach is proposed in this paper in order to improve the adaptiveness and efficiency of compositions. Firstly, a preprocessing is conducted to extract existing service execution information from server-side logs. Then process mining algorithms are applied to discover the overall event sequence with preprocessed data. After that, a scene-based service composition is applied to aggregate scene information and relocate services of the system. Finally, a case study that applied the work in mobile medical application proves that the approach is practical and valuable in improving service composition adaptiveness and efficiency.  2017 Chengxi Huang et al. 

Process mining applications in software engineering Process mining is a field that uses elements from data mining and business process modeling to do tasks such as process discovery, conformance checking, and process improvement. This paper presents a study about the application of process mining techniques in the software development process. It shows a series of case studies that illustrate possible applications in the process and the product. Also, the main current challenges in applying process mining in software engineering are described. The objective of this paper is to show the importance and practical usefulness of applying process mining approaches in software engineering. The main result of this study is the fact that using process mining facilitates software process evaluation and auditing. The development of a methodology for applying process mining in software engineering is proposed as future work, considering the main challenges described previously.  Springer International Publishing AG 2017. Process assessment; Process improvement; Process mining; Software development

Process discovery by synthesizing activity proximity and user's domain knowledge Process mining techniques assist users to automatically infer process models from event logs. However, the result of process model driven by traditional process mining technique may conflict with the knowledge of users due to some real conditions, i.e. alternative activity is selected due to equipment breakdown. First, the use of heuristics may detect inconsistencies caused by bad guess. Second, extraction of all possible ordering of events reflects historical observation that sometimes hinders users to obtain an ideal process model since the activity has some event types. Yet, the current process mining approach is not totally compatible with some aspects such as extra logs behavior and soundness of process model when the process model changes according to user requirements. This paper presents a method for synthesizing activity proximity from event logs in the area of process mining. The method derives a bounded graph that covers the extra-behavior of an event log according to users domain knowledge. Another important property is that it produces a graph with considering the proximity among activities that still contains the original behavior of the event log based on event types. The methods described in this paper have been implemented in ProM framework and tested on a set of real process examples.  Springer International Publishing Switzerland 2013. Business process; Integer linear programming; Process mining; Proximity score; User's knowledge

Efcient implementation of hadoop mapreduce based business process dataflow Hadoop MapReduce is one of the solutions for the process of large and big data, with-it the authors can analyze and process data, it does this by distributing the computational in a large set of machines. Process mining provides an important bridge between data mining and business process analysis, his techniques allow for mining data information from event logs. Firstly, the work consists to mine small patterns from a log traces, those patterns are the workflow of the execution traces of business process. The authors' work is an amelioration of the existing techniques who mine only one general workflow, the workflow present the general traces of two web applications; they use existing techniques; the patterns are represented by finite state automaton; the final model is the combination of only two types of patterns whom are represented by the regular expressions. Secondly, the authors compute these patterns in parallel, and then combine those patterns using MapReduce, they have two parts the first is the Map Step, they mine patterns from execution traces and the second is the combination of these small patterns as reduce step. The results are promising; they show that the approach is scalable, general and precise. It reduces the execution time by the use of Hadoop MapReduce Framework.  2017, IGI Global. Business Process; Log File; MapReduce; Pattern; Trace

Ontology-based data access for extracting event logs from legacy data: The onprom tool and methodology Process mining aims at discovering, monitoring, and improving business processes by extracting knowledge from event logs. In this respect, process mining can be applied only if there are proper event logs that are compatible with accepted standards, such as extensible event stream (XES). Unfortunately, in many real world set-ups, such event logs are not explicitly given, but instead are implicitly represented in legacy information systems. In this work, we exploit a framework and associated methodology for the extraction of XES event logs from relational data sources that we have recently introduced. Our approach is based on describing logs by means of suitable annotations of a conceptual model of the available data, and builds on the ontology-based data access (OBDA) paradigm for the actual log extraction. Making use of a realworld case study in the services domain, we compare our novel approach with a more traditional extract-transform-load based one, and are able to illustrate its added value. We also present a set of tools that we have developed and that support the OBDA-based log extraction framework. The tools are integrated as plugins of the ProM process mining suite.  Springer International Publishing AG 2017. Event log extraction; Ontology-based data access; Process mining; Relational database management systems

Towards the design of a process mining-enabled decision support system for business process transformation Current approaches to business process transformation rely on normative "de jure" process models which are derived manually, costly to create, error-prone, idealistic, and often deviating from process reality. Theoretically grounded in organizational contingency theory, decision support systems (DSSs) and business process management literature, this design science project proposes the development of a DSS which incorporates bottom-up process mining in addition to other top-down sources of process knowledge for business process transformation. The DSS is intended to provide support in both the selection of an appropriate target process design as well as transformation support on the task level. This design project is conducted within a large-scale digital transformation project of a leading German manufacturing corporation to redesign business processes including the migration of the current SAP R/3 system to the SAP S/4 HANA business suite. Therefore, this design science research (DSR) utilizes a real-life event log comprising transaction data from multiple ERP systems as data source for the process mining module of the DSS and the later evaluation of the artifact. This proposal motivates both the practical and theoretical need for process mining-enabled decision support in business process transformation. Further, this proposal highlights research gaps, outline the DSR approach, and introduces the meta-requirements and the technical conceptualization of the DSS. Copyright 2017 for this paper by its authors. Business process management; Contingency theory; Decision support system; Design science; Process mining; Process transformation

Business process comparison: A methodology and case study Business processes often exhibit a high degree of variability. Process variants may manifest due to the differences in the nature of clients, heterogeneity in the type of cases, etc. Through the use of process mining techniques, one can benefit from historical event data to extract non-trivial knowledge for improving business process performance. Although some research has been performed on supporting process comparison within the process mining context, applying process comparison in practice is far from trivial. Considering all comparable attributes, for example, leads to an exponential number of possible comparisons. In this paper we introduce a novel methodology for applying process comparison in practice. We successfully applied the methodology in a case study within Xerox Services, where a forms handling process was analyzed and actionable insights were obtained by comparing different process variants using event data.  Springer International Publishing AG 2017. Business analytics; Process comparison; Process mining

Process mining of event log from web information and administration system for management of students computer networks Process mining is relatively new approach which is often using for performance managing and optimizing of the most important business processes. Process mining analysis allows extracting information from event logs. The main purpose of this paper is to describe advantages of process mining, current trends and provide process mining analysis of event log from web information and administration system for management of students computer networks in case study. The case study deals with using Disco software tool for process mining of mentioned event log. Case study will provide information about processes such as automatic discovery of process model based on imported data, process map with detail information about activities and paths (frequency, repetitions and duration), number of events, overview about events and active cases over time and finally also using resources.  Springer International Publishing AG 2017. Disco software tool; Events log; Management of computer networks; Process mining

Mining business process stages from event logs Process mining is a family of techniques to analyze business processes based on event logs recorded by their supporting information systems. Two recurrent bottlenecks of existing process mining techniques when confronted with real-life event logs are scalability and interpretability of the outputs. A common approach to tackle these limitations is to decompose the process under analysis into a set of stages, such that each stage can be mined separately. However, existing techniques for automated discovery of stages from event logs produce decompositions that are very different from those that domain experts would produce manually. This paper proposes a technique that, given an event log, discovers a stage decomposition that maximizes a measure of modularity borrowed from the field of social network analysis. An empirical evaluation on real-life event logs shows that the produced decompositions more closely approximate manual decompositions than existing techniques.  Springer International Publishing AG 2017. Clustering; Decomposition; Modularity; Multistage; Process mining

Map reduce autoscaling over the cloud with process mining monitoring Over the last years, the traditional pressing need for fast and reliable processing solutions has been further exacerbated by the increase of data volumes  produced by mobile devices, sensors and almost ubiquitous internet availability. These big data must be analyzed to extract further knowledge. Distributed programming models, such as Map Reduce, are providing a technical answer to this challenge. Furthermore, when relaying on cloud infrastructures, Map Reduce platforms can easily be runtime provided with additional computing nodes (e.g., the system administrator can scale the infrastructure to face temporal deadlines). Nevertheless, the execution of distributed programming models on the cloud still lacks automated mechanisms to guarantee the Quality of Service (i.e., autonomous scale-up/-down behavior). In this paper, we focus on the steps of monitoringMap Reduce applications (to detect situations where the temporal deadline will be exceeded) and performing recovery actions on the cluster (by automatically providing additional resources to boost the computation). To this end, we exploit some techniques and tools developed in the research field of Business Process Management: in particular, we focus on declarative languages and tools for monitoring the execution of business process. We introduce a distributed architecture where a logic-based monitor is able to detect possible delays, and trigger recovery actions such as the dynamic provisioning of a congruent number of resources.  Springer International Publishing AG 2017. Autonomic system; Business process management; Cloud computing; Map reduce

Process discovery for industrial control system cyber attack detection Industrial Control Systems (ICSs) are moving from dedicated communications to Ethernet-based interconnected networks, placing them at risk of cyber attack. ICS networks are typically monitored by an Intrusion Detection System (IDS), however traditional IDSs do not detect attacks which disrupt the control flow of an ICS. ICSs are unique in the repetition and restricted number of tasks that are undertaken. Thus there is the opportunity to use Process Mining, a series of techniques focused on discovering, monitoring and improving business processes, to detect ICS control flow anomalies. In this paper we investigate the suitability of various process mining discovery algorithms for the task of detecting cyber attacks on ICSs by examining logs from control devices. Firstly, we identify the requirements of this unique environment, and then evaluate the appropriateness of several commonly used process discovery algorithms to satisfy these requirements. Secondly, the comparison was performed and validated using ICS logs derived from a case study, containing successful attacks on industrial control systems. Our research shows that the Inductive Miner process discovery method, without the use of noise filtering, is the most suitable for discovering a process model that is effective in detecting cyber-attacks on industrial control systems, both in time spent and accuracy.  IFIP International Federation for Information Processing 2017. Anomaly detection; Industrial control systems; Process mining

Process-based query tool to rationalize document bases Organizational activities require and produce documents like policies, transactional documents, business reports, audit reports. These documents are usually stored in document bases belonging to their hosting IT systems that makes difficult to search them. However they are connected to their generating, modifying and utilizing activities in process models which can be transformed into process ontologies. Process ontologies can be served as a basis for transforming process models into workflows, and interpreting or searching documents released during the runtime of processes. An application presented in this paper uses process model transformation, process-based text mining and semantic technologies for processing documents and querying them.  Springer International Publishing AG 2017. Business process management; Document base; Semantic searching

A framework for interactive multidimensional process mining The emerging concept of multidimensional process mining adopts the ideas of data cubes and OLAP to analyze processes from multiple views. Analysts can split the event log into a set of homogenous sublogs according to its case and event attributes. Process mining techniques are used to create an individual process model for each sublog representing variants of the process. These models can be compared to identify the differences between the variants. Due to the explorative character of the analysis, interactivity is crucial to successfully apply multidimensional process mining. However, current approaches lack interactivity, e.g., they require the analyst to re-perform the analysis steps after changing the view on the data cube. In this paper, we introduce a novel framework to improve the interactivity of multidimensional process mining. As our main contribution, we provide a generic concept for interactive process mining based on a stack of operations.  Springer International Publishing AG 2017. Interactive process mining; Mining; Multidimensional process; Process cubes

Discovering social networks instantly: Moving process mining computations to the database and data entry time Process mining aims to turn event data into insights and actions in order to improve processes. To improve process performance it is crucial to get insights into the way people work and collaborate. In this paper, we focus on discovering social networks from event data. To be able to deal with large data sets or with an environment which requires repetitive discoveries during the analysis, and still provide results instantly, we use an approach where most of the computation is moved to the database and things are precomputed at data entry time. Differently from traditional process mining where event data is stored in file-based system, we store event data in relational databases. Moreover, the database also has a role as an engine to compute the intermediate structure of social network during insertion data. By moving computation both in location (to database) and time (to recording time), the discovery of social networks in a process context becomes truly scalable. The approach has been implemented using the open source process mining toolkit ProM. The experiments reported in this paper demonstrate scalability while providing results instantly.  Springer International Publishing AG 2017. Process mining; Relational database; Repetitive discovery; Social network

Knowledge-based trace abstraction for semantic process mining Many hospital information systems nowadays record data about the executed medical process instances in the form of traces in an event log. In this paper we present a framework able to convert actions found in the traces into higher level concepts, on the basis of domain knowledge. Abstracted traces are then provided as an input to semantic process mining. The approach has been tested in stroke care, where we show how the abstraction mechanism allows the user to mine process models that are easier to interpret, since unnecessary details are hidden, but key behaviors are clearly visible.  Springer International Publishing AG 2017. 

Leveraging process mining techniques for up-To-date resource profiles Keeping an up-To-date overview of the knowledge and skills available in an organization is a difficult task. Looking at this problem we propose the use of data, that already exists in the organization's information systems, as a means to keep user knowledge profiles up to date. To extract the required information from these information systems, we suggest the use of process mining. We illustrate the current state of our research and the end goals we aim to reach with it. We state a general research question. We then apply this to a software development setting, applying knowledge gained during an ongoing case study at a software development company. Knowledge management; Process mining; Resource metrics

Audit trails in OpenSLEX: Paving the road for process mining in healthcare The analysis of organizational and medical treatment processes is crucial for the future development of the healthcare domain. Recent approaches to enable process mining on healthcare data make use of the hospital information systems Audit Trails. In this work, methods are proposed to integrate Audit Trail data into the generic OpenSLEX meta model to allow for an analysis of healthcare data from different perspectives (e.g. patients, doctors, resources). Instead of flattening the event data in a single log file the proposed methodology preserves as much information as possible in the first stages of data extraction and preparation. By building on established standardized data and message specifications for auditing in healthcare, we increase the range of analysis opportunities in the healthcare domain.  2017, Springer International Publishing AG. Audit trails; Healthcare; Meta model; Process mining

A process mining approach for discovering ETL black points ETL tasks are quite complex often leading to a very complex network of working processes. Many difficulties of their development come from the number of sources of information we need to work, the heterogeneity and dispersion of data, and from the complexity of the tasks to implement, in order to populate appropriately a data warehouse. Thus, it is not difficult to occur some undesirable situations related to ETL system design errors or to the implementation of faulty or inefficient tasks. Many of these situations are only detectable at run time. In this paper, we discuss in particular the case of ETL bottleneck situations - ETL black points -, which can occur during the execution of an ETL system, identifying them and characterizing them using process mining. Based on the process mining results analysis, it is possible to develop alternative implementations for inefficient tasks and improve the overall system performance.  Springer International Publishing AG 2017. Data warehousing systems; ETL black points; ETL efficiency and optimization; ETL processes; Process mining

A process mining based model for customer journey mapping Customer journey maps (CJMs) are used to understand customers' behavior, and ultimately to better serve them. This new approach is used in numerous disciplines for different purposes. As a response, several software applications have emerged. Although they provide interfaces to understand CJMs, they lack measures to assist in decision making. We contribute by proposing a CJM model. We show its potential by using it with process mining, a data analytics technique that we leverage to assess the impact of the journey's duration on the customer experience. The model brings data scientists and customer journey planners closer together, the first step in gaining a better understanding of customer behavior. This study also highlights the prospective value of process mining for CJM analysis. Copyright 2017 for this paper by its authors. Customer journey analytics; Customer journey mapping; Process mining

Subgroup discovery in process mining Process mining enables multiple types of process analysis based on event data. In many scenarios, there are interesting subsets of cases that have deviations or that are delayed. Identifying such subsets and comparing process mining results is a key step in any process mining project. We aim to find the statistically most interesting patterns of a subset of cases. These subsets can be created by process mining algorithms features (e.g., conformance checking diagnostics) and serve as input for other process mining techniques. We apply subgroup discovery in the process mining domain to generate actionable insights like patterns in deviating cases. Our approach is supported by the ProM framework. For evaluation, an experiment has been conducted using event data from a large Spanish telecommunications company. The results indicate that using subgroup discovery, we could extract interesting insights that could only be found by spitting the event data in the right manner.  Springer International Publishing AG 2017. Pattern mining; Performance management; Process mining; Quality of metrics; Subgroup discovery

Process analytics through event databases: Potentials for visualizations and process mining Events, routinely broadcasted by news media all over the world, are captured and get recorded to event databases in standardized formats. This wealth of information can be aggregated and get visualized with several ways, to result in alluring illustrations. However, existing aggregation techniques tend to consider that events are fragmentary, or that they are part of a strictly sequential chain. Nevertheless, events occurrences may appear with varying structures (i.e., others than sequence), reflecting elements of a larger, implicit process. In this work, we propose several transformation templates to a enable a process perspective for raw event data. The basic idea is to transform event databases into a format suitable for process mining (aka event log) to enable the rich toolbox of process mining tools. We present our approach through the illustrative example of the events that happened in Greece during the referendum period (summer 2015).  Springer International Publishing AG 2017. Event analytics; Event data; Process mining

A log handling application framework for process mining of steel industry Many companies have been investing in various information systems such as enterprise resource planning (ERP), manufacturing execution system (MES), advanced planning & scheduling (APS) and supply chain management (SCM) for their competitiveness. Over the year, data volume in business and the types of log created by enterprise applications have been rapidly increasing with all those information systems. Under this IT environment, process mining techniques draw global attention to find business values from these huge log data. As the world enters the era of big data, tools and methodologies are actively being researched for storing and analyzing massive volume of data. This is also applied to the process mining area that actively searches an application framework to incorporate big data related technologies into log handling methodologies. In this paper, authors categorize multiple types of log, and organize the procedure of process mining from the viewpoint of big data technology such as Hadoop and Hive. Authors also propose a method to archive extracted logs into Hive, and to produce information from Hive by retrieving and refining. By demonstrating the proposed approach for log data from steel industry, authors show the usability of the proposed approach in accordance with commercial process mining tools like DISCO.  2017 ICIC International. Log analysis; Log mining methodology; Process mining; Steel industry

Process mining in intrusion detection-the need of current digital world In the current age of digital world, all users of Internet/Network as well as organizations are suffering from intrusions which results into data/information are theft/loss. In the present manuscript concept of intrusion detection system (IDS) were discussed along with its types and basic approaches. It is found that signature analysis, expert system, data mining etc. still using for IDS. Survey was given related to cybercrime incidents across various industry sectors. After analyzing the attacks on networks of organizations in different industry sectors it is found that still attacks like DDoS are not preventable. Comparison of data mining algorithms used for intrusion detection was also done. Various methods to implement the algorithm along with the advantages and disadvantages were also discussed in detail. Because of the disadvantages like over fitting, slow testing speed, unstable algorithms etc., intruders in the network are still active. To avert these shortcomings there is a need to develop real-time intrusion detection and prevention system through which data/information can be protected and saved in real-time basis before a severe loss is experienced. The real-time prevention is possible only if alerts are received instantly without delays. For this purpose, process mining could be used. This technique gives instant time alerts with real time analysis so as to prevent intrusions and data loss.  2017, Springer Nature Singapore Pte Ltd. Audit trails/event logs; Data mining; Intrusion; Process mining; Security

Process cubes: Slicing, dicing, rolling up and drilling down event data for process mining Recent breakthroughs in process mining research make it possible to discover, analyze, and improve business processes based on event data. The growth of event data provides many opportunities but also imposes new challenges. Process mining is typically done for an isolated well-defined process in steady-state. However, the boundaries of a process may be fluid and there is a need to continuously view event data from different angles. This paper proposes the notion of process cubes where events and process models are organized using different dimensions. Each cell in the process cube corresponds to a set of events and can be used to discover a process model, to check conformance with respect to some process model, or to discover bottlenecks. The idea is related to the well-known OLAP (Online Analytical Processing) data cubes and associated operations such as slice, dice, roll-up, and drill-down. However, there are also significant differences because of the process-related nature of event data. For example, process discovery based on events is incomparable to computing the average or sum over a set of numerical values. Moreover, dimensions related to process instances (e.g. cases are split into gold and silver customers), subprocesses (e.g. acquisition versus delivery), organizational entities (e.g. backoffice versus frontoffice), and time (e.g., 2010, 2011, 2012, and 2013) are semantically different and it is challenging to slice, dice, roll-up, and drill-down process mining results efficiently.  Springer International Publishing Switzerland 2013. Big Data; Conformance Checking; OLAP; Process Discovery; Process Mining

Clustering and operation analysis for assembly blocks using process mining in shipbuilding industry A block assembly process in the shipbuilding industry consists of many work stages. Block assembly involves many workers in many shops. Each assembly block, which is a part of a ship, has a different structure requiring specific work processes. Therefore, in order to better understand such real processes, an information system for monitoring of block position has been developed. Recently, the necessity of using data accumulated in information systems has become greater. This paper proposes a new, clustering and operation analysis method for assembly blocks based on process mining techniques suitable for the shipbuilding industry. The approach consists of four steps: 1) trace clustering from the task perspective, 2) trace clustering from the work shop perspective, 3) definition of new clusters considering task and work shop simultaneously, and 4) comparison of new clusters with other clusters from the process perspective. The output of clustering and operation analysis can be used for production planning purposes such as resource allocation and operation scheduling for assembly blocks. The effectiveness of the proposed method was verified in a case study using real event logs generated from the Block Assembly Monitoring System (BAMS), an information system.  Springer International Publishing Switzerland 2013. Block assembly; Process mining; Process model; Shipbuilding; Trace clustering

A practical approach for process mining in production processes Processes are the core of an enterprise and describe the inter-connection of tasks in daily business. The purpose of this article is to present methods and tools that enable extraction of processes based on the concept of process analysis/mining. This valuable knowledge about the current processes of a company can serve as the starting point for performance analysis and process improvement, for implementation of a software system or for monitoring adherence to processes. In this paper, we present two actual business scenarios of manu-facturing companies and their requirements regarding process analysis. We used a practical research approach including quantitative methods. Important results are the suggestion of a procedure and the development of a process mining tool. A comparison of de jure and de facto processes and a suggestion of optimization potentials complete the work.  Springer International Publishing AG 2017. Optimization; Process comparison; Process mining

Context Aware Process Mining in Logistics Processes in manufacturing and logistics are characterized by a high frequency of changes and fluctuations, caused by the high number of participants in logistic processes and the variety of goods handled and services offered. This dynamic behavior particularly requires well documented processes, but at the same time it also complicates process documentation. Manually documented processes can, e.g., miss details of alternative process branches, and the continuing change in logistic processes renders the documentation quickly outdated. A possible solution approach is to automate the documentation of processes. This automated documentation, if based on transaction and master data from the IT systems connected to the logistic process, is called Process Mining. Being a subfield of Data Mining, Process Mining extracts sequences of activities from event logs in databases. Logistics has the opportunity to greatly benefit from the application of Process Mining, because the identification and tracking of goods in the supply chain involves many IT systems. However, the IT landscape in logistics is heterogeneous, because the data are scattered among different specialized systems for various purposes (e.g., warehousing, transportation planning, and billing) of different companies. Due to this lack of standardization, the data cannot simply be analyzed by a predefined routine. Therefore, additional information beside the stored data should be taken into consideration. Machine Learning offers the possibility to classify single items in large data sets and to categorize these items with regard to the context they are in. Adding context awareness to unstructured event data in logistics has the potential to improve the results of Process Mining. Our research investigates how to apply context awareness based on Machine Learning in Process Mining for logistic processes and demonstrates its performance in a logistic scenario.  2017 The Authors. Published by Elsevier. Context Awareness; Logistics; Process Mining

OBDA for log extraction in process mining Process mining is an emerging area that synergically combines model-based and data-oriented analysis techniques to obtain useful insights on how business processes are executed within an organization. Through process mining, decision makers can discover process models from data, compare expected and actual behaviors, and enrich models with key information about their actual execution. To be applicable, process mining techniques require the input data to be explicitly structured in the form of an event log, which lists when and by whom different case objects (i.e., process instances) have been subject to the execution of tasks. Unfortunately, in many real world set-ups, such event logs are not explicitly given, but are instead implicitly represented in legacy information systems. To apply process mining in this widespread setting, there is a pressing need for techniques able to support various process stakeholders in data preparation and log extraction from legacy information systems. The purpose of this paper is to single out this challenging, open issue, and didactically introduce how techniques from intelligent data management, and in particular ontology-based data access, provide a viable solution with a solid theoretical basis.  Springer International Publishing AG 2017. Event log extraction; Ontology-based data access; Process mining; Relational database management systems

Multi-level interactive medical process mining In this paper, we present a novel process mining approach, specifically tailored to medical applications, which allows the user to build an initial process model from the hospital event log, and then supports further model refinements, by directly exploiting her knowledge-based model evaluation. In such a way, it supports the interactive construction of the process model at multiple and user-defined levels of abstraction, ranging from a model which perfectly adheres to the input traces (i.e., all of its paths correspond to at least one trace in the log) to models which increasingly loose precision, but gain generality. Our results in the field of stroke management, reported as a case study in this paper, show that our approach can provide relevant advantages with respect to traditional process mining techniques.  Springer International Publishing AG 2017. 

Parallelization of transition counting for process mining on multi-core CPUs and GPUs Many process mining tools and techniques produce output models based on the counting of transitions between tasks or users in an event log. Although this counting can be performed in a forward pass through the event log, when analyzing large event logs according to different perspectives it may become impractical or time-consuming to perform multiple such passes. In this work, we show how transition counting can be parallelized by taking advantage of CPU multi-threading and GPU-accelerated computing. We describe the parallelization strategies, together with a set of experiments to illustrate the performance gains that can be expected with such parallelizations.  Springer International Publishing AG 2017. 

Analyzing the trajectories of patients with sepsis using process mining Process mining techniques analyze processes based on event data. We analyzed the trajectories of patients in a Dutch hospital from their registration in the emergency room until their discharge. We considered a sample of 1050 patients with symptoms of a sepsis condition, which is a life-Threatening condition. We extracted an event log that includes events on activities in the emergency room, admission to hospital wards, and discharge. The event log was enriched with data from laboratory tests and triage checklists. We try to automatically discover a process model of the patient trajectories, we check conformance to medical guidelines for sepsis patients, and visualize the flow of patients on a de-jure process model. The lessons-learned from this analysis are: (1) process mining can be used to clarify the patient flow in a hospital; (2) process mining can be used to check the daily clinical practice against medical guidelines; (3) process discovery methods may return unsuitable models that are difficult to understand for stakeholders; and (4) process mining is an iterative process, e.g., data quality issues are often discovered and need to be addressed. Medical guidelines; Patient trajectories; Process mining

Using Process Mining to Model Multi-UAV Missions through the Experience The interest in civilian missions with multiple unmanned aerial vehicles (UAVs) has increased significantly in recent years, but these missions pose multiple challenges related to operator workload and situational awareness. Human-machine interfaces must consider these challenges and control the amount of information flowing to operators. The authors propose a procedure for automatically modeling multi-UAV missions that uses process mining to discover Petri nets through event logs. Specifically, it applies several discovery algorithms, generates and evaluates models, and determines the best among the four.  2001-2011 IEEE. artificial intelligence; discovery algorithms; intelligent systems; mission modeling; multi-robot; Petri nets; process mining

Visual analytics meets process mining: Challenges and opportunities Event data or traces of activities often exhibit unexpected behavior and complex relations. Thus, before and during the application of automated analysis methods, such as process mining algorithms, the analyst needs to investigate and understand the data at hand in order to decide which analysis methods might be appropriate. Visual analytics integrates the outstanding capabilities of humans in terms of visual information exploration with the enormous processing power of computers to form a powerful knowledge discovery environment. The combination of visual data exploration with process mining algorithms makes complex information structures more comprehensible and facilitates new insights. In this position paper I portray various concepts of interactive visual support for process mining, focusing on the challenges, but also the great opportunities for analyzing process data with visual analytics methods.  IFIP International Federation for Information Processing 2017. Challenges; Visual analytics; Visual process mining

Inferring the repetitive behaviour from event logs for process mining discovery This paper addresses the problem of discovering a sound Workflow net (WFN) from event traces representing the behavior of a discrete event process. A novel and efficient method for inferring the repetitive behaviour in a workflow log is proposed. It is based on an iterative search and filtering of cycles computed in each trace; a graph of causal relations is built for each cycle, which helps to find the supports of the t-invariants of an extended WFN. The t-invariants are used for determining causal and concurrent relations between events, allowing building the WFN efficiently in a complete discovery technique.  2017, Springer International Publishing AG. Petri nets discovery; Process mining; t-invariants

Interoperability assessment in health systems based on process mining and MCDA methods Healthcare processes are complex and require a high-level of interdisciplinary cooperation among the different specialists and sectors involved in their delivery. Information flows among organizational entities, sectors, areas and employees represent possible risks of low process interoperability as well as of non-compliance between business rules and actual process deliveries. In addition to this complexity, the Brazilian healthcare area has well-known problems in its public and private health care systems. These problems are of structural, organizational and financial natures, reflecting the low value attributed to quality and to the actual services provided evidenced in recent surveys of Instituto Data Folha and the Brazilian Ministry of Health (Ministério da Saúde). The extraction of process data logs, and the use of process mining, enables extraction of qualitative and quantitative indicators for hospital processes. On top of these, multi-criteria decision analysis (MCDA) tools can be used for analysis and decision making in support to process diagnosis. This paper aims to propose the joint use of process data mining and multi-criteria decision analysis (MCDA) methods in analysing and identifying organizational performance levels in a particular hospital process. In order to accomplish this, a case study was carried out through the use of treatment data logs of venous chemotherapy patients at the Erasto Gaertner Hospital, located in Curitiba  PR, Brazil, a local reference in cancer treatments.  Springer International Publishing AG 2017. Health care; Indicators; Interoperability; Maturity model; Multiple-criteria decision analysis; Performance; Process mining

Managing business process variability through process mining and semantic reasoning: An application in healthcare Managing process variability enable the process model adaptability according changes in the application environment. In the healthcare area, flexibility is essential to provide a quality treatment because, even patients with the same diagnostic, may follow different paths and suffer different proceedings. Besides, there are many aspects to be considered for the selection of a path, as patients symptoms, and clinical guidelines, among others. In this context, this research presents a framework for the management of the process variants through semantic reasoning. The enrichment of the business process with semantics enables the automation of the configuration, thus promoting more flexible and adaptive solutions. The proposed framework helps selecting the appropriate process variant according the patients symptoms by reasoning on ontologies based known expertise. In our specific use case, we will use the expertise of the Brazilian guideline for acute ischemic stroke.  IFIP International Federation for Information Processing 2017. Process mining; Process variability; Semantic reasoning

Toward a new generation of log pre-processing methods for process mining Real-life processes are typically less structured and more complex than expected by stakeholders. For this reason, process discovery techniques often deliver models less understandable and useful than expected. In order to address this issue, we propose a method based on statistical inference for pre-processing event logs. We measure the distance between different segments of the event log, computing the probability distribution of observing activities in specific positions. Because segments are generated based on time-domain, business rules or business management system properties, we get a characterisation of these segments in terms of both business and process aspects. We demonstrate the applicability of this approach by developing a case study with real-life event logs and showing that our method is offering interesting properties in term of computational complexity.  Springer International Publishing AG 2017. Event-log clustering; Lightweight trace profiling; Pre-processing; Process mining

An exploratory study on usage of process mining in agile software development Agile software development methods have become popular in the software development field during the last decade. Majority of software organizations develop or claim to develop software based on agile methods. Process mining is a process management technique that allows for the analysis of business processes based on the event logs. The aim of process mining is to discover, monitor and improve real processes, but not assumed processes, by extracting knowledge from event logs readily available in information systems. Process mining can be used to discover agile processes followed in organizations/projects to determine the actual processes followed. Process mining can also establish the necessary evidences for assessing or measuring the agility of organizations. This study explores the usability of process mining methods in agile software development context. The results of an exploratory case study on using process mining techniques in a software project managed by Scrum are depicted. We also discuss the benefits of the process mining techniques used and compare different tools utilized.  Springer International Publishing AG 2017. Agile software development; Process conformance checking; Process discovery; Process mining

pMineR: An innovative R library for performing process mining in medicine Process Mining is an emerging discipline investigating tasks related with the automated identification of process models, given realworld data (Process Discovery). The analysis of such models can provide useful insights to domain experts. In addition, models of processes can be used to test if a given process complies (Conformance Checking) with specifications. For these capabilities, Process Mining is gaining importance and attention in healthcare. In this paper we introduce pMineR, an R library specifically designed for performing Process Mining in the medical domain, and supporting human experts by presenting processes in a human-readable way.  Springer International Publishing AG 2017. Decision support system; Process mining; R

Process mining approach to discover shopping behavior process model in ecommerce web sites using click stream data Process mining uses the click stream data of the website by the user's to automatically discover and extract information (Knowledge) from Web documents and services of ecommerce sites. Process mining acts as a bridge between data mining and web mining. The method of general web access pattern is extracted and analyzed using knowledge discovery techniques to understand the usage patterns of the customers. This paper have a clear insight of Process mining , observation of web usage by customers (click stream data) as sequence of tasks, and analysis and study on classification of users two important shopping behavior as bargain shopper and surgical shopper. The workflow model of these two types of shoppers and their real time behavior are analyzed using process mining tool and the observed model is shown in the petrinet.  IAEME Publication. Click stream analysis; Customer shopping behavior; Petrinet; Process mining; Work flow model

Improving pattern detection in healthcare process mining using an interval-based event selection method Clinical pathways are highly variable and although many patients may follow similar pathway each individual will experience a unique set of events, for example with multiple repeated activities or varied sequences of activities. Process mining techniques are able to discover generalizable pathways based on data mining of event logs but using process mining techniques on a raw clinical pathway data to discover underlying healthcare processes is challenging due to this high variability. This paper involves two main contributions to healthcare process mining. The first contribution is developing a novel approach for event selection and outlier removing in order to improve pattern detection and thus representational quality. The second contribution is to demonstrate a new open access medical dataset, the MIMIC-III (Medical Information Mart for Intensive Care) database, which has not been used in process mining publications. In this paper, we developed a new method for variations reduction in clinical pathways data. Variation can result from outlier events that prevent capturing clear patterns. Our approach targets the behavior of repeated activities. It uses interval-based patterns to determine outlier threshold based on the time of events occurring and the distinctive attribute of observed events. The approach is tested on clinical pathways data for diabetes patients with congestive heart failure extracted from the MIMIC-III medical database and analyzed using the ProM process mining tool. The method has improved model precision conformance without reducing model fitness. We were able to reduce the number of events while making sure the mainstream patterns were unaffected. We found that some activity types had a large number of outlier events whereas other activities had a relatively few. The interval-based event selection method has the potential of improve process visualization. This approach is undergoing implementation as an event log enhancement technique in the ProM tool.  Springer International Publishing AG 2017. Event log quality; Feature selection; Healthcare processes; Interval pattern; MIMIC-III; Process mining; Variation reduction

DTminer: A tool for decision making based on historical process data Process mining is a discipline that uses techniques to extract knowledge from event logs recorded by information systems in most companies these days. Among main perspectives of process mining, organizational and time perspectives focus on information about resources stored on the event logs and timing and frequency of the events, respectively. In this paper we introduce a method that combines organizational and time perspectives of process mining with a decision support tool called decision trees. The method takes the information of historical process data by means of an event log, generates a decision tree, annotates the decision tree with processing times, and recommends the best performer for a given running instance of the process. We finally illustrate the method through several experiments using a developed plug-in for the process mining framework ProM, first using synthetic data and then using a real-life event log.  Springer International Publishing Switzerland 2013. Decision making; Decision tree; Process mining tool; Recommendation

Using domain knowledge to enhance process mining results Process discovery algorithms typically aim at discovering process models from event logs. Most algorithms achieve this by solely using an event log, without allowing the domain expert to influence the discovery in any way. However, the user may have certain domain expertise which should be exploited to create better process models. In this paper, we address this issue of incorporating domain knowledge to improve the discovered process model. First, we present a verification algorithm to verify the presence of certain constraints in a process model. Then, we present three modification algorithms to modify the process model. The outcome of our approach is a Pareto front of process models based on the constraints specified by the domain expert and common quality dimensions of process mining.  IFIP International Federation for Information Processing 2017. Algorithm post processing; Declare templates; Domain knowledge; User guided process discovery

Challenges in knowledge-intensive processes. Mining from semi-structured information and providing run-time automated adaptation [No abstract available] 

A relational data warehouse for multidimensional process mining Multidimensional process mining adopts the concept of data cubes to split event data into a set of homogenous sublogs according to case and event attributes. For each sublog, a separated process model is discovered and compared to other models to identify group-specific differences for the process. For an effective explorative process analysis, performance is vital due to the explorative characteristics of the analysis. We propose to adopt well-established approaches from the data warehouse domain based on relational databases to provide acceptable performance. In this paper, we present the underlying relational concepts of PMCube, a data-warehouse-based approach for multidimensional process mining. Based on a relational database schema, we introduce generic query patterns which map OLAP queries onto SQL to push the operations (i.e. aggregation and filtering) to the database management system. We evaluate the run-time behavior of our approach by a number of experiments. The results show that our approach provides a significantly better performance than the state-of-the-art for multidimensional process mining and scales up linearly with the number of events.  IFIP International Federation for Information Processing 2017. 

Process adaptation patterns for cross-organizational business process modeling Nowadays organizations collaborate through cross-organizational business processes. These business processes require the coordination of several partners who are often geographically dispersed. Modeling such processes is complex and requires that designers have extensive experience in particular when organizations' processes are incompatible. This paper addresses the problem of modeling cross-organization processes out of collection of organizations private process models. To this end, we propose a set of process adaptation patterns that connect private processes and resolve interoperability issues. Proposed patterns are formalized with workflow net. Copyright  2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved. Business Patterns; Business Process Integration; Business Process Modeling; Process Adaptation Patterns; Process Mining; Workflow Net

Missing data problem in the event logs of transport processes Data and process mining techniques are very helpful in analyzing transport problems. The model of the process can be built using the available data. It leads to make possible the operational support which improves the process. Very important task is to record data in the proper way. Unfortunately some errors may occur. In this kind of situation some data lacks can be observed. On the other hand the data may be complete but having very high error coefficient. The model of the process should have as minimum error as possible and has to be reliable. Although some missing data can occur, there are some ways to do some data recovery. In this paper the problem of missing numerical data in the event log is described. Different solutions and conclusions are presented.  2017, Springer International Publishing AG. Data lack; Data mining; Event log; Missing data; Process mining

Mining encrypted software logs using alpha algorithm The growing complexity of software with respect to technological advances encourages model-based analysis of software systems for validation and verification. Process mining is one recently investigated technique for such analysis which enables the discovery of process models from event logs collected during software execution. However, the usage of logs in process mining can be harmful to the privacy of data owners. While for a software user the existence of sensitive information in logs can be a concern, for a software company, the intellectual property of their product and confidential company information within logs can pose a threat to company's privacy. In this paper, we propose a privacy-preserving protocol for the discovery of process models for software analysis that assures the privacy of users and companies. For this purpose, our proposal uses encrypted logs and processes them using cryptographic protocols in a two-party setting. Furthermore, our proposal applies data packing on the cryptographic protocols to optimize computations by reducing the number of repetitive operations. The experiments show that using data packing the performance of our protocol is promising for privacy-preserving software analysis. To the best of our knowledge, our protocol is the first of its kind for the software analysis which relies on processing of encrypted logs using process mining techniques. Copyright  2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved. Applied Cryptography; Homomorphic Encryption; Software Privacy; Software Process Mining

Towards simulation- and mining-based translation of resource-aware process models Imperative languages like BPMN are eminently suitable for representing routine processes and are likewise cumbersome in case of flexible processes. The latter are easier to describe using declarative process modeling languages (DPMLs). However, understandability and tool support of DPMLs are comparatively poor. Additionally, there may be an affinity to a particular language caused by existing company infrastructure or individual preferences. Hence, a technique for automatically translating process models between different languages is required. Process models usually describe several aspects of a process, such as activity orderings and role assignments. Therefore, our approach focuses on translating resource-aware process models. We utilize well-established techniques for process simulation and mining to avoid the definition of cumbersome model transformation rules. Our implementation is based on a discussion of general configuration principles and a concrete configuration suggestion. The whole translation approach is discussed and evaluated at the example of BPMN and DPIL.  Springer International Publishing AG 2017. Process mining; Process model translation; Simulation

Mining projects from structured and unstructured data Companies working on safety-critical projects must adhere to strict rules imposed by the domain, especially when human safety is involved. These projects need to be compliant to standard norms and regulations. Thus, all the process steps must be clearly documented in order to be verifiable for compliance in a later stage by an auditor. Nevertheless, documentation often comes in the form of manually written textual documents in different formats. Moreover, the project members use diverse proprietary tools. This makes it difficult for auditors to understand how the actual project was conducted. My research addresses the project mining problem by exploiting logs from project-generated artifacts, which come from software repositories used by the project team. Process mining; Project-oriented business processes; Software projects

Towards a multi-parametric visualisation approach for business process analytics Visualisation is an integral part of many scientific areas and is reportedly an important tool for learning and teaching. One reason for this is the picture superior effect. Nevertheless, little research endeavour has been carried out so far to effectively apply visualisation principles to the emerging field of business process analytics. In this paper a novel multi-parametric visualisation approach is proposed in such a context. General visualisation principles are used to create, evaluate, and improve the approach in the design process. They are drawn from a wide range of fields, and are synthesised from theory and empirical evidence.  Springer International Publishing AG 2017. Business process analytics; Business process management; Process mining; Visualisation

Business Process Intelligence tools This chapter analyzes contemporary software tools enabling Business Process Intelligence (BPI). BPI is one of the emerging trends in enterprise computing, which allows companies and organizations to maximize the value derived from their business processes. Moreover, BPI constitutes an umbrella term that summarizes different software tools, methods and best practices for real-time process analytics. The chapter presents an analysis of the features as well as the strengths and weaknesses of contemporary BPI tools along two characteristic application strategies of modern enterprises.  2017, Springer International Publishing AG. Business process intelligence; Process mining; Process performance measurement

Discovery of dependency relations in sequential data flow The idea of extracting knowledge from log data for both data mining and process mining emphasises data flow and relations among data items in the data. Unfortunately, challenges have been encountered when working with the data flow and relations. One of the challenges is that the representation of the data flow between a pair of elements or tasks is insufficiently simplified and formulated, as it considers only a one-to-one data flow relation. In this paper, we discuss how to effectively represent dependency relations in log data. To this end, we introduce a new representation of the data flow and dependency formulation using an extracted flow graph. The solution solves the issue of the insufficiency of presenting other relation types, such as many-to-one and one-to-many relations. As an experiment, a new evaluation framework is applied to the Teleclaim process in order to show how this method can provide us with more precise results when compared with other definitions.  2017-IOS Press and the authors. Data flow; Data mining; Dependency; Flow graph; Process mining

Responsible data science: Using event data in a people friendly manner The omnipresence of event data and powerful process mining techniques make it possible to quickly learn process models describing what people and organizations really do. Recent breakthroughs in process mining resulted in powerful techniques to discover the real processes, to detect deviations from normative process models, and to analyze bottlenecks and waste. Process mining and other data science techniques can be used to improve processes within any organization. However, there are also great concerns about the use of data for such purposes. Increasingly, customers, patients, and other stakeholders worry about irresponsible forms of data science. Automated data decisions may be unfair or non-transparent. Confidential data may be shared unintentionally or abused by third parties. Each step in the data science pipeline (from raw data to decisions) may create inaccuracies, e.g., if the data used to learn a model reflects existing social biases, the algorithm is likely to incorporate these biases. These concerns could lead to resistance against the large-scale use of data and make it impossible to reap the benefits of process mining and other data science approaches. This paper discusses Responsible Process Mining (RPM) as a new challenge in the broader field of Responsible Data Science (RDS). Rather than avoiding the use of (event) data altogether, we strongly believe that techniques, infrastructures and approaches can be made responsible by design. Not addressing the challenges related to RPM/RDS may lead to a society where (event) data are misused or analysis results are deeply mistrusted.  Springer International Publishing AG 2017. Accuracy; Big data; Confidentiality; Data science; Fairness; Process mining; Transparency

Guest Editorial: Advances in Web Services Research Research on Web Services and Services Computing began shortly after the start of the new millennium and with the first major research conference on the subject, the International Conference on Web Services, starting in 2003. Due to the new and practical utility of Web service technology, many researchers began to work in this field. New ideas, applications and related technologies continue to invigorate this discipline. This special issue of IEEE Transactions on Services Computing considers four such topics that lead to "Advances in Web Services Research": Cloud Services; Polices and Agreements; Services Engineering; and Service/Process Mining. It consists of the best extended papers from the two premier research conferences on services computing: the 2015 IEEE International Conference on Web Services and the 2015 IEEE Conference on Services Computing.  2016 IEEE. cloud services; policies and agreements; service/process mining; services computing; services engineering; Web services

Discovering hierarchical consolidated models from process families Process families consist of different related variants that represent the same process. This might include, for example, processes executed similarly by different organizations or different versions of a same process with varying features. Motivated by the need to manage variability in process families, recent advances in process mining make it possible to discover, from a collection of event logs, a generic process model that explicitly describes the commonalities and differences across variants. However, existing approaches often result in flat complex models where it is hard to obtain a comparative insight into the common and different parts, especially when the family consists of a large number of process variants. This paper presents a decomposition-driven approach to discover hierarchical consolidated process models from collections of event logs. The discovered hierarchy consists of nested process fragments and allows to browse the variability at different levels of abstraction. The approach has been implemented as a plugin in ProM and was evaluated using synthetic and real-life event logs.  Springer International Publishing AG 2017. Configurable fragments; Consolidated process families; Decomposed discovery; Hierarchical configurable models; Process mining

An approach for incorporating expert knowledge in trace clustering Trace clustering techniques are a set of approaches for partitioning traces or process instances into similar groups. Typically, this partitioning is based on certain patterns or similarity between the traces, or done by discovering a process model for each cluster of traces. In general, however, it is likely that clustering solutions obtained by these approaches will be hard to understand or difficult to validate given an experts domain knowledge. Therefore, we propose a novel semi-supervised trace clustering technique based on expert knowledge. Our approach is validated using a case in tablet reading behaviour, but widely applicable in other contexts. In an experimental evaluation, the technique is shown to provide a beneficial trade-off between performance and understandability.  Springer International Publishing AG 2017. Domain knowledge; Process mining; Semi-supervised learning; Trace clustering

An Investigation of Human Trajectories in Ski Resorts Analyzing human trajectories based on sensor data is a challenging research topic. It has been analyzed from many aspects like clustering, process mining, and others. Still, less attention has been paid on analyzing this data based on hidden factors that drive the behavior of people. We, therefore, adapt the standard matrix factorization approach and reveal factors which are interpretable and soundly explain the behavior of a dynamic population. We analyze the motion of a skier population based on data from RFID-recorded ski entrances of skiers on ski lift gates. The approach is applicable to other similar settings, like shopping malls or road traffic. We further applied recommender systems algorithms for testing how well we can predict the distribution of ski lift usage (number of ski lift visits) based on hidden factors, but also on other benchmark algorithms. The matrix factorization algorithm showed to be the best recommender score predictor with an RMSE of 2.569 ± 0.049 and an MAE of 1.689 ± 0.019 on a 1 to 10 scale.  2017, Springer International Publishing AG. Matrix factorization; Principal component analysis; Recommender systems; Ski lift transportation patterns

Data-driven process discovery - Revealing conditional infrequent behavior from event logs Process discovery methods automatically infer process models from event logs. Often, event logs contain so-called noise, e.g., infrequent outliers or recording errors, which obscure the main behavior of the process. Existing methods filter this noise based on the frequency of event labels: infrequent paths and activities are excluded. However, infrequent behavior may reveal important insights into the process. Thus, not all infrequent behavior should be considered as noise. This paper proposes the Data-aware Heuristic Miner (DHM), a process discovery method that uses the data attributes to distinguish infrequent paths from random noise by using classification techniques. Data- and control-flow of the process are discovered together. We show that the DHM is, to some degree, robust against random noise and reveals data-driven decisions, which are filtered by other discovery methods. The DHM has been successfully tested on several real-life event logs, two of which we present in this paper.  Springer International Publishing AG 2017. Event logs; Noise; Process discovery; Process mining; Rules

Extended process models for activity prediction In addition to the classical exploitation as a means for checking process enactment conformance, process models may be used to predict which activities will be carried out next. The prediction performance may provide indirect indications on the correctness and reliability of a process model. This paper proposes a strategy for activity prediction using the WoMan framework for workflow management. It extends a previous approach, that has proved to be able to handle complex processes. Experimental results on different domains show an increase in prediction performance compared to the previous approach.  Springer International Publishing AG 2017. Activity prediction; Process mining; Process model

Unsupervised Event Abstraction using Pattern Abstraction and Local Process Models Process mining analyzes business processes based on events stored in event logs. However, some recorded events may correspond to activities on a very low level of abstraction. When events are recorded on a too low level of abstraction, process discovery methods tend to generate overgeneralizing process models. Grouping low-level events to higher level activities, i.e., event abstraction, can be used to discover better process models. Existing event abstraction methods are mainly based on common sub-sequences and clustering techniques. In this paper, we propose to first discover local process models and, then, use those models to lift the event log to a higher level of abstraction. Our conjecture is that process models discovered on the obtained high-level event log return process models of higher quality: Their fitness and precision scores are more balanced. We show this with preliminary results on several real-life event logs. Event abstraction; Process discovery; Unsupervised learning

Activity prediction in process management using the WoMan framework In addition to the classical exploitation of process models for checking process enactment conformance, a very relevant but almost neglected task concerns the prediction of which activities will be carried out next at a given moment during process execution. The outcomes of this task may allow to save time and money by taking suitable actions that facilitate the execution of those activities, may support more fundamental and critical tasks involved in automatic process management, and may provide indirect indications on the correctness and reliability of a process model. This paper proposes an enhanced declarative process model formalism and a strategy for activity prediction using the WoMan framework for workflow management. Experimental results on different domains show very interesting prediction performance.  Springer International Publishing AG 2017. Activity prediction; Process mining; Process model

An universal approach for compliance management using compliance descriptors Trends like outsourcing and cloud computing have led to a distribution of business processes among different IT systems and organizations. Still, businesses need to ensure compliance regarding laws and regulations of these distributed processes. This need gave way to many new solutions for compliance management and checking. Compliance requirements arise from legal documents and are implemented in all parts of enterprise IT, creating a business IT gap between legal texts and software implementation. Compliance solutions must bridge this gap as well as support a wide variety of compliance requirements. To achieve these goals, we developed an integrating compliance descriptor for compliance modeling on the legal, requirement and technical level, incorporating arbitrary rule languages for specific types of requirements. Using a modeled descriptor a compliance checking architecture can be configured, including specific rule checking implementations. The graphical notation of the compliance descriptor and the formalism its based on are described and evaluated using a prototype as well as expert interviews. Based on evaluation results, an extension for compliance management in unstructured processes is outlined.  Springer International Publishing AG 2017. Business process compliance; Business process management; Compliance modeling; Model-driven architecture; Process mining

Analyzing process variants to understand differences in key performance indices Service delivery organizations cater similar processes across several clients. Process variants may manifest due to the differences in the nature of clients, heterogeneity in the type of cases, etc. The organizations operational Key Performance Indices (KPIs) across these variants may vary, e.g., KPIs for some variants may be better than others. There is a need to gain insights for such variance in performance and seek opportunities to learn from well performing process variants (e.g., to establish best practices and standardization of processes) and leverage these learnings/insights on non-performing ones. In this paper, we present an approach to analyze two or more process variants, presented as annotated process maps. Our approach identifies and reasons the key differences, manifested in both the control-flow (e.g., frequent paths) and performance (e.g., flow time, activity execution times, etc.) perspectives, among these variants. The fragments within process variants where the key differences manifest are targets for process redesign and re-engineering. The proposed approach has been implemented as a plug-in in the process mining framework, ProM, and applied on real-life case studies.  Springer International Publishing AG 2017. Annotations; Pair-wise; Process comparison; Process mining; Process variants; Unified process model

Automatic discovery of object-centric behavioral constraint models Process discovery techniques have successfully been applied in a range of domains to automatically discover process models from event data. Unfortunately existing discovery techniques only discover a behavioral perspective of processes, where the data perspective is often as a second-class citizen. Besides, these discovery techniques fail to deal with object-centric data with many-to-many relationships. Therefore, in this paper, we aim to discover a novel modeling language which combines data models with declarative models, and the resulting object-centric behavioral constraint model is able to describe processes involving interacting instances and complex data dependencies. Moreover we propose an algorithm to discover such models.  Springer International Publishing AG 2017. Cardinality constraints; Object-centric modeling; Process discovery; Process mining

Everything you always wanted to know about your process, but did not know how to ask The size of execution data available for process mining analysis grows several orders of magnitude every couple of years. Extracting and selecting the relevant data to be analyzed on each case represents an open challenge in the field. This paper presents a systematic literature review on different approaches to query process data and establish their provenance. In addition, a new query language is proposed, which overcomes the limitations identified during the review. The proposal is based on a combination of data and process perspectives. It provides simple constructs to intuitively formulate questions. An implementation of the language is provided, together with examples of queries to be applied on different aspects of the process analysis.  Springer International Publishing AG 2017. Databases; Event logs; Process mining; Query languages

Time series petri net models enrichment and prediction Operational support as an area of process mining aims to predict the performance of individual cases and the overall business process. Although seasonal effects, delays and performance trends are well-known to exist for business processes, there is up until now no prediction model available that explicitly captures seasonality. In this paper, we introduce time series Petri net models. These models integrate the control flow perspective of Petri nets with time series prediction. Our evaluation on the basis of our prototypical implementation demonstrates the merits of this model in terms of better accuracy in the presence of time series effects.  IFIP International Federation for Information Processing 2017. Business intelligence; Petri nets; Predictive analytics; Time series

A non-compensatory approach for trace clustering One of the main functions of process mining is the automated discovery of process models from event log files. However, in flexible environments, such as healthcare or customer service, delivering comprehensible process models can be very challenging, mainly due to the complexity of the registered logs. A prevalent response to this problem is trace clustering, that is, grouping behaviors and discovering a distinct model per group. In this paper, we propose a novel trace clustering technique inspired from the outranking relations theory. The proposed technique can handle multiple criteria with strongly heterogeneous scales, and it allows a non-compensatory logic to guide the creation of a similarity metric. To reach this, we use three key components: We separate factors that are in favor of the similarity from those that are not, through discrimination thresholds; we provide non-concordant factors with a "veto" power; and we aggregate all factors into an overall metric. We evaluated this novel, non-compensatory approach against two of the most spotlighted trace clustering functions: variants' identification and model complexity reduction. Results suggest that the proposed technique can be used at both functions with compelling performance.  2017 The Authors. Multiple criteria decision aid; Process mining; Trace clustering

Aligning modeled and observed behavior: A compromise between computation complexity and quality Certifying that a process model is aligned with the real process executions is perhaps the most desired feature a process model may have: aligned process models are crucial for organizations, since strategic decisions can be made easier on models instead of on plain data. In spite of its importance, the current algorithmic support for computing alignments is limited: either techniques that explicitly explore the model behavior (which may be worst-case exponential with respect to the model size), or heuristic approaches that cannot guarantee a solution, are the only alternatives. In this paper we propose a solution that sits right in the middle in the complexity spectrum of alignment techniques; it can always guarantee a solution, whose quality depends on the exploration depth used and local decisions taken at each step. We use linear algebraic techniques in combination with an iterative search which focuses on progressing towards a solution. The experiments show a clear reduction in the time required for reaching a solution, without sacrificing significantly the quality of the alignment obtained.  Springer International Publishing AG 2017. Alignments; Conformance checking; Heuristics; ILP; Process mining

Multi-objective trace clustering: Finding more balanced solutions In recent years, a multitude of techniques has been proposed for the task of clustering traces. In general, these techniques either focus on optimizing their solution based on a certain type of similarity between the traces, such as the number of insertions and deletions needed to transform one trace into another; by mapping the traces onto a vector space model, based on certain patterns in each trace; or on the quality of a process model discovered from each cluster. Currently, the main technique of the latter category, ActiTraC, constructs its clusters based on a single objective: fitness. However, a typical view in process discovery is that one needs to balance fitness, generalization, precision and simplicity. Therefore, a multi-objective approach to trace clustering is deemed more appropriate. In this paper, a thorough overview of current trace clustering techniques and potential approaches for multi-objective trace clustering is given. Furthermore, a multi-objective trace clustering technique is proposed. Our solution is shown to provide unique results on a number of real-life event logs, validating its existence.  Springer International Publishing AG 2017. Multi-objective learning; Process mining; Process model quality; Trace clustering

A multi-criteria approach for team recommendation Team recommendation is a key and little-explored aspect within the area of business process management. The efficiency with which the team is conformed may influence the success of the process execution. The formation of work teams is often done manually, without a comparative analysis based on multiple criteria between the individual performance of the resources and their collective performance in different teams. In this article, we present a multi-criteria framework to allocate work teams dynamically. The framework considers four elements: (i) a resource request characterization, (ii) historical information on the process execution and expertise information, (iii) different metrics which calculate the suitability of the work teams taking into account both individual performance as well as collective performance of the resources, and (iv) a recommender system based on the Best Position Algorithm (BPA2) to obtain a ranking for the recommended work teams. A software development process was used to test the usefulness of our approach.  Springer International Publishing AG 2017. Business processes; Organizational perspective; Process mining; Recommender systems; Resource allocation; Team recommendation

Model checking of mixed-paradigm process models in a discovery context: Finding the fit between declarative and procedural The act of retrieving process models from event-based data logs can offer valuable information to business owners. Many approaches have been proposed for this purpose, mining for either a procedural or declarative outcome. A blended approach that combines both process model paradigms exists and offers a great way to deal with process environments which consist of different layers of flexibility. In this paper, it will be shown how to check such models for correctness, and how this checking can contribute to retrieving the models as well. The approach is based on intersecting both parts of the model and provides an effective way to check (i) whether the behavior is aligned, and (ii) where the model can be improved according to errors that arise along the respective paradigms. To this end, we extend the functionality of Fusion Miner, a mixed-paradigm process miner, in a way to inspect which amount of flexibility is right for the event log. The procedure is demonstrated with an implemented model checker and verified on real-life event logs.  Springer International Publishing AG 2017. Declarative process models; Model checking; Process mining

Discovering causal factors explaining business process performance variation Business process performance may be affected by a range of factors, such as the volume and characteristics of ongoing cases or the performance and availability of individual resources. Event logs collected by modern information systems provide a wealth of data about the execution of business processes. However, extracting root causes for performance issues from these event logs is a major challenge. Processes may change continuously due to internal and external factors. Moreover, there may be many resources and case attributes influencing performance. This paper introduces a novel approach based on time series analysis to detect cause-effect relations between a range of business process characteristics and process performance indicators. The scalability and practical relevance of the approach has been validated by a case study involving a real-life insurance claims handling process.  Springer International Publishing AG 2017. Performance analysis; Process mining; Root cause analysis

A new framework for defining realistic SLAs: An evidence-based approach In a changing and competitive business world, business processes are at the heart of modern organizations. In some cases, service level agreements (SLAs) are used to regulate how these business processes are provided. This is usually the case when the business process is outsourced, and some guarantees about how the outsourcing service is provided are required. Although some work has been done concerning the structure of SLAs for business processes, the definition of service level objectives (SLOs) remains a manual task performed by experts based on their previous knowledge and intuition. Therefore, an evidence-based approach that curtails humans involvement is required for the definition of realistic while challenging SLOs. This is the purpose of this paper, where performance-focused process mining, goal programming optimization techniques, and simulation techniques have been availed to implement an evidence-based framework for the definition of SLAs. Furthermore, the applicability of the proposed framework has been evaluated in a case study carried out in a hospital scenario.  Springer International Publishing AG 2017. Goal programming; Optimization; Process mining; Process performance indicators; Service level agreement; Simulation

Checking process compliance on the basis of uncertain event-to-activity mappings A crucial requirement for compliance checking techniques is that observed behavior, captured in event traces, can be mapped to the process models that specify allowed behavior. Without a mapping, it is not possible to determine if observed behavior is compliant or not. A considerable problem in this regard is that establishing a mapping between events and process model activities is an inherently uncertain task. Since the use of a particular mapping directly influences the compliance of a trace to a specification, this uncertainty represents a major issue for compliance checking. To overcome this issue, we introduce a probabilistic compliance checking method that can deal with uncertain mappings. Our method avoids the need to select a single mapping, but rather works on a spectrum of possible mappings. A quantitative evaluation demonstrates that our method can be applied on a considerable number of real-world processes where traditional compliance checking methods fail.  Springer International Publishing AG 2017. Compliance checking; Event-to-activity mapping; Matching; Process mining; Uncertainty

Extracting clinical-event-packages from billing data for clinical pathway mining Clinical pathway can be used to reduce medical cost and improve medical efficiency. Traditionally, clinical pathways are designed by experts based on their experience. However, it is time consuming and sometimes not adaptive for specific hospitals, and mining clinical pathways from historic data can be helpful. Clinical pathway naturally can be regarded as a kind of process, and process mining can be used for clinical pathway mining. However, due to the complexity and dynamic of medical behaviors, traditional process mining methods often generate spaghetti-like clinical pathways with too many nodes and edges. To reduce the number of nodes in the resulting models, we put correlated events into clinical-event-packages as new units of log event for further mining. The experiment results has shown that our approach is a good way of generating more comprehensible clinical process as well as packages with better quality according to medical practitioners.  Springer International Publishing AG 2017. Clinical process; Clinical-event-package; Process mining

An approach for hospital planning with multi-agent organizations The background for this paper is a development that the Danish hospitals are undertaking which requires the establishment of a common emergency department. It is uncertain exactly what and how many resources the department needs and so resources are assigned dynamically as seen necessary by the staff. Such dynamic adjustments pose a challenge in predicting what consequences these adjustments may lead to. We propose an approach to deal with this challenge that applies simulation with intelligent agents and logics for organizational reasoning. We present some of the expected obstacles with this approach and potential ways to overcome them.  Springer International Publishing AG 2017. Logic; Multi-agent organizations; Process mining; Simulation; Soft computing

An interest-based tour planning tool by process mining from Twitter In this paper, we proposed a new concept of tour, named interest-based tour, and based on this new concept, we have developed a tour planning tool. The interest-based tour is literally a tour to visit places related to a given interest. Interest argued in this paper is not limited to only point such as things and places. We extend the concept of interest to line (e.g. a famous person's history) and area (e.g. the Age of Discovery). Social network site (SNS) enables us to find travel experiences of visiting places related to the interest. So we use Twitter to collect travel experiences related to the given interest, then use process mining technique to make these experiences into a tour plan.  2016 IEEE. 

Clustering-Based Predictive Process Monitoring The enactment of business processes is generally supported by information systems that record data about each process execution (a.k.a. case). This data can be analyzed via a family of methods broadly known as process mining. Predictive process monitoring is a process mining technique concerned with predicting how running (uncompleted) cases will unfold up to their completion. In this paper, we propose a predictive process monitoring framework for estimating the probability that a given predicate will be fulfilled upon completion of a running case. The framework takes into account both the sequence of events observed in the current trace, as well as data attributes associated to these events. The prediction problem is approached in two phases. First, prefixes of previous (completed) cases are clustered according to control flow information. Secondly, a classifier is built for each cluster using event data attributes to discriminate between cases that lead to a fulfillment of the predicate under examination and cases that lead to a violation within the cluster. At runtime, a prediction is made on a running case by mapping it to a cluster and applying the corresponding classifier. The framework has been implemented in the ProM toolset and validated on a log pertaining to the treatment of cancer patients in a large hospital. IEEE clustering; Decision trees; Encoding; Medical services; Monitoring; Payloads; predictive monitoring; process mining; Runtime; sequence classification; Training

Conformance checking based on multi-perspective declarative process models Process mining is a family of techniques that aim at analyzing business process execution data recorded in event logs. Conformance checking is a branch of this discipline embracing approaches for verifying whether the behavior of a process, as recorded in a log, is in line with some expected behavior provided in the form of a process model. Recently, techniques for conformance checking based on declarative specifications have been developed. Such specifications are suitable to describe processes characterized by high variability. However, an open challenge in the context of conformance checking with declarative models is the capability of supporting multi-perspective specifications. This means that declarative models used for conformance checking should not only describe the process behavior from the control flow point of view, but also from other perspectives like data or time. In this paper, we close this gap by presenting an approach for conformance checking based on MP-Declare, a multi-perspective version of the declarative process modeling language Declare. The approach has been implemented in the process mining tool ProM and has been experimented using artificial and real-life event logs.  2016 Elsevier Ltd Business constraints; Conformance checking; Declare; Linear temporal logic; Process mining

Process mining in oncology: A literature review Process mining, an emerging data analytics method, has been used effectively in various healthcare contexts including oncology, the study of cancer. Cancer is a complex disease with many complicated care requirements and there is an urgent need to improve the cost and clinical effectiveness of cancer care pathways. Process mining of the e-health records of cancer patients may play an important future role and this paper presents a literature review of process mining in oncology as a contribution to this research. The search produced 758 articles which were manually reviewed by title, abstract, and full paper text review to develop the original pool of papers. An in-depth ancestor search was used to gather additional articles from the references of the original pool. These steps resulted in 37 papers. Through a thematic review process, the papers were analysed and five themes emerged. These were: 1) process and data types; 2) research questions; 3) techniques, perspectives and tools; 4) methodologies; 5) limitations and future work. This review can: (i) highlight the potential value of process mining for improving cancer care processes (ii) provide a useful overview of the current work undertaken; (iii) help researchers to choose process mining algorithms, techniques, tools, methodologies and approaches; and (iv) identify research opportunities in this new field of study.  2016 IEEE. cancer; clinical pathways; data mining; oncology; process mining

A Cross-Organizational Process Mining Framework for Obtaining Insights from Software Products: Accurate Comparison Challenges Software vendors offer various software products to large numbers of enterprises to support their organization, in particular Enterprise Resource Planning (ERP) software. Each of these enterprises use the same product for similar goals, albeit with different processes and configurations. Therefore, software vendors want to obtain insights into how the enterprises use the software product, what the differences are in usage between enterprises, and the reasons behind these differences. Cross-organizational process mining is a possible solution to address these needs, as it aims at comparing enterprises based on their usage. In this paper, we present a novel Cross-Organizational Process Mining Framework which takes as input, besides event log, semantics (meaning of terms in an enterprise) and organizational context (characteristics of an enterprise). The framework provides reasoning capabilities to determine what to compare and how. Besides, the framework enables one to create a catalog of metrics by deducing diagnostics from the usage. By using this catalog, the framework can monitor the (positive) effects of changes on processes. An enterprise operating in a similar context might also benefit from the same changes. To accommodate these improvement suggestions, the framework creates an improvement catalog of observed changes. Later, we provide a set of challenges which have to be met in order to obtain the inputs from current products to show the feasibility of the framework. Next to this, we provide preliminary results showing they can be met and illustrate an example application of the framework in cooperation with an ERP software vendor.  2016 IEEE. Cross-Organizational Process Mining; ERP; Framework

Conformance checking and performance improvement in scheduled processes: A queueing-network perspective Service processes, for example in transportation, telecommunications or the health sector, are the backbone of today?s economies. Conceptual models of service processes enable operational analysis that supports, e.g., resource provisioning or delay prediction. In the presence of event logs containing recorded traces of process execution, such operational models can be mined automatically. In this work, we target the analysis of resource-driven, scheduled processes based on event logs. We focus on processes for which there exists a pre-defined assignment of activity instances to resources that execute activities. Specifically, we approach the questions of conformance checking (how to assess the conformance of the schedule and the actual process execution) and performance improvement (how to improve the operational process performance). The first question is addressed based on a queueing network for both the schedule and the actual process execution. Based on these models, we detect operational deviations and then apply statistical inference and similarity measures to validate the scheduling assumptions, thereby identifying root-causes for these deviations. These results are the starting point for our technique to improve the operational performance. It suggests adaptations of the scheduling policy of the service process to decrease the tardiness (non-punctuality) and lower the flow time. We demonstrate the value of our approach based on a real-world dataset comprising clinical pathways of an outpatient clinic that have been recorded by a real-time location system (RTLS). Our results indicate that the presented technique enables localization of operational bottlenecks along with their root-causes, while our improvement technique yields a decrease in median tardiness and flow time by more than 20%.  2016 Elsevier Ltd Conformance checking; Process improvement; Process mining; Queueing networks; Scheduled processes; Scheduling; Statistical inference

Data analytics framework for semi-continuous manufacturing process-Implementation vision with a use case This paper discusses some of the challenges and opportunities involving implementation of data analytics frameworks for semi-continuous manufacturing processes. With the concurrent efforts in process modeling, data collection and on-line process control, process performance has been continually improving over the years. On a modern production center, there are hundreds of sensors continuously collecting process information along with the product quality information available post-process. These data contain vital process insights yet organization, filtering and contextualization challenges prohibit the widespread use of the data to gain valuable insights about the process. The first part of this paper discusses data requirements and pre-processing necessary to utilize data for process insights discovery. The second part of the paper presents a use case of a data analytics framework to diagnose a particular process fault using multiple data forms and timescales. The paper concludes with thoughts on wide-spread deployment of such techniques.  2017 The Society of Manufacturing Engineers. Data analytics implementation; ISA95; Machine learning; Process mining; Smart manufacturing

A virtual laboratory for multiagent systems: Joining efficacy, learning analytics and student satisfaction This study introduces a distributed virtual laboratory for a multiagent programming course which has been very satisfactorily adopted by students, with a success rate of nearly 80%. It also aims at capturing the daily activity of students, providing the basis for data-driven assessment. Finally, it also allows for using process mining technologies to unveil successful and failed behaviors of students enabling the teacher for an early detection and intervention to improve their learning experience1.  2016 IEEE. data-driven assessment; Learning analytics; multiagent systems

An application of process mining for queueing system in health service Health services are looking for ways to improve the processes and optimize the service time. Process Mining has been applied in the process discovery in variety of domain. The process mining is a promising method to discover the activity behaviors. However, early applications of process mining do not support the queue analysis. In this work, we introduce the method for applying process mining with queue system for health services. Process mining was used for the process discovery and the queueing theory was used to model the performance. The experiment shows that the process mining discovered the actual process model and provided the information to construct a queueing model. The method is suitable for analyzing control-flow and time performance in health service domain.  2016 IEEE. Process Mining; Queue system; Workflow Analysis

Minimizing total completion time in flowshop with availability constraint on the first machine A real-world company asked us to solve emerging problem related to the flow of the documents: some of the documents had been lost. We used methods of process mining to solve this problem. We found an error in the information system. Moreover, our analysis of the flow of the documents led to the conclusion that the business processes did not meet the company's needs, and with our help they were redesigned and reimplemented. This research gave an additional important insight to process mining methodology-in order to extract knowledge about business processes that is useful for the decision makers, it is crucial to create algorithms capable of collaborating with human experts.  2016 Polish Information Processing Society. 

Statistical verification of process model fitness in process mining The primary purpose of process mining is to explore a process model from an event log and analyze it in order to suggest enhancements to the process. Evaluation of the conformance of process models is of great importance in this regard. However, due to their large data size and complex structure, this is not easy. Previous studies on conformance checking have applied fitness measuring methods that use token replay and node-arc relations based on Petri net. Fitness thus far has not considered statistical significance, but just offers a numeric ratio. We herein propose a statistical fitness test based on the Kolmogorov-Smirnov test to formulate statistical process model fitness guidelines and conformance parameters for model selection. We also propose a new concept of maximum confidence dependency to solve the problem of the trade-off between model abstraction and process conformance.  2016 ICIC International. Conformance checking; Kolmogorov-smirnov test; Maximum confidence dependency; Process mining; Process model selection

A Co-Training Strategy for Multiple View Clustering in Process Mining Process mining refers to the discovery, conformance, and enhancement of process models from event logs currently produced by several information systems (e.g. workflow management systems). By tightly coupling event logs and process models, process mining makes it possible to detect deviations, predict delays, support decision making, and recommend process redesigns. Event logs are data sets containing the executions (called traces) of a business process. Several process mining algorithms have been defined to mine event logs and deliver valuable models (e.g. Petri nets) of how logged processes are being executed. However, they often generate spaghetti-like process models, which can be hard to understand. This is caused by the inherent complexity of real-life processes, which tend to be less structured and more flexible than what the stakeholders typically expect. In particular, spaghetti-like process models are discovered when all possible behaviors are shown in a single model as a result of considering the set of traces in the event log all at once.To minimize this problem, trace clustering can be used as a preprocessing step. It splits up an event log into clusters of similar traces, so as to handle variability in the recorded behavior and facilitate process model discovery. In this paper, we investigate a multiple view aware approach to trace clustering, based on a co-training strategy. In an assessment, using benchmark event logs, we show that the presented algorithm is able to discover a clustering pattern of the log, such that related traces result appropriately clustered. We evaluate the significance of the formed clusters using established machine learning and process mining metrics.  2015 IEEE. Clustering; co-training; multiple view learning; process mining

Scientific workflows for process mining: building blocks, scenarios, and implementation Over the past decade process mining has emerged as a new analytical discipline able to answer a variety of questions based on event data. Event logs have a very particular structure; events have timestamps, refer to activities and resources, and need to be correlated to form process instances. Process mining results tend to be very different from classical data mining results, e.g., process discovery may yield end-to-end process models capturing different perspectives rather than decision trees or frequent patterns. A process-mining tool like ProM provides hundreds of different process mining techniques ranging from discovery and conformance checking to filtering and prediction. Typically, a combination of techniques is needed and, for every step, there are different techniques that may be very sensitive to parameter settings. Moreover, event logs may be huge and may need to be decomposed and distributed for analysis. These aspects make it very cumbersome to analyze event logs manually. Process mining should be repeatable and automated. Therefore, we propose a framework to support the analysis of process mining workflows. Existing scientific workflow systems and data mining tools are not tailored towards process mining and the artifacts used for analysis (process models and event logs). This paper structures the basic building blocks needed for process mining and describes various analysis scenarios. Based on these requirements we implemented RapidProM, a tool supporting scientific workflows for process mining. Examples illustrating the different scenarios are provided to show the feasibility of the approach.  2015, The Author(s). Large scale process analysis; Process mining; RapidProM; Scientific workflows

Introduction This chapter presents the concepts of processes, process models and event data, and provides an overview of the discipline that uses event data to improve process models, known as process mining. Moreover, the chapter introduces the reader to conformance checking - final goal of this book- the set of process mining techniques that focus on evaluate the difference between the assumed process model and the real process.  Springer International Publishing AG 2016. 

Process mining for project management Business process mining or process mining is the intersection between data mining and business process modelling that extracts business patterns from event logs. Event logs are freely available in any organization. Business logs are a potential source of useful information. By the various patterns that are present in the logs, a lot can be estimated about the type of procedures that should be incorporated into the organization for better performance. Event logs store information about time and event data of business processes. Process mining algorithms are used to mine business process models using event logs. Generating automated business models out of this could provide valuable insight to a firm eventually leading to customer satisfaction. Process Mining works by three phases: Discovery, conformation and alteration. By using process mining, many kinds of information can be collected about the process, such as control-flow, performance, organizational information and decision patterns. A process model could be represented as Petri nets which is a formal graphical representation of the workflow diagram or it can be represented as Business Process Modelling Notation. This project aims to develop a user friendly platform which is capable of generating petri net like models by process mining. By using various process mining algorithms we will develop software which would mine the event logs of a particular firm. It would provide a data or workflow analysis scheme. This would optimize business process intelligence and thus provide alternative and superior work strategies. In this project, we are mainly targeting project management using process mining. There are many projects that are undertaken by an IT company that all follow the same procedure. The concept of business process mining can be used in order to improve the performance of a company by optimizing its Software Development Life Cycle. By feeding the previous logs of a similar project of the company, the software would give a flowgraph. This flowgraph can help to identify the sequence of the activities, roles in the organization as well as various efficiency parameters. The algorithm being used is the Heuristic Miner Algorithm for process mining.  2016 IEEE. event logs; process mining

Mining team compositions for collaborative work in business processes Process mining aims at discovering processes by extracting knowledge about their different perspectives from event logs. The resource perspective (or organisational perspective) deals, among others, with the assignment of resources to process activities. Mining in relation to this perspective aims to extract rules on resource assignments for the process activities. Prior research in this area is limited by the assumption that only one resource is responsible for each process activity, and hence, collaborative activities are disregarded. In this paper, we leverage this assumption by developing a process mining approach that is able to discover team compositions for collaborative process activities from event logs. We evaluate our novel mining approach in terms of computational performance and practical applicability.  2016 Springer-Verlag Berlin Heidelberg Business process management; Declarative process mining; Event log analysis; Resource perspective; Teamwork

Business process modeling for processing classified documents using RFID technology The article outlines the application of the processing approach to the functional description of the designed IT system supporting the operations of the secret office, which processes classified documents. The article describes the application of the method of incremental modeling of business processes according to the BPMN model to the description of the processes currently implemented ("as is") in a manual manner and target processes ("to be"), using the RFID technology for the purpose of their automation. Additionally, the examples of applying the method of structural and dynamic analysis of the processes (process simulation) to verify their correctness and efficiency were presented. The extension of the process analysis method is a possibility of applying the warehouse of processes and process mining methods.  2016 The Authors, published by EDP Sciences. BPMN; Business process modeling; Business process simulation; Classified Registry/secret office; Process mining; RFID; Warehouse of processes; Workflow system

Enhancing mobile device security with process mining We present part of a research project aimed at mobile device security. During the project we have tested several methods of processing of data from mobile devices in order to detect attacks and suspicious activity in general. One method we have tested was also mining of processes found in mobile device activity logs and analysis of those processes. We have used several devices with the AndroidTMOS, collected a large amount of activity data, including (simulated) harmful activity, and then modeled processes found in the data. Results of the comparison of these processes to the harmful activity suggest that this application of process mining shows promise, but also requires a lot of further research.  2016 IEEE. 

Building instance graphs for highly variable processes Organizations increasingly rely on business process analysis to improve operations performance. Process Mining can be exploited to distill models from real process executions recorded in event logs, but existing techniques show some limitations when applied in complex domains, where human actors have high degree of freedom in the execution of activities thus generating highly variable processes instances. This paper contributes to the research on Process Mining in highly variable domains, focusing on the generation of process instance models (in the form of instance graphs) from simple event logs. The novelty of the approach is in the exploitation of filtering Process Discovery (PD) techniques coupled with repairing, which allows obtaining accurate models for any instance variant, even for rare ones. It is argued that this provides the analyst with a more complete and faithful knowledge of a highly variable process, where no process execution can be really targeted as "wrong" and hence overlooked. The approach can also find application in more structured domains, in order to obtain accurate models of exceptional behaviors. The quality of generated models will be assessed by suitable metrics and measured in empirical experiments enlightening the advantage of the approach.  2016 Elsevier Ltd. All rights reserved. Building instance graphs; Highly variable processes; Process instances; Process mining

The use of a process mining technique to characterize the work process of main control room crews: A feasibility study In terms of supporting HRA (Human Reliability Analysis) practitioners, one of the urgent issues is to establish a set of objective criteria for determining the proper level of PSFs (Performance Shaping Factors), which are crucial for estimating the likelihood of HEPs (Human Error Probabilities). From this concern, the feasibility study of process mining techniques to characterize the work process of MCR (Main Control Room) crews is presented in this study. Three kinds of information requirements that are essential for determining the quality of the work process are first identified, and the application of process mining techniques is then introduced to address those requirements. As a case study, we illustrate the process mining techniques with communication logs that were collected from MCR crews exposed to simulated off-normal conditions. As a result, three kinds of insightful information (i.e., a work flow, time and spatial information along with a given work flow, and the flow of keywords describing what kinds of symptoms and/or knowledge were considered by MCR crews) are soundly extracted from communication logs. Consequently, it is expected that process mining techniques are effective for identifying a set of necessary information that would helpful for assessing the quality of the work process in an objective manner.  2016 Elsevier Ltd. All rights reserved. Feasibility; Human reliability analysis; Nuclear power plant; Process mining; Work process

Impact-driven process model repair The abundance of event data in today's information systems makes it possible to "confront" process models with the actual observed behavior. Process mining techniques use event logs to discover process models that describe the observed behavior, and to check conformance of process modelsby diagnosing deviations between models and reality. In many situations, it is desirable to mediate between a preexisting model and observed behavior. Hence, we would like to repair the model while improving the correspondence between model and log as much as possible. The approach presented in this article assigns predefined costs to repair actions (allowing inserting or skipping of activities). Given a maximum degree of change, we search for models that are optimal in terms of fitness - that is, the fraction of behavior in the log not possible according to the model is minimized. To compute fitness, we need to align the model and log, which can be time consuming. Hence, finding an optimal repair may be intractable. We propose different alternative approaches to speed up repair. The number of alignment computations can be reduced dramatically while still returning nearoptimal repairs. The different approaches have been implemented using the process mining framework ProM and evaluated using real-life logs.  2016 ACM. Event log; Process mining; Process model; Process model repair; Repair recommendation

Automated Event Driven Dynamic Case Management Workflow automation was first applied for structured processes, for processes which were determined at design time. Decades later case management emerged, workflows which were determined at runtime. Decisions in case management are made by human actors. Case management processing is very labor intensive. How could case management be transferred to a Straight-through processing type workflow which reduces involvement of human actors? This paper focuses on merger of case management with real time analytics which helps to replace human decision makers in the case management process with automated real time decision making while preserving non-deterministic nature of the workflow. Merger of case management with real time big data analytics could be next step in the evolution of the case management. Reference architecture for case management and real time analytics merger is defined. Also a case study is presented which implements defined reference architecture.  2016 IEEE. big data; Business process management; case management; human centric workflow; process analytics; process mining; real time analytics; straight-through processing

A Toolkit for Streaming Process Data Analysis This paper presents a software toolkit that can be used to analyze event data streams in real-time. It has a specific focus on stochastic analysis of business processes, based on event data that is produced during the execution of those processes. The toolkit provides a software environment that facilitates easy connection to event data streams and quick development and testing of analysis and visualization techniques. It is developed by classifying existing techniques for streaming process data analysis, which are identified in the current literature, and by extracting and formalizing the core mechanisms that these techniques are based on. These core mechanisms serve as the basis for the toolkit. The toolkit is implemented and made available as open source. In this way it can facilitate quick prototyping of streaming process data analysis techniques.  2016 IEEE. 

Efficient business process consolidation: combining topic features with structure matching Accurate and effective business process consolidation is an efficient means of overcoming the dynamics and uncertainty in business process modeling. This article presents an approach to automating business process consolidation by applying process topic clustering based on business process libraries, using a graph mining algorithm to extract process patterns, identifying frequent subgraphs under the same process topic, filling the pertinent subgraph information into a table of frequent process subgraphs, and finally merging these frequent subgraphs to obtain merged business processes using a process merging algorithm. Tests on 604 models from the SAP reference model were performed, in which we used the compression ratio to judge the capability of our merging methods; the compression ratios of integrated processes in the same topic cluster were found to be much lower than those of processes related to different topics, and our method was found to achieve compression ratios similar to those reported in previous work.  2016 Springer-Verlag Berlin Heidelberg Business process merging; Correlated topic model; gSpan; Process subgraph; Topic distillation

Location-Aware Path Alignment in Process Mining Location-aware log data is an untapped source of information that promises new business analysis insights. This is in particular the case for business processes that can be linked to sensor data such as RFID or WiFi signals. Technically, this question can be formulated as a special type of alignment problem, which is well known in process mining. In this paper, we formalize the alignment problem for spatio-temporal event data. Our contribution is a novel algorithm that finds sensor IDs that travel together on the basis of their location information. Questions centered around spatio-temporal event logs may include all kinds of movements, such as customers in shops highlighting 'Hot and Cold areas' or tracking of material and goods in a production plant. For this paper, we choose a specific challenge for retail companies, which is to find out if customers are alone or visit the shop together with family or friends. Therefore, the algorithm is tested using positioning-data of a retail shop from the fashion industry. Our results highlight the benefits of location-based process mining by showing its applicability in real scenarios.  2016 IEEE. Path Alignment; Process Mining; Trace Clustering; Trace Similarity

Apriori and sequence analysis for discovering declarative process models The aim of process discovery is to build a process model from an event log without prior information about the process. The discovery of declarative process models is useful when a process works in an unpredictable and unstable environment since several allowed paths can be represented as a compact set of rules. One of the tools available in the literature for discovering declarative models from logs is the Declare Miner, a plug-in of the process mining tool ProM. Using this plug-in, the discovered models are represented using Declare, a declarative process modelling language based on LTL for finite traces. In this paper, we use a combination of an Apriori algorithm and a group of algorithms for Sequence Analysis to improve the performances of the Declare Miner. Using synthetic and real life event logs, we show that the new implemented core of the plug-in allows for a significant performance improvement.  2016 IEEE. 

Communication-Based Business Process Task Detection-Application in the CRM Context During the last decades, several research works have been conducted in Business Process Management (BPM) field, and a whole range of tools allowing capturing and managing the business process (BP) has been proposed. However, the current BPM systems leave aside the informal work, which is often based on communication and collaborative tools. In this paper, we introduce the concept of «communication-based manual task» in the BP design. It is a kind of a BP activity which is associated to a set of semantic patterns that enable the qualification of communication content as an achievement of the BP task. This association of semantic patterns with BP activities enables the system to capture informal work, done through communication and collaborative tools such as: email, phone calls, instant messaging, etc. We have implemented and applied the proposal to the customer relationship management (CRM) field in order to respond to the challenges induced by the variety of communication channels. We highlight two main advantages compared to classical CRM approaches. It firstly enables the reconstruction of the customer journeys across the communication channels and secondly identifies all BP actors who are involved in the customer journey; providing by this way a mean to promote collaboration between communication channels teams.  2016 IEEE. BPMN; Business process management; CRM; customer relationship management; process mining

Hybrid heuristics miner based on time series prediction for streaming process mining To cope with time-attribute and variations of event distribution in dynamic evolving process, an streaming process mining based on time series prediction and hybrid heuristic miner is proposed. A heuristic miner is improved based on post-task of activity in event logs to optimize the initial particle distribution for Particle Swarm Optimization. Furthermore, 'aging factor' based on time series attribute is also designed for adaptive global optimization. Besides, time-related Process Decision Indicator(PDI) is defined as a pattern observable to identify domain-independent evolution indicators in process model. The experimental results show that our algorithm is more effective and scalable for streaming process mining.  2016 IEEE. Heuristics Miner; Process Mining; Process Prediction; PSO

Understanding knowlegde-intensive processes: From traces to instance graphs Enterprise information systems, while support daily activities, typically collect data on executed processes in event logs. These data describe the temporal sequence in which activities were carried out, hiding possible parallelism and other control flows. Representing the structure of each process execution in the form of an Instance Graph, enables managers to discover valuable knowledge on enterprise behaviors. In this work, we describe BIG4ProM, a tool which implements the Building Instance Graph (BIG) algorithm. BIG4ProM exploits filtering Process Discovery algorithms implemented in ProM in order to return the set of instance graphs related to the given event log. The plug-in is conceived to support both expert and standard users.  2016 IEEE. building instance graph; knowledge-intensive process; process mining; ProM

A process-mining-based scenarios generation method for SOA application development Business process models which are usually constructed by business designers from experience and analysis are the main guidelines for services composition in the service-oriented architecture (SOA) applications development. However, due to the complexity of business models, it is a challenging task for business process designers to optimize the process models dynamically in accordance with changes in business environments. In this paper, a process-mining-based method is proposed to support business process designers to monitor efficiency or capture the changes of a business process. Firstly, we define a scenario model to depict business elements and their relationships which are critical to business process design. Based on the proposed scenario model, process mining algorithms, including control flow mining, roles mining and data flow mining are carried out in a certain sequence synthetically to extract business scenarios from event logs recorded by SOA application systems. Finally, we implement a prototype using a logistic scenario to illustrate the feasibility of our method in SOA applications development.  2015, Springer-Verlag London. Business process model; Process mining; Scenario discovery; SOA

A framework for efficiently mining the organisational perspective of business processes Process mining aims at discovering processes by extracting knowledge from event logs. Such knowledge may refer to different business process perspectives. The organisational perspective deals, among other things, with the assignment of human resources to process activities. Information about the resources that are involved in process activities can be mined from event logs in order to discover resource assignment conditions, which is valuable for process analysis and redesign. Prior process mining approaches in this context present one of the following issues: (i) they are limited to discovering a restricted set of resource assignment conditions; (ii) they do not aim at providing efficient solutions; or (iii) the discovered process models are difficult to read due to the number of assignment conditions included. In this paper we address these problems and develop an efficient and effective process mining framework that provides extensive support for the discovery of patterns related to resource assignment. The framework is validated in terms of performance and applicability.  2016 Elsevier B.V. Business process management; Declarative process mining; Event log analysis; Organisational perspective; Resource perspective

Domain-driven actionable process model discovery Process discovery is a type of process mining that constructs a process model from the event logs of an information system. The model discovered using process discovery techniques and the process as perceived by users will always differ in some ways and to some extents. In particular, less structured process, such as operational process in business and manufacturing, often result overly confusing, spaghetti-like, process models caused by the inherent complexity of the process. As a result, the mined model has many limitations for providing the users with explicit knowledge that can be directly used to influence behavior for the user's interest. Explicit knowledge, as later called by actionable knowledge, is an important representation on measuring the interestingness of mined patterns. This actionable knowledge, which is incorporated with users background knowledge and based on some notions of actionable rules, can result an actionable process model. Undoubtedly, domain experts, who know the process well, play a key role to enhance the mined model into an actionable model by their involvements during the discovery process. This paper presents a discovery method to obtain an actionable process model that is based on both the event relation in the log and users knowledge to improve the incompatibility of the traditional process mining approaches. Users can set their knowledge in terms of constraints. Unlike the existing approach, the proposed approach synthesizes the activity proximity and attempts to extract behavior satisfied by the constraints which may be hidden in the event logs for resulting an actionable process model. In addition, the proposed method is used in order to achieve a sound process model when the existence of the constraints does not satisfy the workflow soundness property. The method was implemented in the ProM framework and tested on a real process.  2016 Elsevier Ltd Business process; Integer linear programming; Process mining; Proximity score; Users knowledge

Applying Process Mining Techniques to DNS Traces Analysis One of the key technologies on the Internet is the DNS protocol. While many studies have taken a statistical approach, the representation of DNS traces as a graph has not received enough attention. In this position paper we present our work of applying Process Mining (PM) techniques to study DNS traffic. Process Mining has been successfully used to understand processes on the enterprise as part of Business Process Management (BPM) analysis tools and techniques. Applying PM techniques allow us discovering unexpected behaviors in DNS operations such as spam botnet attacks. We show examples of the studies performed by our group and we also present new ideas for future work.  2014 IEEE. DNS traces modeling; Process Mining

Superclass extraction problem of workflow nets and a solution procedure based on process mining technique An organization may have two or more similar workflows as a result of workflow evolutions or mergers and acquisitions. We should grasp the common behavior of those workflows to consolidate the management of them and/or to do business process reengineering. Workflows can be modeled as a particular class of Petri nets, called workflow nets. The common behavior of two or more workflow nets can be represented as a superclass under the behavioral inheritance of those workflow nets. In this paper, we tackled a problem of extracting a superclass from two workflow nets, named Superclass Extraction problem. We first gave a definition of the problem. Next we proposed a procedure to solve the problem on the basis of process mining technique. Then we gave an application of the proposed procedure. Copyright  2016 The Institute of Electronics, Information and Communication Engineers. Behavioral inheritance; Petri net; Process mining; Superclass; Workflow net

Analytical study on conformance checking in terms of fitness and behaviroal appropriateness in control flow sequence pattern using process mining algorithms Process mining comprises the research area which is concerned with knowledge discovery from event logs. Process mining technique focuses on the conformance checking by comparing the discovered process models with the original real-life event logs in order to evaluate the goodness of the process model. This paper makes a comparative study between the discovered process models with respect to the real-life behavior as captured in event logs using the heuristic miner algorithm. To achieve this,the metrics of fitness and appropriateness is considered and the metrics are evaluated and measured by comparing the process flow of planned process model and its observed model using the heuristic miner algorithm. In Business processes,Flow of events in particular planned sequence is said to be discovered or designed process model (Work Flow Model) and observing the sequence of real time event logs is observed model. Process mining is the young research discipline; it is used to discover knowledge from event logs. Event logs are the processes that are extracted from the information systems like transaction log,Ms-Excel spread sheet or a normal database tables. A study is conducted on the observed event logs from the Business process outsourcing organization which deals with computer technical faults. The output predicts the ratio of deviated fitness and behavioral appropriateness,of process flow with respect to the work flow model.  2016,International Journal of Pharmacy and Technology. All rights reserved. Business process mining; Conformance checking; Control flow bench mark; ProM; Workflow model

Performance assessment architecture for collaborative business processes in BPM-SOA-based environment To be competitive and flexible, companies engage in collaborations to develop and share their competences in order to cope with the dynamic environment. Collaborative business process evaluation helps to reflect the actual functioning of business process and their performance level. In this perspective, research in assessing collaborative business process performance presents relevant guidelines in order to adapt IT solutions when business requirements evolve. In this paper, we present an analysis and assessment approach for collaborative business processes in the service-oriented architecture in order to maintain their performance in competitive markets. Our approach proposes an evaluation method using execution traces of business process combined with a high-level assessment method using key performance indicators. Our main objectives are to track the execution of collaborative business process and to analyze the performance trajectory of a business process regarding the business performance level. To collect and structure the performance knowledge (execution and measurement), we create an ontological model-based knowledge repository in order to enrich the semantics of an evaluation business process. The precise track of execution data in our approach is able to identify events that disrupt the proper functioning of processes at the runtime. From an industrial case study, we can conclude that our ontological approach can target the performance assessment of collaborative business processes effectively.  2015 Elsevier B.V. Assessment; Collaborative business process; Execution traces; Ontology; Process mining

Revising history for cost-informed process improvement Organisations are constantly seeking new ways to improve operational efficiencies. This study investigates a novel way to identify potential efficiency gains in business operations by observing how they were carried out in the past and then exploring better ways of executing them by taking into account trade-offs between time, cost and resource utilisation. This paper demonstrates how these trade-offs can be incorporated in the assessment of alternative process execution scenarios by making use of a cost environment. A number of optimisation techniques are proposed to explore and assess alternative execution scenarios. The objective function is represented by a cost structure that captures different process dimensions. An experimental evaluation is conducted to analyse the performance and scalability of the optimisation techniques: integer linear programming (ILP), hill climbing, tabu search, and our earlier proposed hybrid genetic algorithm approach. The findings demonstrate that the hybrid genetic algorithm is scalable and performs better compared to other techniques. Moreover, we argue that the use of ILP is unrealistic in this setup and cannot handle complex cost functions such as the ones we propose. Finally, we show how cost-related insights can be gained from improved execution scenarios and how these can be utilised to put forward recommendations for reducing process-related cost and overhead within organisations.  2015, Springer-Verlag Wien. Business process analysis; Business process improvement; Cost-informed; Genetic algorithm; Optimisation; Process mining

Discovery of process model using click stream analysis in web mining Web mining uses the data mining techniques to automatically discover and extract information (Knowledge) from Web documents and services. The method of general web access pattern is extracted and analyzed using knowledge discovery techniques to understand the patterns. This usage mining can be done from the click stream data of the website by the users. Sequence of tasks are observed through click stream analysis and a business process model may be discovered in web structure mining. This paper suggests a plan and proposal about how to consider the user behavior in E commerce sites as process and to discover a process model which enhances business intelligence.  2016,International Journal of Pharmacy and Technology. All rights reserved. Click stream analysis; Process centric view; Process mining; Process model; Web mining

Process mining approach based on partial structures of event logs and decision tree learning Process mining techniques are able to improve processes by extracting knowledge from event logs commonly available in today's information systems. In the area, it is important to verify whether business goals can be satisfied. LTL (Linear Temporal Logic) verification is an important means for checking the goals automatically and exhaustively. However, writing formal language like LTL is difficult, and the properties by which the user's intentions are not reflected sufficiently have bad influence on the verification results. Therefore, it is needed to help writing correct LTL formula for users who do not have sufficient domain knowledge and knowledge of mathematical logic. We propose an approach for goal achievement prediction based on decision tree learning. It is conducted focusing on partial structures represented as event order relations of each trace. The proposed technique is evaluated on a phone repair process log.  2016 IEEE. Business constraints; Business process management; Linear temporal logic; Process aware information system; Process mining; Requirements engineering

A semantic framework supporting business process variability using event logs Large organizations often have multiple branches situated in different locations, each branch may collaborate and learn from other branches' experience. Their Business processes (BPs) share often similar business goals and are slightly different. These branches are eager to develop new process variants to satisfy new requirements. Process execution logs, so called process event logs, can be used to analyze requirement changing situations and efficiently develop BP variants. However, these logs often have heterogeneous data-sources which prevent an easy and dynamic interoperability between different branches. In this paper, we propose a semantic framework tackling this heterogeneity issue. This framework promotes the creation of a semantic knowledge base from process event logs. Using this knowledge base, we offer BP designers the means to discover suitable BP fragments to assist process variant modeling. We performed experiments on a large public dataset and experimental results show that our approach is feasible and accurate in realistic situations.  2016 IEEE. Business process; Ontologies; Process event logs; Process mining; Semantic Web technologies

Model business process improvement by statistical analysis of the users' conduct in the process Process Mining is a research area that meets the gap between business processes and various IT systems. Most of the works in this area focus on the control flow perspective, while very few of them address the organizational aspect. The organization perspective of process mining supports the discovery of social network within organization by analyzing events logs recorded during real process execution. For process owners, it is very important to know how users perform their activities in process. In this paper, we introduce a process discovery method that combines an organizational perspective with probabilistic approach. Combining these two approaches we are able to fit distribution of users work and distribution of instance generation in process. We use different statistic methods like Cullen and Frey graph, Kolmogorov-Smirnov statistic test, Carmén-von-Mises statistic test and Anderson-Darling statistic test. After finding appropriate distribution we estimate its parameters. Research conducted and presented in this paper reveals that the information about users behaviour in process is significantly useful in further analysis: in simulations, to identify bottlenecks, to improve productivity of resource management and to identify task complexity in process.  2016 University of Split, FESB. Business Processes; Organization Mining; Parameters Estimation; Probability Distribution Fitting; Process Mining; Statistical Tests

Toward the Support of Challenging Service Level Agreements (SLAs) in Manual and Context-Dependent Activities Recent research initiatives in the domain of business process management such as process intelligence, monitoring, and mining have shown significant results in automated process environments. However, such techniques fall short to provide efficient solutions and support for non-fully automated business processes i.e., processes that embody dynamic, continuous, and manual activities such as in logistics. More precisely, things turn to be very challenging when it comes to the monitoring and Service Level Agreement (SLA) violation prediction throughout context-dependent and manual processes. Unlike current approaches that mainly focus on the model of the process as a whole, we shift in this work toward instance-based and specific processing for each activity depending on its context. We showcase a contextualized template-driven framework while providing the missing link of continuous monitoring and early prediction within manual activities.  2016 IEEE. Business Process Management; Complex Event Processing; Data Mining

Anvaya: An Algorithm and Case-Study on Improving the Goodness of Software Process Models Generated by Mining Event-Log Data in Issue Tracking Systems Issue Tracking Systems (ITS) such as Bugzilla can be viewed as Process Aware Information Systems (PAIS) generating event-logs during the life-cycle of a bug report. Process Mining consists of mining event logs generated from PAIS for process model discovery, conformance and enhancement. We apply process map discovery techniques to mine event trace data generated from ITS of open source Firefox browser project to generate and study process models. Bug life-cycle consists of diversity and variance. Therefore, the process models generated from the event-logs are spaghetti-like with large number of edges, inter-connections and nodes. Such models are complex to analyse and difficult to comprehend by a process analyst. We improve the Goodness (fitness and structural complexity) of the process models by splitting the event-log into homogeneous subsets by clustering structurally similar traces. We adapt the K-Medoid clustering algorithm with two different distance metrics: Longest Common Subsequence (LCS) and Dynamic Time Warping (DTW). We evaluate the goodness of the process models generated from the clusters using complexity and fitness metrics. We study back-forth and self-loops, bug reopening, and bottleneck in the clusters obtained and show that clustering enables better analysis. We also propose an algorithm to automate the clustering process-the algorithm takes as input the event log and returns the best cluster set.  2016 IEEE. Bug Tracking System; Clustering; Mining Software Repositories; Process Mining; Process Model Fitness Metric; Process Model Structural Complexity

Reflections on the use of chord diagrams in social network visualization in process mining Data Visualization is an important area of research including different techniques to enhance the capability of people to understand and use data-driven information. The chord diagram is a technique that aims to support the visualization of relations among different participants in a social network. Although this technique is widely used and adopted in many disciplines, it is not currently implemented in Business Process Management (BPM). In this paper, we show the potential of the visualizing social network in BPM area using the chord diagram. The result shows the potential benefits and strength of this technique to discover social network patterns in BPM area.  2016 IEEE. Business Process; Chord Diagram; Process Mining; Social Network; Visualization

A process tree-based algorithm for the detection of implicit dependencies Process Mining aims to extract information from event logs to highlight the underlying business processes. It is useful in situations where there is no detailed and complete knowledge of how an overall system works, such as in a hospital where most processes are complex and ad-hoc. Many Process Mining discovery techniques have been proposed so far, but many challenges are still to be faced. Implicit dependencies are one of them. Choice-related phenomenon, implicit dependencies are not taken into account in most algorithms and graphical representations. In this paper, we propose the Implicit Dependencies Miner, a Process Tree based algorithm able to detect relevant dependencies.  2016 IEEE. Implicit Dependencies; Process Mining; Process Tree

Process mining for recommender strategies support in news media The strategic transition of media organizations to personalized information delivery has urged the need for richer methods to analyze the customers. Though useful in supporting the creation of recommender strategies, the current data mining techniques create complex models requiring often an understanding of techniques in order to interpret the results. This situation together with the recommender technologies deluge and the particularities of the news industry pose challenges to the news organization in making decisions about the most suitable strategy. Therefore, we propose process mining as a high-level, end-to-end solution to provide insights into the consumers' behavior and content dynamics. Specifically, we explore if it allows news organizations to analyze independently and effectively their data in order to support them in defining recommender strategies. The solution was implemented in a case study with the third largest news provider in Norway and yielded preliminary positive results. To our knowledge, this is the first attempt to apply a process mining methodology and adapt the techniques to support media industry with the recommender strategies.  2016 IEEE. behavioral analysis; inferred intentional process models; news media case study; process mining; process mining methodology; recommender strategies

Enabling process mining on sensor data from smart products In this paper we address the challenge of applying process mining to discover models of human behaviour from sensor data. This challenge is caused by a gap between sensor data and the event logs that are used as input for process mining techniques, so we provide a transformation approach to bridge this gap. As a result, besides the automatic discovery of process models, the transformed sensor data can also be used by various other process mining techniques, e.g. to identify differences between observed behaviour and expected behaviour. We discuss the transformation approach in the context of the design process of smart products and related services, using a case study performed at Philips where a smart baby bottle has been developed. This case study also demonstrates that the use of process mining can add value to the smart product design process.  2016 IEEE. activity recognition; process mining; product design; sensor data; smart products

Empirical Study of Using Big Data for Business Process Improvement at Private Manufacturing Firm in Cloud Computing The implementations of new technologies have been broadly accepted by multiple industries in recent years, such as big data nad cloud computing. A quick and efficient data mining has become an alternative of creating values ever, the dynamic economic context and continuous changing business envoronment have driven numerous demands and applications in various industries. This phenomenon results in the problem of forming proper strategies in applying big data and cloud computing, which is one of the major challenges of reach the goal of value creations for current enterprises. This paper focuses on this problem and presents an empirical study on the issue of using big data for business process improvements in cloud computing. The investigation target is a Chinese large-size private enterprise that strives to be a global enterpriise in the manufacturing industry. The completed research is based on the real data collected from the collaboration partner. The main findings of this research include two parts:1) the efforts of using big data are varied, which are relatedto the operation levels,2) implementating cloud computing solutions is at an exploring stage for Chinese provate sector due to a few restrictions.  2016 IEEE. Big data; business process improvement; cloud computing; empirical study; manufacturing firm; private sector

Examining diagnosis paths: A process mining approach This paper is motivated by two observations on computer-supported education: First, there has been growing availability, rapid proliferation, and increased diversity of learner-system educational data. Second, advances in learning analytics and data mining have facilitated and spawned a variety of novel investigations using such data. Driven by these complementary trends, the present work is geared towards exploring knowledge-based discovery approaches in understanding learner-system usage data. More specifically, with an eye toward tracing and comprehending learner behaviors in a medical intelligent tutoring system, we explore the utility of Process Mining, in understanding the problem solving trajectories of students in a medical computer-based learning environment.  2016 IEEE. Computer-based learning environments; Data mining; Intelligent tutoring systems; Process mining

TCPM: Topic-Based Clinical Pathway Mining Clinical pathway is important for improving medical quality, reducing cost and regulating resource. However, a static, non-adaptive clinical pathway designed by experts with limited data can be hardly implemented in practice. Thus, mining the execution clinical pathway from various historical data is meaningful. Existing works focus on applying either process mining or clustering methods on medical data. These methods generally produce low-granularity process models or unordered trace groups with similar treatment behaviors. In this paper, we propose a topic-based clinical pathway mining approach, which is concise, interpretable and of sequential information. We start from billing data, and use Latent Dirichlet Allocation to cluster billing items without specifying the topic number. The treatment of each day is represented as a set of topics, which convey the treatment goals. To emphasize critical and essential activities, we prune the low-frequency topics and remove sub-traces. Finally, by applying fuzzy mining method on these topic sequences, we can discover the execution clinical pathway. The experiments on a real-world data set show the effectiveness and practicability of our approach.  2016 IEEE. clinical pathway mining; LDA; process mining

Process mining for clinical workflows In current scenario healthcare organization and their services are concerned for everyone. Healthcare organizations are continuously upgrading their work practices and standards for better quality. It involves controlling and monitoring of several healthcare processes or careflows which is identified as recent research area for effective utilization of healthcare resources and better satisfaction for stakeholders. For this, it is important to have correct view of care flows inside the hospital because in a hospital environment, the processes show a complex and dynamic behavior, which is difficult to control. Process mining is an emerging research area use to monitoring and controlling of set of processes for better understanding and effective utilization of organization resources. In this paper, we applied some of the process mining techniques with the help of petri net on the real time data of a private community hospital to get meaningful information and knowledge about these flow, for example discover paths followed by particular groups of patients. Basically we analyzed the control flow perspective of process mining. By using a process mining technique this paper has analyzed the healthcare data and the ongoing processes.  2016 ACM. Clinical workflows; Event log; Petri net; Process mining

A two-step clustering approach for improving educational process model discovery Process mining refers to the extraction of process models from event logs. As real-life processes tend to be less structured and more flexible, clustering techniques are used to divide traces into clusters, such that similar types of behavior are grouped in the cluster. Educational process mining is an emerging field in the educational data mining (EDM) discipline, concerned with developing methods to better understand students' learning habits and the factors influencing their performance. However, the obtained models, usually, cannot fit well to the general students' behaviour and can be too large and complex for use or analysis by an instructor. These models are called spaghetti models. In the present work, we propose to use a two steps-based approach of clustering to improve educational process mining. The first step consist of creating clusters based employability indicators and the second step consist on clustering the obtained clusters using the AXOR algorithm which is based on traces profiles in order to refine the obtained results from the first step. We have experimented this approach using the tool ProM Framework and we have found that this approach optimizes at the same time, both the performance/suitability and comprehensibility/size of the obtained model.  2016 IEEE. Clustering; Educational process mining; Fitness; Process discovery

Analyzing inter-organizational business processes: Process mining and business performance analysis using electronic data interchange messages Companies are increasingly embedded in B2B environments, where they have to collaborate in order to achieve their goals. Such collaborations lead to inter-organizational business processes that may be commonly supported through the exchange of electronic data interchange (EDI) messages (e.g., electronic purchase orders, invoices etc.). Despite the appearance of XML, traditional approaches to EDI, such as EDIFACT and ANSI X.12, still play an overwhelmingly dominant role. However, such traditional EDI standards lack a notion of process. In other words, the exchanged business documents are typically not embedded in the context of other exchanged business documents. This has two shortcomings: (1) the inability to apply proven business process management (BPM) methods, including process mining techniques, in such settings; and (2) the unavailability of systematic approaches to business intelligence (BI) using information from exchanged EDI messages. In this article, we present the EDImine Framework for enabling (1) the application of process mining techniques in the field of EDI-supported inter-organizational business processes, and (2) for supporting inter-organizational performance evaluation using business information from EDI messages, event logs and process models. As an enabling technology, we present a method for the semantic preprocessing of EDIFACT messages to exploit this potentially rich source of information by applying state of the art BPM and BI techniques. We show the applicability of our approach by means of a case study based on real-world EDI data of a German consumer goods manufacturing company.  2015, Springer-Verlag Berlin Heidelberg. Electronic data interchange; Inter-organizational business processes; Inter-organizational relationships; Key performance indicators; Process mining

A method for churn analysis of new users of mobile games using process mining These days most mobile game applications (apps) can be downloaded for free by users. That is to say that basically users can play games without payment. Revenue from mobile games is generated primarily from additional payments for items by in-app purchasing. However, it is not easy to lock new users into a mobile game, as it is a highly competitive market with a large range of mobile games available. Currently, mobile game companies in Korea are trying to analyze the leaving behaviors of new users using funnel analysis, a type of churn analysis. In particular, in the mobile game industry, the initial game play patterns of new users are very important as most new users leave the game on the day that they join it. In this study, we propose a new framework for analyzing users initial churn patterns using process mining techniques. The framework consists of 3 steps: Data preparation, comparative user behavior analysis, and discussion. In the comparative user behavior analysis step, users game play processes are analyzed in order to detect game playing patterns. In addition, users are classified into either a churn user group or a retention user group. The churn user group is defined as the user group who leaves the game on the day of joining. The retention user group is defined as the user group who plays the game continually. We suggest a method for comparing the differences in performance between the two groups.  2016 ICIC International. Churn analysis; Funnel analysis; Mobile game; Process mining; User pattern analysis

Behavioral process mining for unstructured processes Real world applications provide many examples of unstructured processes, where process execution is mainly driven by contingent decisions taken by the actors, with the result that the process is rarely repeated exactly in the same way. In these cases, traditional Process Discovery techniques, aimed at extracting complete process models from event logs, reveal some limits. In fact, when applied to logs of unstructured processes, Process Discovery techniques usually return complex, spaghetti-like models, which usually provide limited support to analysts. As a remedy, in the present work we propose Behavioral Process Mining as an alternative approach to enlighten relevant subprocesses, representing meaningful collaboration work practices. The approach is based on the application of hierarchical graph clustering to the set of instance graphs generated by a process. We also describe a technique for building instance graphs from traces. We assess advantages and limits of the approach on a set of synthetic and real world experiments.  2016, Springer Science+Business Media New York. Behavioral patterns discovery; Hierarchical clustering; Instance graphs; Unstructured processes

An entropy-based clustering ensemble method to support resource allocation in business process management Resource allocation, as a crucial task of business process management, has been widely acknowledged by its importance for process performance improvement. Although some methods have been proposed to support resource allocation, there is little effort to allocate resources from the task preference perspective. This paper proposes a novel mechanism in which resource allocation is considered as a multi-criteria decision problem and solved by a new entropy-based clustering ensemble approach. By mining resource characteristics and task preference patterns from past process executions, the right resources could be recommended to improve resource utility. Further, to support dynamic resource allocation in the context of multiple process instances running concurrently, a heuristic method is devised to deal with resource conflicts caused by the interplay between various instances. The effectiveness of this study is evaluated with a real-life scenario, and the simulation results indicate that resource utility can be improved and resource workload can be balanced with the support of resource recommendation.  2015, Springer-Verlag London. Business process management; Clustering ensemble; Multi-criteria recommendation; Process mining; Resource allocation

Pervasive business intelligence as a competitive advantage Today the strategic significance of information is fundamental to any organization. With the intensification of competition between companies in open markets and often saturated, companies must learn to know themselves and to the market through the collection and analysis of quality information. The strategic information is seen as a key resource for success in the business, which is provided by Business Intelligence systems. A successful business strategy requires an awareness of the surrounding (internal and external) environment of organizations, including customers, competitors, industry structure and competitive forces. Managing the future means not only is able to anticipate what will happen outside the organization, but also be able to represent the events through their own actions timely. To make it possible, Pervasive Business Intelligence arises as a natural evolution of business intelligence applications in organizations, allowing to companies achieve and maintain a sustainable competitive advantage.  2016 AISTI. business intelligence; business intelligence systems; competitive advantage; data mining; pervasive systems; process mining

The butterfly: An intelligent framework for violation prediction within business processes Recent research initiatives in the domain of business process management such as process intelligence, monitoring, and mining have shown significant results in automated process environments. However, such techniques fall short to provide efficient solutions and support for non-fully automated business processes i.e., processes embodying dynamic, continuous, and manual activities such as in logistics. More precisely, things turn to be very challenging when it comes to consider the monitoring and violation predictions throughout context-dependent and manual processes. Unlike current initiatives that mainly focus on the model of the process as a whole, we shift in this work towards instance-based and specific processing for each activity. We showcase a contextualized template-driven framework called the butterfly, along side its architecture that could address the needs of continuous monitoring and prediction. Satisfactory results from evaluations on real data demonstrate the effectiveness of our framework.  ACM 2016. Business process management; Complex event processing; Time series data mining

Scalable process discovery and conformance checking Considerable amounts of data, including process events, are collected and stored by organisations nowadays. Discovering a process model from such event data and verification of the quality of discovered models are important steps in process mining. Many discovery techniques have been proposed, but none of them combines scalability with strong quality guarantees. We would like such techniques to handle billions of events or thousands of activities, to produce sound models (without deadlocks and other anomalies), and to guarantee that the underlying process can be rediscovered when sufficient information is available. In this paper, we introduce a framework for process discovery that ensures these properties while passing over the log only once and introduce three algorithms using the framework. To measure the quality of discovered models for such large logs, we introduce a modelmodel and modellog comparison framework that applies a divide-and-conquer strategy to measure recall, fitness, and precision. We experimentally show that these discovery and measuring techniques sacrifice little compared to other algorithms, while gaining the ability to cope with event logs of 100,000,000 traces and processes of 10,000 activities on a standard computer.  2016 The Author(s) Algorithm evaluation; Big data; Block-structured process discovery; Conformance checking; Directly-follows graphs; Rediscoverability; Scalable process mining

Combining Case-Based Reasoning and Process Mining to improve collaborative decision-making in products design In this paper, we present a research in progress that expose an integral collaborative decision making process combining Case-Based Reasoning approach and the Process Mining techniques (CBR-Mining) to improve designing of manufacturing products. In collaborative decision-making participating actors have different objectives, constraints, knowledge, and viewpoints. The purpose of this paper is to illustrate via a use case study how process mining techniques may be integrated into Case-base-Reasoning.  2015 IEEE. case based reasoning; decision support; Industrial design; knowledge management; process mining; Product development process

Enhancing medical evidence discovery through Interactive Pattern Recognition and process mining Surrounded by heterogeneous clinical data, medical staff needs to take easily the right decisions at the point of care in real time supported by medical evidence. Up to few years ago, evidence was not available at the point of care, making use of doctor's experience or heavy books. Nowadays, the challenge is to have such decision support systems available at any time, any place and any device. Interactive Pattern Recognition is a good approach to infer knowledge based on previous existing datasets whereas process mining is the tool to handle such knowledge in a very pragmatic way, helping medical staff to visualize the whole healthcare case.  2016 IEEE. interactive pattern recognition; medical evidence; process mining

Analysis and prediction cost of manufacturing process based on process mining Analysis and prediction of manufacturing cost play a decisive role in manufacturing process management; however, they face a challenge to be conducted due to the complexity of manufacturing process. Process mining has demonstrated to be a valuable tool for observing and diagnosing inefficiencies of a business process based on event logs. Nevertheless, significantly less attention has been done on investigating cost perspective. Therefore, this paper suggests a framework to analyze and predict manufacturing cost by utilizing and extending existing process mining techniques. In this study, new techniques such as process model-enhanced cost, and cost prediction based on production volume and time prediction using working progress of manufacturing processes are presented.  2016 IEEE. Cost analysis; Cost prediction; Manufacturing cost; Manufacturing process; Processmining

Turning event logs into process movies: animating what has really happened Todays information systems log vast amounts of data. These collections of data (implicitly) describe events (e.g. placing an order or taking a blood test) and, hence, provide information on the actual execution of business processes. The analysis of such data provides an excellent starting point for business process improvement. This is the realm of process mining, an area which has provided a repertoire of many analysis techniques. Despite the impressive capabilities of existing process mining algorithms, dealing with the abundance of data recorded by contemporary systems and devices remains a challenge. Of particular importance is the capability to guide the meaningful interpretation of oceans of data by process analysts. To this end, insights from the field of visual analytics can be leveraged. This article proposes an approach where process states are reconstructed from event logs and visualised in succession, leading to an animated history of a process. This approach is customisable in how a process state, partially defined through a collection of activity instances, is visualised: one can select a map and specify a projection of events on this map based on the properties of the events. This paper describes a comprehensive implementation of the proposal. It was realised using the open-source process mining framework ProM. Moreover, this paper also reports on an evaluation of the approach conducted with Suncorp, one of Australias largest insurance companies.  2014, Springer-Verlag Berlin Heidelberg. Event-log animation; Process mining; Process visualisation; Visual analytics

Process monitoring using maximum sequence divergence Process monitoring involves tracking a systems behaviors, evaluating the current state of the system, and discovering interesting events that require immediate actions. In this paper, we consider monitoring temporal system state sequences to help detect the changes of dynamic systems, check the divergence of the system development, and evaluate the significance of the deviation. We begin with discussions of data reduction, symbolic data representation, and anomaly detection in temporal discrete sequences. Time-series representation methods are also discussed and used in this paper to discretize raw data into sequences of system states. Markov chains and stationary-state distributions are continuously generated from temporal sequences to represent snapshots of the system dynamics in different time frames. We use generalized JensenShannon divergence as the measure to monitor changes of the stationary symbol probability distributions and evaluate the significance of system deviations. We prove that the proposed approach is able to detect deviations of the systems we monitor and assess the deviation significance in probabilistic manner.  2015, Springer-Verlag London. Anomaly detection; Information theory; Process mining; Process monitoring; Sequence data mining

Health care analysis for process deviation using alpha-fitness algorithm in process mining Health care sectors are continuously exploring new and innovative way to improve operational efficiencies. This research study investigate a way to find potential efficiency gains in healthcare sectors by observing how they are carried out in the past and then investigating better ways of implementing them by considering the factors like time, cost and resource utilization. To achieve competitive advantage, healthcare centers try and contour their processes. Process mining can be enforced to extract data from recorded event. The aim of the system is to propose effective process models by applying dataset for each model which indeed identifies the deviation from the actual process with help the of analytical tool ProM. In this paper several blood tests are considered as the baseline scenario wherein effective process models are generated and checked for the efficiency using alpha-fitness algorithm. One of the major parts involved in process improvement is process modeling which can be optimized and analyzed.  2005 - 2016 JATIT & LLS. All rights reserved. Alpha; Event log; Information management systems; Process deviation; Prom

A case study for the application of data and process mining in intervention program assessment and improvement The University of Illinois at Chicago offers an intervention program by admitting students to its Honors College. We call this program Honors Program (HP). HP offers additional, valuable resources that can positively affect the educational trajectory of an individual student. The current selection process for admission into HP or dismissal from HP is traditional. Administration views a students' current Cumulative Grade Point Average (CGPA) and does not look at the students' past. In this paper, we take advantage of the educational history of a student to make the admission or dismissal of each student from HP more effective. We use data and process mining techniques to study students CGPA traces and their HP participation history. We measure the graduation rates of students based on their CGPA traces and HP participation history. We show that it is possible to improve the graduation rate of students if HP admission/dismissal rules are designed based on CGPA traces and HP participation history rather than just the current CGPA of students. The model produced from our study creates a method for both students and administration to evaluate whether or not a student benefits from participating in HP. For students who are eligible and might benefit from HP, the model also determines the optimal entering semester to HP.  American Society for Engineering Education, 2016. 

Construction of decision support system in business design based on integration of information technology In an increasingly competitive environment the successful functioning of any business requires continuous improvement of services, expanding the range of products and range of services, standardization, and implementation of new busines ideas, establishment and dissemination of innovative solutions on the market. The implementation of such measures were carried out in a well-developed business projects. Automating business processes often requires the organization of various programs, which creates a problem of integration. The paper attempts to organizations handling business processes through the integration of various software tools. One of the major component due implementing business projects is the automation of business processes. At the same time, as a result of the automation of business processes significantly increases the efficiency of decision support systems in the enterprise management system.  2016 IEEE. Data Integration; Data-Mining; Decision Support Systems; Enterprise; Enterprise Resource Planning; Information Systems; Supply Chain Management

Industry paper: Lessons learned using a process mining approach to analyze events from distributed applications The execution of distributed applications are captured by the events generated by the individual components. However, understanding the behavior of these applications from their event logs can be a complex and error prone task, compounded by the fact that applications continuously change rendering any knowledge obsolete. We describe our experiences applying a suite of processaware analytic tools to a number of real world scenarios, and distill our lessons learned. For example, we have seen that these tools are used iteratively, where insights gained at one stage inform the configuration decisions made at an earlier stage. As well, we have observed that data onboarding, where the raw data is cleaned and transformed, is the most critical stage in the pipeline and requires the most manual effort and domain knowledge. In particular, missing, inconsistent, and low-resolution event time stamps are recurring problems that require better solutions. The experiences and insights presented here will assist practitioners applying process analytic tools to real scenarios, and reveal to researchers some of the more pressing challenges in this space.  2016 ACM. Event-driven process discovery; Process mining; Process-aware analytics

Process mining in healthcare: A literature review Process Mining focuses on extracting knowledge from data generated and stored in corporate information systems in order to analyze executed processes. In the healthcare domain, process mining has been used in different case studies, with promising results. Accordingly, we have conducted a literature review of the usage of process mining in healthcare. The scope of this review covers 74 papers with associated case studies, all of which were analyzed according to eleven main aspects, including: process and data types; frequently posed questions; process mining techniques, perspectives and tools; methodologies; implementation and analysis strategies; geographical analysis; and medical fields. The most commonly used categories and emerging topics have been identified, as well as future trends, such as enhancing Hospital Information Systems to become process-aware. This review can: (i) provide a useful overview of the current work being undertaken in this field; (ii) help researchers to choose process mining algorithms, techniques, tools, methodologies and approaches for their own applications; and (iii) highlight the use of process mining to improve healthcare processes.  2016 Elsevier Inc. Case studies; Healthcare; Literature review; Process mining; Processes

Coupled hidden Markov model for process mining of invisible prime tasks Process mining provides process improvement in a variety of application domains. A primary focus of process mining is transferring information from event logs into process model. One of the issues of process mining is dealing with invisible prime tasks. An invisible prime task is an additional task in the process model to assist in showing real processes. However, a few of algorithm solves the issue. This research proposes an algorithm for dealing with invisible prime tasks. The proposed algorithm contains rules and equations utilizing probability of state transition of Coupled Hidden Markov and double time-stamped in event logs. The rules and equations are used for determining invisible prime tasks and parallel control-flows patterns. In addition to dealing with invisible prime tasks, the experiment results also show that the proposed algorithm obtains right parallel control-flow patterns from non-complete event logs. This proposed algorithm also decreases usage of the invisible prime task in A# algorithm without reducing the quality of discovered process models. It has proven with the fitness of process models obtained by the proposed algorithm are relatively high as those obtained by A# algorithm.  2016 Praise Worthy Prize S.r.l. - All rights reserved. Coupled hidden Markov model; Double time-stamped event log; Fitness; Invisible prime tasks; Process mining

Recompiling learning processes from event logs In this paper a novel approach to reuse units of learning (UoLs) - such as courses, seminars, workshops, and so on - is presented. Virtual learning environments (VLEs) do not usually provide the tools to export in a standardized format the designed UoLs, making thus more challenging their reuse in a different platform. Taking into account that many of these VLEs are legacy or proprietary systems, the implementation of a specific software is usually out of place. However, these systems have in common that they record the events of students and teachers during the learning process. The approach presented in this paper makes use of these logs (i) to extract the learning flow structure using process mining, and (ii) to obtain the underlying rules that control the adaptive learning of students by means of decision tree learning. Finally, (iii) the process structure and the adaptive rules are recompiled in IMS Learning Design (IMS LD) - the de facto educational modeling language standard. The three steps of our approach have been validated with UoLs from different domains.  2016 Elsevier B.V. All rights reserved. Adaptive rules mining; IMS Learning Design; Learning flows discovery; Process mining

Mining software process lines There is a vast growth of generated event data being collected and stored by organizations. Within the field of Process Mining, this data has been used to discover, analyze and enhance processes from different domains. For this purpose there are hundreds of techniques available in different tools. These techniques are mostly focused on single processes. On the other hand, there are several proposals for dealing with multiple processes. Under different names, such as: configurable process models, process families or process lines, processes are characterized by capturing commonalities and variability between (similar) process models. These approaches have shown to be useful for organizations that have multiple variants of a given process, e.g., reducing redundancy and maintenance time. In this research proposal, we are developing a framework that allows the use of Process Mining techniques in families of processes within the software development domain (i.e., Software Process Lines).  2016 ACM. Process mining; Software process lines; Variability

A process mining-based analysis of business process work-arounds Business process work-arounds are specific forms of incompliant behavior, where employees intentionally decide to deviate from the required procedures although they are aware of them. Detecting and understanding the work-arounds performed can guide organizations in redesigning and improving their processes and support systems. Existing process mining techniques for compliance checking and diagnosis of incompliant behavior rely on the available information in event logs and emphasize technological capabilities for analyzing this information. They do not distinguish intentional incompliance and do not address the sources of this behavior. In contrast, the paper builds on a list of generic types of work-arounds found in practice and explores whether and how they can be detected by process mining techniques. Results obtained for four work-around types in five real-life processes are reported. The remaining two types are not reflected in events logs and cannot be currently detected by process mining. The detected work-around data are further analyzed for identifying correlations between the frequency of specific work-around types and properties of the processes and of specific activities. The analysis results promote the understanding of work-around situations and sources.  2014, Springer-Verlag Berlin Heidelberg. Business process work-arounds; Compliance checking; Process mining

Scalable Process Discovery Using Map-Reduce Process discovery is an approach to extract process models from event logs. Given the distributed nature of modern information systems, event logs are likely to be distributed across different physical machines. Map-Reduce is a scalable approach for efficient computations on distributed data. In this paper we present Map-Reduce implementations of two well-known process mining algorithms to take advantage of the scalability of the Map-Reduce approach. We present the design of a series of mappers and reducers to compute the log-based ordering relations from distributed event logs. These can then be used to discover a process model. We provide experimental results that show the performance and scalability of our implementations.  2008-2012 IEEE. Alpha Algorithm; Flexible Heuristic Miner; Map-Reduce; Process Discovery; Process Mining; Workflow Management

Statistical relational learning for workflow mining The management of business processes can support efficiency improvements in organizations. One of the most interesting problems is the mining and representation of process models in a declarative language. Various recently proposed knowledge-based languages showed advantages over graph-based procedural notations. Moreover, rapid changes of the environment require organizations to check how compliant are new process instances with the deployed models. We present a Statistical Relational Learning approach to Workflow Mining that takes into account both flexibility and uncertainty in real environments. It performs automatic discovery of process models expressed in a probabilistic logic. It uses the existing DPML algorithm for extracting first-order logic constraints from process logs. The constraints are then translated into Markov Logic to learn their weights. Inference on the resulting Markov Logic model allows a probabilistic classification of test traces, by assigning them the probability of being compliant to the model. We applied this approach to three datasets and compared it with DPML alone, five Petri net- and EPC-based process mining algorithms and Tilde. The technique is able to better classify new execution traces, showing higher accuracy and areas under the PR/ROC curves in most cases.  2016 - IOS Press and the authors. All rights reserved. business process management; inductive logic programming; knowledge-based process models; process mining; statistical relational learning; Workflow mining

Mining structured Petri nets for the visualization of process behavior Visualization is essential for understanding the models obtained by process mining. Clear and efficient visual representations make the embedded information more accessible and analyzable. This work presents a novel approach for generating process models with structural properties that induce visually friendly layouts. Rather than generating a single model that captures all behaviors, a set of Petri net models is delivered, each one covering a subset of traces of the log. The models are mined by extracting slices of labelled transition systems with specific properties from the complete state space produced by the process logs. In most cases, few Petri nets are sufficient to cover a significant part of the behavior produced by the log.  2016 ACM. Petri nets; Process mining; Visualization

Goal achievement analysis based on LTL checking and decision tree for improvements of PAIS Process aware information system (PAIS) is important in the recent business environment. Developments of PAIS need to consider contexts about technical and business elements. They are needed to develop PAIS effectively (e.g. monitoring environment and constructing adequate business process). Process mining is an important method for analyzing a business environment and utilizing PAIS development and improvement. LTL checking is an important method for checking a specific property to be satisfied with business processes, but correctly writing formal language like LTL is difficult. In this paper, we use LTL checking and prediction based on decision-tree learning for checking goal achievement, false detection and oversight detection. It helps writing properly LTL formula for representing the correct goal property. We conducted a case study using a real life log of traffic fine management process in Italy.  2016 ACM. Conformance checking; Process aware information system; Process mining; Process modeling

Business process compliance checking  Applying and evaluating a generic pattern matching approach for conceptual models in the financial sector Given the strong increase in regulatory requirements for business processes the management of business process compliance becomes a more and more regarded field in IS research. Several methods have been developed to support compliance checking of conceptual models. However, their focus on distinct modeling languages and mostly linear (i.e., predecessor-successor related) compliance rules may hinder widespread adoption and application in practice. Furthermore, hardly any of them has been evaluated in a real-world setting. We address this issue by applying a generic pattern matching approach for conceptual models to business process compliance checking in the financial sector. It consists of a model query language, a search algorithmand a corresponding modelling tool prototype. It is (1) applicable for all graph-based conceptual modeling languages and (2) for different kinds of compliance rules. Furthermore, based on an applicability check, we (3) evaluate the approach in a financial industry project setting against its relevance for decision support of audit and compliance management tasks.  Springer Science+Business Media New York 2014. Business process compliance management; Business process modeling; Conceptual modeling; Model checking; Model querying; Patternmatching compliance checking

Process-mining enabled feedback: "tell me what i did wrong" vs. "tell me how to do it right" Fast advancement of technology has led to an increased interest for using information technology to provide feedback based on learning behavior observations. This work outlines a novel approach for analyzing behavioral learner data through the application of process mining techniques specifically targeting a complex problem solving process. We realize this in the context of one particular learning case, namely, domain modeling. This work extends our previous research on process-mining analysis of domain modeling behavior of novices by elaborating with new insights from a replication study enhanced with an extra observation on how novices verify/validate models. The findings include a set of typical modeling and validation patterns that can be used to improve teaching guidance for domain modeling courses. From a scientific viewpoint, the results contribute to improving our knowledge on the cognitive aspects of problem-solving behavior of novices in the area of domain modeling, specifically regarding process-oriented feedback as opposed to traditional outcome feedback (is a solution correct? Why (not)?) usually applied in this type of courses. Ultimately, the outcomes of the work can be inspirational outside of the area of domain modeling as learning event data is becoming readily available through virtual learning environments and other information systems.  2015 Elsevier Ltd. All rights reserved. Conceptual modeling; Domain modeling; Information systems education; Learning analytics; Modeling patterns; Process mining; Process-oriented feedback; Teaching/learning modeling

Hidden markov model for process mining of parallel business processes One of all the works on process mining is the process discovery which produces a representation of a parallel business process. This representation is called process model and it consists of sequence and parallel control-flow patterns. The parallel control-flow patterns contain XOR, AND, and OR relations. Hidden Markov Model is rarely used to represent a process model since XOR, AND and OR relations are not visible. In Hidden Markov Model, the control-flow patterns are represented by probabilities of state transitions. This research proposes an algorithm consisting in a process discovery based on Hidden Markov Model. This algorithm contains equations and rules: the equations are used to differentiate XOR, AND, and OR relations, while the rules are used to establish the process model utilizing detected control-flow patterns. The experiment results show that the proposed algorithm obtain the right control-flow patterns in the process model. The paper demonstrates that the fitness of process models obtained by the proposed algorithm are relatively higher respect to those obtained by Heuristics Miner and Timebased Heuristics Miner algorithms. This paper also shows that the validity of process models obtained by the proposed algorithm are better than those obtained by other algorithms.  2016 Praise Worthy Prize S.r.l. - All rights reserved. Fitness; Hidden markov model; Parallel business process; Process mining; Validity

Metamodel of the artifact-centric approach to event log extraction from ERP systems Enterprise Resource Planning (ERP) systems handle a huge amount of data related to the actual execution of business processes and the goal is to discover from transaction log a model of how the business processes are actually carried out. The authors' work captures the knowledge of existing approaches and tools in converting the data from transaction logs to event logs for process mining techniques. They conduct a detailed analysis of the artifact-centric approach concepts and describe its constructs by the ontological metamodel. The underlying logical and semantically rich structure of the approach is presented through the model definition. The paper specifies how concepts of the data source are mapped onto the concept of the event log. Dynamics NAV ERP system is used as an example to illustrate the data-oriented structure of ERP system. Copyright  2016, IGI Global. Data conversion; Dynamics NAV; ERP system; Event log; Metamodel; Process mining

Balanced multi-perspective checking of process conformance Organizations maintain process models that describe or prescribe how cases (e.g., orders) are handled. However, reality may not agree with what is modeled. Conformance checking techniques reveal and diagnose differences between the behavior that is modeled and what is observed. Existing conformance checking approaches tend to focus on the control-flow in a process, while abstracting from data dependencies, resource assignments, and time constraints. Even in those situations when other perspectives are considered, the control-flow is aligned first, i.e., priority is given to this perspective. Data dependencies, resource assignments, and time constraints are only considered as second-class citizens, which may lead to misleading conformance diagnostics. For example, a data attribute may provide strong evidence that the wrong activity was executed. Existing techniques will still diagnose the data-flow as deviating, whereas our approach will indeed point out that the control-flow is deviating. In this paper, a novel algorithm is proposed that balances the deviations with respect to all these perspectives based on a customizable cost function. Evaluations using both synthetic and real data sets show that a multi-perspective approach is indeed feasible and may help to circumvent misleading results as generated by classical single-perspective or staged approaches.  2015, The Author(s). Data Petri nets; Log-process alignment; Multi-perspective conformance checking; Process mining

Assessing Big Data SQL Frameworks for Analyzing Event Logs Performing Process Mining by analyzing event logs generated by various systems is a very computation and I/O intensive task. Distributed computing and Big Data processing frameworks make it possible to distribute all kinds of computation tasks to multiple computers instead of performing the whole task in a single computer. This paper assesses whether contemporary structured query language (SQL) supporting Big Data processing frameworks are mature enough to be efficiently used to distribute computation of two central Process Mining tasks to two dissimilar clusters of computers providing BPM as a service in the cloud. Tests are performed by using a novel automatic testing framework detailed in this paper and its supporting materials. As a result, an assessment is made on how well selected Big Data processing frameworks manage to process and to parallelize the analysis work required by Process Mining tasks.  2016 IEEE. automatic business process discovery; distributed computing framework; distributed SQL; event log analysis; Hadoop; Hive; Presto; process mining; Spark

A Value Semantics Framework for Business Process Network Management The concept of Big Data of Values within Business Process Network Management has been used in many different ways and all sorts of concepts, such as large quantity of data, social media analytics, new capabilities of data management, real-time data, data mining, and many others. Currently, considering the ability to profoundly affect commerce cooperation, Business Process Engineering is a business need to understand semantics of the Legacy Data, Transitions, and its Synchronicity with the Final Expected Values and Results in the globally interoperated economy. This paper presents a framework of a Business Value Living Laboratory to lead with Semantic Modeling for Big Data Analytics.  2016 IEEE. business process management; business process network; Living laboratory; semantic modeling framework

A slippery genetic algorithm-based process mining system for achieving better quality assurance in the garment industry Due to the error-prone nature of garment manufacturing operations, it is challenging to guarantee the quality of garments. Previous research has been done to apply fuzzy association rule mining to determine process settings for improving the garment quality. The relationship between process parameters and the finished quality is represented in terms of rules. This paper enhances the application by encoding the rules into variable-length chromosomes for optimization with the use of a novel genetic algorithm (GA), namely the slippery genetic algorithm (sGA). Inspired by the biological slippage phenomenon in DNA replication, sGA allows changes to the chromosome lengths by insertion and deletion. During rule optimization, different parameters can be inserted to or removed from a rule, increasing the diversity of the solutions. In this paper, a slippery genetic algorithm-based process mining system (sGAPMS) is developed to optimize fuzzy rules with the aim of facilitating a comprehensive quality assurance scheme in the garment industry. The significance of this paper includes the development of a novel variable-length GA mechanism and the hybridization of fuzzy association rule mining and variable-length GAs. Though the capability of conventional GA in rule optimization has been proven, the diversity in the population is inherently limited by the fixed chromosome length. Motivated by this phenomenon, the sGA suggested in this paper allows various parameters to be considered in a rule, improving the diversity of the solutions. A case study is conducted in a garment manufacturing company to evaluate the sGAPMS. The results illustrate that better quality assurance can be achieved after rule optimization.  2015 Elsevier Ltd. Biological slippage; Fuzzy association rule mining; Garment industry; Genetic algorithm; Quality assurance

Personalized micro-learning support based on process mining Micro-Learning is a new leaning paradigm based on microblogging, e-mail or SMS, in which an integral learning resource consists of a series of micro learning units that are dispersed via the services of Internet, and can be used to help users learn at anywhere with a short-term. But the problem is that most of the micro learning units are disorganized. Therefore, it is a critical issue how to organize these micro learning units, in order to make them easier to be used and learned. In this study, we propose an approach based on process mining to organize the learning units according to the situation of users. Firstly, the successful micro-learning processes are extracted from the access logs. And then, the learning process map named navigation map is created based on the domain knowledge and the access sequence of users. Secondly, according to the similarity of access behavior, a reference user group is extracted dynamically for a target user. Based on the dynamic Bayesian network, the navigation map is then used to calculate the posterior probabilities of learning units. Finally, on the basis of posterior probabilities, a learning unit can be recommended for the target user to learn as the next step. The results are provided to the target user gradually, until the target user finish the whole course by the guide of learning process at his/her fragmented time.  2015 IEEE. Big data; Micro-learning; Process mining

Process model representation layers for financial audits Business processes play a significant role in financial audits. They are carried out by auditors who require diverse information for this purpose. Process mining techniques offer new opportunities to exploit data from ERP systems to generate reliable process models very effectively and efficiently. Traditional process models are only suited to provide information on a single process. This study illustrates how diverse information aspects that are required for process audits can be provided to the auditor by using different process model types that relate to different representation layers. Process mining techniques commonly operate on the business process and instance level. This study introduces process map and process stream models as higher level abstractions of multiple business processes. The introduction of higher-level process models in combination with traditional model types allows an all-encompassing representation of information aspects that are relevant for process audits in the context of financial audits.  2016 IEEE. Big data analytics; Business process modeling; Design science; ERP systems; Financial audits; Process mining

A generic platform to automate legal knowledge work process using machine learning Management of legal contracts in various business domains such as Real Estate are examples of typical business process outsourcing activity. One of such process is Lease Abstraction, where largely manual inspection and validation of large commercial lease documents made for real estate deals is done by offshore experts and relevant information from the documents is extracted into a structured form. This structured information is further used for aggregate analytics and decision making by large real estate firms. We propose a system based on machine learning techniques to semi automate this process, essentially leading to 50% human effort savings. Our approach weaves together state-of-the-art machine learning techniques like supervised classifier models, sequence modeling techniques and various semi-supervised approaches. We articulate the effectiveness of our solution using the results from the experiments. Our platform is being used in production environment by Accenture Operations and the initial results and user feedback are encouraging.  2015 IEEE. Information extraction; Knowledge work automation; Machine learning; Natural language processing; Process automation; Supervised and semi supervised learning

Determining process model using Time-based Process Mining and control-flow pattern Determining right model of business process from event log is the purpose of process discovery. However some problems i.e the inability to discover OR, noise and event log incompleteness are emmerged while determining right model of business process. First, OR relation is often discovered as AND relation. Second, noise problem is occured when there are truncated and low frequency traces in event log. Thus control-flow pattern is used to solve issues of same noise relation frequency hence it discovers relation based on transaction function of activity. Consequently, it can refine non noise relation in business process model. Third, incompleteness leads to incorrect discovery of parallel process model; therefore we used Timed-based Process Mining which utilized non-linear dependence to solve the incompleteness. Finally this paper proposed combination of Timed-based Process Mining and control-flow pattern to discover OR and handle same frequency noise and incompleteness. From the experiment in section 3, this proposed method manages to get right process model from event log.  2016 Universitas Ahmad Dahlan. Conditional OR; Control-flow pattern; Incompleteness; Noise; Timed-based Process Mining

A general process mining framework for correlating, predicting and clustering dynamic behavior based on event logs Process mining can be viewed as the missing link between model-based process analysis and data-oriented analysis techniques. Lions share of process mining research has been focusing on process discovery (creating process models from raw data) and replay techniques to check conformance and analyze bottlenecks. These techniques have helped organizations to address compliance and performance problems. However, for a more refined analysis, it is essential to correlate different process characteristics. For example, do deviations from the normative process cause additional delays and costs? Are rejected cases handled differently in the initial phases of the process? What is the influence of a doctors experience on treatment process? These and other questions may involve process characteristics related to different perspectives (control-flow, data-flow, time, organization, cost, compliance, etc.). Specific questions (e.g., predicting the remaining processing time) have been investigated before, but a generic approach was missing thus far. The proposed framework unifies a number of approaches for correlation analysis proposed in literature, proposing a general solution that can perform those analyses and many more. The approach has been implemented in ProM and combines process and data mining techniques. In this paper, we also demonstrate the applicability using a case study conducted with the UWV (Employee Insurance Agency), one of the largest "administrative factories" in The Netherlands.  2015 Elsevier Ltd.All rights reserved. Decision and regression trees; Event-log clustering; Event-log manipulation; Process mining

Modified time-based heuristics miner for parallel business processes Process Mining, or Process Discovery, is a method for modeling the workflow of a business process from event logs. Business process models contain sequential and parallel traces. In this paper, a modification of the frequently used process-mining algorithm Heuristics Miner is proposed. The proposed algorithm is called Modified Time-based Heuristics Miner because it considers not only the sequence of activities but also the time-based information from the event log. It can effectively distinguish parallel (AND), single choice (XOR) and conditional (OR) patterns; the latter cannot be discovered by the original Heuristics Miner. The threshold intervals are determined on the basis of the average dependency measure in the dependency graph. The experimental results show that the proposed algorithm is able to discover concurrent business processes formed by parallel (AND) and conditional (OR) patterns, whereas the existing Heuristics Miner algorithm can only discover concurrent business processes formed by parallel (AND) patterns. This paper also provides an evaluation of validity and fitness of the discovered process model.  2016 Praise Worthy Prize S.r.l. - All rights reserved. Activity Lifespan; Completeness; Double time-stamped event log; Fitness; Heuristics Miner; Parallel business process; Process discovery; Process mining; Time-based interval

Efficient discovery of Target-Branched Declare constraints Process discovery is the task of generating process models from event logs. Mining processes that operate in an environment of high variability is an ongoing research challenge because various algorithms tend to produce spaghetti-like process models. This is particularly the case when procedural models are generated. A promising direction to tackle this challenge is the usage of declarative process modelling languages like Declare, which summarise complex behaviour in a compact set of behavioural constraints on activities. A Declare constraint is branched when one of its parameters is the disjunction of two or more activities. For example, branched Declare can be used to express rules like "in a bank, a mortgage application is always eventually followed by a notification to the applicant by phone or by a notification by e-mail". However, branched Declare constraints are expensive to be discovered. In addition, it is often the case that hundreds of branched Declare constraints are valid for the same log, thus making, again, the discovery results unreadable. In this paper, we address these problems from a theoretical angle. More specifically, we define the class of Target-Branched Declare constraints and investigate the formal properties it exhibits. Furthermore, we present a technique for the efficient discovery of compact Target-Branched Declare models. We discuss the merits of our work through an evaluation based on a prototypical implementation using both artificial and real-life event logs.  2015 Elsevier Ltd. Declarative process; Knowledge discovery; Process mining

BPMN Miner: Automated discovery of BPMN process models with hierarchical structure Existing techniques for automated discovery of process models from event logs generally produce flat process models. Thus, they fail to exploit the notion of subprocess as well as error handling and repetition constructs provided by contemporary process modeling notations, such as the Business Process Model and Notation (BPMN). This paper presents a technique, namely BPMN Miner, for automated discovery of hierarchical BPMN models containing interrupting and non-interrupting boundary events and activity markers. The technique employs approximate functional and inclusion dependency discovery techniques in order to elicit a process-subprocess hierarchy from the event log. Given this hierarchy and the projected logs associated to each node in the hierarchy, parent process and subprocess models are discovered using existing techniques for flat process model discovery. Finally, the resulting models and logs are heuristically analyzed in order to identify boundary events and markers. By employing approximate dependency discovery techniques, BPMN Miner is able to detect and filter out noise in the event log arising for example from data entry errors, missing event records or infrequent behavior. Noise is detected during the construction of the subprocess hierarchy and filtered out via heuristics at the lowest possible level of granularity in the hierarchy. A validation with one synthetic and two real-life logs shows that process models derived by the proposed technique are more accurate and less complex than those derived with flat process discovery techniques. Meanwhile, a validation on a family of synthetically generated logs shows that the technique is resilient to varying levels of noise.  2015 Elsevier Ltd. Automated process discovery; BPMN; Process mining

Utilization of sequential data for machine learning in process control Correct data collection and reasonably timely data processing are very important in Big Data analysis. Furthermore, interpreting the analyzed result is also an interesting issue. Although many sophisticated data mining techniques are already available, they cannot be applied directly to process mining, due to the input-data format differences. For example, whereas data mining techniques focus on the relations between attributes without considering the process, formatting data as row-based instances, process mining finds flow-patterns among instances, formatting data as column-based instances in the MXML/XES format. In the present study, we utilized a sequential dataset to enable the use of more enhanced statistical methods and to broaden the utilization of process analysis to many sophisticated data mining techniques. We experimented on artificial data to calculate the activities probability distribution using machine learning and the probability density function (PDF).  2016, ICIC International. K-means clustering; Machine learning; Probability density function (PDF); Process analysis; Sequence analysis

A business-data-oriented workflow mining algorithm and its application The mining of workflow process aims at finding valuable objective information from log data. It leads useful implications for new business processes and analysis. Unfortunately most of business process data is incomplete and noisy which brings deficiencies for describing and mining workflow. The existing algorithms ignore time-based parameters, which is important for processing the incomplete workflow data. In this paper, we define the parameters of single transaction frequency and time intervals. Then we propose a business-data-oriented workflow excavation algorithm (termed as E-&-algorithm), which improves the exploration of differences between the actual business processes by removing noisy data efficiently. With this new algorithm, we aim to optimize the key business process model and build future intelligent workflow system to assist decision-making and process mechanism optimization.  2015 IEEE. Business data; E algorithm; Workflow mining

Using process mining to model interarrival times: Investigating the sensitivity of the ARPRA framework Accurately modeling the interarrival times (IAT) is important when constructing a business process simulation model given its influence on process performance metrics such as the average flow time. To this end, the use of real data from information systems is highly relevant as it becomes more readily available. This paper considers event logs, a particular type of file containing process execution information, as a data source. To retrieve an IAT input model from event logs, the recently developed ARPRA framework is used, which is the first algorithm that explicitly integrates the notion of queues. This paper investigates ARPRA's sensitivity to the initial parameter set estimate and the size of the original event log. Experimental results show that (i) ARPRA is fairly robust for the specification of the initial parameter estimate and (ii) ARPRA's output represents reality more closely for larger event logs than for smaller logs.  2015 IEEE. 

Model discovery of parallel business processes using modified Heuristic Miner Process Mining or Process Discovery is a method to automatically discover process models from event log data. Since the process discovery is gaining attention among researchers as well as practitioners, the quality of the resulted process models is required. Business process model contains sequence and parallel traces. Many algorithms have been employed for process discovery, such as Alpha, Alpha++ and Heuristic Miner. Both Alpha ++ and existing Heuristic Miner cannot discover processes containing parallel OR. In this paper we propose the modified Heuristic Miner which utilizes the threshold intervals to discover parallel XOR, AND, and OR. The threshold intervals are determined based on average dependency measure in dependency graph. The results show that the modified Heuristic Miner can discover OR split and join which cannot be discovered by Alpha ++ as well as the existing Heuristic Miner.  2015 IEEE. Discovery Parallel Activity OR and AND; Modified Heuristic Miner; Process Discovery

Assessing Process Discovery Scalability in Data Intensive Environments Tremendous developments in Information Technology (IT) have enabled us to store and process huge amounts of data at unprecedented rates. This phenomenon largely impacts business processes. The field of process discovery, originating from the area of process mining, is concerned with automatically discovering process models from event data related to the execution of business processes. In this paper, we assess the scalability of applying process discovery techniques in data intensive environments. We propose ways to compute the internal data abstractions used by the discovery techniques within the MapReduce framework. The combination of MapReduce and process discovery enables us to tackle much bigger event logs in less time. Our generic approach scales linearly in terms of the data size and the number of computational resources used, and thus, shows great potential for the adoption of process discovery in a Big Data context.  2015 ACM. Automated process discovery; Big Data; Hadoop; MapReduce; Process mining; ProM; Scalability

Using a flow graph to represent data flow and dependency in event logs The idea of extracting knowledge in process mining is a descendant of data mining. Both mining disciplines emphasise data flow and relations among elements in the data. Unfortunately, challenges have been encountered when working with the data flow and relations. One of the challenges is that the representation of the data flow between a pair of elements or tasks is insufficiently simplified and formulated, as it considers only a one-to-one data flow relation. In this paper, we discuss how the effectiveness of knowledge representation can be extended in both disciplines. To this end, we introduce a new representation of the data flow and dependency formulation using a flow graph. The flow graph solves the issue of the insufficiency of presenting other relation types, such as many-to-one and one-to-many relations. As an experiment, a new evaluation framework is applied to the Teleclaim process in order to show how this method can provide us with more precise results when compared with other representations.  2015 IEEE. Data Flow; Data Mining; Dependency; Flow Graph; Process Mining

Analyzing PACS Usage Patterns by Means of Process Mining: Steps Toward a More Detailed Workflow Analysis in Radiology In this paper, statistical analysis and techniques from process mining are employed to analyze interaction patterns originating from radiologists reading medical images in a picture archiving and communication system (PACS). Event logs from 1 week of data, corresponding to 567 cases of single-view chest radiographs read by 14 radiologists, were analyzed. Statistical analysis showed that the numbers of commands and command types used by the radiologists per case only have a slightly positive correlation with the time to read a case (0.31 and 0.55, respectively). Further, one way ANOVA showed that the factors time of day, radiologist and specialty were significant for the number of commands per case, whereas radiologist was also significant for the number of command types, but with no significance of any of the factors on time to read. Applying process mining to the event logs of all users showed that a seemingly simple examination (single-view chest radiographs) can be associated with a highly complex interaction process. However, repeating the process discovery on each individual radiologist revealed that the initially discovered complex interaction process consists of one group of radiologists with individually well-structured interaction processes and a second smaller group of users with progressively more complex usage patterns. Future research will focus on metrics to describe derived interaction processes in order to investigate if one set of interaction patterns can be considered as more efficient than another set when reading radiological images in a PACS.  2015, Society for Imaging Informatics in Medicine. Chest radiographs; Data mining; Efficiency; PACS; Productivity; Workflow

Providing online operational support for distributed, security sensitive electronic business processes Online process mining techniques are increasingly used to provide operational support. In this work we describe tools to support distributed business processes which handle sensitive data and require a high level of security together with real-time validation. The techniques presented here have been specifically developed for real-time compliance checking of distributed processes in choreographies of heterogeneous entities. Challenges include the fast aggregation, analysis and validation of process logs that are collected from the distributed participants. The autonomy of the participating entities has to be respected and no sensitive data pertaining to the content of the individual transactions must be accessed for process support and validation purposes. A validation authority for process monitoring and validation is set up. Together with software agents dispatched to the participating entities the validation authority collects events in a central log and then analyzes these events using a particular representation of the process in form of a validation tree to detect and resolve anomalies. We describe the application of these technologies in a distributed business process with more than 400,000 daily process executions. The business process is supported by a help desk managing and responding to incidents and anomalies. We observe a reduction of 90% of the calls to the help desk and an average reduction of 15% in call length. Further the help desk was enabled to act pro-actively, calling participants to the process even before they became aware of anomalies that affected their organization.  2015 IEEE. compliance checking; IT security; IT service desk automation; operational support; process mining; real-time business process validation

Decomposition using Refined Process Structure Tree (RPST) and control flow complexity metrics Process mining is a technique that aims to gain knowledge of the event log. The amount of data in the event log is very influential in the Process mining, because it contains millions of activities that shape the behavior of a company. The three main capabilities possessed by mining process is a discovery, conformance, and enhancement. This paper, we present an approach to decompose business processes using Refine Process Structure Tree (RPST). By breaking down a whole into sub models Business Processes (fragments) to the smallest part (atomic) can facilitate the analysis process and can easily be rebuilt. To measure the level of complexity in the model fragment and atomic models we use complexity Control flow metrics. Control flow complexity metrics have two main approaches that are count based measurement and execution path based measurement path. Count based measurement used to describe a static character, while an execution path based measurement used to describe the dynamic character of each model fragment or atomic models (bond fragment).  2015 IEEE. control flow complexity metrcs; decompose business process; Process mining; refined process structure tree

Time based Discovery of parallel business processes Process mining for discovering concurrent activities is important since there are many of them contained in business processes. The concurrency is formed by AND parallel or OR conditional. However, most of the existing process mining algorithm discover only concurrency formed by AND parallel. Substituting OR conditional with AND parallel does not always discover the real business processes. Also, the existing process mining algorithms use linear dependence principle; therefore, they require complete event logs which are difficult to be provided since there are many possible traces. In this regard, this paper proposes Time based Discovery algorithm which utilizes non-linear dependence principle. The proposed algorithm can effectively distinguish AND parallel and OR conditional. The experimental results show that the proposed algorithm can discover the concurrent business processes formed by AND parallel or OR conditional.  2015 IEEE. Incompleteness; Parallel Bussiness Process; Time Based Process Mining

Research on the computer-aided business process management based on Data mining and Apriori algorithm In recent years, data centric business process is becoming a new trend in the development of BPM. It is very valuable for enterprises to make full use of these resources and knowledge, to dig out the new process model or to find the deficiency in the existing process model. In this paper, the author analyzes the computer-aided business process management based on data mining and artifact. Process model mining technology is an important way to implement process reengineering and optimization. Through the construction of computer aided business process model. The results show that the improved data mining algorithm has significant advantages in query time and execution efficiency, shows higher recall and precision rate. Apriori algorithm; Business process; Computer-aided; Data mining

Towards a formal framework for business process re-design based on data mining In todays ever changing world, business processes need to be dynamic. Data accumulated as the processes operate capture the meaning of transactions in the past, which opens a door for the dynamics of the business processes in question. Mining the operational data to explicitly represent this meaning could lead to process re-design to make the business processes more efficient. In this paper, we propose a formal framework for redesigning business processes taking data mining rules and business rules as the driver. We formally represent business processes using the artifact-centric approach put forward by the IBM Research. We devise redesigning algorithms that take classification rules extracted from data mining together with business rules and transform the business process in question by eliminating redundant tasks and/or re-ordering inefficiently placed tasks. We illustrate our algorithms and report experiments that were conducted using a proof-of-concept case-study.  Springer International Publishing Switzerland 2016. Artifact-centric processes; Data mining; Formal methods; Process modeling; Process redesign

A graph and trace clustering-based approach for abstracting mined business process models Process model discovery is a significant research topic in the business process mining area. However, existing workflow discovery techniques run into a stone wall while dealing with event logs generated from highly flexible environments because the raw models mined from such logs often suffer from the problem of inaccuracy and high complexity. In this paper, we propose a new process model abstraction technique for solving this problem. The proposed technique is able to optimise the quality of the potential high level model (abstraction model) so that a high-quality abstraction model can be acquired and also considers the quality of the submodels generated where each sub-model is employed to show the details of its relevant high level activity in the high level model. Copyright  2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved. Business process mining; Business process model abstraction; Graph clustering; Trace clustering; Workflow discovery

Business process models for visually navigating process execution data To analyze large amounts of data, visual analysis tools offer filter mechanisms for drilling down into multi-dimensional information spaces, or slicing and dicing them according to given criteria. This paper introduces an analysis approach for navigating multi-dimensional process instance execution logs based on business process models. By visually selecting parts of a business process model, a set of available log entries is filtered to include only those entries that result from execution instances of the selected process branches. Using this approach allows to exploratively navigate through process execution logs and analyze them according to the causal-temporal relationships encoded in the underlying business process model. The business process models used by the approach can either be created using model editors, or be statistically derived using process mining techniques. We exemplify our approach with a prototypical implementation.  Springer International Publishing Switzerland 2016. Big data; Business analysis; Business intelligence; Business process modeling; Process mining; Visual analysis

Business process merging based on topic cluster and process structure matching This article presents an approach for automating business process consolidation by applying process topic clustering based on business process libraries, using graph mining algorithm to extract process patterns, find out frequent sub-graphs under the same process topic, then filling sub-graph information into the table of process frequent sub-graph, finally merging these frequent sub-graphs to get merged business processes on the basis of process merge algorithm. We use compression ratio to judging the capability of our merge methods, the compression ratios of integrated processes in same topic cluster are much lower than the different topic processes, and our method achieves similar compression ratio compare with previous work.  Springer Science+Business Media Singapore 2016. Business process merge; Correlated Topic Model; Gspan; Process sub-graph; Topic distillation

Towards a general solution for business process model extension with cost perspective based on Process Mining Several organizations look for improving their Business Processes (BP) in order to enhance their efficiency and competitiveness. BP Management (BPM) approach includes techniques allowing continuous BP improvement. Process Mining (PMining) is a BPM technique allowing to extract knowledge from event logs commonly available in today's information systems. BP model extension is a PMining technique enriching a BP model with different perspectives useful for decision making support. Furthermore, financial costs incurred during BP execution is prominent information needed for BP improvement decision making in terms of cost reduction. We proposed a solution for BP model extension with cost perspective based on PMining. The solution is based on cost extension of the High Level Process Structure (HLPS) which is a meta-model enabling the integration of different perspectives into one model independently of its notation. However, the cost extension is designed only at the activity level and the general approach needs to be validated. In this paper, on one hand, we propose an improved version of the proposed approach providing cost extension including cost data description and analysis at both activity and BP levels, and on the other hand, we present an illustration of the improved solution. Business process management; Cost extension; High Level Process Structure; Process mining

Supporting social network analysis using chord diagram in process mining Data visualization is an important area of research aims to empower people to discover information from data through visual artefacts. The huge volume of data can result in abundance of elements in data visualization, which can make the information discovery challenging. Chord diagrams is a sort of visual representation that has been recently introduced to increase the level of abstraction. Although this diagram is widely used and adapted in many disciplines, it is not currently implemented in Business Process Management (BPM). Thus, this paper extends the social network visualization approaches in BPM area using chord diagram. This paper defines the formal definitions of elements and elaborates on how the visual representation can be compiled from them. The visualization is supported by implementing a plug-in in ProM. The plug-in is used to demonstrate social networks discovered from real log files in compare with those discovered by current visualization techniques. The result shows that this technique can complement previous ones to discover more social network patterns in BPM area.  Springer International Publishing Switzerland 2016. Business process; Process mining; Social network; Visualization

A novel heuristic method for improving the fitness of mined business process models Business process model discovery (BPMD) is one of the most important research topics in the business process mining area. Many outstanding BPMD algorithms which perform well in most cases have been developed in the last years. As one of the most widely used BPMD algorithms, the Heuristics Miner meets great challenges while dealing with event logs that contain complex behaviours. As a result, process models with low fitness values might be obtained. In this paper, we propose a new technique that is able to locate the process behaviours recorded in an event log which cannot be expressed by the Heuristics Miner and then transform them into expressible behaviours so that a high-fitness model can be built.  Springer International Publishing Switzerland 2016. Business process mining; Business process model discovery; Heuristics miner; Model fitness improvement

Cross-system process mining using RFID technology In times of digitalization, the collection and modeling of business processes is still a challenge for companies. The demand for trustworthy process models that reflect the actual execution steps therefore increases. The respective kinds of processes significantly determine both, business process analysis and the conception of future target processes and they are the starting point for any kind of change initiatives. Existing approaches to model as-is processes, like process mining, are exclusively focused on reconstruction. Therefore, transactional protocols and limited data from a single application system are used. Heterogeneous application landscapes and business processes that are executed across multiple application systems, on the contrary, are one of the main challenges in process mining research. Using RFID technology is hence one approach to close the existing gap between different application systems. This paper focuses on methods for data collection from real world objects via RFID technology and possible combinations with application data (process mining) in order to realize a cross system mining approach. Cross-system; Process mining; Production; RFID

Re-expressing business processes information from corporate documents into controlled language In this paper, we propose a top-down approach for converting business processes information from corporate documents into controlled language. This proposal is achieved with a multi-level methodology. We first characterize document structure by using rhetorical analysis to determine relevant sections for information extraction. Then, a verb-centered event analysis is performed to start defining the typical patterns featured by business processes information. Lastly, morpho-syntactic and dependency parsing is carried out for extracting this information. This multi-level knowledge is used to define rules for converting the extracted sentences into a controlled language, which is intended to be used in software requirements elicitation.  Springer International Publishing Switzerland 2016. Business processes; Controlled language; Information extraction; Rhetorical analysis

Repairing alignments: Striking the right nerve Process Mining is concerned with the analysis, understanding and improvement of business processes. One of the most important branches of process mining is conformance checking, i.e. assessing to what extent a business process model conforms to observed business process execution data. Alignments are the de facto standard instrument to compute conformance statistics. Alignments map elements of an event log onto activities present in a business process model. However, computing them is a combinatorial problem and hence, extremely costly. In this paper we show how to compute an alignment for a given process model, using an existing alignment and an existing process model as a basis. We show that we are able to effectively repair the existing alignment by updating those parts that no longer fit the given process model. Thus, computation time decreases significantly. Moreover, we show that the potential loss of optimality is limited and stays within acceptable bounds.  Springer International Publishing Switzerland 2016. Alignments; Conformance checking; Process mining

A semantic framework for configurable business process as a service in the cloud With the advent of Cloud Computing, new opportunities for Business Process Outsourcing services have emerged. Business Process as a Service (BPaaS), a new cloud service model, has recently gained a great importance for outsourcing cloud-based business processes constructed for multi-tenancy. In such a multi-tenant environment, using configurable business process models enables the sharing of a reference process among different tenants that can be customized according to specific needs. With a large choice of configurable process modeling languages, different providers may deliver configurable processes with common functionalities but different representations which makes the process discovery and configuration a manual tedious task. This in turn creates cloud silos and vendors lock-in with non-reusable configurable BPaaS models. Therefore, with the aim of enabling the interoperability between multiple BPaaS providers, we propose in this paper a semantic framework for BPaaS configurable models. Taking advantage of Semantic Web technologies and data mining techniques, our framework allows for (1) an ontology-based high level abstract representation of BPaaS configurable models enriched with configuration guidelines and (2) an automated approach for extracting the configuration guidelines from existing process repositories. To show the feasibility and effectiveness of our approach, we extend Signavio with our semantic framework and conduct experiments on a dataset from SAP reference model.  2015 Elsevier Ltd. All rights reserved. BPaaS; Business Process as a Service; Cloud Computing; Configurable process model; Green IT; Semantic technology

Business intelligence for business processes: The case of it incident management IT service desks have become an integral part of intra-enterprise ecosystems, keeping IT hardware and software services within the company running. Business Intelligence methods have an enormous potential to support IT helpdesk employees by making implicit knowledge explicit, accelerating business processes throughout the entire company, and retaining the knowledge of experienced employees upon retirement. In this paper, we investigate these benefits by showing how analytics can automate the assignment of helpdesk tasks, enable early warning mechanisms for accumulated incidents, and enhance knowledge sharing among helpdesk users. For this purpose, we use a combination of topic modeling and predictive analytics, which is applied to an extensive dataset of support tickets from a global automotive supplier. Our approach identifies relevant topics and assigns these to helpdesk tickets, thereby decoding implicit knowledge into formal rules and business processes. Business intelligence; Business process engineering; Case study; Decision support; IT incident management; Knowledge management; Latent dirichlet allocation; Text mining

A Study of Process Mining-based Business Process Innovation Businesses have adopted diverse process management approaches such as business process re-engineering (BPR) and Six Sigma for their survival and growth. Even though these approaches have partially made a contribution to the improvement of organizational performances such as cost reduction and value innovation, they have a high possibility of failure. In particular, the failure probability of BPR and process innovation (PI) is as high as 60-70%. Most process management approaches include traditional interviews and observation-dependent business process analysis (BPA). This conventional BPA requires a lot of time. However, it derives subjective and incomplete analysis results and has no tool to measure improvement effects. As a way to overcome this kind of limitation of conventional BPA, this study introduces a process mining technique through the analysis and utilization of a huge amount of process data kept almost unused in domestic information systems. Processing mining is a process management technique which helps users figure out business processes in a fast and objective manner by analyzing these data and automatically visualizing actual process flows. In particular, this study derives a process improvement plan and offers academic and practical implications through analysis on municipality data in the Netherlands.  2016 Published by Elsevier B.V. Big data; Business process reengineering; Process innovation; Process mining

A framework for recommending resource allocation based on process mining Dynamically allocating the most appropriate resource to execute the different activities of a business process is an important challenge in business process management. An ineffective allocation may lead to an inadequate resources usage, higher costs, or a poor process performance. Different approaches have been used to solve this challenge: data mining techniques, probabilistic allocation, or even manual allocation. However, there is a need for methods that support resource allocation based on multi-factor criteria. We propose a framework for recommending resource allocation based on Process Mining that does the recommendation at sub-process level, instead of activity-level. We introduce a resource process cube that provides a flexible, extensible and fine-grained mechanism to abstract historical information about past process executions. Then, several metrics are computed considering different criteria to obtain a final recommendation ranking based on the BPA algorithm. The approach is applied to a help desk scenario to demonstrate its usefulness.  Springer International Publishing Switzerland 2016. Business processes; Organizational perspective; Process mining; Recommendation systems; Resource allocation; Time perspective

Process mining in IT service management: A case study The explosion of process-related data in nowadays organizations has raised the interest to exploit the data in order to know in deep how the business processes are being carried out. To face this need, process mining has emerged as a way to analyze the behavior of an organization by extracting knowledge from process related data. In this paper, we present a case study of process mining in a real IT service management scenario. We describe an exploratory analysis of real life event logs generated between 2012 and 2015, in four different processes designed within an IT platform. More specifically, we analyze the way of handling the different requests and incidents registered in an organization. 

New approaches for automated process model discovery The implementation of business processes through the use of information systems (ERP, CRM, PLM and MES) has become a key success factor for companies. For further development and optimization of processes, many companies havent trusted processes for the analysis. Surveying as-is processes is complex and only possible by manual recording. To perform this task automatically the theory shows us different approaches (process mining, Application Usage Mining and Web Usage Mining). The target of the concepts and tools is to complement the process of continuous improvement in the company with meaningful process models, which can be reconstructed from protocols and user actions in the information systems. This article focuses on the limitations of these concepts and the challenges they present and gives an outlook on how future solutions must work to speed up the process of continuous improvement and to meet the challenges of heterogeneity in IS-architectures.  Springer International Publishing Switzerland 2016. 

Using event logs to model interarrival times in business process simulation The construction of a business process simulation (BPS) model requires significant modeling efforts. This paper focuses on modeling the interarrival time (IAT) of entities, i.e. the time between the arrival of consecutive entities. Accurately modeling entity arrival is crucial as it influences process performance metrics such as the average waiting time. In this respect, the analysis of event logs can be useful. Given the limited process mining support for this BPS modeling task, the contribution of this paper is twofold. Firstly, an IAT input model taxonomy for process mining is introduced, describing event log use depending on process and event log characteristics. Secondly, ARPRA is introduced and operationalized for gamma distributed IATs. This novel approach to mine an IAT input model is the first to explicitly integrate the notion of queues. ARPRA is shown to significantly outperform a benchmark approach which ignores queue formation.  Springer International Publishing Switzerland 2016. Business process simulation; Interarrival time modelling; Process mining

RT-PLG: Real time process log generator Streaming process mining has been rising as an emergent tool to analyze industrial practices. Obviously, the advance of streaming process mining requires the availability of a suite of real-world business processes and the execution logs in the real time manner. Literally, it is hard to obtain it. This paper aims to develop a real time process log generator for the usage of streaming process mining tool. The real time process log generator (RT-PLG) is constructed in an independent tool. Afterward, the RT-PLG is utilized to generate a synthetic log for streaming process mining. The tool has been evaluated using an existing simulation model.  Springer International Publishing Switzerland 2016. Process log generator; Real time system; Streaming process mining

A capability-driven development approach for requirements and business process modeling Requirements modeling and business process modeling are two essential activities in the earliest steps of any sound software production process. A precise conceptual alignment between them is required in order to assess that requirements are operationalized through an adequate set of processes. Complementary, the trip from requirements to code should benefit from using a precise model driven development connection, intended to characterize not only the involved conceptual models, but also their corresponding model transformations. Selecting the most appropriate conceptual models for specifying the different system perspective becomes a crucial task. This conceptual modeling-based solution requires to use a holistic conceptual framework to determine those modeling elements to be taken into account. Surprisingly, the link with MDD approaches to provide a rigorous link with the software components of a final software application has not been analyzed in a clear and convincing way. Exploring the notion of capability, this keynote will present a capability driven development approach together with its associated meta-model as the selected conceptual framework. Additionally, it will be shown how this framework facilitates the selection of the most appropriate method components in order to design an effective software process and in order to make feasible a sound MDD connection.  Springer International Publishing AG 2016. 

An experience on applying process mining techniques to the tuscan port community system [Context & Motivation] The Business Process Management is an important and widespread adopted proposal for modelling process specifications and developing an executable framework for the management of the process itself. In particular the monitoring facilities associated to the on-line process execution provide an important means to the control of process evolution and quality. In this context, this paper provides an experience on the application of business process modelling techniques and process mining techniques to the TPCS, Tuscan Port Community System. This is a web-services based platform with multilevel access control and data recovery facilities, developed for supporting and strengthening the Motorways of the Sea and Italian regulations. The paper describes a storytelling approach applied to derive the TPCS business process model and the conformance checking techniques used to validate it and improve the overall TPCS software quality.  Springer International Publishing Switzerland 2016. Business process modelling; Process mining; Storytelling

The woman formalism for expressing process models Workflow management is fundamental to efficiently, effectively and economically carry out complex processes. In turn, the formalism used for representing workflow models is crucial for effectiveness. The formalism introduced by the WoMan framework for workflow management, based on First-Order Logic, is more expressive than standard formalisms adopted in the literature, and ensures strict adherence to the observed practices. This paper discusses in some details such a formalism, highlighting its most outstanding strengths and comparing it to the current standard formalism (Petri nets), also providing techniques for the translation of workflow models among the two formalisms. The comparison between the two models shows that WoMan is more powerful than standard Petri Nets, and that it can handle naturally and straightforwardly cases that would require complex patterns in Petri Nets.  Springer International Publishing Switzerland 2016. Business process modeling; Logic programming; Process mining

Ontological considerations about the representation of events and endurants in business models Different disciplines have been established to deal with the representation of entities of different ontological natures: the business process modeling discipline focuses mostly on event-like entities, and, in contrast, the (structural) conceptual modeling discipline focuses mostly on object-like entities (known as endurants in the ontology literature). In this paper, we discuss the impact of the event vs. endurant divide for conceptual models, showing that a rich ontological account is required to bridge this divide. Accounting for the ontological differences in events and endurants as well as their relations can lead to a more comprehensive representation of business reality.  Springer International Publishing Switzerland 2016. Conceptual modeling; Endurants; Events; Ontology; Reification

autoCEP: Automatic learning of predictive rules for complex event processing Complex Event Processing (CEP) is becoming more and more popular in service-oriented practices, especially to monitor the behaviour of continuous tasks within manual business processes, such as in logistics. The inference mechanisms of CEP engines are completely guided by rules, which are specified manually by domain experts. We argue that this user-based rule specification is a limiting factor that complicates the integration of CEP within the realm of Business Process Management (BPM) in a seamless way. Therefore, we present autoCEP as a two-phase data mining-based approach that automatically learns CEP rules from historical traces. In the first phase, complex temporal patterns are learned using early classification on time series techniques, then these patterns are algorithmically transformed into CEP rules in the second phase. Satisfactory results from evaluations on real data demonstrate the effectiveness of our framework.  Springer International Publishing Switzerland 2016. Complex event processing; Rule learning; Time series data mining; Violation prediction

Towards simulation- and mining-based translation of process models Process modeling is usually done using imperative modeling languages like BPMN or EPCs. In order to cope with the complexity of human-centric and flexible business processes several declarative process modeling languages (DPMLs) have been developed during the last years. DPMLs allow for the specification of constraints that restrict execution flows. They differ widely in terms of their level of expressiveness and tool support. Furthermore, research has shown that the understandability of declarative process models is rather low. Since there are applications for both classes of process modeling languages, there arises a need for an automatic translation of process models from one language into another. Our approach is based upon well-established methodologies in process management for process model simulation and process mining without requiring the specification of model transformation rules. In this paper, we present the technique in principle and evaluate it by transforming process models between two exemplary process modeling languages.  Springer International Publishing AG 2016. Process mining; Process model translation; Simulation

Efficient and customisable declarative process mining with SQL Flexible business processes can often be modelled more easily using a declarative rather than a procedural modelling approach. Process mining aims at automating the discovery of business process models. Existing declarative process mining approaches either suffer from performance issues with real-life event logs or limit their expressiveness to a specific set of constaint types. Lately, RelationalXES, a relational database architecture for storing event log data, has been introduced. In this paper, we introduce a mining approach that directly works on relational event data by querying the log with conventional SQL. By leveraging database performance technology, the mining procedure is fast without limiting itself to detecting certain control-flow constraints. Queries can be customised and cover process perspectives beyond control flow, e.g., organisational aspects. We evaluated the performance and the capabilities of our approach with regard to several real-life event logs.  Springer International Publishing Switzerland 2016. Declarative process mining; Relational databases; SQL

PROMOTE: A process mining tool for embedded system development Embedded system development workflow is complex, often poorly modelled, and thus difficult to optimize. We propose a new process mining tool PROMOTE as the first step of the flow improvement. The tool includes an event log analyzer and web user interface. PROMOTE has been tested in four real industrial projects, and in an open source SW project. We exposed several bottlenecks otherwise undiscovered, which proved the need and feasibility of PROMOTE. It will be deployed in production in a big embedded system company in 2017.  Springer International Publishing AG 2016. Business process modeling; Embedded system development; Event log; Optimization; Process mining; Web interface; Workflow

Research on collaboration business process model of logistics supply chain system based on event-driven process chain The paper aims at researching the collaboration business process model of logistics supply chain system based on EPC. The data mining technology is applied for the proposed model in this paper. The problem that core members of supply chain face will be how to choose better partners in order to improve product quality, service and performance, thus to enhance customer satisfaction, so research on suppliers as the source of the supply chain has great significance for the enterprise. Meanwhile, a lot of data and information is accumulated by supply chain operation, then how to get unknown or hidden knowledge from these vast amounts of data and information through BI (Business Intelligence) and DM (Data Mining) techniques so as to guide the optimization and implementation of supply chain will play a very important role. Therefore, this dissertation combine the real business of supply chain management system to research the relevant data mining methods and techniques, to solve the supplier classification problem in order to support supply chain operation effectively. Copyright  2016 American Scientific Publishers All rights reserved. Business intelligence; Collaboration business process model; Data mining; EPC; Logistics supply chain system

The ROAD from sensor data to process instances via interaction mining Process mining is a rapidly developing field that aims at automated modeling of business processes based on data coming from event logs. In recent years, advances in tracking technologies, e.g., Real-Time Locating Systems (RTLS), put forward the ability to log business process events as location sensor data. To apply process mining techniques to such sensor data, one needs to overcome an abstraction gap, because location data recordings do not relate to the process directly. In this work, we solve the problem of mapping sensor data to event logs based on process knowledge. Specifically, we propose interactions as an intermediate knowledge layer between the sensor data and the event log. We solve the mapping problem via optimal matching between interactions and process instances. An empirical evaluation of our approach shows its feasibility and provides insights into the relation between ambiguities and deviations from process knowledge, and accuracy of the resulting event log.  Springer International Publishing Switzerland 2016. Business processes; Knowledge-driven; Optimal matching; RTLS data

Automatic building of ER and data flow graph: A business process-based approach Nowadays, many tools are available for drawing entity relationship(ER) diagram and data flow graph, but the graph layout is manually designed and the drawing process is tedious and time-consuming. Moreover, the management of business model is independent of the data model, the inconsistency is frequently occurred. This paper proposes an entity-based process model called Entity-Process Model (EP-Model) to build up the linkage between the business model and data model. Based on the EP-Model, this paper gives the construction algorithms of ER diagrams and data flow graph. Finally, a modeling tool is developed for business process modeling and data modeling. Using this platform, the consistency between business model and data model is guaranteed, and the ER diagram and data flow graph can be built automatically. It plays an important role in the process modeling, data modeling and the integration of information systems in the future.  2016, Revista Tecnica de la Facultad de Ingeniera. All rights reserved. Business model; Data flow graph; Entity relationship diagram; Modeling tool

A framework for efficiently mining the organisational perspective of business processes Process mining aims at discovering processes by extracting knowledge from event logs. Such knowledge may refer to different business process perspectives. The organisational perspective deals, among other things, with the assignment of human resources to process activities. Information about the resources that are involved in process activities can be mined from event logs in order to discover resource assignment conditions, which is valuable for process analysis and redesign. Prior process mining approaches in this context present one of the following issues: (i) they are limited to discovering a restricted set of resource assignment conditions; (ii) they do not aim at providing efficient solutions; or (iii) the discovered process models are difficult to read due to the number of assignment conditions included. In this paper we address these problems and develop an efficient and effective process mining framework that provides extensive support for the discovery of patterns related to resource assignment. The framework is validated in terms of performance and applicability. The work summarized in this extended abstract has been published in [Sc16]. Business process management; Declarative process mining; Event log analysis; Organisational perspective; Resource perspective

Conceptual modeling of event processing networks Complex Event Processing (CEP) enables analyses with high velocity on high volume and varied data. It is an established technology to enable flexible event-driven systems. These systems can provide realtime analytics for business process management or support the realization of cyber-physical systems in the context of the Internet of Things. While the technology is maturing rapidly, the design of event-based systems is still in its infancy and complex. In particular, there is no established means to support the early stages of the IS development process through conceptual modeling. Currently, any comprehensive graphical specification of the involved event processing networks (EPN) is tool-dependent and creates vendor lock-in effects before an informed decision for a software product can be made. Current conceptual modeling options are limited to generic flow diagrams and methods from related areas. In this paper, we describe a method to conceptually model EPN which allow not only the filtering and projection but also the translation, enrichment, and aggregation as well as the splitting and composition of events. This artifact enables the design of EPN prior to deciding for a particular CEP product alleviating vendor lock-in effects. We present meta models excerpts and a notation as well as sample code in Esper to emphasize their serializability. The results are applied to a sample process. Complex Event Processing; Conceptual modeling; Event processing agent; Event processing network

Understanding production chain business process using process mining: A case study in the manufacturing scenario Due to the continuous market change the enterprises need to react fast. To do that a better understanding of the way to work is needed. Indeed this was a real need of a manufacturing enterprise working in the production of coffee machines and selling them all over the world. In this paper, we present the experience made in the application of process mining techniques on a rich set of data that such enterprise collected during the last six years. We compare five mining algorithms, such as: a-algorithm, Heuristics Miner, Integer Linear Programming Miner, Inductive Miner, Evolutionary Tree Miner. We evaluated algorithms according to specific quality criteria: fitness, precision, generalization and simplicity. Even if comparison studies are already available in the literature we check them according to our working context. We conclude that the Inductive Miner algorithm is especially suited for discovering production chain processes in the context under study. The application of process mining gives the enterprise a comprehensive picture of the internal process organization. Resulting models were used by the company with successful results to motivate the discussion on the need of developing a flexible production chain.  Springer International Publishing Switzerland 2016. Business process; Mining algorithm; Process discovery; Process mining; Production chain; Prom framework

Correlating unlabeled events from cyclic business processes execution Event logs are invaluable sources about the actual execution of processes. Most of process mining and postmortem analysis techniques depend on logs. All these techniques require the existence of the case ID to correlate the events. Real life logs are rarely originating from a centrally orchestrated process execution. Hence, case ID is missing, known as unlabeled logs. Correlating unlabeled events is a challenging problem that has received little attention in literature. Moreover, the few approaches addressing this challenge support acyclic business processes only. In this paper, we build on our previous work and propose an approach to deduce case ID for unlabeled event logs produced from cyclic business processes. As a result, a set of ranked labeled logs are generated. We evaluate our approach using real life logs.  Springer International Publishing Switzerland 2016. Cyclic processes loops; Event correlation; Process mining; Unlabeled event log

Semantic audit application for analyzing business processes Standard regulations are used to assess the compliance of business operations by auditors. This procedure is too time-consuming and Computer Assisted Audit Tools lack of the feature of processing documents semantically in an automatic manner. This paper presents a semantic application which is capable of extracting business process models in the shape of process ontologies from business regulations based on reference process ontologies transformed from process models derived from standard regulations. The application uses ontology matching to discover deviations of a given business operation and creates a transparent report for auditors. This semantic tool has been tested on one of the Internationalization processes in the respect of Erasmus mobility.  IFIP International Federation for Information Processing 2016. Audit; Business process management; Ontology matching; Process ontology; Text mining

Connecting databases with process mining: A meta model and toolset Process Mining techniques require event logs which, in many cases, are obtained from databases. Obtaining these event logs is not a trivial task and requires substantial domain knowledge. In addition, the result is a single view on the database in the form of a specific event log. If we desire to change our view, e.g. to focus on another business process, and generate another event log, it is necessary to go back to the source of data. This paper proposes a meta model to integrate both process and data perspectives, relating one to the other and allowing to generate different views from it at any moment in a highly flexible way. This approach decouples the data extraction from the application of analysis techniques, enabling its use in different contexts.  Springer International Publishing Switzerland 2016. Data schema; Database; Event extraction; Meta model; Process mining

A management tool for distributed heterogeneous process logs Process logs present the characteristics of distribution and heterogene in todays process aware information systems, which causes lots of difficulties in log management and integration. To address this problem, a management tool for distributed heterogeneous process logs is designed and developed. The tool supports the sharing of cross-organizational processes logs under privacy protection, and provides functional operations such as integration of distributed heterogeneous process log files, format standardization of heterogeneous process logs, visual presentation of case trajectory, clustering analysis of process cases attributes, pre-processing of process logs and so on. Compared with existing management tools for process logs, this tool is capable of facilitating the horizontal and vertical integration of distributed and heterogeneous logs, which has benefit the privacy protection of cross-organizational business processes logs and cross-organizational business process mining.  Springer Science+Business Media Singapore 2016. Event logs; Log integration; Process mining

Advanced ETL (AETL) by integration of PERL and scripting method Enhancing ETL (Extraction, Transformation and Loading) process framework data streams can give better profit for your Business venture. An endeavor level planning arrangement that is anything but difficult to utilize and handles heterogeneous situations may simply do what you require. Before, the attention was for the most part on business process plan, demonstrating. As of late, ventures have understood that they can advantage immensely from mechanizing the ETL process with the target of streamlining or enhancing them. With a specific end goal to extract, transform and load huge scale of data from miscellaneous data sources into data warehouse effectively, AETL come into existence and designed in this paper by using of PERL subroutine, data partition with integration of scripting method. The main function of AETL is to boost the efficiency of ETL and increase processing speed. AETL; ETL (Extract; PERL; Scripting method; Transform and Loading)

Extraction of topic map ontology for web service-oriented enterprises A Service Oriented Enterprise (SOE) is a new model of organization linking business processes and IT infrastructure across the enterprise. It can be enabled through the deployment of Service Oriented Architectures (SOA). At the heart of SOA are the services that are orchestrated using message passing, action coordination etc., web services being an example. However, there is almost no standard business semantics of web services which makes them isolated and opaque. In order to provide a common understanding of business of each other organizations are using trading exchange languages like Universal Business Languages (UBL). Although, these standards provide syntactic interoperability, they do not support efficient sharing of conceptualizations. Ontology can play an important part here, by providing a formal approach to specify shared conceptualization, and thus enabling semantic interoperability. This paper presents an approach for ontology modeling for business process standards used in B2B transactions in web services in terms of a semantic web formalism, viz. Topic Map.  Springer-Verlag Berlin Heidelberg 2016. Business process; Ontology; Service oriented enterprise (SOE); Tolog; Topic Map; UBL; Web services; XML

A novel fitness improvement method for mined Business process models Business process model discovery (BPMD) is a significant research topic in the business process mining area. The present BPMD techniques encounter great challenges while dealing with real-life event logs that contain complex process behaviors. As a result, non-fitting process models might be obtained. In this paper, we propose a new mechanism for locating and handling the process behaviors recorded in event logs which cannot be expressed by the utilised model discovery algorithms. Copyright  by the paper's authors. Copying permitted only for private and academic purposes. Business process mining; Business process model discovery; Process model fitness improvement

Process compliance checking using taint flow analysis Due to the growing complexity of processes, regulations, policies and guidelines (e.g., Sarbanes-Oxley-Act) computer-assisted business process analysis - known as process mining - is becoming more and more relevant for organisations. One discipline of process mining is backward compliance checking, which aims to detect non-compliant process variants based on historic data. Most existing approaches compare the "as-is" view with desired process models. However, most organisations do not maintain such models, making such approaches less attractive. This paper proposes a process flow analysis which uses graph-reachability to check whether the actual "as-is" process graph violates compliance constraints. Our approach is inspired by the taint flow algorithm which is used in code analysis to identify security vulnerabilities in software applications. We conducted a case study evaluating the compliance of event logs and performed a benchmark to show that our approach outperforms the LTL checker and the PetriNet pattern approach in ProM. Compliance checking; Conformance checking; Process mining; Taint flow analysis

Process mining functional and structural validation Current study proposes solutions for functional and structural validation of business process models extracted after mining the event log dataset with several process mining algorithms. Structural validation (verification) assesses the quality of the business processes using conformance analysis techniques and computed statistical results. Cross-validation for structural validation is also presented as a methodology used for evaluating business processes. Furthermore we propose extending verification of process models with functional validation with the scope of aligning business processes with business objectives. Functional validation starts with process requirement definition, split of process requirements on clear use cases, and generating event log data capturing the use case functionality. Functional validation is applied on real event log data generated during one software release in automotive industry, tools development area. Structural and functional validation techniques are captured in a proposal for a framework.  Springer International Publishing Switzerland 2016. Conformance analysis; Functional validation; Process discovery; Process mining

Using process mining to measure the expected costs of business processes Process mining is a means to extract hidden information from the event logs accumulated by the information systems that drive increasingly complex business processes, potentially improving their manageability. Traditional process mining is used mainly to extract a useful description of how an enterprise's processes actually work (as versus how they are documented to work), usually presented in the form of a flowchart. To the best of our best knowledge, previous process mining techniques have not used available information on duration and frequency of portions of a business process. We propose a method that combines process mining with Bayes' Theorem to augment a mined model with probabilities information. This additional information increases the value of the mined model and can be used not only in making predictions, but also in making decisions. Together with activity-based costing that assigns some cost to each activity in a process, our process mining technique can measure the expected costs of different stages in the process to support improvement of the underlying processes. We apply our approach to a chip probing process of a semiconductor firm in Taiwan. Our results confirm that the proposed approach could improve company decisions regarding their internal supply chain management. Activity-based costing; Bayes' Theorem; Process mining; Semi-conductor

Discovering and tracking organizational structures in event logs The goal of process mining is to extract process-related information by observing events recorded in event logs. An event is an activity initiated or completed by a resource at a certain time point. Organizational mining is a subfield of process mining that focuses on the organizational perspective of a business process. It considers the resource attribute and derives a profile that characterizes the behavior of a resource in a specific business process. By relating resources associated with correlated profiles, it is possible to define a social network. This paper focuses on the idea of performing organizational mining of event logs via social network mining. It presents a framework that resorts to a stream representation of an event log. It adapts the time-based window model to process this stream, so that window-based social resource networks can be constructed, in order to represent interactions between resources operating at the data window level. Finally, it integrates specific algorithms, in order to discover (overlapping) communities of resources and track the evolution of these communities over consecutive windows. This paper applies the defined framework to two real event logs.  Springer International Publishing Switzerland 2016. 

A case study on the business benefits of automated process discovery Automated process discovery represents the defining capability of process mining. By exploiting transactional data from information systems, it aims to extract valuable process knowledge. Through process mining, an important link between two disciplines - data mining and business process management - has been established. However, while methods of both data mining and process management are well-established in practice, the potential of process mining for evaluation of business operations has only been recently recognised outside academia. Our quantitative analysis of real-life event log data investigates both the performance and social dimensions of a selected core business process of an Austrian IT service company. It shows that organisations can substantially benefit from adopting automated process discovery methods to visualise, understand and evaluate their processes. This is of particular relevance in today's world of data-driven decision making.  2016, CEUR-WS. All rights reserved. 

Refinement mining: Using data to sift plausible models Process mining techniques have been developed in the ambit of business process management to extract information from event logs consisting of activities and then produce a graphical representation of the process control flow, detect relations between components involved in the process and infer data dependencies between process activities. These process characterisations allow the analyst to discover an annotated visual representation of the conceptual model or the performance model of the process, check conformance with an a priori model to detect deviations and extend the a priori model with quantitative information such as frequencies and performance data. However, a process model yielded by process mining techniques is more similar to a representation of the process behaviour rather than an actual model of the process: it often consists of a huge number of states and interconnections between them, thus resulting in a spaghettilike net which is hard to interpret or even read. In this paper we propose a novel technique, which we call model mining, to derive an abstract but concise and functionally structured model from event logs. Such a model is not a representation of the unfolded behaviour, but comprises, instead, a set of formal rules for generating the system behaviour. The set of rules is inferred by sifting a plausible a priori model using the event logs as a sieve until a reasonably concise model is achieved (refinement mining). We use rewriting logic as the formal framework in which to perform model mining and implement our framework using the MAUDE rewrite system. Once the final formal model is attained, it can be used, within the same rewriting logic framework, to predict future evolutions of the behaviour through simulation, to carry out further validation or to analyse properties through model checking. We illustrate our approach on a case study from the field of ecology.  Springer International Publishing AG 2016. Application to ecosystem modelling; Formal methods; Model-driven approaches; Process mining

Predictive business process monitoring with structured and unstructured data Predictive business process monitoring is concerned with continuously analyzing the events produced by the execution of a business process in order to predict as early as possible the outcome of each ongoing case thereof. Previous work has approached the problem of predictive process monitoring when the observed events carry structured data payloads consisting of attribute-value pairs. In practice, structured data often comes in conjunction with unstructured (textual) data such as emails or comments. This paper presents a predictive process monitoring framework that combines text mining with sequence classification techniques so as to handle both structured and unstructured event payloads. The framework has been evaluated with respect to accuracy, prediction earliness and efficiency on two real-life datasets.  Springer International Publishing Switzerland 2016. Predictive monitoring; Process monitoring; Text mining

PMCube: A data-warehouse-based approach for multidimensional process mining Process mining provides a set of techniques to discover process models from recorded event data or to analyze and improve given process models. Typically, these techniques give a single point of view on the process. However, some domains need to differentiate the process according to the characteristic features of their cases. The healthcare domain, for example, needs to distinguish between different groups of patients, defined by the patients properties like age or gender, to get more precise insights into the treatment process. The emerging concept of multidimensional process mining aims to overcome this gap by the notion of data cubes that can be used to spread data over multiple cells. This paper introduces PMCube, a novel approach for multidimensional process mining based on the multidimensional modeling of event logs that can be queried by OLAP operators to mine sophisticated process models. An optional step of consolidation allows to reduce the complexity of results to ease its interpretation. We implemented this approach in a prototype and applied it in a case study to analyze the perioperative processes in a large German hospital.  Springer International Publishing Switzerland 2016. Comparative process mining; Data warehousing; Multidimensional process mining; OLAP

Multidimensional process mining: Questions, requirements, and limitations Multidimensional process mining is an emerging approach that adopts the concept of data cubes to analyze processes from multiple views. This enables analysts to split event logs into a set of homogenous sublogs according to the case and event attributes. Each sublog is independently analyzed using process mining techniques resulting in an individual process model for each sublog. These models can be compared to identify group-related differences between the process variants. In this paper, we derive a number of general research questions addressed for multidimensional process mining by a literature review. We analyze the requirements for its application and point out its limitations and challenges. We conduct two case studies applying multidimensional process mining in two different use cases to evaluate our findings. Copyright  by the paper's authors. Copying permitted only for private and academic purposes. Multidimensional process mining; Process cubes

Cross-company collaboration analyzed through process mining: A method for analyzing the working environment and measuring impacts of change [No abstract available] Bug tracker; Collaboration; Process mining; Software process mining

Semantical vacuity detection in declarative process mining A large share of the literature on process mining based on declarative process modeling languages, like declare, relies on the notion of constraint activation to distinguish between the case in which a process execution recorded in event data vacuously satisfies a constraint, or satisfies the constraint in an interesting way. This finegrained indicator is then used to decide whether a candidate constraint supported by the analyzed event log is indeed relevant or not. Unfortunately, this notion of relevance has never been formally defined, and all the proposals existing in the literature use ad-hoc definitions that are only applicable to a pre-defined set of constraint patterns. This makes existing declarative process mining technique inapplicable when the target constraint language is extensible and may contain formulae that go beyond pre-defined patterns. In this paper, we tackle this hot, open challenge and show how the notion of constraint activation and vacuous satisfaction can be captured semantically, in the case of constraints expressed in arbitrary temporal logics over finite traces. We then extend the standard automata-based approach so as to incorporate relevance-related information. We finally report on an implementation and experimentation of the approach that confirms the advantages and feasibility of our solution.  Springer International Publishing Switzerland 2016. Constraint activation; Declarative process mining; Vacuity detection

Process mining with token carried data Process mining is to discover, monitor and improve real processes by extracting the knowledge from logs which are available in today's information systems. The existing process mining algorithms are based on the event logs where only the executions of tasks are recorded. In order to reduce the pre-processing efforts and strengthen the mining ability of the existing process mining algorithms, we have proposed a novel perspective to employ the data carried by tokens recorded in token log which tracks the changes of process resources for process mining in this study. The feasibility of the token logs is proved and the results of pairwise t-tests show that there is no big difference between the efforts that are taken by the same workflow system to generate the token log and the event log. Besides, a process mining algorithm (t) based on the new log is proposed in this paper. With algorithm t, the mining efficiency as well as the mining capability is improved compared to the traditional event-log-based mining algorithms. We have also developed three plug-ins on top of the existing workflow engine, process modeling and mining platforms (YAWL, PIPE and ProM) for proving the feasibility of token log and realizing the token log generation and algorithm t.  2015 Elsevier Inc. All rights reserved. Petri net; Process discovery; Process mining; Token; Token log; Workflow net

Process mining of interactions during computer-based testing for detecting and modelling guessing behavior Detecting, recognizing and modelling patterns of observed examinee behaviors during assessment is a topic of great interest for the educational research community. In this paper we investigate the perspectives of processcentric inference of guessing behavior patterns. The underlying idea is to extract knowledge from real processes (i.e., not assumed nor truncated), logged automatically by the assessment environment. We applied a three-step process mining methodology on logged interaction traces from a case study with 259 undergraduate university students. The analysis revealed sequences of interactions in which low goal-orientation students answered quickly and correctly on difficult items, without reviewing them, while they submitted wrong answers on easier items. We assumed that this implies guessing behavior. From the conformance checking and performance analysis we found that the fitness of our process model is almost 85%. Hence, initial results are encouraging towards modelling guessing behavior. Potential implications and future work plans are also discussed.  Springer International Publishing Switzerland 2016. Assessment analytics; Educational data mining; Guessing behavior; Pattern recognition; Process mining; Student interaction analysis

DPMine graphical language for automation of experiments in process mining Process mining is a new direction in the field of modeling and analysis of processes, where an important role is played by the use of information from event logs that describe the history of the system behavior. Methods and approaches used in process mining are often based on various heuristics, and experiments with large event logs are crucial for substantiating and comparing developed methods and algorithms. These experiments are very time consuming, so automation of experiments is an important task in the field of process mining. This paper presents the DPMine language developed specifically to describe and carry out process mining experiments. The basic concepts of the DPMine language as well as principles and mechanisms of its extension are described. Ways of integration of the DPMine language as dynamically loaded components into the VTMine modeling tool are considered. A sample experiment of building a fuzzy model of a process from a data log stored in a normalized database is given.  2016, Allerton Press, Inc. automation; experiments; fuzzy model; modeling language; process mining

Process mining: Spreadsheet-like technology for processes Spreadsheets can be viewed as a success story. Since the late seventies spreadsheet programs have been installed on the majority of computers and play a role comparable to text editors and databases management systems. Spreadsheets can be used to do anything with numbers, but are unable to handle process models and event data. Event logs and operational processes can be found everywhere. Recent breakthroughs in process mining resulted in novel techniques to discover the real processes, to detect deviations from normative process models, and to analyze bottlenecks and waste. Comparable to spreadsheet programs like Excel which are widely used in finance, production, sales, education, sports, process mining software can be used in a broad range of organizations. Whereas spreadsheets work with numbers, process mining starts from event data with the aim to analyze processes. This keynote paper uses spreadsheets as an analogy to make the case for process mining as an essential tool for data scientists and business analysts. 

On marrying model-driven engineering and process mining: A case study in execution-based model profiling In model-driven engineering (MDE), models are mostly used in prescriptive ways for system engineering. While prescriptive models are indeed an important ingredient to realize a system, for later phases in the systems' lifecycles additional model types are beneficial to use. Unfortunately, current MDE approaches mostly neglect the information upstream in terms of descriptive models from operations to design, which would be highly needed to improve systems continuously. To tackle this limitation, we propose execution-based model profiling as a continuous process to improve prescriptive models at design-time through runtime information by incorporating knowledge in form of profiled metadata from event logs generated during the execution of a code model. For this purpose we combine techniques of process mining (PM) with runtime models of MDE. In the course of a case study, we implement a preliminary prototype of our framework based on a traffic light system example which shows the feasibility and benefits of our execution-based model profiling approach.  2016, CEUR-WS. All rights reserved. 

Discovery of gatekeepers on information diffusion flows using process mining Online social network services (SNS) such as Twitter and Facebook are currently representative means of disseminating information on the Web. It is therefore crucial to internet marketing to understand the dynamics of information diffusion in online social networks. To this end, we present a probabilistic approach to process discovery, based on an extended hidden Markov model, considering the log data extracted from online SNS. Specifically, we first group users based on their interactions using SNS log data and three community detection algorithms. The process discovery algorithm is an extension of the hidden Markov model and applies to the user communities to reflect probabilistic dissemination among user communities. We illustrate the proposed method with real SNS data gathered from a Facebook fan page. We expect that our method can promote comprehension of the information dynamics in online social networks by visualizing probabilistic information diffusion through user groups.  INTERNATIONAL JOURNAL OF INDUSTRIAL ENGINEERING. Hidden markov model; Information diffusion; Process mining; Social media analytics

Using semantic-based approach to manage perspectives of process mining: Application on improving learning process domain data Mining useful knowledge from data readily available in today's information systems has been a common challenge in recent years as more and more events are being recorded, and there is need to improve and support many organisational processes in a competitive and rapidly changing environments. The work in this paper shows using a case study of Learning Process -how data from various process domains can be extracted, semantically prepared, and transformed into mining executable formats to support the discovery, monitoring and enhancement of real-time processes. In so doing, it enables the prediction of individual patterns/behaviour through further semantic analysis of the discovered models. Our aim is to extract streams of event logs from a learning execution environment and describe formats that allows for mining and improved process analysis of the captured data. The approach involves augmenting the informative value of the resulting model derived from mining event data about the process by semantically annotating the process elements with concepts they represent in real time using process descriptions languages, and linking them to an ontology specifically designed for representing learning processes to allow for the analysis of the extracted event logs based on concepts rather than the event tags of the process. The semantic analysis allows the meaning of the learning object properties and model to be enhanced through the use of property characteristics and classification of discoverable entities, to generate inference knowledge which are then used to determine useful learning patterns by means of the proposed Semantic Learning Process Mining (SLPM) formalization -described technically as Semantic-Fuzzy Miner. As a result, the approach provides us with the capability to infer new and discover hidden relationships/attributes the process instances share amongst themselves within the knowledge base, and the ability to identify and address the problem of determining the presence of different learning patterns or behaviour. Inference knowledge discovered due to semantic enrichment of the process model is advantageous especially in solving some didactic issues and answering some questions with regards to different Learners behaviour within the context of process mining and semantic model analysis. To this end, we show that information derived from process mining algorithms can be improved by adding semantic knowledge to the resulting model.  2016 IEEE. event logs; learning process; ontology; process mining; process model; semantic annotation

Mining user habits in smart spaces through process mining techniques Independently of the specific task to be enacted in a smart space, it is always crucial to mine a set of models representing environmental dynamics and, noteworthy, user habits and desires. Many different formalisms have been proposed to model human habits, but the vast majority of them are either difficult to read and evaluate or their definition requires a huge amount of work from either experts or users. In this paper we propose to employ process mining techniques in order to model human habits, and we experimentally evaluate such an approach on a dataset built adopting the Smart-Home-in-a-Box toolkit with real users.  2016, Sistemi Evoluti per Basi di Dati (SEBD). All rights reserved. 

Self-tracking reloaded: Applying process mining to personalized health care from labeled sensor data Currently, there is a trend to promote personalized health care in order to prevent diseases or to have a healthier life. Using current devices such as smart-phones and smart-watches, an individual can easily record detailed data from her daily life. Yet, this data has been mainly used for self-tracking in order to enable personalized health care. In this paper, we provide ideas on how process mining can be used as a finegrained evolution of traditional self-tracking. We have applied the ideas of the paper on recorded data from a set of individuals, and present conclusions and challenges.  Springer-Verlag Berlin Heidelberg 2016. 

Introduction to integration of the process mining to the knowledge framework for software processes Systems started to be more process oriented during last decades. The knowledge has moved from humans to systems and systems has more and more knowledge about the process. This paper presents an approach to the integration of the process mining to the process modeling supported by the formal layer. The process is modeled by framework that allows selection and formal description of the applicable meta-model parts, formally define process prescription and then model the process by graphical language. Process is executed and logs are stored. The presented process mining part of the framework then can discover the de facto process model, can check the differences between de facto and de jure model, can enhance de jure model according to the findings.  Springer International Publishing Switzerland 2016. Formal approach; OWL; Process mining; Process modeling

When sales meet process mining: A scientific approach to sales process and performance management Selling has long been considered as an "art" driven by personal intuition and native sales talent. However, significant changes have occurred over the past 30 years, as a result of technological advances and changing customer expectations. As one answer to these changes, practitioners and scholars have promoted the idea of "sales as a science", relying on documented, repeatable ways of selling that reflect scientific methods. We argue that process mining is a relevant candidate for empowering "sales as a science" via its capacity to analyze, discover, and enhance end-to-end processes. Through a design science approach, we propose a framework for applying process mining to sales, comprising a refined notation and seven process mining analysis scenarios. Our study represents a first step towards gaining a better understanding of real-world sales processes based on digital traces from operational systems e.g., customer relationship management (CRM) systems, or emerging technologies e.g., smart watches. Customer relationship management; Process mining; Sales as a science; Sales force automation; Sales performance; Scientific workflow

Linking Diagnostic-Related Groups (DRGs) to their processes by process mining The knowledge of patient-flow is very important for healthcare organizations, because strongly connected to effectiveness and efficiency of resource allocation. Unfortunately, traditional approaches to process analysis are scarcely effective and low efficient: they are very time-consuming and they may not provide an accurate picture of healthcare processes. Process mining techniques help to overcome these problems. This paper proposes a methodology for building a DRG related patient-flow using process mining. Findings show that it is possible to discover the different sequences of activities associated with a DRG related process. Managerial implications concern both process identification, analysis and improvement. A case study, based on a real open data set, is reported. Copyright  2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved. Diagnostic-Related Group (DRG); Healthcare; Patient-flow; Process discovery; Process mining

Accelerating process mining using relational databases Given the abundance of event data, the challenge of process mining today is to enable process mining in the large. This research aims to address scalability problem in terms of memory use and time consumption. To this end, we use relational databases as the framework to both store event data and do process mining analysis. We conduct a pre-computation of intermediate structures during insertion time of the data. Finally, we implement the existing process mining algorithms to be compatible with relational database settings.  2016, CEUR-WS. All rights reserved. Big event data; Process mining; Relational database

Focusing business improvements using process mining based influence analysis Business processes are traditionally regarded as generalized abstractions describing the activities and common behaviour of a large group of process instances. However, the recent developments in process mining and data analysis show that individual process instances may behave very different from each other. In this paper we present a generic methodology called influence analysis for finding business improvement areas related to business processes. Influence analysis is based on process mining, root cause analysis and classification rule mining. We present three generic target levels for business improvements and define corresponding probability-based interestingness measures. We then define measures for reporting the contribution results to business people and show how these measures can be used to focus improvements. Real-life case study is also included to show the methodology in action.  Springer International Publishing Switzerland 2016. Classification rule mining; Contribution; Data mining; Influence analysis; Process analysis; Process improvement; Process mining; Root cause analysis

On the use of process mining and machine learning to support decision making in systems design Research on process mining and machine learning techniques has recently received a significant amount of attention by product development and management communities. Indeed, these techniques allow both an automatic process and activity discovery and thus are high added value services that help reusing knowledge to support decision-making. This paper proposes a double layer framework aiming to identify the most significant process patterns to be executed depending on the design context. Simultaneously, it proposes the most significant parameters for each activity of the considered process pattern. The framework is applied on a specific design example and is partially implemented.  IFIP International Federation for Information Processing 2016. Collaborative design process; Decision-making; Process mining; Process patterns; Supervised classification

Discovery and enhancement of learning model analysis through semantic process mining Semantic concepts can be layered on top of existing learner information asset to provide a more conceptual analysis of real time processes capable of providing real world answers that are closer to human understanding. Challenges from current research shows that even though learning data are captured and modelled with acceptable performance to accurately reflect process executions, they are still limited for many process mining analysis because they lack the abstraction level required from real world perspectives. The work in this paper describes a Semantic Process Mining approach directed towards enriching streams of event data logs from a learning process using semantic descriptions that references concepts in an Ontology specifically designed for representing learning processes. The proposed approach involves the extraction of process history data from learning execution environments unfolding how we extract the input data necessary to be mapped unto the learning process logs, which is then followed by submitting the resulting eXtensible Event Streams - XES and Mining eXtensible Markup Language - MXML format to the process analytics environment for mining and further analysis. The consequence is a learning process model which we semantically annotate with concepts they represent in real time using semantic descriptions, and then linking them to an ontology to allow for analysis of the extracted event logs streams based on concepts rather than the event tags of the process. The aim is to provide real time knowledge about the learning process which are more intuitive and closer to human understanding. By referring to ontologies and piloting series of validation experiments, the approach provides us with the capability to infer new and discover relationships the process instances share amongst themselves and to address the problem of determining the presence of different learning patterns within the learning knowledge base. To this end, we demonstrate how data from learning process can be extracted, semantically prepared, and transformed into mining executable formats to enable prediction of individual learning patterns and outcomes through further semantic analysis of the discovered models. Therefore, our approach is grounded on Process Mining and Semantic Modelling Techniques.  MIR Labs. Event logs; Learning process; Ontology; Process mining; Process model; Semantic annotation

Process mining to knowledge discovery in healthcare processes Healthcare processes are complex and require a high-level of interdisciplinary cooperation among the different specialists and sectors involved in their delivery. Information flows among organizational entities, sectors, areas and employees represent possible low process interoperability risks as well as noncompliance risks between business rules and actual process deliveries. Besides this complexity, the Brazilian healthcare area has a notorious problem in its public and private health care systems. These problems are of structural, organizational and financial natures, reflecting the low value attributed to quality and to the actual services in recent surveys of Instituto Data Folha and the Brazilian Ministry of Health (Ministério da Saúde). This paper intends to propose an adaptation of Process Mining as an ancillary tool in knowledge discovery processes in healthcare in order to contribute to further improving this area in Brazil. In order to accomplish this, a case study was carried out in the Erasto Gaertner Hospital, located in Curitiba - PR, Brazil, a local reference in cancer treatments.  2016 The authors and IOS Press. Business rules; Healthcare; Organizational mining; Process mapping; Process mining

Introducing process mining for AECFM: Three experimental case studies The research field of process mining is relatively new and not been applied often in the Architecture, Engineering, Construction and Facility Management industry (AECFM). Process mining uses databases of existing IT systems to gain major insights in processes. Currently the AECFM industry increasingly adapts IT systems within all phases of the process. This creates the possibility to use process mining techniques to gain insight in the processes of construction projects. This paper introduces process mining by presenting three experimental case studies which are conducted in order to study the applicability of process mining in the AECFM. Studies are done in the design-, buildand operational phase. The study has proven to provide useful insight and potential applications. The research method that was used does not allow generalisation of the conclusions for the whole industry. Additional research is needed to study the potential of integrating different data sources from several phases.  2016 Taylor & Francis Group. BIM; Data mining; Facility management; Process mining; Systems engineering

Process mining: On the fly process discovery Process mining is a set of techniques helping enterprises to avoid process modeling, which is time consuming, and error prone task. The goal of such techniques is to extract the process as it has been executed. However, the increase of data production in event logs of process aware information systems makes it necessary to mine the processes in real time. For this purpose, it is necessary to define new approaches for process discovery analyzing data on the fly. This paper presents a new process discovery approach aiming to extract data on the fly by discovering the set of blocks composing the process.  Springer International Publishing Switzerland 2016. On the fly process discovery; Process discovery; Process mining

A novel process mining model for teleclaim insurance process In this paper, we propose a process mining model for teleclaim insurance process. The major problem faced by every insurance organization is to manage enormous amount of data, which were generated for every business activities. Managing teleclaim data is a complex task, which requires process model to know the control flow of the event logs. Researchers today use ProM tool as an extensible framework that supports a wide variety of process mining techniques which makes use of a-algorithm. a-algorithm generates a process model. But, the generated process model will not be specific for every cases instead it is the generalized model. So, the logs which will not suit the compliance or the process model will not be considered its neglected which is the main drawback of a-algorithm. To overcome this problem, we propose a Teleclaim Model algorithm. The proposed algorithm generates process models and traces for teleclaim dataset, in which processes flow within their respective models, so that it will not eliminate the logs which do not fit into given compliance. The fitness for each model is obtained by replaying the event logs on the process models to analyze its behavior. The proposed process model is useful for insurance organizations to improve their business process for their clients. Fitness for the proposed models can be used as a base of the insurance company to decide whether the claim is valid or not. A-algorithm; Petrinets; Process mining (PM); ProM; Teleclaim model (TCM)

Process mining: Towards comparability of healthcare processes With the technology emerging more and more possible applications of process mining in healthcare become apparent. In most cases the goal of applying process mining to the healthcare domain is to find out what actually happened and to deliver a concise assessment of the organizational reality by mining the event logs of health information systems. To develop medical guidelines or patient pathways considering economic aspects and quality of care, a comparative analysis of different existing approaches is useful (e.g. how different hospitals execute the same process in different ways). This work discusses how to use existing process mining techniques for comparative analysis of healthcare processes and presents an approach based on the L* life-cycle model.  Springer International Publishing Switzerland 2016. Data mining; Process mining; Process quality

Using periodic patterns for dynamic estimation of future database workloads Analysis of historical database workloads can be used to improve the future performance of database systems. This work investigates a problem how to use information about periodic processing of database applications recorded in the past for static and dynamic estimation of the future database workloads. The new concepts of anchor events and event expressions are used to create the mappings of past periodic patterns in data processing into the future database workloads. We show that event expressions allow for both static and dynamic estimation of future database workloads. The paper presents the algorithms for static a dynamic estimation of future database workloads from information about time distributions of periodic processing of database applications and information about the events that trigger processing of the applications. Automated performance tuning process mining; Database workloads; Mining periodic patterns

Ontology-driven extraction of event logs from relational databases Process mining is an emerging discipline whose aim is to discover, monitor and improve real processes by extracting knowledge from event logs representing actual process executions in a given organizational setting. In this light, it can be applied only if faithful event logs, adhering to accepted standards (such as XES), are available. In many real-world settings, though, such event logs are not explicitly given, but are instead implicitly represented inside legacy information systems of organizations, which are typically managed through relational technology. In this work, we devise a novel framework that supports domain experts in the extraction of XES event log information from legacy relational databases, and consequently enables the application of standard process mining tools on such data. Differently from previous work, the extraction is driven by a conceptual representation of the domain of interest in terms of an ontology. On the one hand, this ontology is linked to the underlying legacy data leveraging the well-established ontology-based data access (OBDA) paradigm. On the other hand, our framework allows one to enrich the ontology through user-oriented log extraction annotations, which can be flexibly used to provide different log-oriented views over the data. Different data access modes are then devised so as to view the legacy data through the lens of XES.  Springer International Publishing Switzerland 2016. Event data; Log extraction; Multi-perspective process mining; Ontology-based data access

Measuring the precision of multi-perspective process models Process models need to reflect the real behavior of an organizations processes to be beneficial for several use cases, such as process analysis, process documentation and process improvement. One quality criterion for a process model is that they should precise and not express more behavior than what is observed in logging data. Existing precision measures for process models purely focus on the control-flow dimension of a process model, thereby ignoring other perspectives, such as the data objects manipulated by the process, the resources executing process activities, and time-related aspects (e.g., activity deadlines). Focusing on the control-flow only, the results may be misleading. This paper extends existing precision measures to incorporate the other perspectives and, through an evaluation with a real-life process and corresponding logging data, demonstrates how the new measure matches our intuitive understanding of precision.  Springer International Publishing Switzerland 2016. Multi-perspective process mining; Precision; Process mining; Process model quality

Pushing decision points backward to the latest possible positions with a workflow log Currently, enterprises face more competitive and complex environments than ever before. Companies would suffer devastating setbacks if business changes were ignored. Enterprises could leverage competitive advantages if business changes were automatically adopted in processes by stimulating workflow redesign. Business changes imply new business processes with decision points. The effects of business changes on business operations are firmly recorded by system logs. Pushing decision points to the latest possible position may be a feasible method while facing business changes. Business changes also imply redesigning business processes. This study proposes an algorithm for pushing decision points backward, which enables decision points in business processes to be identified automatically. This study also proposes a new workflow graphic based on the algorithms for pushing decision points backward. The new workflow graphic from the results of this study can contribute to redesigning businesses.  Springer International Publishing Switzerland 2016. Business process mining; Pushing decision points backward; System log mining; Workflow mining

Towards a real-time usability improvement framework based on process mining and big data for business information systems Workflow improvement nowadays plays an important role in the selection process of supporting software. This is especially true in the context of user-centric development, where the usability of business information systems is a crucial characteristic of differentiation. However, automatically measuring the usability of such systems as well as their dynamic enhancement has not been studied before. This paper describes an approach to improve the usability of web-based information systems in real-time. Different concepts are presented, which build on data gathering methods from web analytics to provide log mechanisms for user interactions at a detailed level and subsequently process this data by means of data analytics and process mining methods. Concepts are then integrated into a comprehensive framework representing the main contribution of this paper. We evaluate our framework with a software prototype based on in-memory technologies developed in cooperation with a major German software company. Furthermore, we report on findings of a user study that was conducted in an exemplary use case scenario demonstrating dynamic workflow improvements to validate our research in a real-world setting. 

The technological maturity of process mining: An exploration of the status quo in top IS journals This paper reviews top IS journals to explore the status quo of process mining as a technology. We use a three-category classification scheme that emerged from synthesizing prior maturity models from an ERP and a business analytics context. The three categories string together the organizational and system-orientated perspective and add a focus on digital services. The tentative results from screening twenty-two top IS journals show that thus far publications within these journals have dedicated attention primarily to the first category, single systems. Cross-system or cross-organizational process mining is underrepresented as well as the analysis of services with non-digital components. However, the results also suggest that process mining is on the cusp of becoming a technology that allows new insights into consumer processes by supplying business operations with detailed information to tailor the customer experience. 

Process mining monitoring for map reduce applications in the cloud The adoption of mobile devices and sensors, and the Internet of Things trend, are making available a huge quantity of information that needs to be analyzed. Distributed architectures, such as Map Reduce, are indeed providing technical answers to the challenge of processing these big data. Due to the distributed nature of these solutions, it can be difficult to guarantee the Quality of Service: e.g., it might be not possible to ensure that processing tasks are performed within a temporal deadline, due to specificities of the infrastructure or processed data itself. However, relaying on cloud infrastructures, distributed applications for data processing can easily be provided with additional resources, such as the dynamic provisioning of computational nodes. In this paper, we focus on the step of monitoring Map Reduce applications, to detect situations where resources are needed to meet the deadlines. To this end, we exploit some techniques and tools developed in the research field of Business Process Management: in particular, we focus on declarative languages and tools for monitoring the execution of business process. We introduce a distributed architecture where a logic-based monitor is able to detect possible delays, and trigger recovery actions such as the dynamic provisioning of further resources. Copyright  2016 by SCITEPRESS-Science and Technology Publications, Lda. All rights reserved. Autonomic System; Business Process Management; Cloud Computing; Map Reduce; Monitoring

Time drift detection in process mining Currently, most of the information systems can record the tracking information and logs, this helps people to know the performance of the process execution. Process Mining techniques allow knowledge extractions such as model discovery, conformance checks and process improvements to take place. Processes are subject to various changes during their execution, for instance, a change in structure may occur when a new regulation comes into force and imposes some change, or may happen under the influence of seasonal effects, natural disasters etc. For many industries, time is a crucial factor in most cases equal to efficiency and profitability. Thus, this research paper presents an approach for detecting time-related changes. Our method extracts time-related characteristics from processes and then compares all of them together by using statistical hypothesis tests in different successive populations. Such a method could not only allow accurate detection when some parts of the processes started to have abnormal behavior: longer or shorter but also enable identification of which parts are involved. Based on the proposed approach in this paper, a ProM6 plug-in is implemented and tested. Further, synthetic data is used to do the experiment, finally, the results are explained and discussed.  2016 Taylor & Francis Group, London. 

Complex symbolic sequence clustering and multiple classifiers for predictive process monitoring This paper addresses the following predictive business process monitoring problem: Given the execution trace of an ongoing case, and given a set of traces of historical (completed) cases, predict the most likely outcome of the ongoing case. In this context, a trace refers to a sequence of events with corresponding payloads, where a payload consists of a set of attribute-value pairs. Meanwhile, an outcome refers to a label associated to completed cases, like, for example, a label indicating that a given case completed on time (with respect to a given desired duration) or late, or a label indicating that a given case led to a customer complaint or not. The paper tackles this problem via a two-phased approach. In the first phase, prefixes of historical cases are encoded using complex symbolic sequences and clustered. In the second phase, a classifier is built for each of the clusters. To predict the outcome of an ongoing case at runtime given its (uncompleted) trace, we select the closest cluster(s) to the trace in question and apply the respective classifier(s), taking into account the Euclidean distance of the trace from the center of the clusters. We consider two families of clustering algorithms  hierarchical clustering and k-medoids  and use random forests for classification. The approach was evaluated on four real-life datasets.  Springer International Publishing Switzerland 2016. Clustering; Complex symbolic sequence; Ensemble methods; Predictive process monitoring; Process mining

Data science challenges to improve quality assurance of internet of things applications With the increasing importance and complexity of Internet of Things (IoT) applications, also the development of adequate quality assurance techniques becomes essential. Due to the massive amount of data generated in workflows of IoT applications, data science plays a key role in their quality assurance. In this paper, we present respective data science challenges to improve quality assurance of Internet of Things applications. Based on an informal literature review, we first outline quality assurance requirements evolving with the IoT grouped into six categories (Environment, User, Compliance/Service Level Agreement, Organizational, Security and Data Management). Finally, we present data science challenges to improve the quality assurance of Internet of Things applications sub-divided into four categories (Defect prevention, Defect analysis, User incorporation and Organizational) derived from the six quality assurance requirement categories.  Springer International Publishing AG 2016. Data science; Internet of things; Process mining; Software quality assurance; Software quality engineering; Software testing

Online discovery of cooperative structures in business processes Process mining is a data-driven technique aiming to provide novel insights and help organizations to improve their business processes. In this paper, we focus on the cooperative aspect of process mining, i.e., discovering networks of cooperating resources that together perform processes. We use online streams of events as an input rather than event logs, which are typically used in an off-line setting. We present the Online Cooperative Network (OCN) framework, which defines online cooperative resource network discovery in a generic way. A prototypical implementation of the framework is available in the open source process mining toolkit ProM. By means of an empirical evaluation we show the applicability of the framework in the streaming domain. The techniques presented operate in a real time fashion and are able to handle unlimited amounts of data. Moreover, the implementation allows to visualize network dynamics, which helps in gaining insights in changes in the execution of the underlying business process.  Springer International Publishing AG 2016. Cooperative resource networks; Event streams; Process enhancement; Process mining

Location-based automated process modelling Services are today over 70% of the Gross National Product in most developed countries. Hence, the productivity improvement of services is an important area. How to collect data from services has been a problem and service data is largely missing in national statistics. This work presents an approach to collect service process data based on wireless indoor positioning using inexpensive wireless sensors and smart phones. This work also presents how the collected data can be used to extract automatically the process model. These models can further be used to analyse the improvements of the service processes. The presented approach comprises a light-weight process data acquisition system, which collects a minimised but precise data sets for automated process modelling. This automated modelling can be used to greatly improve the traditional process modelling in various service industries, for example, in the healthcare field. The presented approach has been tested and used in Tampere City dental care clinics.  2016, CEUR-WS. All rights reserved. Automated process modelling; Location-based; Process mining

Abducing compliance of incomplete event logs The capability to store data about business processes execution in so-called Event Logs has brought to the diffusion of tools for the analysis of process executions and for the assessment of the goodness of a process model. Nonetheless, these tools are often very rigid in dealing with Event Logs that include incomplete information about the process execution. Thus, while the ability of handling incomplete event data is one of the challenges mentioned in the process mining manifesto, the evaluation of compliance of an execution trace still requires an end-to-end complete trace to be performed. This paper exploits the power of abduction to provide a flexible, yet computationally effective, framework to deal with different forms of incompleteness in an Event Log. Moreover it proposes a refinement of the classical notion of compliance into strong and conditional compliance to take into account incomplete logs.  Springer International Publishing AG 2016. Abductive logic programming; Compliance in business process; Formal verification; Incompleteness in business processes

From low-level events to activities - A pattern-based approach Process mining techniques analyze processes based on event data. A crucial assumption for process analysis is that events correspond to occurrences of meaningful activities. Often, low-level events recorded by information systems do not directly correspond to these. Abstraction methods, which provide a mapping from the recorded events to activities recognizable by process workers, are needed. Existing supervised abstraction methods require a full model of the entire process as input and cannot handle noise. This paper proposes a supervised abstraction method based on behavioral activity patterns that capture domain knowledge on the relation between activities and events. Through an alignment between the activity patterns and the low-level event logs an abstracted event log is obtained. Events in the abstracted event log correspond to instantiations of recognizable activities. The method is evaluated with domain experts of a Norwegian hospital using an event log from their digital whiteboard system. The evaluation shows that state-of-the art process mining methods provide valuable insights on the usage of the system when using the abstracted event log, but fail when using the original lower level event log.  Springer International Publishing Switzerland 2016. Alignment; Event log; Process mining; Supervised abstraction

Decomposed replay using hiding and reduction In the area of process mining, decomposed replay has been proposed to be able to deal with nets and logs containing many different activities. The main assumption behind this decomposition is that replaying many subnets and sublogs containing only some activities is faster then replaying a single net and log containing many activities. Although for many nets and logs this assumption does hold, there are also nets and logs for which it does not hold. This paper shows an example net and log for which the decomposed replay may take way more time, and provides an explanation why this is the case. Next, to mitigate this problem, this paper proposes an alternative decomposed replay, and shows that this alternative decomposed replay is faster than the monolithic replay even for the problematic cases as identified earlier. However, the alternative decomposed replay is often slower than the original decomposed approach. An advantage of the alternative decomposed approach over the original approach is that its cost estimates are typically better. 

Towards flexibility in business processes by mining process patterns and process instances The possibility to react to unexpected situations in business process execution is restricted since all possible process flows must be specified at design-time. Thus, there is need for a flexible approach that reflects the way in which human actors would handle discrepancies between real-life activities and their representation in business process definitions. In this paper, we propose a novel approach that supports dynamic business processes and is based on a framework comprising a process pattern library with domain-specific patterns and execution logs for mining related process instances. Given a running business process and an unexpected situation, the proposed approach provides a largely automatic adaptation of the business process by replacing failed activities with fitting process alternatives identified by exploring existing process knowledge. The feasibility of the approach is demonstrated by applying the main steps to a business scenario taken from the industry domain.  Copyright 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved. Business Process Flexibility; Dynamic Adaptation; Process Mining; Process Pattern Library

Formal Knowledge Framework for Software Processes Architecture Last decades have introduced different improvements into software process modeling yet none has proven itself as a silver bullet; software development community has proposed various solutions from rigid prescriptive processes to agile methods, in the end, however, every good software process implementation require process modeling that can be used for different purposes like process auditing, analysis, and evaluation. This paper discusses application of explicit knowledge profiles based on process meta-model within software process modeling, alignment with visual process modeling, and further analysis with simulation and reverse engineering methods.  2016 The authors and IOS Press. All rights reserved. Knowledge Modeling; OWL; Petri Nets; Process Mining; Reverse Engineering Software Process; UML

Merging alignments for decomposed replay In the area of process mining, conformance checking aims to find an optimal alignment between an event log (which captures the activities that actually have happened) and a Petri net (which describes expected or normative behavior). Optimal alignments highlight discrepancies between observed and modeled behavior. To find an optimal alignment, a potentially challenging optimization problem needs to be solved based on a predefined cost function for misalignments. Unfortunately, this may be very time consuming for larger logs and models and often intractable. A solution is to decompose the problem of finding an optimal alignment in many smaller problems that are easier to solve. Decomposition can be used to detect conformance problems in less time and provides a lower bound for the costs of an optimal alignment. Although the existing approach is able to decide whether a trace fits or not, it does not provide an overall alignment. In this paper, we provide an algorithm that is able to provide such an optimal alignment from the decomposed alignments if this is possible. Otherwise, the algorithm produces a so-called pseudo-alignment that can still be used to pinpoint non-conforming parts of log and model. The approach has been implemented in ProM and tested on various real-life event logs.  Springer International Publishing Switzerland 2016. 

Optimizing decision support in business process management using obligation and prohibition norms Social norms constrain behavior of individuals either through obligating or prohibiting certain types of behavior. Norm-based mechanisms have only recently found applications in enhancing decisions of knowledge workers in an automated business process management context. While previous work on such social BPM has focused on the use of prohibition norms based approach for norm inference, this paper extends the work by combining both prohibition and obligation norm based approaches to provide a holistic approach of norm inference. The norms inferred in the context of business process executions are then recommended to users so as to enable them to make informed decisions. The previous work on prohibition norm inference focused on identifying failure cases, which is now complemented by first inferring norms from the successful process execution cases (i.e. obligations) and then inferring prohibition norms. This approach based on considering social feedback (i.e. inferring what is obliged and prohibited from history logs of process execution) shows encouraging results under uncertain business environments. Using simulation results the paper demonstrates that using the norm based mechanism results in reduced failure rates in the decision making of a knowledge worker while still providing maximum flexibility for the user to choose from a range of actions to execute.  2016. Norm Inference; Operational Decision Support; Process Mining

Predicting process behavior in WoMan In addition to the classical exploitation as a means for checking process enactment conformance, process models may be precious for making various kinds of predictions about the process enactment itself (e.g., which activities will be carried out next, or which of a set of candidate processes is actually being executed). These predictions may be much more important, but much more hard to be obtained as well, in less common applications of process mining, such as those related to Ambient Intelligence. Also, the prediction performance may provide indirect indications on the correctness and reliability of a process model. This paper proposes a way to make these kinds of predictions using the WoMan framework for workflow management, that has proved to be able to handle complex processes. Experimental results on different domains suggest that the prediction ability of WoMan is noteworthy and may be useful to support the users in carrying out their processes.  Springer International Publishing AG 2016. Activity prediction; Process mining; Process prediction

Automated business process management Business process management (BPM) activities can be divided into categories such as design, modelling, execution, monitoring, and optimization. Some of these activities are usually automated, mainly the first ones, where Automated Business Process Discovery (ABPD) solutions, also know as process mining, can automatically find process models (using unstructured, event-level logs). However, BPM usually involves several activities that are executed in different applications, which are not integrated with each other, or are even manually executed. This may involve the waste of resources and time, and eventually not applying BPM with full potential. We propose an integrated solution, that allows to complete the BPM cycle in a single application and with most of the steps automatically. This proposal was applied in practice in the context of a research project and the results are being integrated into a commercial product.  Springer International Publishing Switzerland 2016. Business process management; Process execution; Process improvement; Process mining

A trace clustering solution based on using the distance graph model Process discovery is the most important task in the process mining. Because of the complexity of event logs (i.e. activities of several different processes are written into the same log), the discovered process models may be diffuse and unintelligible. That is why the input event logs should be clustered into simpler event sub-logs. This work provides a trace clustering solution based on the idea of using the distance graph model for trace representation. Experimental results proved the effect of the proposed solution on two measures of Fitness and Precision, especially the effect on the Precision measure.  Springer International Publishing Switzerland 2016. Distance graph model; Event log; Fitness measure; Precision measure; Process discovering; Process mining; Trace clustering

Discovering and exploring state-based models for multi-perspective processes Process mining provides fact-based insights into process behaviour captured in event data. In this work we aim to discover models for processes where different facets, or perspectives, of the process can be identified. Instead of focussing on the events or activities that are executed in the context of a particular process, we concentrate on the states of the different perspectives and discover how they are related. We present a formalisation of these relations and an approach to discover state-based models highlighting them. The approach has been implemented using the process mining framework ProM and provides a highly interactive visualisation of the multi-perspective state-based models. This tool has been evaluated on the BPI Challenge 2012 data of a loan application process and on product user behaviour data gathered by Philips during the development of a smart baby bottle equipped with various sensors.  Springer International Publishing Switzerland 2016. 

On generation of time-based label refinements Process mining is a research field focused on the analysis of event data with the aim of extracting insights in processes. Applying process mining techniques on data from smart home environments has the potential to provide valuable insights in (un)healthy habits and to contribute to ambient assisted living solutions. Finding the right event labels to enable application of process mining techniques is however far from trivial, as simply using the triggering sensor as the label for sensor events results in uninformative models that allow for too much behavior (overgeneralizing). Refinements of sensor level event labels suggested by domain experts have shown to enable discovery of more precise and insightful process models. However, there exist no automated approach to generate refinements of event labels in the context of process mining. In this paper we propose a framework for automated generation of label refinements based on the time attribute of events. We show on a case study with real life smart home event data that behaviorally more specific, and therefore more insightful, process models can be found by using automatically generated refined labels in process discovery. Label refinements; Process discovery; Unsupervised learning

Learning analytics for a puzzle game to discover the puzzle-solving tactics of players Games can be used as effective learning tools, proved to enhance players performance in a wide variety of cognitive tasks. In this context, Learning Analytics (LA) can be used to improve game quality and to support the achievement of learning goals. In this paper, we investigate the use of LA in digital puzzle games, which are commonly used for educational purposes. We describe our approach to explore the way players learn game skills and solve problems in an open-source puzzle game called Lix. We performed an initial study with 15 participants, in which we applied Process Mining and cluster analysis in a three-step analysis approach. This approach can be used as a basis for recommending interventions so as to facilitate the puzzle-solving process of players.  Springer International Publishing Switzerland 2016. Cluster analysis; Educational data mining; Learning analytics; Process mining; Puzzle games; Serious games; Technology enhanced learning

A general framework for predictive business process monitoring As organizations gain awareness of the potential business value locked in their process execution event logs, "evidence-based" business process management (BPM) becomes a common tool for process analysts. In contrast to traditional process monitoring techniques which are typically performed using data from running process instances only, predictive evidence-based BPM methods tap also into historical data, to allow process workers to respond, in real-time, to specific process performance issues and compliance violations as they arise or even before they arise. In previous work, various approaches have been proposed to address typical predictive process monitoring problems, such as whether a running process instance will meet its performance targets, or when will an instance be finally finished. However, these approaches are rather ad-hoc and lack generality, as they tackle only particular, pre-defined aspects of predictive monitoring and often only work with specific characteristics of the dataset. The proposed research project aims at developing a general and robust framework for predictive process monitoring that will address a variety of process monitoring tasks such as predicting the outcome of individual activities or of the whole process instance, or predicting the completion path of an instance. Business activity monitoring; Business process management; Machine learning; Predictive monitoring; Process mining

Extending BPMN model for improving expressiveness and machine-understandability BPMN has become the preferred support for modelling and describing processes in the context of process developing. Nevertheless, several shortcomings have been identified in its application in particular usage scenarios. In particular, contexts demanding real-time monitoring of manual services, or with requirements to feed Data Analytics system can not take full advantage of BPMN. This papers address this arising issue by suggesting an extension for BPMN. This backwards compliant enhancement supports the definition of probe-oriented features to support services aimed at facilitating the fully automatic data processing in many scenarios.  Springer International Publishing Switzerland 2016. BPMN; Data analytics; Process mining; Quality control

Conformance checking using formal methods Conformance checking is an important process mining task; it aims to detect inconsistencies between the model of a process and its corresponding execution log. This paper proposes an approach in which it is given a declarative description, represented by a set of temporal logic properties, for the process model; the process discovered from the log is described by means of a process algebra, and conformance checking is performed through the model checking of the discovered process against the properties. To discover the process we consider additional information contained in the log and associated with the single events. Moreover, since discovered processes tend, in general, to be very large and complex, we look for a reduced process containing only the parts relevant for the properties satisfaction. In this way we reduce both the space needed for the discovered process and the time complexity for the properties verification. Copyright  2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved. Conformance checking; Model checking; Model discovery; Process mining

SQL mining: Knowledge discovery from DML statements Process centric knowledge discovery led to the founding of a new discipline called process mining, discipline that uses event logs and has as aim process models' discovery. But, not all information systems are able to record these kind of event logs. Moreover, even the information systems provide event logs, most of the existing process mining techniques focus on the control-flow perspective of processes, therefore neglecting the data-flow. The data-flow of a process relies on the data needed (input data elements) in order to execute each activity and the resulted data (the output data elements) after the execution of each activity. This paper focuses on two directions: a) a novel approach for event log extraction (SQL mining using DML statements) and b) a data-flow visualization of process models. The data-flow visualization is expressed using Product Data Model (PDM), so each activity has input and output data elements, but control-flow process mining algorithms may also be applied. Data-centric perspective; DML; Process centric knowledge discovery; Process mining; Product Data Model; SQL mining

Social mining as a knowledge management solution We introduce knowledge management and identify common problems and challenges. We then introduce social mining, a technique from the field of process mining. We show that the techniques used in social mining could have added value for the knowledge management challenges. We also identify areas for improvement in social mining. The first of these concerns the joint activity metric. We argue that for this metric only correlation measures should be used and the distance measures should be re-evaluated. Next we propose the more detailed use of time information to add value to the existing metrics. Lastly we suggest a way of validating the connection in a social network. As a conclusion we find that social mining can be enhanced in these areas and then used as a tool to tackle knowledge management problems. Copyright  by the paper's authors. Copying permitted only for private and academic purposes. 

Log-based Evaluation of Label Splits for Process Models Process mining techniques aim to extract insights in processes from event logs. One of the challenges in process mining is identifying interesting and meaningful event labels that contribute to a better understanding of the process. Our application area is mining data from smart homes for elderly, where the ultimate goal is to signal deviations from usual behavior and provide timely recommendations in order to extend the period of independent living. Extracting individual process models showing user behavior is an important instrument in achieving this goal. However, the interpretation of sensor data at an appropriate abstraction level is not straightforward. For example, a motion sensor in a bedroom can be triggered by tossing and turning in bed or by getting up. We try to derive the actual activity depending on the context (time, previous events, etc.). In this paper we introduce the notion of label refinements, which links more abstract event descriptions with their more refined counterparts. We present a statistical evaluation method to determine the usefulness of a label refinement for a given event log from a process perspective. Based on data from smart homes, we show how our statistical evaluation method for label refinements can be used in practice. Our method was able to select two label refinements out of a set of candidate label refinements that both had a positive effect on model precision.  2016 The Authors. Published by Elsevier B.V. Label refinement; Process Mining; Sensor Networks

Comparative evaluation of quantitative effects of information systems implementation This paper presents a new method for evaluating the effects of newly implemented information systems quantitatively based on process mining techniques. Furthermore, in order to facilitate a comparative analysis of an existing system and a new system, we propose a configuration tool that can be used conveniently for visual comparison of changed activities, resources, organizers, and so on between processes of the two systems. Actual business processes can be discovered from event logs or transaction records produced by information systems using the process mining techniques. In addition, process mining provides various functionalities, such as performance analysis, and pattern analysis. These functionalities are used to propose a framework for quantitatively analyzing and comparing the performances of the newly implemented information system and the existing system. The framework can be utilized for the performance verification of newly implemented information systems in various industries.  2016 ICIC Express Letters Office. Comparative evaluation; Information systems; Process mining; Quantitative effects

Discovering interacting artifacts from ERP systems (extended abstract) Enterprise Resource Planning (ERP) systems are widely used to manage business documents along a business processes and allow very detailed recording of event data of past process executions and involved documents. This recorded event data is the basis for auditing and detecting unusual flows. Process mining techniques can analyze event data of processes stored in linear event logs to discover a process model that reveals unusual executions. Existing techniques assume a linear event log that use a single case identifier to which all behavior can be related. However, in ERP systems processes such as Order to Cash operate on multiple interrelated business objects, each having their own case identifier, their own behavior, and interact with each other. Forcing these into a single case creates ambiguous dependencies caused by data convergence and divergence which obscures unusual flows in the resulting process model.We present a new semi-Automatic, end-To-end approach for analyzing event data in a plain database of an ERP system for unusual executions.We identify an artifact-centric process model describing the business objects, their life-cycles, and how the various objects interact along their life-cycles. The technique was validated in two case studies and reliably revealed unusual flows later confirmed by domain experts. The work summarized in this extended abstract has been published in [Lu15]. Artifact-centric model; ERP-system; Interaction discovery; Object life-cycle; Process mining

In log and model we trust? A generalized conformance checking framework While models and event logs are readily available in modern organizations, their quality can seldom be trusted. Raw event recordings are often noisy, incomplete, and contain erroneous recordings. The quality of process models, both conceptual and data-driven, heavily depends on the inputs and parameters that shape these models, such as domain expertise of the modelers and the quality of execution data. The mentioned quality issues are specifically a challenge for conformance checking. Conformance checking is the process mining task that aims at coping with low model or log quality by comparing the model against the corresponding log, or vice versa. The prevalent assumption in the literature is that at least one of the two can be fully trusted. In this work, we propose a generalized conformance checking framework that caters for the common case, when one does neither fully trust the log nor the model. In our experiments we show that our proposed framework balances the trust in model and log as a generalization of state-of-the-art conformance checking techniques.  Springer International Publishing Switzerland 2016. Conformance checking; Log repair; Model repair; Process mining

Decision mining revisited - Discovering overlapping rules Decision mining enriches process models with rules underlying decisions in processes using historical process execution data. Choices between multiple activities are specified through rules defined over process data. Existing decision mining methods focus on discovering mutually-exclusive rules, which only allow one out of multiple activities to be performed. These methods assume that decision making is fully deterministic, and all factors influencing decisions are recorded. In case the underlying decision rules are overlapping due to nondeterminism or incomplete information, the rules returned by existing methods do not fit the recorded data well. This paper proposes a new technique to discover overlapping decision rules, which fit the recorded data better at the expense of precision, using decision tree learning techniques. An evaluation of the method on two real-life data sets confirms this trade off. Moreover, it shows that the method returns rules with better fitness and precision in under certain conditions.  Springer International Publishing Switzerland 2016. Decision mining; Overlapping rules; Process mining

Deducing case IDs for unlabeled event logs Event logs are invaluable sources of knowledge about the actual execution of processes. A large number of techniques to mine, check conformance and analyze performance have been developed based on logs. All these techniques require at least case ID, activity ID and the timestamp to be in the log. If one of those is missing, these techniques cannot be applied. Real life logs are rarely originating from a centrally orchestrated process execution. Thus, case ID might be missing, known as unlabeled log. This requires a manual preprocessing of the log to assign case ID to events in the log. In this paper, we propose a new approach to deduce case ID for the unlabeled event log depending on the knowledge about the process model.We provide a set of labeled logs instead of a single labeled log with different rankings.We evaluate our prototypical implementation against similar approaches.  Springer International Publishing Switzerland 2016. Decision trees; Event correlation; Missing data; Process mining; Unlabeled event log; Unmanaged business process

Collective unconscious interaction patterns in classrooms Students unconscious interactions can be estimated from their gaze patterns. They signal who they are paying visual attention to, which is not necessarily conscious as they could express in surveys, but it reveals the students unconscious preferences and decisions. A students gaze reveals who captures their attention among a class full of students. Using two months of video recordings taken from a fourth grade class, where, every day, a sample of 3 students wore a mini video camera mounted on eyeglasses, we analyzed students gaze tendencies throughout the sessions. We found that low GPA students gaze to the teacher decreases much more than high GPA students after 40 min. On the other hand, popular students, high GPA students, attractive boys, and girls without upper body strength receive much more gazes from peers systematically throughout the sessions. However there are groups with some combinations of these characteristics that unexpectedly receive more gazes. On the other hand, in some cases there is a clear pattern on gender and popularity of the peers that do more of the gazes to the previous groups than the rest.  Springer International Publishing Switzerland 2016. Classroom practices; Collective intelligence; Educational process mining; Interaction patterns; Students unconscious preferences; Video analysis; Visual attention

A Petri Net specification of the REA business ontology Current auditing procedures struggle with the incorporation of new data-driven techniques such as Process Mining. Although Process Mining has been applied experimentally on micro-level workflow processes, it is not so easy to apply on the level of the value cycle that is at the core of accounting databases. A more general problem is that the new smart approaches lack a well-developed accounting ontology. The REA business ontology does offer such an ontology but so far, its main focus has been on accounting database design. In this paper, a Petri Net specification of REA is proposed for ontologybased process analysis. This specification makes it possible to express more than the traditional static specification. The paper also describes how REA Petri Nets can be developed using Process Mining and how they can be applied in a Continuous Auditing framework. Copyright  by the paper's authors. Copying permitted only for private and academic purposes. Coloured Petri Net; Continuous Auditing; Process Mining; REA business ontology

On process model synthesis based on event logs with noise Process mining is a new emerging discipline related to process management, formal process modelling, and data mining. One of the main tasks of process mining is model synthesis (discovery) based on event logs. A wide range of algorithms for process model discovery, analysis, and enhancement is developed. The real-life event logs often contain noise of different types. In this paper, we describe the main causes of noise in the event logs and study the effect of noise on the performance of process discovery algorithms. The experimental results of application of the main process discovery algorithms to artificial event logs with noise are provided. Specially generated event logs with noise of different types were processed using the four basic discovery techniques. Although modern algorithms can cope with some types of noise, in most cases, their use does not lead to obtaining a satisfactory result. Thus, there is a need for more sophisticated algorithms to deal with noise of different types.  2016, Allerton Press, Inc. event log; event log generation; Petri net; process mining; ProM

Improving process model precision by loop unrolling Despite the advent of scalable process mining techniques that can handle both noisy and incomplete real-life event logs, there is a lack of scalable algorithms capable of handling a common cause of model underfitting: when the same activity in the log in fact behaves differently depending on the number of occurrences in a particular trace. This paper proposes a simple scalable technique to identify these cases and successfully mine better process models from event logs. The technique has been implemented and evaluated on well-known benchmarks in the literature.  2016, CEUR-WS. All rights reserved. 

Using life cycle information in process discovery Understanding the performance of business processes is an important part of any business process intelligence project. From historical information recorded in event logs, performance can be measured and visualized on a discovered process model. Thereby the accuracy of the measured performance, e.g., waiting time, greatly depends on (1) the availability of start and completion events for activities in the event log, i.e. transactional information, and (2) the ability to differentiate between subtle control flow aspects, e.g. concurrent and interleaved execution. Current process discovery algorithms either do not use activity life cycle information in a systematic way or cannot distinguish subtle controlflow aspects, leading to less accurate performance measurements. In this paper, we investigate the automatic discovery of process models from event logs, such that performance can be measured more accurately. We discuss ways of systematically treating life cycle information in process discovery and their implications. We introduce a process discovery technique that is able to handle life cycle data and that distinguishes concurrency and interleaving. Finally, we show that it can discover models and reliable performance information from event logs only.  Springer International Publishing Switzerland 2016. Concurrency; Performance measurement; Process discovery; Process mining; Rediscoverability

Students' modeling based on their problem solving behavior This research work aims at designing a framework to process the students' logged traces and identifying different learning models based on their problem solving behavior specifically through trace-based exercises. Students depict different behaviors during problem solving including learning sequences and engagement level; thus yielding less structured and more complex interaction traces. It is therefore proposed to use Fuzzy Logic for pattern classification.  2016, CEUR-WS. All rights reserved. Educational process mining; Learning traces; Pattern classification; Problem solving

Port logistics simulation using CPN tools with yard truck and gantry crane configuration Nowadays, most industries utilize information systems to store data. Process mining is a technique commonly used to analyze data. It proceeds by discovering a process model from event logs, from which, additionally, the process model's main flows can be found. Creating a simulation model normally is not easy. In order to convert it from the process model, pre-processing of the event logs is necessary. In this step, we calculated the distribution type and all of the parameters, and later, we obtained, as combined with the process model, the structural simulation model. Afterwards, to improve the port logistics process by CPN simulation, we exported the process model to Colored Petri-Nets (CPN) using the CPN Tools Export plug-in in the ProM framework. CPN tools; Port logistics; Process mining; Simulation

Transition systems reduction: Balancing between precision and simplicity Transition systems are a powerful formalism, which is widely used for process model representation. A number of approaches were proposed in the process mining field to tackle the problem of constructing transition systems from event logs. Existing approaches discover transition systems that are either too large or too small. In this paper we propose an original approach to discover transition systems that perfectly fit event logs and whose size is adjustable depending on the user's need. The proposed approach allows achieving a required balance between simple and precise models. Model reduction; Process mining; Process model quality; Transition systems

Towards predictive behavior analysis for smart environments Predictive behavior analysis allows prediction of the (human) behavior based on the analysis of historical data. Efficient approaches for predictive behavior analysis are available for scenarios with structured processes (e.g., based on ERP systems). The prediction of behavior becomes an obstacle when unstructured (decision making) processes underlie the scenario. Scenarios with unstructured processes can be found in smart environments logging sensor (event) streams such as e.g., Smart Home or Connected Cars. No efficient solutions exist to identify abnormal behavior (anomalies) in such smart environments. To provide a solution for anomaly detection in unstructured processes we suggest crossing process engineering with deep learning. Methods from process engineering allow identifying deviations while deep learning improves the robustness of anomalie detection and prediction. This conjunction is a promising approach in order to find an efficient solution. Behavior analysis; Data; Deep learning; Process mining

Mining conditional partial order graphs from event logs Process mining techniques rely on event logs: the extraction of a process model (discovery) takes an event log as the input, the adequacy of a process model (conformance) is checked against an event log, and the enhancement of a process model is performed by using available data in the log. Several notations and formalisms for event log representation have been proposed in the recent years to enable efficient algorithms for the aforementioned process mining problems. In this paper we show how Conditional Partial Order Graphs (CPOGs), a recently introduced formalism for compact representation of families of partial orders, can be used in the process mining field, in particular for addressing the problem of compact and easy-to-comprehend representation of event logs with data. We present algorithms for extracting both the control flow as well as the relevant data parameters from a given event log and show how CPOGs can be used for efficient and effective visualisation of the obtained results. We demonstrate that the resulting representation can be used to reveal the hidden interplay between the control and data flows of a process, thereby opening way for new process mining techniques capable of exploiting this interplay. Finally, we present opensource software support and discuss current limitations of the proposed approach.  Springer-Verlag Berlin Heidelberg 2016. 

A generic framework for context-aware process performance analysis Process mining combines model-based process analysis with data-driven analysis techniques. The role of process mining is to extract knowledge and gain insights from event logs. Most existing techniques focus on process discovery (the automated extraction of process models) and conformance checking (aligning observed and modeled behavior). Relatively little research has been performed on the analysis of business process performance. Cooperative business processes often exhibit a high degree of variability and depend on many factors. Finding root causes for inefficiencies such as delays and long waiting times in such flexible processes remains an interesting challenge. This paper introduces a novel approach to analyze key process performance indicators by considering the process context. A generic context-aware analysis framework is presented that analyzes performance characteristics from multiple perspectives. A statistical approach is then utilized to evaluate and find significant differences in the results. Insights obtained can be used for finding high-impact points for optimization, prediction, and monitoring. The practical relevance of the approach is shown in a case study using real-life data.  Springer International Publishing AG 2016. Context-aware; Performance analysis; Process mining; Root cause analysis

A social norms based approach for enhancing decision support in business process execution Decision making in complex and volatile business environments is still the realm of human decision makers since their knowledge and experience are paramount in making good decisions. The standard run-of-the-mill automation approaches for making decisions do not work well in these contexts. This paper investigates the use of a socially-inspired norm inference mechanism proposed in the area of multi-agent systems to assist human users to make decisions. Using simulation results the paper demonstrates that using the norm-based mechanism results in reduced failure rates in the decision making of a knowledge worker while still providing maximum flexibility for the user to choose from a range of actions to execute. Copyright ISCA. Norm inference; Operational decision support; Process mining

Business process performance mining with staged process flows Existing business process performance mining tools offer various summary views of the performance of a process over a given period of time, allowing analysts to identify bottlenecks and their performance effects. However, these tools are not designed to help analysts understand how bottlenecks form and dissolve over time nor how the formation and dissolution of bottlenecks - and associated fluctuations in demand and capacity - affect the overall process performance. This paper presents an approach to analyze the evolution of process performance via a notion of Staged Process Flow (SPF). An SPF abstracts a business process as a series of queues corresponding to stages. The paper defines a number of stage characteristics and visualizations that collectively allow process performance evolution to be analyzed from multiple perspectives. It demonstrates the advantages of the SPF approach over state-of-the-art process performance mining tools using a real-life event log of a Dutch bank.  Springer International Publishing Switzerland 2016. Cumulative flow; Multistage processes; Performance analysis; Process mining; Queuing theory

Handling complex process models conditions using first-order horn clauses WorkFlow Management Systems provide automatic support to learn process models or to check compliance of process enactment to correct models. The expressive power of the adopted formalism for representing process models is fundamental to determine the effectiveness or even feasibility of a correct model. In particular, a desirable feature is the possibility of expressing complex conditions on some elements of the model. The formalism used in the WoMan framework for workflow management, based on First-Order Logic, is more expressive than standard formalisms adopted in the literature. It allows tight integration between the activity flow and the conditions, and it allows one to express conditions that take into account contextual information and various kinds of relationships among the involved entities. This paper discusses such a formalism, especially concerning conditions, and provides an explicative example of how this can be applied in practice.  Springer International Publishing Switzerland 2016. Business process modeling; Logic programming; Process mining

Discovering block-structured parallel process models from causally complete event logs a-algorithm is suitable to discover a large class of workflow (WF) nets based on the behaviour recorded in event logs, with the main limiting assumption that the event log is complete. Our research has been aimed at finding ways of discovering business process models based on examples of traces, ie, logs of workflow actions that do not meet the requirement of completeness. In this aim, we have modified the existing and introduced a new relation between activities recorded in the event log, which has led to a partial correction of the process models discovering technique, including the a-algorithm. We have also introduced the notion of causally complete logs, from which our modified algorithm can produce the same result as the a-algorithm from complete logs. The effect of these modifications on the efficiency of the process model discovering is mostly evident for business processes in which many activities can be performed in parallel. The application of the modified method for discovering block-structured models of parallel business processes is presented in this paper.  2016 FEI STU. Block-structured parallel process models; Business process model discovery; Complete log; Process mining; a-algorithm

Characterizing problem gamblers in New Zealand: A novel expression of process cubes This paper reports on the challenges and lessons learned from our case study which uniquely integrates a mixture of process mining, data mining, and confirmatory statistical techniques to explore and characterize the variations in gambling behaviours exhibited by gamblers in New Zealand. We demonstrate how we weaved techniques from these three disciplines to understand the variety of behaviours exhibited by gamblers, and to provide assurances of the correctness of our results. This case study also demonstrates how such a combination of techniques provides a rich set of tools to undertake an exploratory data analysis project that is guided by the process cube concept. Copyright  by the paper's authors. Copying permitted only for private and academic purposes. Data mining; Problem gamblers; Process mining; Statistics

Computing trace alignment against declarative process models through planning Process mining techniques aim at extracting non-trivial knowledge from event traces, which record the concrete execution of business processes. Typically, traces are "dirty" and contain spurious events or miss relevant events. Trace alignment is the problem of cleaning such traces against a process specification. There has recently been a growing use of declarative process models, e.g., Declare (based on LTL over finite traces) to capture constraints on the allowed task flows. We demonstrate here how state-of-the-art classical planning technologies can be used for trace alignment by presenting a suitable encoding. We report experimental results using a real log from a financial domain. Copyright  2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. 

Tree automata mining This paper [The article is an essentially revised version of conference paper (Przybylek (2013) International Conference on Evolutionary Computation Theory and Applications)] describes a new approach to mine business processes. We define bidirectional tree languages together with their finite models and show how they represent business processes. We offer an algebraic explanation for the phenomenon of an evolutionary metaheuristic skeletal algorithms, and show how this explanation gives rise to algorithms for recognition of bidirectional tree automata. We use the algorithms in process mining and in discovering mathematical theories  Springer International Publishing Switzerland 2016. Evolutionary algorithms; Language recognition; Minimum description length; Process mining

Flexible process model design The paper describes the algebraic logical methods, logical network theory, and information object and process models. The algebraic appliance of finite predicates is used as a mathematical framework. The analysis of the formal description means for information processes allows selecting the logical network appliance for design of complete models of the information process description. This logical network appliance is designed for static object modelling. So, the modification of the logical network model is required for the description of information processes that allowing for the process dynamics. A two-layer logical network is designed comprising the system of binary predicates and predicate operations. The flexible process is presented by a modified logical network allowing to adapt the model to the domain.  2016 Trans Tech Publications, Switzerland. Algebra of predicates; Flexible process; Log process; Logical network; Process mining

Green data science: Using Big Data in an "environmentally friendly" manner The widespread use of "Big Data" is heavily impacting organizations and individuals for which these data are collected. Sophisticated data science techniques aim to extract as much value from data as possible. Powerful mixtures of Big Data and analytics are rapidly changing the way we do business, socialize, conduct research, and govern society. Big Data is considered as the "new oil" and data science aims to transform this into new forms of "energy": insights, diagnostics, predictions, and automated decisions. However, the process of transforming "new oil" (data) into "new energy" (analytics) may negatively impact citizens, patients, customers, and employees. Systematic discrimination based on data, invasions of privacy, non-transparent life-changing decisions, and inaccurate conclusions illustrate that data science techniques may lead to new forms of "pollution". We use the term "Green Data Science" for technological solutions that enable individuals, organizations and society to reap the benefits from the widespread availability of data while ensuring fairness, confidentiality, accuracy, and transparency. To illustrate the scientific challenges related to "Green Data Science", we focus on process mining as a concrete example. Recent breakthroughs in process mining resulted in powerful techniques to discover the real processes, to detect deviations from normative process models, and to analyze bottlenecks and waste. Therefore, this paper poses the question: How to benefit from process mining while avoiding "pollutions" related to unfairness, undesired disclosures, inaccuracies, and non-transparency? Copyright  2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved. Accuracy; Big Data; Confidentiality; Data science; Fairness; Process mining; Transparency

Discovery of multi-perspective declarative process models Process discovery is one of the main branches of process mining that allows the user to build a process model representing the process behavior as recorded in the logs. Standard process discovery techniques produce as output a procedural process model (e.g., a Petri net). Recently, several approaches have been developed to derive declarative process models from logs and have been proven to be more suitable to analyze processes working in environments that are less stable and predictable. However, a large part of these techniques are focused on the analysis of the control flow perspective of a business process. Therefore, one of the challenges still open in this field is the development of techniques for the analysis of business processes also from other perspectives, like data, time, and resources. In this paper, we present a full-fledged approach for the discovery of multi-perspective declarative process models from event logs that allows the user to discover declarative models taking into consideration all the information an event log can provide. The approach has been implemented and experimented in real-life case studies.  Springer International Publishing Switzerland 2016. Declarative process model; Declare; Multi-perspective process model; Process discovery; Process mining

A visual approach to spot statistically-significant differences in event logs based on process metrics This paper addresses the problem of comparing different variants of the same process. We aim to detect relevant differences between processes based on what was recorded in event logs. We use transition systems to model behavior and to highlight differences. Transition systems are annotated with measurements, used to compare the behavior in the variants. The results are visualized as transitions systems, which are colored to pinpoint the significant differences. The approach has been implemented in ProM, and the implementation is publicly available. We validated our approach by performing experiments using real-life event data. The results show how our technique is able to detect relevant differences undetected by previous approaches while it avoids detecting insignificant differences.  Springer International Publishing Switzerland 2016. Annotated transition system; Process mining; Process variants comparison; Statistical significance

Clustering traces using sequence alignment Process mining discovers process models from event logs. Logs containing heterogeneous sets of traces can lead to complex process models that try to account for very different behaviour in a single model. Trace clustering identifies homogeneous sets of traces within a heterogeneous log and allows for the discovery of multiple, simpler process models. In this paper, we present a trace clustering method based on local alignment of sequences, subsequent multidimensional scaling, and k-means clustering. We describe its implementation and show that its performance compares favourably to state-of-the-art clustering approaches on two evaluation problems.  Springer International Publishing Switzerland 2016. Process discovery; Process mining; Sequence alignment; Trace clustering

Categorizing identified deviations for auditing Currently, financial statements auditors perform the tests of controls based on sampling. However, when using a sampling approach, information is lost. To counter this drawback, data analytics has been applied as a method for auditors to provide assurance while using all data. Specifically for testing controls, the potential of process mining has been explained in literature. Indeed, conformance checking can be used to compare real process executions with a normative model. However, the outcome of current conformance checking techniques is too vast for an auditor to inspect further. The identified deviations are at an atomic level (skipped and inserted tasks) and there is no feasible approach to gain a quick overview of the deviations. In this paper, we propose an approach to categorize deviations, which enables auditors to quickly gain an overview of different types of existing deviations along with their frequencies. Categorizing deviating process instances can also give an insight for assessing the risk at case level.  2016, CEUR-WS. All rights reserved. Conformance checking; Deviation identification; Financial statemenets auditing; Process mining; Risk assessment

Alignment-based metrics in conformance checking The holy grail in process mining is a process discovery algorithm that, given an event log, produces fitting, precise, properly generalizing and simple process models. Within the field of process mining, conformance checking is considered to be anything where observed behaviour, e.g., in the form of event logs or event streams, needs to be related to already modelled behaviour. In the conformance checking domain, the relation between an event log and a model is typically quantified using fitness, precision and generalization. In this paper, we present metrics for fitness, precision and generalization, based on alignments and the newer concept named anti-Alignments. The work summarized here is presented in detail in [vdAAvD12, vDCC16]. Alignments; Fitness; Generalization; Precision; Process mining; Quality metrics

Capturing resource behaviour from event logs Process mining mainly focuses on the retrieval of process models from event logs. As these discovery algorithms make assumptions, performance analyses based on these models can present a biased view. In literature, algorithm-agnostic process metrics have been introduced. Given the critical importance of resources in the light of continuous process improvement, this paper extends the process metrics framework towards the resource perspective. New metrics are added and existing metrics are adapted. Using the extended framework, organisations can retrieve useful insights in resource behaviour.  2016, CEUR-WS. All rights reserved. Log-based process metrics; Operational excellence; Process mining; Resource behaviour

A method for automated gait pattern classification This work presents the development of a data mining application for gait pattern classification. The objective is to understand the differences and similarities among patterns of walking from healthy and unhealthy subjects groups. The data repository contains the spatial parameters of centers of pressure (CoP) trajectories during gait. The trajectory of each CoP is extracted from the contact points of the feet with the ground form each footprint. The data was collected with a GaitRite® Pressure Sensor Mat. The proposed method includes the standardization of data and creation of an organized repository (data warehouse) from previously collected data. Also, it includes the development of a process mining example to analytical comparison between these two different groups. A graphical analysis based on decision tree provides the interpretation of the pattern of 'signature' footprints. This study is the starting point to classifying different pathologies and assisting the rehabilitation treatments.  2016 The authors and IOS Press. Data mining; Gait analysis; Pattern Analysis; Pattern Classification; Signature Footprints

Minimizing overprocessing waste in business processes via predictive activity ordering Overprocessing waste occurs in a business process when effort is spent in a way that does not add value to the customer nor to the business. Previous studies have identified a recurrent overprocessing pattern in business processes with so-called knockout checks, meaning activities that classify a case into accepted or rejected, such that if the case is accepted it proceeds forward, while if rejected, it is cancelled and all work performed in the case is considered unnecessary. Thus, when a knockout check rejects a case, the effort spent in other (previous) checks becomes overprocessing waste. Traditional process redesign methods propose to order knockout checks according to their mean effort and rejection rate. This paper presents a more fine-grained approach where knockout checks are ordered at runtime based on predictive machine learning models. Experiments on two real-life processes show that this predictive approach outperforms traditional methods while incurring minimal runtime overhead.  Springer International Publishing Switzerland 2016. Overprocessing waste; Process mining; Process optimization

Synthesis and simulation of surgical process models Virtual Reality for surgical training is mainly focused on technical surgical skills. We work on providing a novel approach to the use of Virtual Reality focusing on the procedural aspects. Our system relies on a specific work-flow generating a model of the procedure from real case surgery observation in the operating room. This article presents the different technologies created in the context of our project and their relations as other components of our workflow.  2016 The authors and IOS Press. All rights reserved. Collaboration; Ontology; Process mining; Surgical process model; Surgical training; Virtual environments

In log and model we trust? While models and event logs are readily available in modern organizations, their quality can seldom be trusted. Raw event recordings are often noisy, incomplete, and contain erroneous recordings. The quality of process models, both conceptual and data-driven, heavily depends on the inputs and parameters that shape these models, such as domain expertise of the modelers and the quality of execution data. The mentioned quality issues are specifically a challenge for conformance checking. Conformance checking is the process mining task that aims at coping with low model or log quality by comparing the model against the corresponding log, or vice versa. The prevalent assumption in the literature is that at least one of the two can be fully trusted. In this work, we propose a generalized conformance checking framework that caters for the common case, when one does neither fully trust the log nor the model. In our experiments we show that our proposed framework balances the trust in model and log as a generalization of state-of-The-Art conformance checking techniques. Conformance checking; Log repair; Model repair; Process mining

DB-XES: Enabling process discovery in the large Dealing with the abundance of event data is one of the main process discovery challenges. Current process discovery techniques are able to efficiently handle imported event log files that fit in the computer's memory. Once data files get bigger, scalability quickly drops since the speed required to access the data becomes a limiting factor. This paper proposes a new technique based on relational database technology as a solution for scalable process discovery. A relational database is used both for storing event data (i.e. we move the location of the data) and for pre-processing the event data (i.e. we move some computations from analysis-time to insertion-time). To this end, we first introduce DB-XES as a database schema which resembles the standard XES structure, we provide a transparent way to access event data stored in DB-XES, and we show how this greatly improves on the memory requirements of a state-of-the-art process discovery technique. Secondly, we show how to move the computation of intermediate data structures, such as the directly follows relation, to the database engine, to reduce the time required during process discovery. The work presented in this paper is implemented in ProM tool, and a range of experiments demonstrates the feasibility of our approach.  2016, CEUR-WS. All rights reserved. Big event data; Process discovery; Process mining; Relational database

A skiing trace clustering model for injury risk assessment This paper investigates the relation between skiing movement activity patterns and risk of injury. The goal is to provide a framework which can be used for estimating the level of skiers' injury risks, based on skiing patterns. Data, collected from ski-lift gates in the form of process event logs is analyzed. After initial transformation of data into traces, trace vectors, and similarity matrix, using several clustering methods different skiing patterns are identified and compared. The quality of clusters is determined by how well clusters discriminate between injured and noninjured skiers. The goal was to achieve the best possible discrimination. Several experimental settings were made to achieve and suggest a good combination of algorithm parameters and cluster number. After clusters are obtained, they are categorized in three categories according to risk level. It can be concluded that the proposed method can be used to distinguish skiing patterns by risk category based on injury occurrences. Copyright  2016, IGI Global. Injuries; Process mining; Risk assessment; Skiing; Spectral clustering; Trace clustering

Calculating the number of unique paths in a Block-Structured process model Estimating the number of execution paths in a process model is a non-trivial task as one runs quickly into an combinatorial explosion of possible paths. This paper introduces a new algorithm to calculate the number of different execution paths for finite-behavior block-structured models in a computationally efficient way. Block functions are defined for the workflow constructs sequence, parallel, exclusive choice and finite loops, such that the amount of behavior in each block-construct can be computed efficiently. Subsequently, the block-structuredness of the model is exploited to efficiently calculate the number of unique paths in the model. The algorithm has been implemented for process trees, although the translation to other modeling notations is straightforward. An empirical analysis showed that the run-time of the algorithm is very low, and only slightly impacted by the complexity of the model. Process mining; Process model complexity; Process modeling; Process trees

Sensing distress  Towards a blended method for detecting and responding to problematic customer experience events Excellent Customer Experience (CE) is a strategic priority for many large service organisations in a competitive marketplace. CE should be seamless, and in most cases it is, with customers ordering, paying for and receiving services that align with their expectations. However, in rare cases, an exceptional process event leads to service delivery delay or failure, and both the customer and organisation end up in complex recovery situations as a result. Unless this recovery is handled effectively inefficiency, avoidable costs and brand damage can result. So how can organisations sense when these problems are occurring and how can they respond to avoid these negative consequences? Our paper proposes a blended methodology where process mining and qualitative user research combine to give a holistic picture of customer experience issues, derived from a particular customer case study. We propose a theoretical model for detecting and responding to customer issues, and discuss the challenges and opportunities of such a model when applied in practice in large service organisations.  Springer International Publishing Switzerland 2016. Customer experience; HCI; Process mining

Analysis of handover of work in call center using social network process mining technique This article investigates and analyzes the Handover of Work in a call center data previously collected from a telecommunication company in Thailand. The main objective of the study is to find the relationship values of the handover of work amongst the call center personnel in order to improve the efficiency of the handling with customers' receiving calls in total. To do this, we visualized the stored data based on the social network graphs with respect to handover of work metric. The main idea was to count the total number of times department J(in charge of specific received calls) performed an activity inbetween two activities performed by department I in such a way to indicate that work was subcontracted from department in to department J. Following the above-mentioned approach enabled us to easily and quickly track and trace the different departments (as well as the human resources dealing with the incoming calls) to attend and address the customers' receiving call in a more efficient, effective and timely manner.  2015 IEEE. call center event log; causal relationships; Process Mining; Social Network Miner (Handover of work); subsequent activities

Analysis of call-center operational data using role hierarchy miner The main objective of this research is to analyze information of customer contact made to a call center section of a telecommunication company in Thailand. Using role hierarchy mining approach (as process mining technique) enabled us to focus on the hierarchical perspectives of the collected event log with respect to the functional relationships amongst the originators (i.e., the administrators and operators who were in charge of handling incoming calls made from customers/clients). Following a role hierarchy approach, we could better track and trace the interactions made between different personnel/administrators in a functional organizational structure from top to down. One of the main advantages of the proposed approach was the ability to detect and identify potential discrepancies and outbreaks made against the rules and responsibilities previously defined by the top management and human resource staff. Accordingly, the results of the study can help the telecommunication companies to improve their call center (customer service) section in such a way to result in more customer/client satisfaction toward the quality of service on work. Therefore, applying a role hierarchy mining approach will eventually lead to improving the performance of the handling calls made to the callcenter section, in a more efficient, effective and timely manner.  2015 IEEE. call center event log; Disco Fluxicon; Fuzzy Mining model; Process Mining; Role Hierarchy Miner; telecommunication company

Analysis of the patients' treatment process in a hospital in Thailand using fuzzy mining algorithms This article investigates the corresponding relation of the patients who come to receive treatment at a hospital in Thailand. We applied Process Mining process discovery techniques in order to scrutinize and analyze the data which was previously collected in Microsoft Excel format, and later it was converted into a.csv extension file using the ProM 5.2 and the Disco Fluxicon. The main rationale for the study was to visualize and simulate the behavior of patients (at a estate governmental hospital in Bangkok) referring to different ward for versatile treatment processes of their diseases with respect to the number of time (i.e., frequency) they have visited those wards. Based on the results of study, we could better indicate the corresponding relationships between a group of patients (with specific diseases) which are related to each other and as well as a holistic treatment process view of the tasks and activities undertaken to attend to each case (i.e., patient). Accordingly, the findings of the research can significantly help the researchers and hospital administrators to develop and improve the collaboration of personnel in hospitals in a more effective and efficient way leading to enhancement of the performance.  2015 IEEE. Fuzzy Mining (Disco); Fuzzy Mining (ProM); Patients' Behavior Analytics; process mining; ProM

Analysis of the social network miner (working together) of physicians The main objective of the study is to analyze and investigate the relationships between staff and resources in a hospital using process mining social network miner technique with respect to working together metric. Using social network miner (working together metric) we could better track and trace the behavior of doctors during the treatment process of patients. Using this technique, we could better visualize and analyze the working behavior of physicians as well as identifying the doctors who actively played a major contribution during the treatment process. Therefore, the results of this study can be facilitate the treatment process of patients in a more timely, effective and efficient manner.  2015 IEEE. Healthcare; Process Mining; Prom; Social Network; Social Network Miner; Working Together

Process simulation and pattern discovery through alpha and heuristic algorithms The paper is divided into two main parts. In the first part of the study, we applied two process mining discovery techniques (i.e., alpha and heuristic algorithms) on an event log previously collected from an information system during an Academic Writing (English) training course at a private university in Thailand. The event log was initially consisted of 330 process instances (i.e., number of participants) and 3,326 events (i.e., number of actions/tasks) in total. Using alpha algorithm enabled us to reconstruct causality in form of a Petri-net graph/model. By using heuristic algorithm we could derive XOR and AND connectors in form of a C-net. The results showed 86.36% of the applicants/participants managed to achieve the Academic Writing (English) certificate successfully, while 6.36% of them failed to achieve any certificate after a maximum number of 3 attempts to repeat the training course. Surprisingly, 7.28% of the participants neither achieved an accredited certificate nor failed the course by dropping out before ending the course training process. In the second part of the study, we used performance analysis with Petri net technique (as a process mining conformance checking approach) in order to further analyze the points of noncompliant behavior (i.e., so-called bottlenecks or points of noncompliant behavior) for every case in the collected course training log. Based on the results, we could eventually detect the existing discrepancies of the event log leading to +24 missed tokens and -24 remained tokens altogether.  2015 IEEE. Alpha algorithm; Bottleneck Mining; Conformance Checker; Heuristic Miner algorithm; Model Discovery; MXML; Performance Analysis with Petri net; Process Mining; Process Simulation; ProM

Analysis of surgical event logs in a hospital by using heuristics miner technique The main objective of the research was to analyze and investigate the behavior of the patients and surgeons based on an event log previously collected from a private hospital in Bangkok, Thailand. We applied Heuristics Mining algorithm supported by ProM (as a process mining tool) to discover the extent of the significance metric (i.e., with respect to the relative importance of behaviors) as well as the correlation metric (i.e., with respect to how closely the behaviors are related with each other) amongst of the process instances within the MXML-formatted event log. The results showed that the activity named Implantation of diaphragmatic pacemaker was the most significant activity within the event log with a total of 2,903 cased frequency of repetition as a significance metric of 0.999 (i.e., the highest) and a correlation metric of 1358 (i.e., very firm and robust). The findings of the study can be used by hospitals administrators, managers, surgeons and staff in order to benchmark the patients' treatment processes in a more efficient, effective and timely manner.  2015 IEEE. Heuristic miner algorithm; hospital information system; medical event log; process mining; ProM 5.2

Social network analysis and role hierarchy mining through MXML-based event logs This paper is divided into three main parts. In the first part of the study, we initially collected a process event log -from an information system -during an Academic Writing (English) training course in Thailand. The original data was consisted of 330 process instances and 3,326 events in total. Being aware of the fact that ProM process mining framework accepts and supports only XES and MXML logs, the data was subsequently configured and converted into the fitting format. In the second part of the study, we applied role hierarchy mining technique in order to evaluate the role of every individual throughout the course/training program. Moreover, the organizational mining technique enabled us to better understand the functional structure of the training organization (based on models) and ultimately improve (or benchmark) the underlying processes. In the thirst part of the study, we used social network mining as a pre-requisite for social network analysis to discover the interaction patterns between the originators during the teaching process. Accordingly, the handover of work metric -of the social network mining technique-made possible to not only investigate direct relationships but also indirect relationships as well.  2015 IEEE. Handover of Work; MXML; Organizational Mining; Originator-by-Task Matrix; Process Mining; Process Simulation; ProM; Role Hierarchy Mining; Social Network Analysis; Social Network Miner

Analysis of customer behavior in a call center using fuzzy miner The main objective of this research is to investigate and analyze customer behavior in call center of a telecommunication company. In order to find the purpose of their contact, we applied Fuzzy mining algorithm (supported by ProM 5.2 and Disco Fluxicon) on event log of stored and collected from the call center database. Using these techniques enables us to better track and trace the number of times each section/segment has received calls from customers in total (with respect to frequency of the contacts made via the call center). Also, we could better follow up the steps undertaken dealing with the calls made to communicate company with respect to topic and type of the problems, complaints, services and so on. One of the main advantages of Fuzzy mining techniques is the ability to deal with the concurrent activities (i.e., loops) in a more sophisticated approach compared with other knowledge discovery model such as Alpha or Heuristic mining. Considering the results of the study, administrators and operators of the telecommunication companies can better handle the inbound calls leading to better performance, efficiency, and customer satisfaction.  2015 IEEE. Customers' Behavior Analytics; Fuzzy Mining (Disco); Fuzzy Mining (ProM); Knowledge Discovery; Process Mining; Process Mining

Time performance analysis of medical treatment processes by using disco In this research we applied process mining techniques in order to analyze work processes of a healthcare system. The main objective of the study was to investigate the performance of a private hospital treatment processes in Bangkok based on the event logs. Being aware of the fact that currently healthcare systems of majority of hospitals worldwide are equipped with information systems, provided us a great opportunity to access large amounts of the medical data with the intention of the research and knowledge discovery purposes. In this paper, we emphasized on the Time Performance of the process instances of the collected event logs from different wards/sections of a hospital in order to better visualize and study the behavior of patients referring to the following sections/wards (as well as the hospital's administrators/personnel attending to each case) during the entire treatment processes.. The results showed that the treatment process with respect to the waiting time was too long between the wards Irradiation cystitis and Osteoradionecrosi sections allocating 7.8 waiting time to themselves. Subsequently, the findings of the research can be used in order to help the hospital administrators and managers to better understand the amount of waiting time spent between different treatment processes in such a way that they can improve the performance of handling patients' demands and needs in a more efficient, effective and timely manner, eventually leading to increased customer satisfaction and better performance.  2015 IEEE. Disco Fluxicon; hospital information systems; medical event log; Process Mining; time performance analysis

Discovering organizational process models of resources in a hospital using Role Hierarchy Miner In this research, we analyzed the roles of the resources (i.e., personnel and staff in charge of handling the patients' treatment processes)based on an authentic medical event log previously captured and collected from an estate hospital in Bangkok, Thailand. The applications Disco and ProM were used in order to generate social networks in such a way that can evaluate the role of a resource in the hospital. Accordingly, using the Role Hierarchy Miner technique we could better visualize and simulate the relationships between the relevant resources with the assigned tasks in a well-structured approach. The results of the study can help the administrators to have a better idea about the personnel in charge of each task, resulting to better performance and efficiency of the process treatment processes in total. The findings of the study also can be used to detect and track the violations of the roles (and assigned duties) between the human resources of the governmental or private hospitals.  2015 IEEE. Disco Fluxicin; healthcare treatment process; organizational perespectives; Process Mining; ProM 5.2; Role Hierarchy Miner; social netwroks

Improvement of call center customer service in a Thai bank using disco fuzzy mining algorithm The main objective of the study was to benchmark performance, control discrepancies, and investigate variations of a bank customer service call center data dealing with incoming calls of its clients and customers. To do this, initially an event log consisting of a total of 625,767 process instances (i.e., events) was collected from a private bank in Thailand for the month of July 2015. Using Disco fuzzy mining technique as a process mining tool enabled us to simulate and create authentic visual models/maps from the collected event log in form of fuzzy mining graphs. To better investigate the behavior of the bank's clients/customers and administrators/operators dealing with inappropriate (not successful) customer service and calls, only Failure or Not Responded types of process instances/events were chosen and selected for the study. The findings showed that the number of the incoming calls made into the call center (customer service section) due to the over card limit problem was the highest (i.e., with 4,667 process instances in total) compared with the other problems within the call center event log. On the other hand, the results showed that almost 32%of the Over Card Limit type of the problems were not solved at the first attempt (i.e., clients/customers have to re-dial and re-contact the operators in charge of the section again for the second, third or sometimes multiple-times). Similarly, our results showed that the problems occurred due to the reason why the card number is already activated allocated the second highest number of problems (i.e., with a total of 2,068 process instances in total) within the call center event log. Interestingly, 10% of the incoming calls facing the card number is already activated were not solved/fixed at the first attempt and clients/customers need to re-contact the call center operators again afterwards. With the same token record not found (with 52% of the calls not solved at the first attempt), account not found (with 68% of the calls not solved at the first attempt) and account does not exist (with 61% of the calls not solved at the first attempt) types of the problems allocated the third, fourth and fifth most frequent incoming calls made into the call center customer service section. Eventually, the results of the study can be used in order to enhance and improve the performance of the customer service processes in a more efficient, effective and timely manner.  2015 IEEE. call center customer service; Disco Fluxicon; Fuzzy Mining algorithm; Process mining

Applying social network miner on medical event logs using handover of work metric The main objective of the paper is to analyze of the behavior of patients (as well as the doctors and surgeons) referring to a private hospital for treatment in Thailand. The main idea is to investigate and scrutinize the relationships of the patients and the relevant physicians during the treatment process based on an event log previously collected from the information system of the hospital. Accordingly, we applied process mining social network analysis approach (in term of the handover of work metric) to discover meaningful relationships and insights between the personnel and patients. One of the major benefits of the applied approach was that we could better track and trace the handover of workload from a doctor/surgeon to another doctor/physician within different medical wards/sections dealing with the patients' disease during the treatment process. Considering the results of the study, can significantly help the hospital's administrators and physicians to monitor and recognize the correct flow of transactions and interactions made between different resources in specify sections/wards. Moreover, the proposed technique enabled us to identify those resources who probably were playing an idle role dealing with patients' needs and medical procedures, while not contributing in the assigned tasks and duties as they should do. Eventually, by contemplating on the findings of the study, the researchers and hospitals' management level can benchmark and improve the handling of the patients' treatment process in a way to lead to increased customer satisfaction toward the quality of the service on work, in a more efficient, effective and timely manner.  2015 IEEE. Disco Fluxicon; handover of work; hospital information system; medical event log; Process mining; ProM 5.2; social network miner

Declarative process mining in healthcare Clinical guidelines aim at improving the quality of care processes through evidence-based insights. However, there may be good reasons to deviate from such guidelines or the guidelines may provide insufficient support as they are not tailored toward a particular setting (e.g., hospital policy or patient group characteristics). Therefore, we report a case study that shows how process mining techniques can be used to mediate between event data reflecting the clinical reality and clinical guidelines describing best-practices in medicine. Declarative models are used as they allow for more flexibility and are more suitable for describing healthcare processes that are highly unpredictable and unstable. Concretely, initial (hand made) models based on clinical guidelines are improved based on actual process executions (if these executions are proven to be correct). Process mining techniques can be also used to check conformance, analyze deviations, and enrich models with conformance-related diagnostics. The techniques have been applied in the urology department of the Isala hospital in the Netherlands. The results demonstrate that the techniques are feasible and that our toolset based on ProM and Declare is indeed able to provide valuable insights related to process conformance.  2015 Elsevier Ltd. All rights reserved. Declarative modeling languages; Healthcare processes; Process mining

Event interval analysis: Why do processes take time? Through the application of process mining, valuable evidence-based insights can be obtained about business processes in organisations. As a result, the field has seen an increased uptake in recent years as evidenced by success stories and increased tool support. However, despite this impact, current performance analysis capabilities remain somewhat limited in the context of information-poor event logs. For example, natural daily and weekly patterns are not considered but they are vital for understanding the performance of processes and resources. In this paper, a new framework for analysing event logs is defined. Our framework is based on the concept of event interval. The framework allows for a systematic approach to sophisticated performance-related analysis beyond the capabilities of existing log-based analysis techniques, even with information-poor event logs. The paper formalises a range of event interval types and then presents an implementation as well as an evaluation of the proposed approach.  2015 Elsevier B.V. All rights reserved. Business process management; Data mining; Process mining; ProM

An intelligent approach to data extraction and task identification for process mining Business process mining has received increasing attention in recent years due to its ability to provide process insights by analyzing event logs generated by various enterprise information systems. A key challenge in business process mining projects is extracting process related data from massive event log databases, which requires rich domain knowledge and advanced database skills and could be very labor-intensive and overwhelming. In this paper, we propose an intelligent approach to data extraction and task identification by leveraging relevant process documents. In particular, we analyze those process documents using text mining techniques and use the results to identify the most relevant database tables for process mining. The novelty of our approach is to formalize data extraction and task identification as a problem of extracting attributes as process components, and relations among process components, using sequence kernel techniques. Our approach can reduce the effort and increase the accuracy of data extraction and task identification for process mining. A business expense imbursement case is used to illustrate our approach.  2015, Springer Science+Business Media New York. Business process management; Computational experiments; Data extraction; Process mining; Task identification; Text mining

Semantics-based event log aggregation for process mining and analytics In highly complex and flexible environments, event logs tend to exhibit high levels of heterogeneity, and clustering-based methods are candidate techniques for simplifying the mined process models from the process observations. To compensate for the information loss occurring during clustering, semantic information from event logs may be extracted and organized in the form of knowledge structures such as process ontologies using methods of ontology learning. In this article, we propose an overall computational framework for event log pre-processing, and then focus on a specific component of the framework, namely event log aggregation. We develop a detailed system architecture for this component, along with an implemented and evaluated research prototype SemAgg. We use phrase-based semantic similarity between normalized event names to aggregate event logs in a hierarchical form. We discuss the practical implications of this work for learning lower level process ontology classes as well as performing further process mining and analytics.  2015, Springer Science+Business Media New York. Agglomerative hierarchical clustering; Event logs; Natural language processing; Process analytics; Process mining; Process ontologies

MapReduce based frequent itemset mining algorithm on stream data Offers on e-commerce websites have been mostly a decision made by companies for advertising or clearing stocks. KAAL algorithm was used on sample transaction data to generate frequent itemsets. These frequent itemsets will give an idea of offers to be made on purchase of base items. With advent of internet, the amount of data being generated by business processes is growing exponentially. This paper makes use of Hadoop MapReduce framework to generate association rules on transaction data stream. Offers are suggested spontaneously as the frequent itemsets are being generated at runtime. The paper concludes that the execution time has a linear relationship with number of transactions per batch. It was found that increase in stock size did not have much impact on execution time. Execution time is also inversely proportional to number of nodes.  2015 IEEE. Apriori Algorithm; Association Rule Mining; Big Data; e-commerce; Hadoop; KAAL Algorithm; MapReduce

Process mining methodology for health process tracking using real-time indoor location systems The definition of efficient and accurate health processes in hospitals is crucial for ensuring an adequate quality of service. Knowing and improving the behavior of the surgical processes in a hospital can improve the number of patients that can be operated on using the same resources. However, the measure of this process is usually made in an obtrusive way, forcing nurses to get information and time data, affecting the proper process and generating inaccurate data due to human errors during the stressful journey of health staff in the operating theater. The use of indoor location systems can take time information about the process in an unobtrusive way, freeing nurses, allowing them to engage in purely welfare work. However, it is necessary to present these data in a understandable way for health professionals, who cannot deal with large amounts of historical localization log data. The use of process mining techniques can deal with this problem, offering an easily understandable view of the process. In this paper, we present a tool and a process mining-based methodology that, using indoor location systems, enables health staff not only to represent the process, but to know precise information about the deployment of the process in an unobtrusive and transparent way. We have successfully tested this tool in a real surgical area with 3613 patients during February, March and April of 2015.  2015 by the authors; licensee MDPI, Basel, Switzerland. Health process; Indoor location systems; Process mining

Process mining in software systems: Discovering real-life business transactions and process models from distributed systems This paper presents a novel reverse engineering technique for obtaining real-life event logs from distributed systems. This allows us to analyze the operational processes of software systems under real-life conditions, and use process mining techniques to obtain precise and formal models. Hence, the work can be positioned in-between reverse engineering and process mining. We present a formal definition, implementation and an instrumentation strategy based the joinpoint-pointcut model. Two case studies are used to evaluate our approach. These concrete examples demonstrate the feasibility and usefulness of our approach.  2015 IEEE. Aspect-Oriented Programming; Distributed Systems; Event Log; Joinpoint-Pointcut Model; Performance Analysis; Process Discovery; Process Mining; Reverse Engineering

Semantic process mining towards discovery and enhancement of learning model analysis Process mining algorithms use event logs to learn and reason about processes by technically coupling event history data and process models. During the execution of a learning process, several events occur which are of interest and/or necessary for completing and achieving a learning goal. The work in this paper describes a Semantic Process Mining approach directed towards automated learning. The proposed approach involves the extraction of process history data from learning execution environments, which is then followed by submitting the resulting eXtensible Event Streams (XES) and Mining eXtensible Markup Language (MXML) format to the process analytics environment for mining and further analysis. The XES and MXML data logs are enriched by using Semantic Annotations that references concepts in an Ontology specifically designed for representing learning processes. This involves the identification and modelling of data about different users. The approach focuses on augmenting information values of the resulting model based on individual learner profiles. A series of validation experiments were conducted in order to prove how Semantic Process Mining can be utilized to address the problem of analyzing concepts and relationships amongst learning objects, which also aid in discovering new and enhancement of existing learning processes. To this end, we demonstrate how data from learning processes can be extracted, semantically prepared, and transformed into mining executable formats for improved analysis.  2015 IEEE. Event logs; Learning process; Ontology; Process mining; Process model; Semantic annotation

Discovering process model from incomplete log using process mining This paper gives an overview of relevant research in the area of process mining. Process mining techniques are able to extract knowledge from event logs. The major objective of process mining is to discover, monitor and improve real processes. Process mining aims to exploit event data in a meaningful way to identify and anticipate problems, and recommend countermeasures. Additionally, process mining places the existing massive volumes of data in the context of processes. Since extracting data is an integral part of any process mining procedure, data preparation or data pre-processing requires certain efforts. Examples have been given to indicate how the chosen process mining technique deals with incompleteness in the event log data. Experiments have been made on the real data collected from information system for accommodation services.  2015 Croatian Society Electronics in Marine-ELMAR. Big Data; Event Log; Incomplete Data; Process Mining

Process mining and practical usage This paper is devoted to an introduction to Process Mining, describes the basic algorithms and the link between Data Mining and Process Mining. It also describes the connection Process Mining and practical usage.  2015 IEEE. Data Mining; Process Mining; Process Models

Process mining on noisy logs - Can log sanitization help to improve performance? Process mining techniques are designed to read process logs and extract process models from them. However, real world logs are often noisy and such logs produce bad, spaghetti-like process models. We propose a technique to sanitize noisy logs by first building a classifier on a subset of the log, and applying the classifier rules to remove noisy traces from the log. The improvement in the quality of the resulting process models is evaluated on synthetic logs from benchmark models of increasing complexity on both behavioral and structural recall and precision metrics. The results show that mined models produced from such preprocessed logs are superior on several evaluation metrics. They show better fidelity to the reference models, and are also more compact with fewer elements. A nice feature of the rule based approach is that it generalizes to any noise pattern since the nature of noise varies from one log to another. The rules can also be explained and may be further modified manually. We also give results from experiments with a real dataset.  2015 Elsevier B.V. All rights reserved. Benchmarking; Log sanitization; Metrics; Noisy data; Process mining; Rules

Activity failure prediction based on process mining Based on the state of the art of process mining, we can conclude that quality characteristics (failure rate metrics or loops) are poorly represented or absent in most predictive models that can be found in the literature. The main goal of this present research work is to analyze how to learn prediction model defining failure as response variable. A model of this type can be used for active real-time-controlling (e. g. through the reassignment of workflow activities based on prediction results) or for the automated support of redesign (i.e., prediction results are transformed in software requirements used to implement process improvements). The proposed methodology is based on the application of a data mining process because the objective of this work can be considered as a data mining goal.  2015 IEEE. Business Process Management; Data mining; Process mining; Supervised learning; Workflow management software

Supporting Knowledge-Intensive Processes through Integrated Task Lifecycle Support The operational support of knowledge-intensive business processes constitutes a big challenge. In particular, these processes are driven by knowledge workers utilizing their skills, experiences, and expertise. Regarding coordination and synchronization, in turn, knowledge workers still rely on simple task lists (e.g., To-do lists or checklists) and established communication software (e.g., email). While these means are prevalent and intuitive, they are ineffective and error-prone as well. Neither tasks are made explicit, synchronized, personalized, nor are they independent from media breaks. Most important, a task management lifecycle is not provided, i.e., The efforts and knowledge invested by the knowledge workers in task management are not preserved for comparable future endeavors. This work introduces the pro Collab approach proposing a systematic and lifecycle-based task management support for knowledge workers. To establish a sound task management lifecycle, in particular, we apply process mining to analyze knowledge workers' changes applied to task lists in order to derive optimizations task list templates. To demonstrate feasibility and benefits, a proof-of-concept prototype was developed and applied. Overall, the integrated, systematic and lifecycle-based task management support is prerequisite for the effective IT support of KiBPs.  2015 IEEE. adaptive case management; checklists; knowledge workers; knowledge-intensive business process; process mining; task management; to-do lists

Diabetes care related process modelling using Process Mining techniques. Lessons learned in the application of Interactive Pattern Recognition: Coping with the Spaghetti Effect Diabetes is one of the metabolic disorders with more growth expectations in next decades. The literature points to a correct self-management, to an appropriate treatment and to an adequate healthy lifestyle as a way to dramatically improve the quality of life of patients with diabetes. The implementation of a holistic diabetes care system, using rising information technologies for deploying cares based on the thesis of the Evidence-Based Medicine can be a effective solution to provide an adequate and continuous care to patients. However, the design and deployment of computer readable careflows is not a easy task. In this paper, we propose the use of Interactive Pattern Recognition techniques for the iterative design of those protocols and we analyze the problems of using Process Mining to infer careflows and how to how to cope with the resulting Spaghetti Effect.  2015 IEEE. 

The use of process mining in business process simulation model construction structuring the field The paper focuses on the use of process mining (PM) to support the construction of business process simulation (BPS) models. Given the useful BPS insights that are available in event logs, further research on this topic is required. To provide a solid basis for future work, this paper presents a structured overview of BPS modeling tasks and how PM can support them. As directly related research efforts are scarce, a multitude of research challenges are identified. In an effort to provide suggestions on how these challenges can be tackled, an analysis of PM literature shows that few PM algorithms are directly applicable in a BPS context. Consequently, the results presented in this paper can encourage and guide future research to fundamentally bridge the gap between PM and BPS.  Springer Fachmedien Wiesbaden 2015. Business process simulation; Event log knowledge; Process mining; Simulation model construction

Multilevel Process Mining for Financial Audits The relevance of business intelligence increases with the growing amount of recorded data. The research on business intelligence has led to a mature set of methods and tools that are used in many application areas, but they are almost absent in the auditing industry. Public accountants face the challenge to audit increasingly complex business processes that process huge amounts of transaction data. Process mining can be used as a business intelligence approach in the context of process audits to exploit this data. We introduce a process mining algorithm to improve such audits. Key requirements for this purpose are the reliability of the mining results, the integration of a data flow perspective and the ability to inspect data from the point of origin to the final output on the financial accounts. The presented algorithm integrates the control flow and data flow perspective. It operates on different abstraction levels to enable the auditor to follow the audit trail. The algorithm creates precise and fitting process models to prevent false negative and false positive audit results, accepts specific unlabeled event logs as input, and considers data relationships for inferring the control flow. It was evaluated by using extensive real world data.  2008-2012 IEEE. Business Intelligence (BI); Business Process Intelligence; Business Process Modeling; Data Analysis; Data Mining; Design Science Research; ERP Systems; Financial Audits; Process Mining

Discovering Interacting Artifacts from ERP Systems Enterprise Resource Planning (ERP) systems are widely used to manage business documents along a business processes and allow very detailed recording of event data of past process executions and involved documents. This recorded event data is the basis for auditing and detecting unusual flows. Process mining techniques can analyze event data of processes stored in linear event logs to discover a process model that reveals unusual executions. Existing approaches to obtain linear event logs from ERP data require a single case identifier to which all behavior can be related. However, in ERP systems processes such as Order to Cash operate on multiple interrelated business objects, each having their own case identifier, their own behavior, and interact with each other. Forcing these into a single case creates ambiguous dependencies caused by data convergence and divergence which obscures unusual flows in the resulting process model. In this paper, we present a new semi-automatic, end-to-end approach for analyzing event data in a plain database of an ERP system for unusual executions. More precisely, we identify an artifact-centric process model describing the business objects, their life-cycles, and how the various objects interact along their life-cycles. This way, we prevent data divergence and convergence. We report on two case studies where our approach allowed to successfully analyze processes of ERP systems and reliably revealed unusual flows later confirmed by domain experts.  2008-2012 IEEE. Artifact-Centric Processes; ERP Systems; Log Conversion; Outlier Detection; Process Discovery; Relational Data

Event Correlation Analytics: Scaling Process Mining Using Mapreduce-Aware Event Correlation Discovery Techniques This paper introduces a scalable process event analysis approach, including parallel algorithms, to support efficient event correlation for big process data. It proposes a two-stages approach for finding potential event relationships, and their verification over big event datasets using MapReduce framework. We report on the experimental results, which show the scalability of the proposed methods, and also on the comparative analysis of the approach with traditional non-parallel approaches in terms of time and cost complexity.  2008-2012 IEEE. correlation discovery; distributed computing; Event analytics; MapReduce; Process mining

Bayesian network construction from event log for lateness analysis in port logistics The handling of containers in port logistics consists of several activities, such as discharging, loading, gate-in and gate-out, among others. These activities are carried out using various equipment including quay cranes, yard cranes, trucks, and other related machinery. The high inter-dependency among activities and equipment on various factors often puts successive activities off schedule in real-time, leading to undesirable activity down time and the delay of activities. A late container process, in other words, can negatively affect the scheduling of the following ones. The purpose of the study is to analyze the lateness probability using a Bayesian network by considering various factors in container handling. We propose a method to generate a Bayesian network from a process model which can be discovered from event logs in port information systems. In the network, we can infer the activities' lateness probabilities and, sequentially, provide to port managers recommendations for improving existing activities.  2014 Elsevier Ltd. Bayesian network; Container workflow; Port logistics process; Process mining

Processes Meet Big Data: Connecting Data Science with Process Science As more and more companies are embracing Big data, it has become apparent that the ultimate challenge is to relate massive amounts of event data to processes that are highly dynamic. To unleash the value of event data, events need to be tightly connected to the control and management of operational processes. However, the primary focus of Big data technologies is currently on storage, processing, and rather simple analytical tasks. Big data initiatives rarely focus on the improvement of end-to-end processes. To address this mismatch, we advocate a better integration of data science, data technology and process science. Data science approaches tend to be process agonistic whereas process science approaches tend to be model-driven without considering the 'evidence' hidden in the data. Process mining aims to bridge this gap. This editorial discusses the interplay between data science and process science and relates process mining to Big data technologies, service orientation, and cloud computing.  2008-2012 IEEE. Big Data; Cloud Computing; Data Science; Process Mining; Process Science; Service Orientation

Towards Traditional Simulation Models of Context Using Process Mining Context (sensor) systems are hard to model: they require constant updating and insightful approaches, especially considering the increasing data volume, variety, and generation rate of contemporary networking paradigms, like the Internet of Things. In this paper, we argue that intelligent process models can be mined to look at the actual system activity from alternative context perspectives, i.e., Perspectives observable from the sensor attributes themselves. We explain how the close relationship between the models derived using Process Mining, and Event-Driven Simulation can be exploited to help not only better understand what is happening in such systems but also provide alternative models for the intelligent solutions they support, such as context inference. We demonstrate this using a real-world example and discuss the feasibility of extending these alternative process models to be viewed as simulation. We envision automated steps that would result in traditional simulation models of context using Process Mining.  2015 IEEE. Context-aware computing; Performance modelling; Process Mining

A visual analytics approach to understanding care process variation and conformance With greater pressures of providing high-quality care at lower cost due to a changing financial and policy environment, the ability to understand variations in care delivery and associated outcomes and act upon this understanding is of critical importance. Building on prior work in visualizing healthcare event sequences and in collaboration with our clinical partner, we describe our process in developing a multiple, coordinated visualization system that helps identify and analyze care processes and their conformance to existing care guidelines. We demonstrate our system using data of 5,784 pediatric emergency department visits over a 13-month period for which asthma was the primary diagnosis.  2015 Copyright held by the owner/author(s). Conformance; Health informatics; Information visualization; Pediatric emergency medicine; Visual analytics; Visual process mining

When experts collaborate: Sharing search and domain expertise within an organization Data about how individuals explore an information space and collect facts about their topic of interest is valuable to analyze but difficult to come by. In this paper we outline how this data can be captured in a search task with the help of a special search environment. Domain experts sharing this data in an organization can enhance their collaborative search experience and bene t from each others' search and domain expertise. Our approach facilitates interaction mechanisms of an interface and data mining methods. We also lay out a business process where the system is applied.  2015 ACM. Collaborative Search; CSCW; Knowledge Graph; Topic Graphs

Process mining for knowledge-intensive business processes In recent years, investigating opportunities to support knowledgeintensive business processes has gained increasing momentum in the research community. Novel contributions that introduce paradigms addressing the need for process execution flexibility form an alternative to traditional workflow management approaches and are mostly subsumed under the concept of adaptive case management (ACM). However, many of these approaches omit mining any kind of knowledge about such processes. This is because there is a gap between process mining, which works well for structured processes, and ACM, which mainly focuses on information system support for task management and collaboration using heterogeneous data sources. In this paper, we strive to bridge this gap by introducing a method for mining knowledge-intensive processes. It is part of agendadriven case management, an ACM approach that follows the idea of mining common execution patterns while a case manager handles a flexible agenda.  2015 ACM. Case Management; Knowledge Discovery; Process Mining; Recommender Systems.

Toward an Anonymous Process Mining Process mining is a modern family of techniques applied to datasets generated from business processes run in organizations, in order to improve and obtain useful insights and performance measurements on the processes themselves (with clear societal and economical benefits). While these techniques are very promising in understanding business processes, their complete and efficient implementation inside the organizations is often not possible. Hence, in a way similar to what is done for most non core activities, and in particular for most ICT services, companies evaluate the possibility of outsourcing such task. However, the confidentiality of the dataset related to the business processes are often key assets for most of modern companies. Then, in order to avoid threats that might come from disclosing such information, most companies decide not to benefit from these process mining techniques. In this work, we propose a possible approach toward a complete solution which allows outsourcing of Process Mining without thwarting the confidentiality of the dataset and processes. Furthermore, we provide a prototype implementation of our proposed approach and run several experiments that confirmed the feasibility of our approach. We believe the one highlighted in this paper is an important direction to work on, in order to remove the obstacles that prevent companies to fully benefit from outsourcing process mining.  2015 IEEE. Anonymization; Data extraction; Privacy; Process mining

RTLS-based Process Mining: Towards an automatic process diagnosis in healthcare Log files constitute the main data source required to be able to use a Process Mining tool. As soon as an information system enables to record events corresponding to activity changes, it is rather simple and rapid to completely and automatically model a process. In numerous fields, information systems do not record events enough detailed. Therefore the model obtained with Process Mining will not be accurate and detailed enough for further analysis. In this article, we are interested in modeling with Process Mining patient pathways in an external consulting service of a hospital center. Apart from recording patients at the front desk and when they are leaving, the information system does not collect enough events in order to manage to model in details the different patient pathways. As a result, the model must be realised with successive observations, interviews and manual collects. This work often represents a significant workload without ensuring data quality and representativeness. To resolve this issue we suggest using a Real Time Location System (RTLS) that enables to automatically record events according to patient locations in the service. The log file obtained can contain the pathway tracks followed by the patients with enough details to precisely rebuild the process with Process Mining. This article is intended for users, for diagnosis experts who will be able to realise an accurate diagnosis and then propose improvements. This article deals with our on-going work through a real case study.  2015 IEEE. 

Discovery of patient pathways from a national hospital database using process mining and integer linear programming The analysis of patient pathways from event log is gaining importance in the field of medical information. It provides deep insights about the care process and the ways to improve it. This paper combines optimization and process mining. A new Integer Linear Programming model is proposed to discover the care process at a macroscopic scale from a large-size database. When dealing with health-care data, the main challenge to overcome is the considerable variability of patients' behaviors. An original size constraint and an aggregation method are used to create simple but significant process models. The results of a case study on heart failures confirm the ability of the approach to reveal the process information behind the data.  2015 IEEE. 

Application process mining techniques to optimize the business process models based on information systems issuing licenses and permits e-license: Practical research The proposed models of representations of event logs which are formed by the information system e-license, further Information System (IS) provides the issuance of licenses and permits. When process management generated event logs reflect the steps involved in business processes in the system and in functional management-implementation of certain functions of IS. The proposed models of log create an opportunity to build new models of business processes with process mining techniques based on the processing of structured event logs.  2015 The Society of Instrument and Control Engineers-SICE. data analysis; event log analysis; extraction processes; process analysis; Process Mining

Associating event logs with ontologies for semantic process mining and analysis Process mining uses various forms of event logs to extract process-related information, in order to discover, analyze conformance, or to enhance (business) processes. The vast majority of process mining applications are based on event logs with flat, keyword-based activity and resource descriptions. Many human-designed processes, however, are based on explicit workflow or lifecycle models with associated product models, both of which can be described using taxonomies or more complicated ontologies. This additional information can be used to analyze and visualize the processes with better insight of and improved formal access to the data. In this paper, we introduce a generic approach for enriching process mining using events logs with associated ontology structures. The main contribution and benefit of this approach lies in the ability to analyze the models in different abstraction levels, which greatly helps understanding complicated processes. Our main application areas are related to engineering and documentation processes. Event logs; Maintenance analysis; Ontologies; Process mining

Evaluation of the online assessment test using process mining (Case Study: Intensive English Center) One process in e-learning is Online Assessment Test which is aimed to determine students' understanding of the materials. Online Assessment Test is usually using Multiple Choice Questions (MCQ). Students are not always answer MCQ sequentially, so that each student can have navigational pattern, which can be different from the predefined navigational model. Different navigational patterns can result in different test performance too. This paper presents the process and result of implementing process mining to compare students answering patterns to the predetermined navigational model of MCQ in online assessment test. Process mining is being used to model the business process flow based on the event log of the information system. In this case, online assessment test is the business process and e-learning system is the information system being analyzed. The output of the process are the test marks, performance, students' strength and weakness, and the analysis of navigational patterns compared to the predefined navigational model.  2015 IEEE. e-learning; event log; online assessment test; process mining

Computer Supported ontology-based patent analysis considering business processes and strategic patent portfolio management Two approaches are frequently used to study the critical technology and market trends of industry. One analyzes the business processes from the market perspective with statistics market survey. The other perspective predicts new technologies from the patent (intellectual property) data. Business process analysis is limited to analyzing existing technologies and market applications. Since the service delivery processes are not frequently linked to the intellectual property of the underlying technologies, applying a patent perspective enables the analysis of technology trends, technology ownership, and royalty payment analysis. These data are used to illustrate the technology life cycles, predict emerging trends, and identify research opportunities with Computer Supported tools. Patent analysis enables the predictions of technology trends but poorly links the technology to actual products for market adoption cause of the large amount of the data. This research develops an innovative computer supported approach for technology analysis combining both market and patent perspectives. The business processes of a given knowledge domain, driven by the market perspective, is analyzed to build the basis of the domain's ontology. Afterward, the key phrases of the business processes are added to form the ontology schema. The related patents are then systematically linked to the business process schema nodes. The research approach enables the business process-oriented patent portfolios among current and potential competitors to be mapped and critically compared from both market performance and technology ownership perspectives. The methodology allows in-depth integrated views of rivals' patenting and business development for strategic R and D management. The case of InvisalignTM innovative orthodontic services and the patent portfolio is studied to demonstrate the proposed methodology.  2015 IEEE. business process modeling; keyword frequency analysis; Ontology; patent analysis; text mining

Big software on the run: In vivo software analytics based on process mining (Keynote) Software-related problems have an incredible impact on society, organizations, and users that increasingly rely on information technology. Specification, verification and testing techniques aim to avoid such problems. However, the growing complexity, scale, and diversity of software complicate matters. Since software is evolving and operates in a changing environment, one cannot anticipate all problems at design-time. Hence, we propose to analyze software "in vivo", i.e., we study systems in their natural habitat rather than through testing or software design. We propose to observe running systems, collect and analyze data on them, generate descriptive models, and use these to respond to failures. We focus on process mining as a tool for in vivo software analytics. Process discovery techniques can be used to capture the real behavior of software. Conformance checking techniques can be used to spot deviations. The alignment of models and real software behavior can be used to predict problems related to performance or conformance. Recent developments in process mining and instrumentation of software make this possible. This keynote paper provides pointers to process mining literature and introduces the "Big Software on the Run" (BSR) research program that just started. Conformance checking; Event logs; Process discovery; Process mining; Software analytics; Software engineering

A process mining approach to measure how users interact with software: An industrial case study Characterizing how users interact with software has many applications. For example, to understand which features are used, in which sequence operations are performed, etc. can help to understand how the user interface could be improved, to identify missing features, or to identify scenarios which are good candidates for test cases. This paper presents an industrial case study in which we investigate how users interact with an enterprise resource planning software using process mining. Our case study illustrates how we identify user interaction processes, the encountered advantages, and the faced challenges. One of the major findings is that the decision how to group events into cases is crucial for the application of the method.  2015 ACM. Process mining; User interaction analysis

Observation and mitigation of causal re-ordering in distributed business process logs Cloud computing provides enhanced collaboration opportunities, but auditing business activities in workflows has become more difficult in a distributed, cloud-based system. The fundamental issue stems from timestamp inaccuracy in event logs. Tools that analyze logs for causal relationships are ineffective, yielding products that can neither capture invariant execution, nor perform conformance checking to check workflow health. Therefore, we offer the Flower Chain Net (FCN), a new Petri net that reduces concurrency and improves conformance checking. To build FCN, we provide the Flower Chain Discovery Algorithm. FCN is evaluated for structural expressiveness, efficiency, and behavioral analysis traits against widely employed methods.  2015 IEEE. Collaboration and Cloud Computing; Process Mining; Workflows in Collaborative Operations & Systems

Business activity monitoring solution to detect deviations in business process execution Current paper proposes a custom solution for detecting deviations in process execution by analyzing event logs of running cases. The monitored business processes are extracted with process mining techniques. The behavior of the current alert system is illustrated on a case study, the event process logs resulted from the execution of a software development process used in the IT department of a large automotive company. Enhancing the level of control in project management activities, improving the business process execution by detecting deviations in real time and helping organizations to perform better by providing guidance to the people during task execution are the main reasons for designing the current solution. The statistical information about detected deviations represents the input for an analysis phase having as major scope business process improvements. The alert system was designed as a Web based application and is presented as a Business Activity Monitoring solution operating with process mining concepts.  2015 IEEE. business activity monitoring; operational support; process mining

Business process similarity metric supporting one-To-many relationship In many areas graph match techniques are used to compare and identify common characteristics. In this paper we apply graph similarity techniques on the business processes used inside organizations and extracted with process mining techniques. The scope is to identify if an organization uses a similar process for a specific business case as another organization. However as the existence of exact matching is less probable, error tolerant graph matching techniques are more suitable for real life data. Business processes could have a different granularity level; one business process is more detailed in specific areas than the business process subject of the comparison. The custom algorithm for business process match presented in this paper takes into consideration a one-To-many relation for activities: one activity is matched with a set of activities in the other graph. Such information is important in extracting the common characteristics of organizations and could represent an input for choosing a collaborator. Business processes if not available are extracted with process mining techniques and are reduced to directed graph format. A custom graph similarity algorithm extended for multivalent nodes is applied and a business process similarity factor is retrieved.  2015 IEEE. business proces similarity; graph match; process mining

An Effective Process Mining Approach against Diverse Logs Based on Case Classification Since real-life processes tend to be much flexible because of the ever changing circumstances, there is a lot of diversity in logs leading to complex models which may contain various kinds of complex control-flow structures. However, every mining algorithm has its pros and cons, so there is not a general algorithm which is capable to handle diverse logs. In this paper, we propose a general process mining approach, which first deals with the diversity issue by classifying the cases into sets of categories (sub logs). Next, multiple process miners take these sub logs as input to produce sets of process models. Then, a genetic algorithm (GA) based optimizer taking these process models as parts of initial population aggregates appropriate process fragments into the entire process model with the balance of four quality dimensions. Experiments on synthetic and real-life logs from a telecommunication giant demonstrate the effectiveness of our approach.  2015 IEEE. case classification; genetic algorithm; process mining; process optimizer

Towards Automating Inter-organizational Workflow Semantic Resolution Interoperability in sharing work through services between organizations requires understanding the perspective of each partner. Available resources and requirements are widely distributed with heterogeneous descriptions and enactments. No centralized registration and discovery process exists, nor automated means to map the variety of formal organizations within various overlapping domains, some defined and many not. While drawing from a common language, the mission and culture of each organization shapes their particular collection and definition of symbols, vocabulary and signals. Mining execution logs of historical inter-organizational workflows and tapping into explicitly specified domain and organizational knowledge ontologies provides a corpus of information useful to identify emergent patterns. This paper proposes a novel mediator approach using feature alignment demonstrated in previous partnerships, identified through the employment of topic modeling and word sense disambiguation methods, to infer semantic matches between parties without a priori relationships. This model demonstrates an inter-organizational workflow middleware proof of concept coupling workflow management systems interoperating between a set of organizations to automatically resolve meaning, providing the right services for requirements.  2015 IEEE. Business process mining; Discovery; Inter-organizational workflow; Semantic resolution; Service identification

Conformance Checking of Communicating Resource Systems with RAs Calculus The article tackles the problem of conformance checking of communicating resource systems, such as hierarchical distributed systems, Restful Web services, ROA systems, etc. We present a framework, consisting of methods and algorithms, which allows to check whether a system's behavior, as derived from logs, conforms to its ideal model (derived from APIs and specifications). We define several system properties and present how they can be verified using our approach. To express the model formally, as well as minimize representational bias, we introduce RAs process calculus, a formal language specifically designed to model communicating resource systems.  2015 IEEE. Conformance checking; Formal modeling; Process calculus; Process mining; REST

Enriched content mining for web applications In recent years, it has been witnessed that the ever-interesting and upcoming publishing medium is the World Wide Web. Much of the web content is unstructured so gathering and making sense of such data is very tedious. Web servers worldwide generate a vast amount of information on web users' browsing activities. Several researchers have studied these so-called web access log data to better understand and characterize web users. Data can be enriched with information about the content of visited pages and the origin (e.g., geographic, organizational) of the requests. The goal of this project is to analyze user behavior by mining enriched web access log data. The several web usage mining methods for extracting useful features is discussed and employ all these techniques to cluster the users of the domain to study their behaviors comprehensively. The contributions of this thesis are a data enrichment that is content and origin based and a treelike visualization of frequent navigational sequences. This visualization allows for an easily interpretable tree-like view of patterns with highlighted relevant information. The results of this project can be applied on diverse purposes, including marketing, web content advising, (re-)structuring of web sites and several other E-business processes, like recommendation and advertiser systems. It also rank the best relevant documents based on Top K query for effective and efficient data retrieval system. It filters the web documents by providing the relevant content in the search engine result page (SERP).  2015 IEEE. Data-based approach; SERP; Top K-query; Web mining; World Wide Web

What is the state of the art in self-, co- and socially shared regulation in CSCL? Abstract Articles in this special issue on regulation of learning in computer-supported collaborative learning apply tools across the spectrum of qualitative and quantitative methods to investigate self-, co- and socially shared regulation of learning. As well, a careful consideration of each of these constructs is provided. I briefly review these contributions to identify unique and forward-looking approaches to research in this vibrant area of research. A particular opportunity is recommended for future research regarding the use of process mining, sequence mining, social network analysis and an as-yet to be invented amalgam of these methods in constructing intelligent software agents that could guide participants in CSCL to assemble an optimum mix of self-, co- and socially shared regulation of learning.  2015 Elsevier Ltd. 

Recovering Workflows from Functional Tests When enterprises outsource maintenance of IT systems to service providers, thorough knowledge acquisition is critical to the success of the engagement. Program comprehension contributes significantly to acquiring knowledge of the IT systems. It is a common practice to execute test scripts to identify critical scenarios in the system and then trace these as flows in the programs. Instead of executing test scripts, we propose the novel idea of mining workflows from test scripts to construct formal process models. The global view provided by the mined model can not only help transition teams gain high level understanding of the system but also help identify critical flows. We also suggest categorization of test cases using supervised learning to improve comprehension.  2015 IEEE. Knowledge Acquisition; Process Mining; Program Comprehension; Test Script

Identifying software process management challenges: Survey of practitioners in a large global IT company Process mining consists of mining event logs generated from business process execution supported by Information Systems (IS). Process mining of software repositories has diverse applications because vast data is generated during Software Development Life Cycle (SDLC) and archived in IS such as Version Control System (VCS), Peer Code Review (PCR) System, Issue Tracking System (ITS), and mail archives. There is need to explore its applications on different repositories to aid managers in process management. We conduct two phase surveys and interviews with managers in a large, global, IT company. The first survey and in-person interviews identify the process challenges encountered by them that can be addressed by novel applications of process mining. We filter, group and abstract responses formulating 30 generic problem statements. On the basis of process mining type, we classify identified problems to eight categories such as control analysis, organizational analysis, conformance analysis, and preventive analysis. The second survey asks distinct participants the importance of solving identified problems. We calculate proposed Net Importance Metric (NIM) using 1262 ratings from 43 participants. Combined analysis of NIM and first survey responses reveals that the problems mentioned by few practitioners in first survey are considered important by majority in the second survey. We elaborate on possible solutions and challenges for most frequent and important problems. We believe solving these validated problems will help managers in improving project quality and productivity.  2015 IEEE. Process Mining; Qualitative Study; Software Development Life Cycle; Software Repositories

Fusion Miner: Process discovery for mixed-paradigm models The research area of business process mining has vastly matured in recent years. Its main focus centers around the extraction and analysis of process models from event logs. A strong emphasis lies on the automatic discovery of models for which numerous algorithms have been proposed already. So far, most discovery algorithms were limited to the derivation of single-paradigm models, which contain either procedural or declarative constructs, targeting the mining of strict and flexible processes respectively. This paper proposes the first fully-automated mining technique to discover procedural workflows combined with Declare templates to capture processes that are difficult to mine with only a single paradigm, e.g., workflows with different layers of flexibility. This approach provides process analysts with new discovery capabilities, including the retrieval of better fitting and more precise models with high comprehensibility. The main contribution consists of the Fusion Miner algorithm, which has been implemented in the process mining framework ProM as a plug-in.  2015 Elsevier B.V. All rights reserved. Business process mining; Declare; Workflow models

Vishleshan: Performance comparison and programming process mining algorithms in graph-oriented and relational database query languages Process-Aware Information System (PAIS) are IT systems that manages, supports business processes and generate large event logs from execution of business processes. Process Mining consists of analyzing event logs generated by PAISs and discover business process models and check for conformance between the discovered and actual models. The large volume of event logs generated are stored in databases. Relational databases perform well for certain class of applications. However, there are certain class of applications for which relational databases are not able to scale. Several NoSQL databases have emerged to encounter the challenges of scalability in traditional databases. Discovering social network from event logs is one of the most challenging and important Process Mining task. Similar-Task algorithm is one of the most widely used Organizational Mining techniques. Our objective is to investigate which of the databases (Relational or Graph) perform better for Organizational Mining under Process Mining. We implement Similar-Task algorithm on relational and NoSQL (graph oriented) databases using only query language constructs. We conduct empirical analysis on a large real world data set to compare the performance of row-oriented database and NoSQL graph-oriented database.  2015 ACM. Benchmarking; CYPHER; Graph databases; MySQL; Neo4j; Organizational mining; Performance comparison; Process mining; Relational databases; SQL

Pragamana: Performance comparison and programming alpha-miner algorithm in relational database query language and NoSQL column-oriented using apache phoenix Process-Aware Information Systems (PAIS) is an IT system that support business processes and generate large amounts of event logs from the execution of business processes. An event log is represented as a tuple of CaseID, Timestamp, Activity and Actor. Process Mining is a new and emerging field that aims at analyzing the event logs to discover, enhance and improve business processes and check conformance between run time and design time business processes. The large volume of event logs generated are stored in the databases. Relational databases perform well for a certain class of applications. However, there are a certain class of applications for which relational databases are not able to scale. To handle such class of applications, NoSQL database systems emerged. Discovering a process model (workow model) from event logs is one of the most challenging and important Process Mining task. The a-miner algorithm is one of the first and most widely used Process Discovery technique. Our objective is to investigate which of the databases (Relational or NoSQL) performs better for a Process Discovery application under Process Mining. We implement the a-miner algorithm on relational (row-oriented) and NoSQL (column-oriented) databases in database query languages so that our algorithm is tightly coupled to the database. We present a performance benchmarking and comparison of the a-miner algorithm on row-oriented database and NoSQL column-oriented database so that we can compare which database can efficiently store massive event logs and ana- lyze it in seconds to discover a process model.  2015 ACM. Apache hadoop; Apache HBase; Apache phoenix; Column-oriented database; Hadoop Distributed File System (HDFS); MySQL; Process mining; Row-oriented database

Diversity guided evolutionary mining of hierarchical process models Easy-to-understand and up-to-date models of business processes are important for enterprises, as they aim to describe how work is executed in reality and provide a starting point for process analysis and optimization. With an increasing amount of event data logged by information systems today, the automatic discovery of process models from process logs has become possible. Whereas most existing techniques focus on the discovery of well-formalized models (e.g. Petri nets) which are popular among researchers, business analysts prefer business domain-specific models (such as Business Process Model Notation, BPMN) which are not well formally specified. We present and evaluate an approach for discovering the latter type of process models by formally specifying a hierarchical view on business process models and applying an evolution strategy on it. The evolution strategy efficiently finds process models which best represent a given event log by using fast methods for process model conformance checking, and is partly guided by the diversity of the process model population. The approach contributes to the field of evolutionary algorithms by showing that they can be successfully applied in the real-world use case of process discovery, and contributes to the process discovery domain by providing a promising alternative to existing methods.  2015 Copyright held by the owner/author(s). Business process management; Evolutionary algorithms; Population diversity; Process mining

From process mining to process design: A simulation model to reduce conformance risk An operators mistakes are frequently attributed to inexperience, which leads to a superficial management of these kinds of accidental errors. The weakness of this traditional approach is that it isolates the wrong actions from the general systematic context, overlooking potential learning from error analysis. Modern approaches push organisations to prevent the occurrence of errors and, if necessary, to start recovery operations. The methodology proposed in this paper is aimed precisely at this second type of approach. There is a growing need for systems that show errors or deviations from the desired state of the system, leading operators towards the proper execution of tasks and reducing conformance risk. This paper presents a methodology and a simulation model of Conformance Risk Aware Design in order to support decision-makers in modelling business processes.  2015, Newswood Ltd. All rights reseved. BPM; BPMN; Business process modelling; Compliance checking; Simulation; System dynamics

Queue mining for delay prediction in multi-class service processes Information systems have been widely adopted to support service processes in various domains, e.g., in the telecommunication, finance, and health sectors. Information recorded by systems during the operation of these processes provides an angle for operational process analysis, commonly referred to as process mining. In this work, we establish a queueing perspective in process mining to address the online delay prediction problem, which refers to the time that the execution of an activity for a running instance of a service process is delayed due to queueing effects. We present predictors that treat queues as first-class citizens and either enhance existing regression-based techniques for process mining or are directly grounded in queueing theory. In particular, our predictors target multi-class service processes, in which requests are classified by a type that influences their processing. Further, we introduce queue mining techniques that derive the predictors from event logs recorded by an information system during process execution. Our evaluation based on large real-world datasets, from the telecommunications and financial sectors, shows that our techniques yield accurate online predictions of case delay and drastically improve over predictors neglecting the queueing perspective.  2015 Elsevier Ltd. All rights reserved. Delay prediction; Process mining; Queue mining; Queueing theory

Model repair of Time Petri nets with temporal anomalies In this paper the model repair of Time Petri net models with temporal anomalies is considered assuming that the nominal model is known and an observed timed sequence is given. The nominal model is updated online, if the durations of system activities change while their initial instant does not, without modifying the structure of the PN nominal model but just extending the firing interval of transitions. The approach requires the solution of a Mixed-Integer Linear Programming.  2015, IFAC (International Federation of Automatic Control) Hosting by Elsevier Ltd. All rights reserved. Discrete event systems; Identification; Process mining; Time Petri nets

A knowledge-intensive approach to process similarity calculation Process model comparison and similar processes retrieval are key issues to be addressed in many real world situations, and particularly relevant ones in some applications (e.g., in medicine), where similarity quantification can be exploited in a quality assessment perspective. Most of the process comparison techniques described in the literature suffer from two main limitations: (1) they adopt a purely syntactic (vs. semantic) approach in process activity comparison, and/or (2) they ignore complex control flow information (i.e., other than sequence). These limitations oversimplify the problem, and make the results of similarity-based process retrieval less reliable, especially when domain knowledge is available, and can be adopted to quantify activity or control flow construct differences. In this paper, we aim at overcoming both limitations, by introducing a framework which allows to extract the actual process model from the available process execution traces, through process mining techniques, and then to compare (mined) process models, by relying on a novel distance measure. The novel distance measure, which represents the main contribution of this paper, is able to address issues (1) and (2) above, since: (1) it provides a semantic, knowledge-intensive approach to process activity comparison, by making use of domain knowledge; (2) it explicitly takes into account complex control flow constructs (such as AND and XOR splits/joins), thus fully considering the different semantic meaning of control flow connections in a reliable way. The positive impact of the framework in practice has been tested in stroke management, where our approach has outperformed a state-of-the art literature metric on a real world event log, providing results that were closer to those of a human expert. Experiments in other domains are foreseen in the future.  2015 Elsevier Ltd. All rights reserved. Graph edit distance; Process comparison; Process mining; Stroke management

Business process management as the Killer App for Petri nets Since their inception in 1962, Petri nets have been used in a wide variety of application domains. Although Petri nets are graphical and easy to understand, they have formal semantics and allow for analysis techniques ranging from model checking and structural analysis to process mining and performance analysis. Over time Petri nets emerged as a solid foundation for Business Process Management (BPM) research. The BPM discipline develops methods, techniques, and tools to support the design, enactment, management, and analysis of operational business processes. Mainstream business process modeling notations and workflow management systems are using token-based semantics borrowed from Petri nets. Moreover, state-of-the-art BPM analysis techniques are using Petri nets as an internal representation. Users of BPM methods and tools are often not aware of this. This paper aims to unveil the seminal role of Petri nets in BPM.  2014, Springer-Verlag Berlin Heidelberg. Business process management; Petri nets; Process mining; Process modeling

Next step recommendation and prediction based on process mining in adaptive case management Adaptive Case Management (ACM) is a new paradigm that facilitates the coordination of knowledge work through case handling. Current ACM systems, however, lack support of providing sophisticated user guidance for next step recommendations and predictions about the case future. In recent years, process mining research developed approaches to make recommendations and predictions based on event logs readily available in process-aware information systems. This paper builds upon those approaches and integrates them into an existing ACM solution. The research goal is to design and develop a prototype that gives next step recommendations and predictions based on process mining techniques in ACM systems. The models proposed, recommend actions that shorten the case running time, mitigate deadline transgressions, support case goals and have been used in former cases with similar properties. They further give case predictions about the remaining time, possible deadline violations, and whether the current case path supports given case goals. A final evaluation proves that the prototype is indeed capable of making proper recommendations and predictions. In addition, starting points for further improvement are discussed. Copyright 2015 ACM. Adaptive case management; Business process management; Decision support; Process mining; Recommender systems

Using event logs and the ?-theory to analyse business processes The development of information technologies (IT) has increased the number of IT dependent business processes within organisations, enforcing the crucial role of IT in today's enterprise implementations. In spite of IT advances, human beings still constitute the most valuable asset of any enterprise and the cooperation between them is indispensable for the operation of business processes. Traditional business process modelling techniques have limitations regarding the acquisition process which is time-consuming and do not take fully advantage of IT to represent updated process models. Besides, these techniques are limited concerning the analysis and improvement of the resulting models. This paper proposes a method to analyse updated business processes in terms of the collaboration between the participant actor roles, taking into account the importance of IT and human beings at those processes. The method receives as input event logs extracted from the application and technological infrastructure that supports the business processes and combines techniques from both Process Mining and the ?-theory to analyse enterprise ontology models against the mined processes, detecting opportunities for business process reengineering. The method was applied to analyse a VPN access approval process within a national defence governmental institution. The evaluation was performed using the Osterle principles. Copyright 2015 ACM. Business process analysis; DEMO; Enterprise engineering; Process mining; ?-theory

Matching of events and activities - An approach based on behavioral constraint satisfaction Nowadays, business processes are increasingly supported by IT services that produce massive amounts of event data during the execution of a process. This event data can be used to analyze the process using process mining techniques to discover the real process, measure conformance to a given process model, or to enhance existing models with performance information. While it is essential to map the produced events to activities of a given process model for conformance analysis and process model annotation, it is also an important step for the straightforward interpretation of process discovery results. In order to accomplish this mapping with minimal manual effort, we developed a semi-automatic approach that maps events to activities using the solution of a corresponding constraint satisfaction problem. The approach extracts behavioral profiles from both the log and the model to build constraints to efficiently reduce the number of possible mappings. The evaluation with an industry process model collection and simulated event logs demonstrates the effectiveness of the approach and its robustness towards non-conforming execution logs. Copyright 2015 ACM. Business process intelligence; Constraint satisfaction; Event mapping; Process mining

Mining software development process variations Process tailoring aims to customize a software process to better suit the specific needs of an organization when executing a software project or due to a social context in which the process is inserted. Tailoring happens, in general, through variations in the process elements, such as activities, artifacts, and control flows. This paper aims to introduce a technique that uses process mining to uncover elements from the software process that are candidates for tailoring. The proposed approach analyzes the execution logs from several process instances that share a common standard process. As a result, execution traces that differ from the standard process flow are identified and assessed to uncover their variable elements. The proposed technique was evaluated with data extracted from a real software development scenario when a large system was under development for a set of Brazilian Federal Institutes of Education, Science and Technology. Copyright 2015 ACM. Process mining; Process tailoring; Software process; Variation

Mining processes with multi-instantiation Process mining, in particular discovering process models by mining event traces, is becoming a widely adopted practice. However, when the underlying process contains subprocesses which are instantiated multiple times in parallel, classical process mining techniques that assume a flat process are not directly applicable. Their application can cause one of two problems: either the mined model is overly general, allowing arbitrary order and execution frequency of activities in the sub-process, or it lacks fitness by capturing only single instantiation of sub-processes. For conformance checking, this results in a too high rate of either false positives or false negatives, respectively. In this paper, we propose an extension to well-known process mining techniques, adding the capability of handling multi-instantiated sub-processes to discovery and conformance checking. We evaluate the approach with a real-world data set. Copyright 2015 ACM. Conformance; Discovery; Multi-instantiation; Process mining

Editorial: Business Process intelligence: Connecting data and processes This introduction to the special issue on Business Process Intelligence (BPI) discusses the relation between data and processes. The recent attention for Big Data illustrates that organizations are aware of the potential of the torrents of data generated by today's information systems. However, at the same time, organizations are struggling to extract value from this overload of data. Clearly, there is a need for data scientists able to transform event data into actionable information. To do this, it is crucial to take a process perspective. The ultimate goal of BPI is not to improve information systems or the recording of data; instead the focus should be in improving the process. For example, we may want to aim at reducing costs, minimizing response times, and ensuring compliance. This requires a "confrontation" between process models and event data. Recent advances in process mining allow us to automatically learn process models showing the bottlenecks from "raw" event data. Moreover, given a normative model, we can use conformance checking to quantify and understand deviations. Automatically learned models may also be used for prediction and recommendation. BPI is rapidly developing as a field linking data science to business process management. This article aims to provide an overview thereby paving the way for the other contributions in this special issue.  2015 ACM. Business Process Intelligence; Compliance checking; Performance analysis; Process mining; Process modeling

Using declarative specification to improve the understanding, extensibility, and comparison of model-inference algorithms It is a staple development practice to log system behavior. Numerous powerful model-inference algorithms have been proposed to aid developers in log analysis and system understanding. Unfortunately, existing algorithms are typically declared procedurally, making them difficult to understand, extend, and compare. This paper presents InvariMint, an approach to specify model-inference algorithms declaratively. We applied the InvariMint declarative approach to two model-inference algorithms. The evaluation results illustrate that InvariMint (1) leads to new fundamental insights and better understanding of existing algorithms, (2) simplifies creation of new algorithms, including hybrids that combine or extend existing algorithms, and (3) makes it easy to compare and contrast previously published algorithms. InvariMint's declarative approach can outperform procedural implementations. For example, on a log of 50,000 events, InvariMint's declarative implementation of the kTails algorithm completes in 12 seconds, while a procedural implementation completes in 18 minutes. We also found that InvariMint's declarative version of the Synoptic algorithm can be over 170 times faster than the procedural implementation.  1976-2012 IEEE. API mining; declarative specification; inference comparison; inference extensibility; inference understanding; InvariMint kTails; Model inference; process mining; specification mining; synoptic

A process mining approach to linking the study of aptitude and event facets of self-regulated learning Research on self-regulated learning has taken main two paths: self-regulated learning as aptitudes and more recently, selfregulated learning as events. This paper proposes the use of the Fuzzy miner process mining technique to examine the relationship between students' self-reported aptitudes (i.e., achievement goal orientation and approaches to learning) and strategies followed in self-regulated learning. A pilot study is conducted to probe the method and the preliminary results are reported. Clustering; Learning Patterns; Process Mining; Self-Regulated Learning

A learning analytics approach to characterize and analyze inquiry-based pedagogical processes Here we describe the use of learning analytics (LA) for investigating inquiry-based science instruction. We define several variables that quantify curriculum usage and leverage tools from process mining to examine inquiry-based pedagogical processes. These are initial steps toward measuring and modeling fidelity of implementation of a science curriculum. We use data from one school district's use of an online science curriculum (N=1,021 teachers and nearly 330,000 page views).  Copyright 2015 ACM. Inquiry-Based Pedagogy; Learninformatics; Process Mining

Knowledge-Intensive Processes: Characteristics, Requirements and Analysis of Contemporary Approaches Engineering of knowledge-intensive processes (KiPs) is far from being mastered, since they are genuinely knowledge- and data-centric, and require substantial flexibility, at both design- and run-time. In this work, starting from a scientific literature analysis in the area of KiPs and from three real-world domains and application scenarios, we provide a precise characterization of KiPs. Furthermore, we devise some general requirements related to KiPs management and execution. Such requirements contribute to the definition of an evaluation framework to assess current system support for KiPs. To this end, we present a critical analysis on a number of existing process-oriented approaches by discussing their efficacy against the requirements.  2014, Springer-Verlag Berlin Heidelberg. Case management; Knowledge-intensive processes; Process flexibility; Process management systems; Process mining

Ahaan: Software process intelligence: Mining software process data for extracting actionable information Software Processes consist of a structured set of activities performed during creation and maintenance of software products. The construction and subsequent maintenance of a software is facilitated by several applications and tools. Some of the tools such as Issue Tracking System (ITS) and Version Control System (VCS) can be classified as Process Aware Information System (PAIS) logging data consisting of events, activities, time-stamp, user or actor and context specific information. Such events or trace data generated by information systems used during software construction (as part of the software development process) contains valuable information which can be mined for gaining useful insights and actionable information. Software Process Intelligence (SPI) is an emerging and evolving discipline involving mining and analysis of software processes. This is modeled on the lines of Business Process Intelligence (BPI), but with the focus on software processes and its applicability in software systems. In this paper, we present a generic framework for Software Process Intelligence and some of its applications. Copyright 2015 ACM. Automated software engineering; Business process intelligence (BPI); Mining software repositories; Process mining; Software process intelligence

Comparing concepts for shop floor control of information-processing services in a job shop setting: A case from the financial services sector Controlling information-based service processes in the short term is a major challenge. Within these processes, information is collected, generated and transformed while customers are directly involved. Typically, such processes are characterised by a job shop layout that increases complexity relating to shop floor control. In contrast to manufacturing, such settings have rarely been addressed in the literature to date. This is surprising, as information-processing services exist in every industry. Thus, evidence about the impact of concepts for shop floor control in such pure service environments is needed. As a case study, we use one of the most intense information-processing industries - the financial services sector. A simulation model is built using process mining as a novel approach to gather a major part of the relevant data from business information systems. We identify nine concepts for shop floor control and simulate the usage of these in six scenarios. The results show that the concept that prioritises customer orders with the longest expected processing time is superior in cycle time over all six scenarios. The application of this concept leads to a reduction of the average cycle time of almost 50% in the case study.  2014 Taylor & Francis. Business information systems; Process mining; Service operations; Shop floor control; Simulation application

ProDiGen: Mining complete, precise and minimal structure process models with a genetic algorithm Process discovery techniques automatically extract the real workflow of a process by analyzing the events that are collected and stored in log files. Although in the last years several process discovery algorithms have been presented, none of them guarantees to find complete, precise and simple models for all the given logs. In this paper we address the problem of process discovery through a genetic algorithm with a new fitness function that takes into account both completeness, precision and simplicity. ProDiGen (Process Discovery through a Genetic algorithm) includes new definitions for precision and simplicity, and specific crossover and mutation operators. The proposal has been validated with 39 process models and several noise levels, giving a total of 111 different logs. We have compared our approach with the state of the art algorithms; non-parametric statistical tests show that our algorithm outperforms the other approaches, and that the difference is statistically significant.  2014 Elsevier Inc. All rights reserved. Genetic mining; Petri net; Process discovery; Process mining

Efficient process discovery from event streams using sequential pattern mining Process mining is an emerging research area that applies the well-established data mining solutions to the challenging business process modeling problems. Mining streams of business processes in the real time as they are generated is a necessity to obtain an instant knowledge from big process data. In this paper, we introduce an efficient approach for exploring and counting process fragments from a stream of events to infer a process model using the Heuristics Miner algorithm. Our novel approach, called Str ProM, builds prefix-Trees to extract sequential patterns of events from the stream. Str ProM uses a batch-based approach to continuously update and prune these prefix-Trees. The final models are generated from those trees after applying a novel decaying mechanism over their statistics. The extensive experimental evaluation demonstrates the superiority of our approach over a state-of-The-Art technique in terms of execution time using a real dataset, while delivering models of a comparable quality.  2015 IEEE. 

Function-based case classification for improving business process mining In the last years business process mining has become a wide research area. However, existing process mining techniques encounter challenges while dealing with event logs stemming from highly flexible environments because such logs contain a large amount of different behaviors. As a result, inaccurate and wrong analysis results might be obtained. In this paper we propose a case (a case is an instance of the business process) classification technique which is able to combine domain experts knowledge for classifying cases so that each group is calculated containing the cases with similar behaviors. By applying existing process mining techniques on the cases for each group, more meaningful and accurate analysis results can be obtained. Business process extension; Business process mining; Multi-label case classification; Sequential pattern mining

Business process analysis using process mining in accommodation industry The development of information technology contributed to the advancement and growth of various industries and accordingly vast amounts of data are being generated by information systems. The generated data can be used to analyze materials of various industries. In this study, we propose a systematic approach for discovering and analyzing business process models using process mining in the small and medium accommodation industry. In the proposed approach, we can analyze event log data recorded by the existing information system, and consequently suggest a scheme for improving and complementing the existing operation system. Information systems of the small and medium accommodation industry in South Korea have been designed and developed by system developers or domain experts of the industry itself at the conceptual level. Considering the current situation where a new information system cannot be designed and developed with BPM (Business Process Management), this study can be recognized as an innovative attempt to apply the process mining technique to the small and medium accommodation industry. Managers in the industry can acquire not only implications on systematic improvement but also significant insights on marketing and operation plans.  2015, ICIC International. Accommodation industry; BPM; Business model; Process mining; Process model

Business process model extension with cost perspective based on process mining - Cost data description and analysis Organizations always look for enhancing their efficiency and competitiveness by improving their business processes. Business Process Management includes techniques allowing continuous business process improvement. Process mining is a mature technology allowing to extract knowledge from event logs commonly available in today's information systems. Business process model extension is a process mining technique covering different perspectives of the business process. Furthermore, financial cost incurred during business process execution is prominent information needed by decision makers to take the appropriate decisions for business process improvement in terms of cost reduction. We proposed a solution allowing Petri Net model extension with cost perspective based on process mining extension technique. With respect to the recommendations drawn from interviews with experts, we improved the proposed solution in order to enhance the provided decision making support. These improvements concern three main levels: cost data structure, cost data description and cost data analysis. However, Petri Nets are not used by all organizations as a modeling notation of their business processes. Therefore, there is a need for the generalization of the proposed solution so that it can be used in the context of business processes modeled with other notations. In this paper, we propose a cost extension of the High-Level Process Structure which is a meta-model allowing the integration of different perspectives of a business process into one model independently of its notation. Business Process Management; Business process model cost extension; Cost perspective; Process mining

Towards an extended metamodel of event-driven process chains to model complex event patterns This paper proposes an extension of the Event-driven Process Chain (EPC) metamodel in order to provide means to model complex event patterns within process models. There are some first attempts aiming to graphically depict such patterns; however, none of them focus EPC as a widely-used modeling language, especially in a business-related context. Thus, the paper first of all derives and defines typical complex event patterns and analyzes whether they are representable using standard EPC models. On this basis, a metamodel extension is conceived and additional modeling notations proposed. Finally, the notation is applied on two application examples.  Springer International Publishing Switzerland 2015. Business process management; Complex event processing; Event-driven business process management; Event-driven process chain; Metamodel

Static weaving in aspect oriented business process management Separation of concerns is an important topic in business process modelling that aims to reduce complexity, increase the re-usability and enhance the maintainability of business process models. Some concerns cross over several business processes (known as cross-cutting concerns), and they hinder current modularization techniques to encapsulate them efficiently. Aspect Oriented Business Process Modelling aims to encapsulate these concerns from business process models. Although many researchers proposed different aspect-oriented business process modelling approaches, there is no analysis technique to check these models in terms of soundness. Thus, this paper proposes a formal definitions and semantics for aspect-oriented business process models, and it enables the analysis of these models in terms of soundness at design time through defining a static weaving algorithm. The algorithm is implemented as an artefact that support weaving aspect-oriented business process models. The artefact is used to analyse different scenarios, and the result of analysis reveals the situations that can introduce different problems like deadlock. In addition, an example of such scenario is given that shows how the artefact can detect the problems at design time. Such analysis enables process modellers to discover the problems at design time, so the problems will not be left to be discovered at runtime - which apply a lot of costs to correct them.  Springer International Publishing Switzerland 2015. Aspect orientation; Business process modeling; Weaving

Design dimensions for business process architecture Enterprises employ an array of business processes (BPs) for their operational, supporting, and managerial activities. When BPs are designed to work together to achieve organizational objectives, we refer to them and the relationships among them as the business process architecture (BPA). While substantial efforts have been devoted to designing and analyzing individual BPs, there is little focus on BPAs. As organizations are undergoing changes at many levels, at different times, and at different rates, the BP architect needs to consider how to manage the relationships among multiple BPs. We propose a modeling framework for designing BPAs with a focus on representing and analyzing architectural choices along several design dimensions aimed at achieving various design objectives, such as flexibility, cost, and efficiency.  Springer International Publishing Switzerland 2015. Business process architecture; Goal modeling; Requirements

Experimenting with an OLAP approach for interactive discovery in process mining Business process analysts must face the task of analyzing, monitoring and promoting improvements to different business processes. Process mining has emerged as a useful tool for analyzing event logs that are registered by information systems. It allows the discovering of process models considering different perspectives (control-flow, organizational, time). However, currently they lack the ability to explore jointly and interactively the different perspectives, which hinder the understanding of what is happening in the organization. This article proposes a novel approach for interactive discovery aimed at providing process analysts with a tool that allow them to explore multiple perspectives at different levels of detail, which is inspired on OLAP interactive concepts. This approach was implemented as a ProM plug-in and tested in an experiment with real users. Its main advantages are the productivity and operability when performing process discovery.  Springer International Publishing Switzerland 2015. Business process discovery; OLAP; Process mining

An Integrated mining approach to discover business process models with parallel structures: Towards fitness improvement Process mining (PM) is a technique to extract a process model from an event log to represent the process behaviour recorded in that event log. A mined process model with high fitness means that it can reflect most of the process behaviour recorded in the event log. Previous studies have shown that the mined model with high fitness can be used in process improvement, such as fraud detection, continuous process improvement and benchmarking. Genetic process mining (GPM) is a famous PM approach, which can simultaneously identify several process structures from event logs. However, GPM cannot effectively discover parallel structures from event logs. This study proposes a PM approach based on integration of GPM, particle swarm optimisation and differential evolution to find process models with high fitness for event logs involving multiple parallel structures. The results show that the proposed approach does indeed lead to improvement in gaining process models with high fitness for event logs involving multiple parallel structures.  2014 Taylor and Francis. differential evolution; fitness; genetic algorithm; parallel structures business process model; particle swarm optimisation; process mining

Towards the derivation of secure business process designs Security is a critical aspect of business processes that organisations utilise to achieve their goals. Current works on secure business process design mainly focus on annotating existing process models with security related concepts. Meanwhile, little attention is given to the rationale and the alignment of such security choices to high-level organisational security goals. To that end, a goal-to-process transformation approach, with a clear security orientation, is introduced, as part of a wider framework. This transformation process, presented through an illustrative example, uses Secure Tropos goal models as an input to create intermediate, security-annotated process skeletons. These can be then refined, through a series of manual tasks, to create secure BPMN process models.  Springer International Publishing Switzerland 2015. BPMN; Business process modelling; Business process security; Goal-to-process transformation; Process derivation; Secure tropos

Bitemporal support for business process contingency management Modern organisations are increasingly moving from traditional monolithic business systems to environments where more and more tasks are outsourced to third party providers. Therefore, processes must operate in an open and dynamic environment in which the management of time plays a crucial role. Handling time, however, remains a challenging issue yet to be fully addressed. Traditional processing systems only consider business events in a single time dimension, but are unable to handle bitemporal events: events in two time dimensions. Recently, back-end systems have started to provide increased support for handling bitemporal events, but these enhanced capabilities have not been carried through to business process management systems. In this paper, we consider the possible relationships that exist between bitemporal properties of events and we show how these relationships affect a business process. In addition, we demonstrate how bitemporal events can be handled to prevent certain undesired effects on the business process.  Springer International Publishing Switzerland 2015. Bitemporal events; Business process design; Business rules; Process reconfiguration

The effect of noise on mined declarative constraints Declarative models are increasingly utilized as representational format in process mining. Models created from automatic process discovery are meant to summarize complex behaviors in a compact way. Therefore, declarative models do not define all permissible behavior directly, but instead define constraints that must be met by each trace of the business process. While declarative models provide compactness, it is up until now not clear how robust or sensitive different constraints are with respect to noise. In this paper, we investigate this question from two angles. First, we establish a constraint hierarchy based on formal relationships between the different types of Declare constraints. Second, we conduct a sensitivity analysis to investigate the effect of noise on different types of declarative rules. Our analysis reveals that an increasing degree of noise reduces support of many constraints. However, this effect is moderate on most of the constraint types, which supports the suitability of Declare for mining event logs with noise.  IFIP International Federation for Information Processing 2015. Declarative workflows; Noisy event logs; Process mining

An approach to the discovery of accurate and expressive fix-time prediction models Predicting the fix time (i.e. the time needed to eventually solve a case) is a key task in an issue tracking system, which attracted the attention of data-mining researchers in recent years. Traditional approaches only try to forecast the overall fix time of a case when it is reported, without updating this preliminary estimate as long as the case evolves. Clearly, the actions performed on a case can help refine the prediction of its (remaining) fix time, by using Process Mining techniques, but typical issue tracking systems lack task-oriented descriptions of the resolution process, and store fine-grain records, just registering case attributes updates. Moreover, no general approach has been proposed in the literature that fully supports the definition of high-quality derived data, which were yet proven capable to improve prediction accuracy considerably. A new fix-time prediction framework is presented here, along with an associated system, both based on the combination of two kinds of capabilities: (i) a series of modular and flexible data-transformation mechanisms, for producing an enhanced process-oriented log view, and (ii) several induction techniques, for extracting a prediction model from such a view. Preliminary results, performed on the logs of two real issue tracking scenarios, confirm the validity and practical usefulness of our proposal.  Springer International Publishing Switzerland 2015. Bug tracking; Business process analysis; Data mining; Prediction

Hybrid cuckoo search-based algorithms for business process mining In this paper, we analyze the impact of hybridization on the Cuckoo Search algorithm as applied in the context of business process mining. Thus, we propose six hybrid variants for the algorithm, as obtained by combining the Cuckoo Search algorithm with genetic, Simulated Annealing, and Tabu Search-based components. These components are integrated into the Cuckoo Search algorithm at the steps that correspond to generating the new business process models. The hybrid algorithm variants proposed have been comparatively evaluated on a set of event logs of different complexities. Our experimental results obtained have been compared with the ones as provided by the state of the art Genetic Miner algorithm.  Springer International Publishing Switzerland 2015. Cuckoo search; Genetic algorithm; Process mining; Simulated annealing; Tabu search

Petri net model cost extension based on process mining: Cost data description and analysis Organizations always look for enhancing their efficiency and competitiveness by improving their business processes. Business Process Management includes techniques allowing continuous business process improvement. Process mining is a mature technology allowing to extract knowledge from event logs. Process model extension is a process mining technique covering different perspectives of the business process. Furthermore, financial cost incurred during business process execution is one of the relevant information needed by decision makers to take the appropriate improvement decisions in terms of cost reduction. Thus, we proposed a solution allowing Petri Net model extension with cost information using process mining extension technique. However, the proposed solution simply provides cost information by associating them to the corresponding elements of the Petri Net model, which is not sufficient for decision making support. In this paper, we propose several improvements and extensions of the proposed solution in order to enhance the provided decision making support. These proposals include cost data structuring, description and analysis with respect to the recommendations drawn from talks with experts. Copyright  2015 SCITEPRESS Science and Technology Publications All rights reserved. Business process improvement; Business process management; Cost analysis; Cost description; Petri net model cost extension; Process mining

Measuring and Querying Process Performance in Supply Chains: An Approach for Mining Big-Data Cloud Storages Survival in today's global environment means continuously improving processes, identifying and eliminating inefficiencies wherever they occur. With so many companies operating as part or all of complex distributed supply chain, gathering, collating and analyzing the necessary data to identify such improvement opportunities is extremely complex and costly. Although few solutions exist to correlate the data, it continues to be generated in vast quantities, rendering the use of highly scalable, cloud-based solutions for process analysis a necessity. In this paper we present an overview of an analytical framework for business activity monitoring and analysis, which has been realized using extremely scalable, cloud-based technologies. It provides a low-latency solution for entire supply chains or individual nodes in such chains to query process data stores in order to deliver business insight. A custom query language has been implemented which allows business analysts to design custom queries on processes and activities based on a standard set of process metrics. Ongoing developments are focused on testing and improving the scalability and latency of the system, as well as extending the query engine to increase its flexibility and performance.  2015 The Authors. Published by Elsevier B.V. Big Data; Business Performance Management; Business Process Analytics

A pattern-based approach to transform natural text from laws into compliance controls in the food industry In the food industry, regulations support companies to specify what needs to be done to minimize the risks of processing, trade and consumption of inferior food products. Complying with regulations protects companies from expensive and negative perceived product recalls, sanctions and financial penalties. A compliant manufacturing process requires a process design that conforms to legal requirements, quality and safety standards. Regulations are generally described in natural text so that relevant information has to be retrieved and formalized before it can be used for process description. In this contribution, we use a sample of laws and an initial set of generic control patterns to explore the scope of food regulations and the extent of formalization that can be reached by applying control patterns. All in all, we present a pattern-based approach to turn natural text from laws into formalized machine-readable constructs that may serve as basis for a compliant process design. Copyright  2015 by the paper's authors. Business process compliance; Business process management; Control pattern; Food industry; Regulations

Analysis of event logs: Behavioral graphs Analysis of event logs is very important discipline used for the evaluation of performance and control-flow issues within the systems. This type of analysis is typically used in process mining sphere, where information systems, for example workflow management systems, enterprise resource planning systems, customer relationship management, supply chain management systems, and business to business systems record transactions and executed activities in a systematic way. Social network analysis takes part of process mining techniques, focused on activity performers, on users. The authors present a new approach to analysis of user behavior in the systems. The approach allows to find behavioral patterns and to find groups of users with similar behavior. An observer can obtain relations between the users on the basis of their similar behavior. The visualization of relations between the users is then presented by so called behavioral graphs. The approach was tested for event log analysis of a virtual company model developed as a multi-agent system by modeling environment MAREA.  Springer International Publishing Switzerland 2015. Behavioral graphs; Behavioral patterns; Business process analysis; Business process modeling; Complex networks; MAREA; User behaviour

Merging event logs with many to many relationships Process mining techniques enable the discovery and analysis of business processes, identifying opportunities for improvement. However, processes are often comprised of separately managed procedures that have separate log files, impossible to mine in an integrative manner. A preprocessing step that merges logfiles is quite straightforward when the logs have common case IDs. However, when cases in the different logs have many-to-many relationships among them this is more challenging. In this paper we present an approach for merging event logs which is capable of dealing with all kinds of relationships between logs, one-to-one or many-to-many. The approach matches cases in the logs, using temporal relations and text mining techniques. We have implemented the algorithm and tested it on a comprehensive set of synthetic logs.  Springer International Publishing Switzerland 2015. End-to-end process; Merging logfiles; Multiple instances; Process mining

Efficient process model discovery using maximal pattern mining In recent years, process mining has become one of the most important and promising areas of research in the field of business process management as it helps businesses understand, analyze, and improve their business processes. In particular, several proposed techniques and algorithms have been proposed to discover and construct process models from workflow execution logs (i.e., event logs). With the existing techniques, mined models can be built based on analyzing the relationship between any two events seen in event logs. Being restricted by that, they can only handle special cases of routing constructs and often produce unsound models that do not cover all of the traces seen in the log. In this paper, we propose a novel technique for process discovery using Maximal Pattern Mining (MPM) where we construct patterns based on the whole sequence of events seen on the tracesensuring the soundness of the mined models. Our MPM technique can handle loops (of any length), duplicate tasks, non-free choice constructs, and long distance dependencies. Our evaluation shows that it consistently achieves better precision, replay fitness and efficiency than the existing techniques.  Springer International Publishing Switzerland 2015. 

Enhancing aspect-oriented business process modeling with declarative rules When managing a set of inter-related business processes, typically a number of concerns can be distinguished that are applicable to more than one single process, such as security and traceability. The proper enforcement of these cross-cutting concerns may require a specific configuration effort for each of the business processes involved. Aspect-Oriented Business Process Modelling is an approach that aims at encapsulating these concerns in a model-oriented way. However, stateof- the-art techniques lack efficient mechanisms that allow for the specification of concerns in such a way that they can be executed in parallel to other parts of the process. Moreover, existing techniques exclusively focus on the formulation of mandatory concerns. To address these limitations, this paper proposes a new approach to encapsulate both optional and mandatory concerns, which can be executed concurrently with other process functionalities. One core element of the new approach is that it extends current Aspect-Oriented Business Process Modelling approaches with declarative rules. Thus, this hybrid approach allows for a sophisticated management of cross-cutting concerns.  Springer International Publishing Switzerland 2015. Aspect orientation; Business process modeling; Crosscutting concerns; Declarative rules

A method to analyze, diagnose and propose innovations for complex ecosystems: The InnoServ project Understanding and modeling complex ecosystems, where a great number of entities interact in different ways, is a great challenge in the information systems domain. In this context, the InnoServ project aims to understand and support innovations around fragile people considering public, private and volunteering structures. The aim of this paper is to present the ADInnov method, which facilitates the analysis, the diagnosis and the proposition of innovations for complex ecosystems. This method has been extracted in an empirically way, from the lessons learned in the InnoServ project combining different techniques such as expert interviews, goal modeling and serious games. This method could be used in other areas where it is necessary to analyze complex ecosystems. Drawing out and discussing the results of the InnoServ project, we prove the efficiency of our method.  Springer International Publishing Switzerland 2015. Business processes; Complex ecosystem; Method; Organizational innovations; Services

Material movement analysis for warehouse business process improvement with process mining: A case study Process mining is a technique to model and analyze business process based on traces of activities performed and stored in the database of any information systems being operated by the company i.e. event logs. This paper aims to add literature on the implementation of process mining in warehouse management process. First, extraction of all related activities from LTAK and LTAP tables of SAP Warehouse Management module is conducted. The event log are processed with Heuristic Miner Algorithm in PROM. The output of the mining is the actual business process model. The analysis of the output discover deviation from the standard procedure set by the company with the presence of additional activities and nonstandard flow of materials. The bottleneck analysis shows that the material spent a long time in the high rack and transferred between high racks. The average lead time from material receipt until issued is slightly higher than the target set the company. Further analysis of the issues revealed root-cause of the problems which are insufficient warehouse related capacity such as forklift, racks and staffs to serve incoming materials. Finally, recommendations are provided to deal with the warehouse management issues facing the case companies.  Springer International Publishing Switzerland 2015. Material movement; Process mining; SAP; Warehouse management; Warehousing

Pariket: Mining business process logs for root cause analysis of anomalous incidents Process mining consists of extracting knowledge and action- able information from event-logs recorded by Process Aware Information Systems (PAIS). PAIS are vulnerable to system failures, malfunctions, fraudulent and undesirable executions resulting in anomalous trails and traces. The flexibility in PAIS resulting in large number of trace variants and the large volume of event-logs makes it challenging to identify anomalous executions and determining their root causes. We propose a framework and a multi-step process to identify root causes of anomalous traces in business process logs. We first transform the event-log into a sequential dataset and apply Window-based and Markovian techniques to identify anomalies. We then integrate the basic eventlog data consisting of the Case ID, time-stamp and activity with the contextual data and prepare a dataset consisting of two classes (anomalous and normal). We apply Machine Learning techniques such as decision tree classifiers to extract rules (explaining the root causes) describing anomalous trans- actions. We use advanced visualization techniques such as parallel plots to present the data in a format making it easy for a process analyst to identify the characteristics of anomalous executions. We conduct a triangulation study to gather multiple evidences to validate the effectiveness and accuracy of our approach.  Springer International Publishing Switzerland 2015. Anomalous incidents; Business process mining; Decision tree classifier; Event log; Markovian based technique; Root cause analysis

Business impact analysisa framework for a comprehensive analysis and optimization of business processes The ability to continuously adapt its business processes is a crucial ability for any company in order to survive in todays dynamic world. In order to accomplish this task, a company needs to profoundly analyze all its business data. This generates the need for data integration and analysis techniques that allow for a comprehensive analysis. A particular challenge when conducting this analysis is the integration of process data generated by workflow engines and operational data that is produced by business applications and stored in data warehouses. Typically, these two types of data are not matched as their acquisition and analysis follows different principles, i.e., a process-oriented view versus a view focusing on business objects. To address this challenge, we introduce a framework that allows to improve business processes considering an integrated view on process data and operational data. We present and evaluate various architectural options for the data warehouse that provides this integrated view based on a specialized federation layer. This integrated view is also reflected in a set of operators that we introduce. We show how these operators ease the definition of analysis queries and how they allow to extract hidden optimization patterns by using data mining techniques.  2013, Springer-Verlag Berlin Heidelberg. Business process optimization; Data mining; Data warehousing; Information integration; OLAP

Analysis of business processes with enterprise ontology and process mining This paper describes a business process analysis method that helps determining if a business process complies with the requirements put forward by enterprise ontologys transaction pattern. The method starts by discovering the business process through the application of process mining techniques to the events that are generated by the applications that support the execution of the process. This step discovers the actual implementation of the process from its event trace. Next, the discovered process is analysed against enterprise ontologys transaction pattern to determine whether the process complies with the structure and sequencing of its coordination and production acts. The paper shows that combining process mining with enterprise ontology contributes to the analysis of business processes, especially in terms of determining the boundaries of authority and responsibility of the process. The feasibility and the limitations of the method are discussed using a case study that analyses a semi-automated business process.  Springer International Publishing Switzerland 2015. DEMO; Enterprise ontology; Process analysis; Process mining

An Approach to Business Process Recovery from Source Code Over time Business Process has become an asset for organization since it allows managing what happens within their environments. It is possible to automate some activities of the business process using information systems and accordingly decrease the execution time and increase the production. However, information systems often suffer maintenance over time and become obsolete and a re-engineering process is necessary. In this case, the business knowledge, located more accurately the reality in source code, should be maintained. Thereof, this paper propose an approach to support the business process recovery from source code. For this purpose, the approach uses KDM standard with a set of heuristic rules to identify relevant code elements to the business layer. As result, the models are generated according to the BPMN specification that, together with other artifacts, provide more subsidies to the professionals involved. To evaluate the effectiveness of the approach, a case study was performed in an Academic Management System.  2015 IEEE. Business Process; Knowledge Discovery; Reverse Engineering; Software Re-engineering

Business process event log use for activity sequence analysis It is mandatory for nowadays businesses to improve their processes to survive. The basis of this improvement is business process analysis. The analysis can be done in multiple ways but one of the state of the art solutions is Process Mining which uses historical business process execution data in information systems to improve the process analysis. The historical data for analysis comes in a form of event logs. In this paper an approach is presented which processes an event log into frequency matrixes to allow efficient activity sequence analysis. Additionally, some heuristic rules are presented that allow to make inference on causality between activities in a business process.  2015 IEEE. activity sequence; business process analysis; event log; frequency matrix; process mining

Leveraging textual information for improving decision-making in the business process lifecycle Business process implementations fail, because requirements are elicited incompletely. At the same time, a huge amount of unstructured data is not used for decision-making during the business process lifecycle. Data from questionnaires and interviews is collected but not exploited because the effort doing so is too high. Therefore, this paper shows how to leverage textual information for improving decision making in the business process lifecycle. To do so, text mining is used for analyzing questionnaires and interviews.  Springer International Publishing Switzerland 2015. Bpm; Context Data; Decision-making; Process interviews; Text mining

Production process monitoring using model-driven event processing networks Economic realities make flexibility in production processes a necessity. Small batch production necessitates reuse of machines within different production processes. Monitoring in such production environments must adapt to process changes without impacting production machines and software. In this work we propose a novel method for production monitoring using event processing networks, separating machine and production processes, thus increasing flexibility and minimizing configuration efforts.  Springer International Publishing Switzerland 2015. Business process management; Complex event processing; Event processing networks; Model-driven architecture; Process monitoring

Detecting the effects of changes on the compliance of cross-organizational business processes An emerging challenge for collaborating business partners is to properly define and evolve their cross-organizational processes with respect to imposed global compliance rules. Since compliance verification is known to be very costly, reducing the number of compliance rules to be rechecked in the context of process changes will be crucial. Opposed to intra-organizational processes, however, change effects cannot be easily assessed in such distributed scenarios, where partners only provide restricted public views and assertions on their private processes. Even if local process changes are invisible to partners, they might affect the compliance of the cross-organizational process with the mentioned rules. This paper provides an approach for ensuring compliance when evolving a cross-organizational process. For this purpose, we construct qualified dependency graphs expressing relationships between process activities, process assertions, and compliance rules. Based on such graphs, we are able to determine the subset of compliance rules that might be affected by a particular change. Altogether, our approach increases the efficiency of compliance checking in cross-organizational settings.  Springer International Publishing Switzerland 2015. Change; Compliance; Cross-organizational; Process; Process; Process

Dynamic constructs competition miner - occurrence- vs. time-based ageing Since the environment for businesses is becoming more competitive by the day, business organizations have to be more adaptive to environmental changes and are constantly in a process of optimization. Fundamental parts of these organizations are their business processes. Discovering and understanding the actual execution flow of the processes deployed in organizations is an important enabler for the management, analysis, and optimization of both, the processes and the business. This has become increasingly difficult since business processes are now often dynamically changing and may produce hundreds of events per second. The basis for this paper is the Constructs Competition Miner (CCM): A divide-and-conquer algorithm which discovers block-structured processes from event logs possibly consisting of exceptional behaviour. In this paper we propose a set of modifications for the CCM to enable dynamic business process discovery of a run-time process model from a stream of events. We describe the different modifications with a particular focus on the influence of individual events, i.e. ageing techniques. We furthermore investigate the behaviour and performance of the algorithm and the ageing techniques on event streams of dynamically changing processes.  IFIP International Federation for Information Processing 2015. Big data; Business process management; Complex event processing; Event streaming; Process mining; Run-time models

Meta model extensibility of BPMN: Current limitations and proposed improvements The Business Process Model and Notation (BPMN) is the prevalent conceptual modeling language for business process modeling and process analysis. BPMN benefits from its expressiveness and the well-defined meta model, which is defined by the Meta Object Facility (MOF). The emergence of BPMN entails an increasing demand for language extensions in order to both benefit from the dissemination and apposite concepts. Although BPMN is one of very few languages that explicitly provides capabilities for its extension, the proposed mechanism reveals some shortcomings and inaccuracies concerning model abstractions, specificity and semantical clarity. A list of improvable aspects is hence provided based on an in-depth analysis of the extension mechanism. The analysis has a special focus on the abstract syntax (BPMN meta model). Several techniques for enhanced BPMN extension design are proclaimed by adapting alternative mechanisms for language extensibility: Profiling, under specification (hooking) and annotation (plugins and add-ons). The stated mechanisms are partly adapted from other modeling languages (profiling) or the field of Software Engineering (hooking, plug-ins, add-ons). Each approach is described by its core concepts, its application and by some examples. The approaches are finally compared regarding several criteria.  Springer International Publishing Switzerland 2015. Business process modeling; Conceptual modeling; Extension mechanisms; Language dialects; Meta model extensions; MOF

Process mining reloaded: Event structures as a unified representation of process models and event logs Process mining is a family of methods to analyze event logs produced during the execution of business processes in order to extract insights regarding their performance and conformance with respect to normative or expected behavior. The landscape of process mining methods and use cases has expanded considerably in the past decade. However, the field has evolved in a rather ad hoc manner without a unifying foundational theory that would allow algorithms and theoretical results developed for one process mining problem to be reused when addressing other related problems. In this paper we advocate a foundational approach to process mining based on a well-known model of concurrency, namely event structures. We outline how event structures can serve as a unified representation of behavior captured in process models and behavior captured in event logs. We then sketch how process mining operations, specifically automated process discovery, conformance checking and deviance mining, can be recast as operations on event structures.  Springer International Publishing Switzerland 2015. 

Matching of events and activities  an approach using declarative modeling constraints Nowadays, business processes are increasingly supported by IT services that produce massive amounts of event data during the execution of a process. This event data can be used to analyze the process using process mining techniques to discover the real process, measure conformance to a given process model, or to enhance existing models with performance information. Mapping the produced events to activities of a given process model is essential for conformance checking, annotation and understanding of process mining results. In order to accomplish this mapping with low manual effort, we developed a semi-automatic approach that maps events to activities using the solution of a corresponding constraint satisfaction problem. The approach extracts Declare constraints from both the log and the model to build matching constraints to efficiently reduce the number of possible mappings. The evaluation with an industry process model collection and simulated event logs demonstrates the effectiveness of the approach and its robustness towards nonconforming execution logs.  Springer International Publishing Switzerland 2015 Business process intelligence; Constraint satisfaction; Event mapping; Process mining

The multidimensional data model of integrated accounting needed for compiling management reports based on calculation EBITDA indicator Organization and method of assembly management report using a definition of EBITDA indicator (Earnings before interest and tax, amortization and depreciation) are considered on the practical example of Kherson river port's activity. The process of constructing a multidimensional model, that is necessary for determining EBITDA of integrated accounting using the program "1C: Accounting for Ukraine", and implementation of the model using PivotTable in MS Excel are represented. The range of possibilities to implement the process named "Data Mining" of the models is demonstrated. The management report, formed on the basis of multidimensional data model is used to determine the profitability of the business units, business processes and enterprises considering the organizational architecture of the entity. EBITDA; Eivot table; Management Reporting; Multidimensional data model

Semantic and structural performer clustering in BPMN models transformed into social network models Current trends in organization restructuring focus on the social relationships among the organizational actors in order to improve the business process. Proposed business process model restructuring approaches adopt either social network discovery or rediscovery techniques. Social network discovery uses semantic information to guide the affiliation process during its analyses, whereas social network rediscovery uses structural information to identify groups in the social network. In this paper, we propose a hybrid method that exploits both knowledge discovery and rediscovery to suggest a new structure of a business process model that is based on performers clustering. Using the context concept, the proposed method applies a hierarchical clustering algorithm to determine the performer partitions; the algorithm uses two newly defined distances that account for the semantic and structural information. The method is illustrated and evaluated experimentally to analyze its performance. Affiliation; BPM; Hierarchical clustering; Knowledge discovery; Knowledge rediscovery; Restructuring; Social network model

Relational XES: Data management for process mining Information systems log data during the execution of business processes in so called "event logs". Process mining aims to improve business processes by extracting knowledge from event logs. Currently, the de-facto standard for storing and managing event data, XES, is tailored towards sequential access of this data. Handling more and more data in process mining applications is an important challenge and there is a need for standardized ways of storing and processing event data in the large. In this paper, we first discuss several solutions to address the "big data" problem in process mining. We present a new framework for dealing with large event logs using a relational data model which is backwards compatible with XES. This framework, called Relational XES, provides buffered, random access to events resulting in a reduction of memory usage and we present experiments with existing process mining applications to show how this framework trades memory for CPU time. 

A method to infer the need to update situations in business process adaptation Abstract Contextual knowledge is an essential resource for adapting business processes in order to keep them aligned with its goals. A context-based adaptation environment should learn from the dynamism of the context as well as the decisions made, and continuously identify new unforeseen situations. Data mining is a possibility to maintain the analysis of the processes updated. This paper presents a method that infers the need to learn new situations that influence a business process execution. The method is based on the results of the Apriori algorithm application. Case studies were conducted to evaluate the proposal. We observed evidences of context changes over time and the potential to learn with this dynamics through the method proposed.  2015 Elsevier B.V. Apriori; Context; Data mining; Dynamic adaptation of business processes

POQL: A new query language for Process-oriented Case-based Reasoning Sharing and reuse of best-practice process models is an important knowledge management approach for business process modelling. Process-oriented Case-Based Reasoning (PO-CBR) supports this by retrieving and adapting processes or workflows based on models stored in the repository, which requires an expressive query language. Hence, we present a novel query language for workflows that enables to express generalized query terms and negation. Further, it allows a ranking of the repository workflows. Copyright  2015 by the papers authors. Business Process Querying; Process-oriented Case-based Reasoning; Workflows

Research on conceptual modeling: Themes, topics, and introduction to the special issue Conceptual modeling continues to evolve as researchers and practitioners reflect on the challenges of modeling and implementing data-intensive problems that appear in business and in science. These challenges of data modeling and representation are well-recognized in contemporary applications of big data, ontologies, and semantics, along with traditional efforts associated with methodologies, tools, and theory development. This introduction contains a review of some current research in conceptual modeling and identifies emerging themes. It also introduces the articles that comprise this special issue of papers from the 32nd International Conference on Conceptual Modeling (ER 2013).  2015 Elsevier B.V. All rights reserved. Big data; Business process modeling; Conceptual modeling; Modeling techniques; Modeling tools; Ontology

A method to align goals and business processes Business Process Modeling (BPM) has been for a number of years in the spotlight of research and practice, aiming at providing organizations with conceptual modeling-based representations of the flow of activities that generate its main products and services. It is essential that such flow of activities is engineered in a way to satisfy the organizations goals. However, the work on BPM still makes shy use of goal modeling and the relation between goals and processes is often neglected. In this paper, we propose a method that supports the analyst in identifying which activities in a business process satisfy the organizations goals. Moreover, our method allows reasoning regarding the impact of each of these activities in the satisfaction of the strategic (i.e. top) goals of the organization. The results of this analysis may lead to reengineering, and grant the analyst with the means to design higher quality BPMs. Besides describing the method, this paper presents a preliminary evaluation of the method by the means of an empirical study made in a controlled environment.  Springer International Publishing Switzerland 2015. 

Analysis of Customer Fulfilment with Process Mining: A Case Study in a Telecommunication Company This paper presents results of process mining implementation in a characteristically unstructured customer fulfilment process in a real Telecommunication Company. The aim of process mining implementation is firstly to discover the typical customer fulfilment business process. It is also aimed at assessing the current rate of completed customer fulfilment, the typical component required for the process and the lead time for different types of customer requests. The steps to achieve the goals are to prepare, extract the data and construct the event log from the company's in house built Customer Relationship Management systems. The event log is then processed using Disco and PROM tools. The complete event log when model with Disco results in a Spaghetti-like process model with 673 different variants. In order to identify typical process, the log is filtered to include only business variants with 1% case occurrence of the total case. This enables the identification of 18 typical business variants, which differ based on the order requested, sequence of activities and occurrence of Return Work Order. Based on the typical variants, the components required to fulfil a certain order are identified. Another important findings are the fact that the completion rate is very low (only 8%). This may due to the fact that the issues faced by the field officer in processing the order and the resolution are either recorded manually or in a different systems. Finally, findings from this study can be used by the company to improve their current business process. It also stressed out the importance of resolving data integration issues in implementation of process mining in real cases.  2015 The Authors. Customer Order Fulfilment; Process Mining; Unstructured Process

Handling Big(ger) logs: Connecting ProM 6 to apache hadoop Within process mining the main goal is to support the analysis, improvement and apprehension of business processes. Numerous process mining techniques have been developed with that purpose. The majority of these techniques use conventional computation models and do not apply novel scalable and distributed techniques. In this paper we present an integrative framework connecting the process mining framework ProM with the distributed computing environment Apache Hadoop. The integration allows for the execution of MapReduce jobs on any Apache Hadoop cluster enabling practitioners and researchers to explore and develop scalable and distributed process mining approaches. Thus, the new approach enables the application of different process mining techniques to events logs of several hundreds of gigabytes. Copyright  2015 for this paper by its authors. Apache hadoop; Big data; Distributed computing; Process mining; ProM; Scalability

Mining enterprise models for knowledgeable decision making Knowledge is stored in an enterprise in various forms ranging from unstructured operational data, legal documents to structured information like programs, as well as relational data stored in databases to semi-structured information stored in xml files. All these information if viewed from a holistic standpoint can help an enterprise to understand and reflect upon itself and thereby make knowledgeable decisions whenever required. In order to satisfy this objective of holistic knowledge representation and decision making, we begin with mining unstructured information present in an enterprise. In particular, in this paper, we intend to mine a document intensive business processes and extract information as a knowledge repository that captures the various stakeholders along with their intentions and the tasks they perform. The goal is to automate the validation of such business processes by eliminating any manual verification, which is time consuming and error prone. We believe this is the first step towards realizing our broader objective of collective modeling of enterprise knowledge that will involve mining of information available in unstructured, structured, relational as well as semi-structured form present in an enterprise.  2015 IEEE. Decision making; Enterprise modeling; Information extraction; Knowledge representation; Semantic matching

Designing and evaluating an interpretable predictive modeling technique for business processes Process mining is a field traditionally concerned with retrospective analysis of event logs, yet interest in applying it online to running process instances is increasing. In this paper, we design a predictive modeling technique that can be used to quantify probabilities of how a running process instance will behave based on the events that have been observed so far. To this end, we study the field of grammatical inference and identify suitable probabilistic modeling techniques for event log data. After tailoring one of these techniques to the domain of business process management, we derive a learning algorithm. By combining our predictive model with an established process discovery technique, we are able to visualize the significant parts of predictive models in form of Petri nets. A preliminary evaluation demonstrates the effectiveness of our approach.  Springer International Publishing Switzerland 2015. Data mining; Grammatical inference; Predictive modeling; Process mining

Mining process task post-conditions A large and growing body of work explores the use of semantic annotation of business process designs, but these annotations can be difficult and expensive to acquire. This paper presents a data-driven approach to mining these annotations (and specifically post-conditions) from event logs in process execution histories which describe both task execution events (typically contained in process logs) and state update events (which we record in effect logs). We present an empirical evaluation, which suggests that the approach provides generally reliable results.  Springer International Publishing Switzerland 2015. Data-driven; Effect logs; Process logs; Semantic annotation

Applying process mining to smart spaces: Perspectives and research challenges A software system managing a smart space takes, among its inputs, models of human behavior; such models are usually difficult to obtain and to validate. The employment of techniques from business process modeling and mining may represent a solution to both the problems, but a set of challenges need to be faced in order to cope with major differences between human activities and business processes. In this work we provide insights about these challenges, and propose further research activities to tackle them.  Springer International Publishing Switzerland 2015. Human habits; Process mining; Smart spaces

A novel top-down approach for clustering traces In the last years workflow discovery has become an important research topic in the business process mining area. However, existing workflow discovery techniques encounter challenges while dealing with event logs stemming from highly flexible environments because such logs contain many different behaviors. As a result, inaccurate and complex process models might be obtained. In this paper we propose a new technique which searches for the optimal way for clustering traces among all of the possible solutions. By applying the existing workflow discovery techniques on the traces for each discovered cluster by our method, more accurate and simpler sub-models can be obtained.  Springer International Publishing Switzerland 2015. Business process extension; Business process mining; Greedy algorithm; Trace clustering

Toward using business process intelligence to support incident management metrics selection and service improvement Background: Businesses are increasingly dependent on IT services, and providers need to deliver fast, with high quality and low cost. An incident is an event that can lead to loss or disruption of services. Incident management reinstates normal service operation as quickly as possible and mitigates negative impact to business, ensuring agreed levels of service quality. So, reduce resolution time is usually the most important goal for incidents. Aims We aim to obtain knowledge about process and identify adequate metrics for Incident Management to help reduction of resolution time. Our research questions are: (i) Which Incident Management sub-process is causing more impact to resolution time? (ii) Which metrics can be used to measure this sub-process? (iii) What actions can be taken to improve Incident Management process in order to reduce impact of this subprocess in resolution time? Method: We present a case study in a global large company that considers reduction of incidents resolution time as a goal. Results: By applying BPM, BPI and Process Mining we were able to discover the underlined process and a bottleneck for resolution time. Moreover, we proposed metrics to improve process and service quality by applying GQM+Strategies. BPI; Incident Management; Measurement; Metric; Process Mining

PACT-ART: Adaptive and context-aware processes for the transportation of artworks Artworks transportation processes are highly challenging operations between multiple partners that are specified over service level agreements. They are executed within dynamic and uncontrollable environments that might leave undesired damages on the artworks if not handled efficiently. In this paper we take advantage of the emerging concept of IoT, and we propose PACT-ART1, realized as an architecture that employs advanced computing techniques like data mining and business process intelligence to predict a future state of the process and point out any possible violation from it. Then, by recommending dynamic adaptation actions, the foreseen misbehavior could be eliminated or mitigated proactively.  2015 IEEE. Adaptation; Business Process Management; Cultural Heritage; Logistics Process; Prediction; Recommendation

PM2: A process mining project methodology Process mining aims to transform event data recorded in information systems into knowledge of an organisations business processes. The results of process mining analysis can be used to improve process performance or compliance to rules and regulations. However, applying process mining in practice is not trivial. In this paper we introduce PM2, a methodology to guide the execution of process mining projects. We successfully applied PM2 during a case study within IBM, a multinational technology corporation, where we identified potential process improvements for one of their purchasing processes.  Springer International Publishing Switzerland 2015. Business process management; Case study; Methodology; Process mining

I8K|DQ-BigData: I8K architecture extension for data quality in big data During the execution of business processes involving various organizations, Master Data is usually shared and exchanged. It is necessary to keep appropriate levels of quality in these Master Data, in order to prevent defects and failures in the business processes. A way to support the decision about the usage of data in business processes is to include information about the level of quality alongside the Master Data. ISO/TS 8000 parts 100 to 140, may support the provision of this kind of information in a usable manner. Specifically I8K, a reference implementation from academic sources of the aforementioned standard parts (ISO/TS 8000:100-140), may be used for this objective. Regrettably, I8K is not aimed to support the assessment of large Master Data volumes and does not reach the required efficiency in Big Data surroundings. This paper describe an extension of I8K to resolve those problems of efficiency in Big Data projects.  Springer International Publishing Switzerland 2015. Big data; Data quality; I8K; Master data

Process extraction from texts using semantic unification In order to extract a process model from natural language sources, process elements such as agents, resources or actions have to be identified across one or multiple texts. Natural language descriptions tend to provide only partial and potentially contradictory information. Inability to systematically reconcile partial information significantly limits capabilities of current systems. We propose to address this problem by means of semantic unification integrated in the common text processing pipeline.  2015 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved. Business process management; Natural language processing; Process extraction; Text mining

Business process analysis for Mobile@Old Older adults are people with different needs, different cognitive and motor abilities, and specific health conditions. To enhance older adult's quality of life by improving their mobility and autonomy, there is the need of a personalized and integrated solution that can be tailored both to the level of individual preferences and necesities, and to the combination of health monitoring devices required by a particular person. This paper presents the designing principles of an intelligent system - Mobile@Old - for mobility monitoring through business model analysis. The system will monitor elderly people through physical exercises adapted to their medical status and presented as a user friendly game. Adapted physical exercises; Intelligent systems; Medical parameters monitoring; Serious games for elderly; Wellbeing

Teaching tip: Active learning via a sample database: The case of microsoft's adventure works This paper describes the use and benefits of Microsoft's Adventure Works (AW) database to teach advanced database skills in a hands-on, realistic environment. Database management and querying skills are a key element of a robust information systems curriculum, and active learning is an important way to develop these skills. To facilitate active learning and produce a compelling narrative, the data structure and content of a useful pedagogically-oriented database should be realistic and lifelike. It should contain data that accurately depicts the business processes, functions, and entities of a realistic organization, structured in a way that demonstrates best practices in database design. Most database textbooks include sample databases, but these are often small and sparse of data. By contrast, Microsoft's AW database presents a robust, realistic, and comprehensive framework for many important educational objectives in an IS curriculum. This paper introduces the AW business case and database, and illustrates several pedagogical uses in an undergraduate CIS program.  2015 by the Education Special Interest Group (EDSIG) of the Association of Information Technology Professionals. Active learning; Business intelligence; Case study; Data mining; Data warehouse; Database management systems (DBMS); Extensible markup language (XML); Problem based learning (PBL)

Automated process model discovery limitations and challenges The implementation of business processes through the use of information systems (ERP, CRM, PLM and MES) has become a key success factor for companies. For further development and optimization of processes, many companies havent trusted processes for the analysis. Surveying as-is processes is complex and only possible by manual recording. To perform this task automatically the theory shows us different approaches (process mining, Application Usage Mining and Web Usage Mining). The target of the concepts and tools is to complement the process of continuous improvement in the company with meaningful process models, which can be reconstructed from protocols and user actions in the information systems. This article focuses on the limitations of these concepts and the challenges they present and gives an outlook on how future solutions must work to speed up the process of continuous improvement and to meet the challenges of heterogeneity in IS-Architectures. Process mining; Process model discovery; Screen capturing

Recommendation of process discovery algorithms through event log classification Process mining is concerned with the extraction of knowledge about business processes from information system logs. Process discovery algorithms are process mining techniques focused on discovering process models starting from event logs. The applicability and effectiveness of process discovery algorithms rely on features of event logs and process characteristics. Selecting a suitable algorithm for an event log is a tough task due to the variety of variables involved in this process. The traditional approaches use empirical assessment in order to recommend a suitable discovery algorithm. This is a time consuming and computationally expensive approach. The present paper evaluates the usefulness of an approach based on classification to recommend discovery algorithms. A knowledge base was constructed, based on features of event logs and process characteristics, in order to train the classifiers. Experimental results obtained with the classifiers evidence the usefulness of the proposal for recommendation of discovery algorithms.  Springer International Publishing Switzerland 2015. Classification; Process discovery; Process mining

Know What you stream: Generating event streams from CPN models in ProM 6 The field of process mining is concerned with supporting the analysis, improvement and understanding of business processes. A range of promising techniques have been proposed for process mining tasks such as process discovery and conformance checking. However there are challenges, originally stemming from the area of data mining, that have not been investigated extensively in context of process mining. In particular the incorporation of data stream mining techniques w.r.t. process mining has received little attention. In this paper, we present new developments that build on top of previous work related to the integration of data streams within the process mining framework ProM. We have developed means to use Coloured Petri Net (CPN) models as a basis for eventstream generation. The newly introduced functionality greatly enhances the use of event-streams in context of process mining as it allows us to be actively aware of the originating model of the event-stream under analysis. Copyright  2015 for this paper by its authors. Coloured petri nets; CPN tools; Event-streams; Process mining; ProM

Discovering cross-organizational business rules from the cloud Cloud computing is rapidly emerging as a new information technology that aims at providing improved efficiency in the private and public sectors, as well as promoting growth, competition, and business dynamism. Cloud computing represents, today, an opportunity also from the perspective of business process analytics since data recorded by process-centered cloud systems can be used to extract information about the underlying processes. Cloud computing architectures can be used in cross-organizational environments in which different organizations execute the same process in different variants and share information about how each variant is executed. If the process is characterized by low predictability and high variability, business rules become the best way to represent the process variants. The contribution of this paper consists in providing: (i) a cloud computing multi-tenancy architecture to support cross-organizational process executions; (ii) an approach for the systematic extraction/composition of distributed data into coherent event logs carrying process-related information of each variant; (iii) the integration of online process mining techniques for the runtime extraction of business rules from event logs representing the process variants running on the infrastructure. The proposed architecture has been implemented and applied for the execution of a real-life process for acknowledging an unborn child performed in four different Dutch municipalities.  2014 IEEE. 

A gender perspective on business process management competences offered on professional online social networks While Business Process Management (BPM) originally strongly focused on Information Technology as a key factor driving the efficiency and effectiveness of organisational processes, there is a growing consensus that BPM represents a holistic management approach that also takes factors like corporate governance, human capital and organisational culture into account. Focusing on human capital, our exploratory study examines competences supplied in the BPM field and how far they represent the holistic nature of BPM. Further, our study tries to understand, whether the BPM field, which is traditionally perceived as very technical, is not immune to the challenge of female underrepresentation. Addressing underrepresentation of women in BPM would help to mitigate the existing competence shortage in the field that stems from the lack of qualified BPM professionals. Thus, we take a gender perspective in analysing 10,405 BPM-related LinkedIn profiles using a text mining technique called Latent Semantic Analysis (LSA). We identify 12 distinct categories of competences supplied by BPM professionals, which, in general, reflect the interdisciplinary nature of BPM, ranging from technical to managerial and domain-specific competences. Analysis of the gender distribution shows that women are underrepresented among the BPM professionals under study and, in particular, among those representing most of the identified categories of competences. BPM workforce; Business process management; Competence analysis; Gender diversity; LSA

The use of process mining in a business process simulation context: Overview and challenges This paper focuses on the potential of process mining to support the construction of business process simulation (BPS) models. To date, research efforts are scarce and have a rather conceptual nature. Moreover, publications fail to explicit the complex internal structure of a simulation model. The current paper outlines the general structure of a BPS model. Building on these foundations, modeling tasks for the main components of a BPS model are identified. Moreover, the potential value of process mining and the state of the art in literature are discussed. Consequently, a multitude of promising research challenges are identified. In this sense, the current paper can guide future research on the use of process mining in a BPS context.  2014 IEEE. business process simulation; event log knowledge; process mining; simulation model construction

Process visualization techniques for multi-perspective process comparisons Organizations executing similar business processes need to understand the differences and similarities in activities performed across work environments. Presently, research interest is directed towards the potential of visualization for the display of process models, to support users in their analysis tasks. Although recent literature in process mining and comparison provide several methods and algorithms to perform process and log comparison, few contributions explore novel visualization techniques. This paper analyzes process comparison from a design perspective, providing some practical visualization techniques as analysis solutions. In order to support the needs of business analysts the design of the visual comparison has been tackled via three different points of view: the general model, the superimposed model and the side-by-side comparison. A case study is presented showing a preliminary evaluation of the application of process mining and visualization techniques to patient treatment across two Australian hospitals.  Springer International Publishing Switzerland 2015. Business process management; Comparative visualization; Process mining

Process mining as a modelling tool: Beyond the domain of business process management Process mining emerged in the field of business process management (BPM) as an innovative technique to exploit the large amount of data recorded by information systems in the form of event logs. It allows to discover not only relations and structure in data but also control flow, and produces a process model, which can then be visualised as a process map. In addition to discovery, process mining supports conformance analysis, a technique to compare an a priori model with the event logs to detect deviations and inconsistencies. In this paper we go beyond the domain of BPM and illustrate how process mining and conformance analysis can be used in a number of contexts, in and across the areas of human-computer interaction and learning.  Springer-Verlag Berlin Heidelberg 2015. 

Application of process mining for improving adaptivity in case management systems The character of knowledge-intense processes is that participants decide the next process activities on base of the present information and their expert knowledge. The decisions of these knowledge workers are in general non-deterministic. It is not possible to model these processes in advance and to automate them using a process engine of a BPM system. Hence, in this context a process instance is called a case, because there is no predefined model that could be instantiated. Domain-specific or general case management systems are used to support the knowledge workers. These systems provide all case information and enable users to define the next activities, but they have no or only limited activity recommendation capabilities. In the following paper, we present a general concept for a self-learning system based on process mining that suggests the next best activity on quantitative and qualitative data for a given case. As a proof of concept, it was applied to the area of insurance claims settlement. Adaptive Case Management; Business Process Management; Process Mining

Invited Keynote: Facilitation and management of modeling projects: Experiences and outlook Enterprise Modeling (EM) has proved to be a practicable approach that supports congruent organization and information system (IS) development by creating an integrated and commonly shared model describing different aspects of an enterprise (e.g. goals, business process, concepts, rules, etc.) EM is used for the purposes of (1) developing the business, (2) ensuring the quality of business operations, and (3) using EM as a problem solving tool. EM usually is organized in the form of a project or it is a part of a larger, e.g. organizational or information system development, project.  Springer International Publishing Switzerland 2015. 

On the discovery of explainable and accurate behavioral models for complex lowly-structured business processes Process discovery (i.e. the automated induction of a behavioral process model from execution logs) is an important tool for business process analysts/managers, who can exploit the extracted knowledge in key process improvement and (re-)design tasks. Unfortunately, when directly applied to the logs of complex and/or lowly-structured processes, such techniques tend to produce low-quality workflow schemas, featuring both poor readability ("spaghetti-like") and low fitness (i.e. low ability to reproduce log traces). Trace clustering methods alleviate this problem, by helping detect different execution scenarios, for which simpler and more fitting workflow schemas can be eventually discovered. However, most of these methods just focus on the sequence of activities performed in each log trace, without fully exploiting all non-structural data (such as cases' data and environmental variables) available in many real logs, which might well help discover more meaningful (context-related) process variants. In order to overcome these limitations, we propose a two-phase clustering-based process discovery approach, where the clusters are inherently defined through logical decision rules over context data, ensuring a satisfactory trade-off is between the readability/explainability of the discovered clusters, and the behavioral fitness of the workflow schemas eventually extracted from them. The approach has been implemented in a system prototype, which supports the discovery, evaluation and reuse of such multi-variant process models. Experimental results on a real-life log confirmed the capability of our approach to achieve compelling performances w.r.t. state-of-the-art clustering ones, in terms of both fitness and explainability. Business process intelligence; Data mining; Trace clustering; Workflow discovery

Process mining for clinical processes: A comparative analysis of four australian hospitals Business process analysis and process mining, particularly within the health care domain, remain underutilized. Applied research that employs such techniques to routinely collected health care data enables stakeholders to empirically investigate care as it is delivered by different health providers. However, crossorganizational mining and the comparative analysis of processes present a set of unique challenges in terms of ensuring population and activity comparability, visualizing the mined models, and interpreting the results. Without addressing these issues, health providers will find it difficult to use process mining insights, and the potential benefits of evidence-based process improvement within health will remain unrealized. In this article, we present a brief introduction on the nature of health care processes, a review of process mining in health literature, and a case study conducted to explore and learn how health care data and crossorganizational comparisons with process-mining techniques may be approached. The case study applies process-mining techniques to administrative and clinical data for patients who present with chest pain symptoms at one of four public hospitals in South Australia. We demonstrate an approach that provides detailed insights into clinical (quality of patient health) and fiscal (hospital budget) pressures in the delivery of health care. We conclude by discussing the key lessons learned from our experience in conducting business process analysis and process mining based on the data from four different hospitals.  2015 ACM. Comparative analysis; Data preparation; Health care delivery; Patient pathways; Process mining

BAB Framework: Process Mining on Cloud This paper presents a data analytics tool, BAB (Best Analytics of Big Data), that combines Hadoop Map-Reduce algorithms with cloud computing and process mining to accommodate the data explosion in business fields. Both academics and professionals can benefit from our tool by applying and extending it within their respective research areas. In fact, BAB already has been widely utilized in the fields of port logistics, ship building and manufacturing.  2015 The Authors. business process management; cloud computing; Hadoop; Process mining

Utility-based control flow discovery from business process event logs Process Aware Information Systems (PAIS) are IT systems which support business processes and generate event-logs as a result of execution of the supported business processes. Fuzzy-Miner (FM) is a popular algorithm within Process Mining which consists of discovering a process model from the event-logs. In traditional FM algorithm, the extracted process model consists of nodes and edges of equal value (in terms of the economic utility and objectives). However, in real-world applications, the actors, activities and transition between activities may not be of equal value. In this paper, we propose a Utility-Based Fuzzy Miner (UBFM) algorithm to efficiently mine a process model driven by a utility threshold. The term utility can be measured in terms of profit, value, quantity or other expressions of users preference. The focus of the work presented in this paper is to incorporate the statistical (based on frequency) and semantic (based on users objective) aspects while driving a process model. We conduct experiments on real-world dataset and synthetic dataset to demonstrate the effectiveness of our approach.  Springer International Publishing Switzerland 2015. Fuzzy-miner (FM); Process aware information systems (PAIS); Process mining; Utility based process mining

Supporting rule-based process mining by user-guided discovery of resource-aware frequent patterns Agile processes depend on human resources, decisions and expert knowledge and are especially versatile and comprise rather complex coherencies. Rule-based process models are well-suited for modeling these processes. There exist a number of process mining approaches to discover rule-based process models from event logs. However, existing rule-based approaches are typically based on a given set of rule templates and predominately consider control flow aspects. By only considering a given set of templates, contemporary approaches underlie a representational bias. The usage of a fixed language frequently ends into insuffcient languages. In this paper we propose an approach to automatically suggest adequate resource-aware rule templates for a given domain by pre-processing the provided event log using frequent pattern mining techniques. These templates can then be instantiated and checked by process mining methods.  Springer International Publishing Switzerland 2015. Frequent pattern mining; Resource-aware process mining; Rule-based process mining

A generic approach for calculating and visualizing differences between process models in multidimensional process mining Process mining automatically generates process models from event logs. In multidimensional process mining, these models can be analyzed from various viewpoints by clustering event traces according to their attributes, e.g. age or region of the patient for a healthcare process. For each cluster, a distinct process model is calculated. Since these models are supposed to be identical in most parts, differences between them are hard to spot. Therefore, a tool for emphasizing these differences is needed. To face the different challenges presented by multidimensional process mining like the representational bias, such an approach has to be customizable to support different modeling languages and different layout and differencing algorithms. This paper presents a generic approach to calculate and visualize differences between process models which can be used to compare models in multidimensional process mining.  Springer International Publishing Switzerland 2015. Differencing; Multidimensional process mining; Visualization

Multidimensional process mining using process cubes Process mining techniques enable the analysis of processes using event data. For structured processes without too many variations, it is possible to show a relative simple model and project performance and conformance information on it. However, if there are multiple classes of cases exhibiting markedly different behaviors, then the overall process will be too complex to interpret. Moreover, it will be impossible to see differences in performance and conformance for the different process variants. The different process variations should be analysed separately and compared to each other from different perspectives to obtain meaningful insights about the different behaviors embedded in the process. This paper formalizes the notion of process cubes where the event data is presented and organized using different dimensions. Each cell in the cube corresponds to a set of events which can be used as an input by any process mining technique. This notion is related to the well-known OLAP (Online Analytical Processing) data cubes, adapting the OLAP paradigm to event data through multidimensional process mining. This adaptation is far from trivial given the nature of event data which cannot be easily summarized or aggregated, conflicting with classical OLAP assumptions. For example, multidimensional process mining can be used to analyze the different versions of a sales processes, where each version can be defined according to different dimensions such as location or time, and then the different results can be compared. This new way of looking at processes may provide valuable insights for process optimization.  Springer International Publishing Switzerland 2015 Comparative process mining; OLAP; Process cube; Process mining

Comparative process mining in education: An approach based on process cubes Process mining techniques enable the analysis of a wide variety of processes using event data. For example, event logs can be used to automatically learn a process model (e.g., a Petri net or BPMN model). Next to the automated discovery of the real underlying process, there are process mining techniques to analyze bottlenecks, to uncover hidden inefficiencies, to check compliance, to explain deviations, to predict performance, and to guide users towards better processes. Dozens (if not hundreds) of process mining techniques are available and their value has been proven in many case studies. However, existing techniques focus on the analysis of a single process rather than the comparison of different processes. In this paper, we propose comparative process mining using process cubes. An event has attributes referring to the dimensions of the process cube. Through slicing, dicing, rolling-up, and drilling-down we can view event data from different angles and produce process mining results that can be compared. To illustrate the process cube concept, we focus on educational data. In particular, we analyze data of students watching video lectures given by the first author. The dimensions of the process cube allow us to compare the process of students that passed the course versus the process of students that failed. We can also analyze differences between male and female students, between different parts of the course, and between Dutch students and international students. The initial analysis provided in this paper is used to elicit requirements for better tool support facilitating comparative process mining.   IFIP International Federation for Information Processing 2015. Comparative process mining; Learning analytics; Online analytical processing; Process mining

Workload and delay analysis in manufacturing process using process mining Process analysis is one of the important topics in manufacturing industry. Recently process mining has been applied to analyze manufacturing processes. In this paper we investigate the characteristics of event logs in make-toorder production and propose a method to analyze manufacturing processes in make-to-order production such as construction, shipbuilding and aviation by utilizing and extending existing process mining techniques. Among three major analysis perspectives in process mining such as process discovery, performance analysis, and conformance checking, this paper focuses on the performance analysis including workload analysis and delay analysis. To validate the proposed method, a case study with real data is conducted.  Springer International Publishing Switzerland 2015. Manufacturing execution system; Manufacturing process analysis; Process mining

The optimization of resource allocation based on process mining The effectiveness of resource allocation directly affects process performance. In order to optimize resource allocation, this paper proposes a resource allocation model in view of the relationship between resource allocation and process performance, which minimizes process execution time in terms of resource preference, cost constraints and resource availability criteria. Resource coordination is paid less attention in previous resource allocation studies. Therefore, this paper presents the corresponding resource allocation method in consideration of resource coordination, the interval between adjacent activities and distinguishing turnaround time between different resources from event logs. The experiments show that the proposed method can effectively optimize the resource allocation.  Springer International Publishing Switzerland 2015. Optimization models; Process mining; Process performance; Resource allocation; Resource coordination

Hybrid association rule learning and process mining for fraud detection Data mining and process mining provide solutions for fraud detection. The automated methods based on the historical data, however, still need an improvement. In this regard, we propose a hybrid method between association rule learning and process mining. The process mining, in this case, inspects the event log. Through an expert verification, the itemset of the association rule learning is used to generate positive and negative rules applied for compliance checking towards the testing dataset. The result then shows that the hybrid method has less false discovery rate and provides higher accuracy compared to that of the process-mining method in which the optimum accuracy lies in certain threshold of confidence level. Association rule learning; Fraud detection; Hybrid method; Process mining

Improving the management of an emergency call service by combining process mining and discrete event simulation approaches Each Emergency Medical Assistance Centre in France (SAMU), includes an emergency call service. It provides an adequate and immediate response to medical problems. The processing of the incoming calls can be seen as a collaborative process involving several stakeholders. The control of such a process is crucial. Indeed, the effectiveness of the response to these incoming calls strongly impacts the quality of service of these centres, which is the main information which the government relies for their funding. The aim of this paper is to analyse such a collaborative process, regarding the performance targets requested by the French government. To this end, we suggest applying a new approach, based on the combination of two well-known engineering techniques, in consecutive manner. We will first use process mining techniques to obtain meaningful knowledge about the studied collaborative processes, relying on real data from a French Emergency Medical Assistance Centre. Secondly, we will use a Discrete Event Simulation approach as an effective tool to assess the efficiency of the current management of this emergency call centre and to ask (and answer) some what if? questions to identify possible ways of improving their effectiveness.  IFIP International Federation for Information Processing 2015. Collaborative process analysis; Discrete-event simulation; Emergency call centre; Key performance indicators; Knowledge discovery; Process mining

Decomposed process mining: The ILP case Over the last decade process mining techniques have matured and more and more organizations started to use process mining to analyze their operational processes. The current hype around big data illustrates the desire to analyze ever-growing data sets. Process mining starts from event logsmultisets of traces (sequences of events)and for the widespread application of process mining it is vital to be able to handle big event logs. Some event logs are big because they contain many traces. Others are big in terms of different activities. Most of the more advanced process mining algorithms (both for process discovery and conformance checking) scale very badly in the number of activities. For these algorithms, it could help if we could split the big event log (containing many activities) into a collection of smaller event logs (which each contain fewer activities), run the algorithm on each of these smaller logs, and merge the results into a single result. This paper introduces ageneric framework for doing exactly that, and makes this concrete by implementing algorithms for decomposed process discovery and decomposed conformance checking using Integer Linear Programming (ILP) based algorithms. ILP-based process mining techniques provide precise results and formal guarantees (e.g., perfect fitness), but are known to scale badly in the number of activities. A small case study shows that we can gain orders of magnitude in run-time. However, in some cases there is tradeoff between run-time and quality.  Springer International Publishing Switzerland 2015. Big data; Conformance analysis; Decomposition; Process discovery

Discovery of personal processes from labeled sensor data - An application of process mining to personalized health care Currently, there is a trend to promote personalized health care in order to prevent diseases or to have a healthier life. Using current devices such as smart-phones and smart-watches, an individual can easily record detailed data from her daily life. Yet, this data has been mainly used for self-tracking in order to enable personalized health care. In this paper, we provide ideas on how process mining can be used as a fine-grained evolution of traditional self-tracking. We have applied the ideas of the paper on recorded data from a set of individuals, and present interesting conclusions and challenges. 

Genetic process mining: Alignment-based process model mutation The Evolutionary Tree Miner (ETM) is a genetic process discovery algorithm that enables the user to guide the discovery process based on preferences with respect to four process model quality dimensions: replay fitness, precision, generalization and simplicity. Traditionally, the ETM algorithm uses random creation of process models for the initial population, as well as random mutation and cross over techniques for the evolution of generations. In this paper, we present an approach that improves the performance of the ETM algorithm by enabling it to make guided changes to process models, in order to obtain higher quality models in fewer generations. The two parts of this approach are: (1) creating an initial population of process models with a reasonable quality; (2) using information from the alignment between an event log and a process model to identify quality issues in a given part of a model, and resolving those issues using guided mutation operations  Springer International Publishing Switzerland 2015. 

First Steps Towards Process Mining in Distributed Health Information Systems Business Intelligence approaches such as process mining can be applied to the healthcare domain in order to gain insight into the complex processes taking place. Disclosing asis processes helps identify room for improvement and answers questions from medical professionals. Existing approaches are based on proprietary log data as input for mining algorithms. Integrating the Healthcare Enterprise (IHE) defines in its Audit Trail and Node Authentication (ATNA) profile how real-world events must be recorded. Since IHE is used by many healthcare providers throughout the world, an extensive amount of log data is produced. In our research we investigate if audit trails, generated from an IHE test system, carry enough content to successfully apply process mining techniques. Furthermore we assess the quality of the recorded events in accordance with the maturity level scoring system. A simplified simulation of the organizational workflow in a radiological practice is presented. Based on this simulation a process miing task is conducted.  2015 Emmanuel Helm et al. audit trail and node authentication; digital imaging and communications in medicine; extensible event stream; integrating the healthcare enterprise; process mining; RFC-3881

Implementing process mining to improve COBIT 5 assessment program or managing operations (Case study: A university blog) ISACAs COBIT is widely used to assess the maturity of process capability in many enterprises. Its last version is COBIT 5, which proposes a process assessment as a part of a process improvement initiative or as part of a capability determination approach. Two important steps of the COBIT 5 assessment process are data collection and data validation. This paper proposes process mining as a method to improve the traditional data collection and validation. An internal blog of a private university in Indonesia is analyzed as a case study to implement the model being proposed. The result shows that this model is proven as implementable in a real case of managing operations of a university blog. The resulted findings of the process mining can be combined with the findings of other assessment methods to enhance the result of the assessment program.  2005 - 2015 JATIT & LLS. All rights reserved. Assessment program; COBIT 5; Data collection; Log data; Process mining

Using context overlays to analyse the role of a priori information with Process Mining Notwithstanding the significant advances in context-aware computing in pervasive computing and self-adaptive systems, there is still much more to be desired in providing better context services. The number of sensors deployed world-wide increases very rapidly. The Internet of Things, amongst others, generates vast amounts of data of many different data types. How data are used is essential to improve user experience and efficiencies of the systems in which they occur. We explain how familiar concepts of Process Mining strengthen generalised sensor context services. We present a laboratory case to explain the approach. By way of a real-world example, we confirm the viability of using Process Mining to strengthen context-aware computing.  2015 IEEE. Context-aware computing; Pervasive computing; Process mining; Self-adaptive systems

Leveraging process mining on service events towards service composition Service composition is a widely-used approach in the development of applications. However, well-designed service composition approaches always lacks the consideration of execution environment, and the approach designed for application execution is usually incomplete and lacking necessary business consideration. In order to improve the comprehensiveness covered both design and execution stages, a service composition approach based on process mining is proposed. First, a meta-model is designed to connect the information of execution environment and business requirement. Next, the scene model based on this meta-model is generated by leveraging process mining. Then the scene model is applied to do service composition, including service selection from the Service Registry. After that, BPEL instance is converted based on aggregated scene information so as to enable application execution. Finally, a cloud-based logistics platform is implemented to verify the approach, and the result shows that the approach has high requirement accuracy and execution effectiveness.  Springer International Publishing Switzerland 2015. Cloud computing; Process mining; Service composition; Service composition pattern

Analysis of Hospital Processes with Process Mining Techniques Process mining allows for discovery, monitoring, and improving processes identified in information systems from their event logs. In hospital environments, process analysis has been a crucial factor for cost reduction, control and proper use of resources, better patient care, and achieving service excellence. This paper presents a new component for event logs generation in the Hospital Information System or HIS, developed at University of Informatics Sciences. The event logs obtained are used for analysis of hospital processes with process mining techniques. The proposed solution intends to achieve the generation of event logs in the system with high quality. The performed analyses allowed for redefining functions in the system and proposed proper flow of information. The study exposed the need to incorporate process mining techniques in hospital systems to analyze the processes execution. Moreover, we illustrate its application for making clinical and administrative decisions for the management of hospital activities.  2015 IMIA and IOS Press. Event logs; Hospital environment; Hospital Information System; Process mining; Process model

Process mining on databases: Unearthing historical data from redo logs Process Mining techniques rely on the existence of event data. However, in many cases it is far from trivial to obtain such event data. Considerable efforts may need to be spent on making IT systems record historic data at all. But even if such records are available, it may not be possible to derive an event log for the case notion one is interested in, i.e., correlating events to form process instances may be challenging. This paper proposes an approach that exploits a commonly available and versatile source of data, i.e. database redo logs. Such logs record the writing operations performed in a general-purpose database for a range of objects, which constitute a collection of events. By using the relations between objects as specified in the associated data model, it is possible to turn such events into an event log for a wide range of case types. The resulting logs can be analyzed using existing process mining techniques.  Springer International Publishing Switzerland 2015. Data model; Database; Historical data; Process mining; Redo log; Trace creation; Transitive relations

A proposal of using DEVS model for process mining Process mining is a relative young research area which consists of process modeling and data mining. Process discovery as a part of the process mining focuses on converting event logs into process models. Petri Nets formalism is identified as the most convenient resulting process model. However, it is not entirely satisfying and needs to be improved with the purpose of covering the temporal aspects of the studied system. Compared with it, DEVS has the advantage of explicit and concurrent time and separating model from simulation. The objective of this paper is to specify DEVS model as the resulting process model. Based on the existing Two- Phased Approaches in process mining, a region-based approach with the suitable mapping is designed to convert the transition system directly to DEVS. A study case is presented to implement this approach. This paper is a position paper and it needs to be completed. In addition, a dynamic semantic should be designed to solve some typical representational limitations and a simulation engine should be selected. DEVS; Dynamic semantic; Process discovery; Process mining; Time

Analyzing a TCP/IP-Protocol with process mining techniques In many legacy software systems the communication between client and server is based on proprietary Ethernet protocols. We consider the case that the implementation and specification of such a protocol is unknown and try to reconstruct the rules of the protocol by observation of the network communication. To this end, we translate TCP/IP-logs to appropriate event logs and apply Petri net based process mining techniques. The results of this contribution are a systematic approach to mine client/server protocols, an according tool chain involving existing tools and new tools, and an evaluation of this approach, using a concrete example from practice.  Springer International Publishing Switzerland 2015. 

A methodology for discovering Bayesian networks based on process mining Current maintenance methods are based on the concept of Prediction-and-Prevention, featuring a proactive maintenance schedules that are based on monitoring, diagnosis, prognosis, where maintenance decision-making becomes complex. In this context, many maintenance models have been presented in the literature, with increasing emphasis on addressing the use of Bayesian Networks (BN). This paper proposes a methodology to obtain BN models from a process maintenance database. By using Process Mining techniques applied on maintenance events logs and the computational tool PROM, we seek to obtain variables, network structure and probabilities. The BN model obtained corresponds to effect-cause-action failure relationships and can be used for aid in prognosis and diagnosis of faults and analysis of improvements in maintenance decision making. A Colored Petri Net process model is used to validate the methodology presented. Bayesian networks; Decision making; Maintenance management; Process mining

Process mining event logs from FLOSS data: State of the art and perspectives Free/Libre Open Source Software (FLOSS) is a phenomenon that has undoubtedly triggered extensive research endeavors. At the heart of these initiatives is the ability to mine data from FLOSS repositories with the hope of revealing empirical evidence to answer existing questions on the FLOSS development process. In spite of the success produced with existing mining techniques, emerging questions about FLOSS data require alternative and more appropriate ways to explore and analyse such data.In this paper, we explore a different perspective called process mining. Process mining has been proved to be successful in terms of tracing and reconstructing process models from data logs (event logs). The chief objective of our analysis is threefold. We aim to achieve: (1) conformance to predefined models; (2) discovery of new model patterns; and, finally, (3) extension to predefined models.  Springer International Publishing Switzerland 2015. 

A Co-training strategy for multiple view clustering in process mining Process mining refers to the discovery, conformance and enhancement of process models from event logs currently produced by several information systems (e.g. workflow management systems). By tightly coupling event logs and process models, process mining makes possible to detect deviations, predict delays, support decision making and recommend process redesigns. Event logs are data sets containing the executions (called traces) of a business process. Several process mining algorithms have been defined to mine event logs and deliver valuable models (e.g. Petri nets) of how logged processes are being executed. However, they often generate spaghetti-like process models, which can be hard to understand. This is caused by the inherent complexity of real-life processes, which tend to be less structured and more flexible than what the stakeholders typically expect. In particular, spaghetti-like process models are discovered when all possible behaviors are shown in a single model as a result of considering the set of traces in the event log all at once. To minimize this problem, trace clustering can be used as a preprocessing step. It splits up an event log into clusters of similar traces, so as to handle variability in the recorded behavior and facilitate process model discovery. In this paper, we investigate a multiple view aware approach to trace clustering, based on a co-training strategy. In an assessment, using benchmark event logs, we show that the presented algorithm is able to discover a clustering pattern of the log, such that related traces result appropriately clustered. We evaluate the significance of the formed clusters using established machine learning and process mining metrics.  2015 IEEE. Clustering; Co-training; Multiple view learning; Process mining

Process Mining for Trust Monitoring Communicating systems are today composed of a huge number of distributed processes interoperate with diverse kinds of applications, services and actors. It therefore becomes crucial to monitor and manage these trustworthy interactions. For that purpose, passive testing techniques have been used particularly for checking the system conformance w.r.t. Its standard. Among these studies, trust behaviors have been monitored in such systems. However, while several approaches have been designed, most of them monitor trust properties that have been manually designed or provided by common database. In this paper, we propose a novel approach to automatically generate trust properties from the study and analysis of the system through process mining techniques and by comparing with the formal specification of the system under test.  2015 IEEE. Communication systems; Monitoring; Process mining; Trust

Process mining through artificial neural networks and support vector machines: A systematic literature review Purpose  Process mining is a research area used to discover, monitor and improve real business processes by extracting knowledge from event logs available in process-aware information systems. The purpose of this paper is to evaluate the application of artificial neural networks (ANNs) and support vector machines (SVMs) in data mining tasks in the process mining context. The goal was to understand how these computational intelligence techniques are currently being applied in process mining. Design/methodology/approach  The authors conducted a systematic literature review with three research questions formulated to evaluate the use of ANNs and SVMs in process mining. Findings  The authors identified 11 papers as primary studies according to the criteria established in the review protocol. Most of them deal with process mining enhancement, mainly using ANNs. Regarding the data mining task, the authors identified three types of tasks used: categorical prediction (or classification); numeric prediction, considering the regression type, and clustering analysis. Originality/value  Although there is scientific interest in process mining, little attention has been specifically given to ANNs and SVM. This scenario does not reflect the general context of data mining, where these two techniques are widely used. This low use may be possibly due to a relative lack of knowledge about their potential for this type of problem, which the authors seek to reverse with the completion of this study.  2015, Emerald Group Publishing Limited. Artificial neural networks; Computational intelligence; Data mining; Process mining; Support-vector machines

Capturing the sudden concept drift in process mining Concept drift is the condition when the process changes during the course of execution. Current methods and analysis techniques existing in process mining are not proficient of analyzing the process which has experienced the concept drift. State-of-the-art process mining approaches consider the process as a static entity and assume that process remains same from beginning of its execution period to end. Emphasis of this paper is to propose the technique for localizing concept drift in control-flow perspective by making use of activity correlation strength feature extracted using process log. Concept drift in the process is localized by applying statistical hypothesis testing methods. The proposed method is verified and validated on few of the real-life and artificial process logs, results obtained are promising in the direction of efficiently localizing the sudden concept drifts in process-log. Activity correlation strength; Concept drift; Event class correlation; Process mining; Sudden drift

A process mining technique using pattern recognition Several works have proposed process mining techniques to discover process models fromevent logs. With the existing works, mined models can be built based on analyzing the relationship between any two events seen in event logs. Being restricted by that, they can only handle special cases of routing constructs and often produce unsound models that do not cover all of the traces in the logs. In this paper, we propose a novel technique for process mining based on using a pattern recognition technique called Maximal Pattern Mining (MPM). Our MPM technique can handle loops (of any length), duplicate tasks, non-free choice constructs, and long distance dependencies. Furthermore, by using the MPM, the discovered models are generally much easier to understand. 

A systematic methodology for outpatient process analysis based on process mining Healthcare industry is competitive due to the increase in demand for medical services caused by population aging and improved standards of living. In accordance with this trend, there have been several studies investigating how clinical processes can be improved such as decreasing the waiting time for consultation, optimizing reservation systems, etc. To improve clinical processes in hospitals, understanding current situations and identifying problems are critical. In this paper, a method to analyze outpatient processes based on process mining is suggested. Process mining aims at extracting knowledgeable information from event logs. The proposed methodology consists of data integration, data exploration, data analysis, and discussion steps. In the data analysis, process discovery and matching rate analysis, process pattern analysis and what-if analysis based on performance analysis are conducted by applying several process mining techniques. To validate the proposed method, a case study is conducted with a tertiary general university hospital in Korea.  INTERNATIONAL JOURNAL OF INDUSTRIAL ENGINEERING. Case study; Healthcare; Outpatient process analysis; Process mining

A method for analyzing time series data in process mining: Application and extension of decision point analysis The majority of process mining techniques focuses on control flow. Decision Point Analysis (DPA) exploits additional data attachments within log files to determine attributes decisive for branching of process paths within discovered process models. DPA considers only single attribute values. However, in many applications, the process environment provides additional data in form of consecutive measurement values such as blood pressure or container temperature. We introduce the DPATS method as an iterative process for exploiting time series data by combining process and data mining techniques. The latter ranges from visual mining to temporal data mining techniques such as dynamic time warping and response feature analysis. The method also offers different approaches for incorporating time series data into log files in order to enable existing process mining techniques to be applied. Finally, we provide the simulation environment DPATSSim to produce log files and time series data. The DPATS method is evaluated based on application scenarios from the logistics and medical domain.  Springer International Publishing Switzerland 2015. Data mining; Decision mining; Process mining; Time series data

Designing application to support process audit using process mining Process audit is a mechanism that is frequently used by organizations to ensure the quality of their implemented processes. In auditing, auditors often conduct testing based on sample data taken randomly. The auditors can use computerized data sources, such as event logs which are automatically recorded in the information system. Event logs illustrates how business processes run in real process in the organization. This paper suggests the use of process mining in auditing business processes based on data from event logs stored in information systems. We propose the complete guide to use process mining in business process audit, from planning to the evaluation. We also design an application which implements process mining to support business process audit. This is expected to improve the quality of audit recommendations, because they are based on the overall data in the event logs.  2005-2015 JATIT & LLS. All rights reserved. Application; Event logs; Process audit; Process mining

Application of process mining and semantic structuring towards a lean healthcare network Modern healthcare systems are evolving towards a complex network of interconnected services. The increasing costs and the conversely increased expectations for high service levels leveraged the birth of healthcare monitoring activities and the proposition of numerous performance evaluation indicators. Generally, the adopted performance measures allow to draw a picture of quality, equity, appropriateness and efficiency of the medical care at different levels: caregiver, hospital, local health authority, region. The role of network organization and its impact on the performances is largely underestimated. It is difficult to build a Value Stream Mapping of the healthcare network because of the number and complexity of care and diseases followed. The study tries to overcome this issue. Starting from a database of the accesses to the services in a local health agency, the activity flow diagram is produced by using a process mining software, Disco. A knowledge structured by means of an ontology allows to describe the logic behind the health service provision. The resulting process flow chart is the base for the identification and amendment of redundant and non value added flows among services.  IFIP International Federation for Information Processing 2015. Healthcare network; Ontology; Process mining

Clinical processes and its data, what can we do with them? Global healthcare services have evolved over time, and nowadays they are expected to follow high-quality optimized standards. Analyzing healthcare processes has become a relevant field of study, and different techniques and tools have been developed to promote improvements in the efficiency and effectiveness of these processes. There is a research field called process mining that can be used to extract knowledge from the event data stored in the hospital information systems. With the help of this, it is possible to discover the real executed process, examine its performance and analyze the resource interaction during its execution. The goal of this article is to provide a bibliographic survey about the use of process mining algorithms, techniques, and tools in the analysis of healthcare processes, providing a general overview about the main approaches previously used and the information required to apply them in the medical field. We provide important insights about data, algorithms, techniques and methodologies that are required to help answer medical expert questions about their processes, motivating and inspiring a broader usage. So, if we have the information and it is possible to analyze and understand the healthcare processes, why are we not doing it? Healthcare data; Healthcare processes; Process discovery; Process mining; Process mining methodology

Scalable process discovery with guarantees Considerable amounts of data, including process event data, are collected and stored by organisations nowadays. Discovering a process model from recorded process event data is the aim of process discovery algorithms. Many techniques have been proposed, but none combines scalability with quality guarantees, e.g. can handle billions of events or thousands of activities, and produces sound models (without deadlocks and other anomalies), and guarantees to rediscover the underlying process in some cases. In this paper, we introduce a framework for process discovery that computes a directly-follows graph by passing over the log once, and applying a divide-and-conquer strategy. Moreover, we introduce three algorithms using the framework.We experimentally show that it sacrifices little compared to algorithms that use the full event log, while it gains the ability to cope with event logs of 100,000,000 traces and processes of 10,000 activities.  Springer International Publishing Switzerland 2015 Big data; Block-structured process discovery; Directly-follows graphs; Rediscoverability; Scalable process mining

Finding suitable activity clusters for decomposed process discovery Event data can be found in any information system and provide the starting point for a range of process mining techniques. The widespread availability of large amounts of event data also creates new challenges. Existing process mining techniques are often unable to handle big event data adequately. Decomposed process mining aims to solve this problem by decomposing the process mining problem into many smaller problems which can be solved in less time, using less resources, or even in parallel. Many decomposed process mining techniques have been proposed in literature. Analysis shows that even though the decomposition step takes a relatively small amount of time, it is of key importance in finding a high-quality process model and for the computation time required to discover the individual parts. Currently there is no way to assess the quality of a decomposition beforehand. We define three quality notions that can be used to assess a decomposition, before using it to discover a model or check conformance with. We then propose a decomposition approach that uses these notions and is able to find a high-quality decomposition in little time.  IFIP International Federation for Information Processing 2015. Decomposed process discovery; Decomposed process mining; Distributed computing; Event log

Exploring processes and deviations In process mining, one of the main challenges is to discover a process model, while balancing several quality criteria. This often requires repeatedly setting parameters, discovering a map and evaluating it, which we refer to asprocess exploration. Commercial process mining tools like Disco, Perceptive and Celonis are easy to use and have many features, such as log animation, immediate parameter feedback and extensive filtering options, but the resulting maps usually have no executable semantics and due to this, deviations cannot be analysed accurately. Most more academically oriented approaches (e.g., the numerous process discovery approaches supported by ProM) use maps having executable semantics (models), but are often slow, make unrealistic assumptions about the underlying process, or do not provide features like animation and seamless zooming. In this paper, we identify four aspects that are crucial for process exploration:zoomability, evaluation, semantics,andspeed.Wecompare existing commercial tools and academic workflows using these aspects, and introduce a new tool, that aims to combine the best of both worlds. A feature comparison and a case study show that our tool bridges the gap between commercial and academic tools.  Springer International Publishing Switzerland 2015. Conformance analysis; Multi-perspective process mining; Process deviation visualisation; Process exploration

Mining the organisational perspective in agile business processes Agile processes depend on human resources, decisions and expert knowledge, and they are especially versatile and comprise rather complex scenarios. Declarative, i.e., rule-based, process models are wellsuited for modelling these processes. Although there are several mining techniques to discover such declarative process models from event logs, they put less emphasis on the organisational perspective, which specifies how resources are involved in the activities. As a consequence, the resulting models do not specify who should execute which task and with which constraint (like separation of duties) in mind. In this paper, we propose a process mining approach to discover resource-aware, declarative process models. Our specific contribution is the extraction of complex rules for resource assignment that integrate the control-flow and organisational perspectives. Our experiments demonstrate the expressiveness of the mined rules with a reference to the Workflow Resource Patterns and a real-world use case.  Springer International Publishing Switzerland 2015 Declarative process mining; Event log analysis; Organisational perspective; Resource perspective

Mining multi-variant process models from low-level logs Process discovery techniques are a precious tool for analyzing the real behavior of a business process. However, their direct application to lowly structured logs may yield unreadable and inaccurate models. Current solutions rely on event abstraction or trace clustering, and assume that log events refer to well-defined (possibly low-level) process tasks. This reduces their suitability for logs of real BPM systems (e.g. issue management) where each event just stores several data fields, none of which fully captures the semantics of performed activities. We here propose an automated method for discovering an expressive kind of process model, consisting of three parts: (i) a logical event clustering model, for abstracting low-level events into classes; (ii) a logical trace clustering model, for discriminating among process variants; and (iii) a set of workflow schemas, each describing one variant in terms of the discovered event clusters. Experiments on a real-life data confirmed the capability of the approach to discover readable high-quality process models.  Springer International Publishing Switzerland 2015. Business process mining; Log abstraction; Trace clustering

Automatic process model discovery from textual methodologies: An archaeology case study Process mining has been successfully used in automatic knowledge discovery and in providing guidance or support. The known process mining approaches rely on processes being executed with the help of information systems thus enabling the automatic capture of process traces as event logs. However, there are many other fields such as Humanities, Social Sciences and Medicine where workers follow processes and log their execution manually in textual forms instead. The problem we tackle in this paper is mining process instance models from unstructured, text-based process traces. Using natural language processing with a focus on the verb semantics, we created a novel unsupervised technique TextProcessMiner that discovers process instance models in two steps: 1.ActivityMiner mines the process activities; 2.ActivityRelationshipMiner mines the sequence, parallelism and mutual exclusion relationships between activities. We employed technical action research through which we validated and preliminarily evaluated our proposed technique in an Archaeology case. The results are very satisfactory with 88% correctly discovered activities in the log and a process instance model that adequately reflected the original process. Moreover, the technique we created emerged as domain independent.  2015 IEEE. natural language processing; process mining; process mining technique; process model; technical action research

A hybrid approach to extract business process models with high fitness and precision Process mining (PM) aims at extracting a process model from an event log to represent the process behavior recorded in that event log. An extracted process model with high fitness and precision means it can reflect most of the process behavior recorded in the event log (fitness) and will not generate extra behavior not recorded in the event log (precision). Most of the existing PM methods, such as the genetic process mining (GPM), focused only on the achievement of high fitness, but ignore the pursuit of high precision. This research presents a hybrid PM approach that integrates the GPM, particle swarm optimization, and differential evolution to extract process models with high fitness and precision (FP values) from event logs. The results show that the proposed approach achieves improvement in extracting process models from event logs with higher FP values.  2015 Chinese Institute of Industrial Engineers. differential evolution; fitness; genetic process mining; particle swarm optimization; precision; process mining

An optimal process model for a real time process Recommending an optimal path of execution and a complete process model for a real time partial trace of large and complex organization is a challenge. The proposed AlfyMiner (a<inf>y</inf>Miner) does this recommendation in cross organization process mining technique by comparing the variants of same process encountered in different organization. a<inf>y</inf>Miner proposes two novel techniques Process Model Comparator (a<inf>y</inf>Comp) and Resource Behaviour Analyser (RBA<inf>Miner</inf>). a<inf>y</inf>Comp identifies Next Probable Activity of the partial trace along with the complete process model of the partial trace. RBA<inf>Miner</inf>identifies the resources preferable for performing Next Probable Activity and analyse their behaviour based on performance, load and queue. a<inf>y</inf>Miner does this analysis and recommend the best suitable resource for performing Next Probable Activity and process models for the real time partial trace. Experiments were conducted on process logs of CoSeLoG Project1 and 72% of accuracy is obtained in identifying and recommending NPA and the performance of resources were optimized by 59% by decreasing their load. Best resource; Cross organization process mining; Polynomial regression model; Resource behavior; Resource load; Resource performance; Resource queue: Average waiting time

Goal-aligned categorization of instance variants in knowledge-intensive processes Discovering and reasoning about deviations of business process executions (from intended designs) enables organizations to continuously evaluate their execution/performance relative to their strategic goals. We leverage the observation that a deviating process instance can be viewed as a valid variant of the intended process design provided it achieves the same goals as the intended process design. However, organizations often find it difficult to categorize and classify process execution deviations in a goal-based fashion (necessary to decide if a deviation represents a valid variant). Given that industry-scale knowledge-intensive processes typically manifest a large number of variants, this can pose a problem. In this paper, we propose an approach to help decide whether process instances in execution logs are valid variants using the goalbased notion of validity described above. Our proposed approach also enables analysis of the impact of contextual factors in the execution of specific goal-aligned process variants.We demonstrate our approach with an Eclipse-based plugin and evaluate it using an industry-scale setting in IT Incident Management with a process log of 25000 events.  Springer International Publishing Switzerland 2015. Business Process Mining; Goals; Variability

The multi-perspective process explorer Organizations use process mining techniques to analyze event data recorded by their information systems. Multi-perspective process mining techniques make use of data attributes attached to events to analyze processes from multiple perspectives. Applying those multi-perspective process mining techniques in practice is a laborious task when the event data contains a large number of at- Tributes and many different trace variants. Tools that facilitate the usage of these techniques in practical settings are missing. We describe the Multi-perspective Process Explorer as a new tool that integrates current multi-perspective process mining techniques for discovery and conformance checking. It supports common tasks in multi-perspective process mining, and aims to reduce the time needed to explore event data. Copyright  2015 for this paper by its authors. In- Teractive visualization; Multi-perspective process mining; Process analysis; Process exploration; Process mining

Quality criteria in process mining [No abstract available] 

Change point detection and dealing with gradual and multi-order dynamics in process mining In recent years process mining techniques have matured. Provided that the process is stable and enough example traces have been recorded in the event log, it is possible to discover a high-quality process model that can be used for performance analysis, compliance checking, and prediction. Unfortunately, most processes are not in steady-state and process discovery techniques have problems uncovering secondorder dynamics (i.e., the process itself changes while being analyzed). This paper describes an approach to discover a variety of concept drifts in processes. Unlike earlier approaches, we can discover gradual drifts and multi-order dynamics (e.g., recurring seasonal effects mixed with the effects of an economic crisis). We use a novel adaptive windowing approach to robustly localize changes (gradual or sudden). Our extensive evaluation (based on objective criteria) shows that the new approach is able to efficiently uncover a broad range of drifts in processes.  Springer International Publishing Switzerland 2015. 

Logic-based incremental process mining Manually building process models is complex, costly and error-prone. Hence, the interest in process mining. Incremental adaptation of the models, and the ability to express/learn complex conditions on the involved tasks, are also desirable. First-order logic provides a single comprehensive and powerful framework for supporting all of the above. This paper presents a First-Order Logic incremental method for inferring process models. Its efficiency and effectiveness were proved with both controlled experiments and a real-world dataset.  Springer International Publishing Switzerland 2015. 

Process mining [No abstract available] 

Process mining for stream data sources [No abstract available] 

Obstacles to applying process mining in practice [No abstract available] 

Multidimensional process mining with PMCube explorer Process mining techniques allow process analysts to generate process models from recorded event logs. Typically, process mining considers the event log as a whole and creates a single model reflecting its behavior. However, the process may be influenced by several characteristics of the process instances, e.g., by the individual characteristics of a patient in the healthcare domain like age and sex. This leads to a wide range of process variations which can end up in complex and confusing models, blurring the behavior of specific process variants. Multidimensional process mining (MPM) aims to overcome this limitation by the notion of data cubes, spreading the data over multiple cells, each representing a group of cases with similar characteristics. This allows for the creation of separated process models for a homogenous set of cases. In this paper, we introduce PMCube Explorer, a novel tool for MPM, that allows for the analysis of a process from various views. It enables the analyst to specify OLAP queries to extract multiple cells from the data warehouse. Each cell contains a subset of event data which are mined separately to discover independent process models. To deal with the potentially high amount of resulting models, our tool provides some distinctive features like the visualization of model differences or the consolidation of multiple process models.We applied our tool in a case study to analyze the perioperative processes in a large German hospital. Copyright  2015 for this paper by its authors. 

From early experiments to a company-wide process mining success (extended abstract) [No abstract available] 

Discovering attack strategies using process mining Intrusion Detection Systems generate alerts which depend on manual analysis of a specialist to determine a response plan. However, these systems usually trigger thousands of alerts per day. Investigating unmanageable amounts of alerts manually becomes burdensome and error-prone. Besides, it complicates the analysis of critical alerts. In this paper, an approach is proposed to facilitate the investigation of huge amounts of intrusion detection alerts by a specialist. The proposed approach makes use of process mining techniques to discover attack strategies observed in intrusion alerts, which are presented to the network administrator in friendly visual models. Tests were performed using a real dataset from the University of Maryland. The results show that the proposed approach combines visual features along with quantitative measures that help the network administrator to analyze the alerts in an easy and intuitive manner. Copyright  2015 IARIA. Alert mining; Heuristic mining; Intrusion detection; Security visualization

From IHE Audit Trails to XES Event Logs Facilitating Process Mining Recently Business Intelligence approaches like process mining are applied to the healthcare domain. The goal of process mining is to gain process knowledge, compliance and room for improvement by investigating recorded event data. Previous approaches focused on process discovery by event data from various specific systems. IHE, as a globally recognized basis for healthcare information systems, defines in its ATNA profile how real-world events must be recorded in centralized event logs. The following approach presents how audit trails collected by the means of ATNA can be transformed to enable process mining. Using the standardized audit trails provides the ability to apply these methods to all IHE based information systems.  2015 European Federation for Medical Informatics (EFMI). Data Mining; Process Assessment; Quality of Health Care; Standards

Opportunities for process improvement: A cross-clientele analysis of event data using process mining Services organizations are always under pressure to operate under tight costs and to improve their operational efficiency. Transaction processing is one of the major operations in a services organization. An organization is typically trained to serve a standard set of processes within different domains across several clients. Although each client has their own specifics with respect to a process, there is a lot of commonality within similar processes across clients. An organizations operational KPIs (i.e., Key Performance Indicators like processing time) across these clients when dealing with such related processes might not be similar; an organization might perform well for some clients and perform below par on others. There is a need to gain insights for such variance in performance and seek opportunities to learn from well performing client engagements (e.g., establish best practices) and leverage these learnings/insights on non-performing clients. We present a framework for analysing operational event data of related processes across different clients to gain insights on process executions. We present results of analyzing real-world transaction processing operations of a large services organization using the proposed framework. Our analysis shows that resource workload, clarity of process definitions, experience, and skill proficiency are key factors that influence the average processing time of transactions.  Springer-Verlag Berlin Heidelberg 2015. 

Learning complex activity preconditions in process mining The availability of automatic support may sometimes determine the successful accomplishment of a process. Such a support can be provided if a model of the intended process is available. Many real-world process models are very complex. Additionally, their components might be associated to conditions that determine whether they are to be carried out or not. These conditions may be in turn very complex, involving sequential relationships that take into account the past history of the current process execution. In this landscape, writing and setting up manually the process models and conditions might be infeasible, and even standard Machine Learning approaches may be unable to infer them. This paper presents a First-Order Logic-based approach to learn complex process models extended with conditions. It combines two powerful Inductive Logic Programming systems. The overall system was exploited to learn the daily routines of the user of a smart environment, for predicting his needs and comparing the actual situation with the expected one. In addition to proving the efficiency and effectiveness of the system, the outcomes show that complex, human-readable and interesting preconditions can be learned for the tasks involved in the process.  Springer International Publishing 2015. 

Visual process mining: Event data exploration and analysis The research field of Process Mining deals with the extraction of information from event logs. Since large amounts of event data are generated every day, analyzing these often unstructured event logs poses a research challenge. To cope with the complexity of the data and the associated mining tasks, appropriate visualizations and interactive means are needed. We present our early prototype for the visual exploration of event sequences and patterns. Our approach combines (1) a visual representation of event sequences emphasizing recurring event patterns, (2) automated pattern mining methods, as well as (3) interactive means for exploration. We provide first steps to support browsing event logs in an interactive environment and to facilitate the inspection of recurring pattern locations within the context of the surrounding events.  2014 IEEE. 

Process mining technique for automated simulation model generation using activity log data Generating the structure of a simulation network is one of the most important steps in the process of modeling construction operations using discrete-event simulation (DES). It is, however, a complicated and time-consuming task that requires extensive expert knowledge and data pre-processing, which are needed to establish plausible assumptions to build the network. Often such assumptions fail to capture reality, producing a large discrepancy between the generated simulation model and the underlying actual operation, due to an absence of data or incomplete knowledge of the modeler or subject matter expert (SME). As an alternative solution, this paper proposes an approach to learning the simulation model structure from data. We introduce techniques for discovering workflow models from activity log data, which are time-ordered records of all the activities performed by various types of machines during a given construction operation. The latest advancements in data collection and processing techniques such as activity recognition algorithms have made it possible to harvest activity logs based on sensor-based time series data collected from construction equipment. Since activities are fully ordered and recorded sequentially, these activity logs can be used to construct a process specification which adequately models activity cycle diagram (ACD). We introduce a refined a-algorithm to extract a process model from such log data and represent it in terms of an ACDbased DES model. This paper demonstrates the proposed method in the context of earthmoving operations and shows that it can successfully mine the workflow process of the earthmoving operations represented by an ACD.  2015 ASCE. 

Service analysis and simulation in process mining [No abstract available] 

Dynamic Scoring-Based sequence alignment for process diagnostics Even though process-aware information systems are intensively utilized in the organizations, traditional process management paradigms majorly concentrate on the design and configuration phases. Instead of starting with a process design, process mining attempts to discover interesting patterns from process enactment namely event logs and extract business processes by distilling these event logs as knowledge base. One of the challenging issues in process mining domain is process diagnostics, which is complex and sometimes infeasible, especially when dealing with real-time, flexible and unstructured processes. In this aspect sequence alignment is applicable to find out common subsequences of activities in event logs that are found to recur within the process instances emphasizing some domain significance. In this study, we focus on a hybrid quantitative approach for performing process diagnostics, i.e. comparing the similarity among process models based on dominant behavior concept, confidence metric and Needleman-Wunsch algorithm with dynamic pay-off matrix.  Springer International Publishing Switzerland 2015. Confidence metric; Needleman-Wunsch algorithm with dynamic pay-off matrix; Process diagnostics; Process mining; Sequence alignment

ILP-based process discovery using hybrid regions The language-based theory of regions, stemming from the area of Petri net synthesis, forms a fundamental basis for Integer Linear Programming (ILP)-based process discovery. Based on example behavior in an event log, a process model is derived that aims to describe the observed behavior. Building on top of the existing ILP-formulation, we present a new ILP-based process discovery formulation that unifies two existing types of language-based regions and, additionally, we present a generalized ILP objective function that captures both region-types and helps us to find suitable process discovery results. Integer Linear Programming; Process discovery; Process mining; Region theory

Mining project-oriented business processes Large engineering processes need to be monitored in detail regarding when what was done in order to prove compliance with rules and regulations. A typical problem of these processes is the lack of control that a central process engine provides, such that it is difficult to track the actual course of work even if data is stored in version control systems (VCS). In this paper, we address this problem by defining a mining technique that helps to generate models that visualize the work history as GANTT charts. To this end, we formally define the notion of a project-oriented business process and a corresponding mining algorithm. Our evaluation based on a prototypical implementation demonstrates the benefits in comparison to existing process mining approaches for this specific class of processes.  Springer International Publishing Switzerland 2015. Process mining; Project mining; Projects; Version control systems

Process discovery under precedence constraints Process discovery has emerged as a powerful approach to support the analysis and the design of complex processes. It consists of analyzing a set of traces registering the sequence of tasks performed along several enactments of a transactional system, in order to build a process model that can explain all the episodes recorded over them. An approach to accomplish this task is presented that can benefit from the background knowledge that, in many cases, is available to the analysts taking care of the process (re-)design. The approach is based on encoding the information gathered from the log and the (possibly) given background knowledge in terms of precedence constraints, that is, of constraints over the topology of the resulting process models. Mining algorithms are eventually formulated in terms of reasoning problems over precedence constraints, and the computational complexity of such problems is thoroughly analyzed by tracing their tractability frontier. Solution algorithms are proposed and their properties analyzed. These algorithms have been implemented in a prototype system, and results of a thorough experimental activity are discussed.  2015 ACM. Computational complexity; Graph analysis; Process mining

Detection of sequences with anomalous behavior in a workflow process A workflow process consists of an organized and repeatable pattern of activities that are necessary to complete a task, within the dynamics of an organization. The automatic recognition of deviations from the expected behavior within the workflow of an organization is crucial to provide assistance to new employees to accomplish his/her tasks. In this article, we propose a two-fold approach to this problem. First, taking the process logs as an input, we automatically build a statistical model that captures regularities in the activities carried out by the employees. Second, this model is used to track the activities performed by the employees to detect deviations from the expected behavior, according to the normal workflow of the organization. An experimental evaluation with five processes logs, with different levels of noise, was conducted to determine the validity of our approach.  Springer International Publishing Switzerland 2015. Outliers detection; Process mining

Towards goal-oriented conformance checking Constructing a business process is important area between requirements engineering and business process management. Goal-oriented requirements analysis method is widely researched in requirements engineering and useful for reflecting organizational requirements to business process models, but actual business processes deviate from defined process models. Therefore, it is not sufficient for business process analysis only using model's information. It is important to analyze actual conducted business process logged data. Analyzing business process logged data is called process mining and detecting differences between models and logs is called conformance checking. A lot of conformance checking approaches mainly focus on process aspects of business process, but this is not sufficient for analysis whether actual business processes can satisfy organizational goals. In this paper, we propose a goal-oriented conformance checking approach which can detect deviations between logs and models, and can analyze the effects of the deviation. It is useful for evaluation of the detected deviation. We represent the effectiveness of our approach conducting a case study using the publicly available log. Copyright  2015 by KSI Research Inc. and Knowledge Systems Institute Graduate School. 

CCaaS: Online conformance checking as a service Conformance checking, a method of process mining, is commonly used to assess how well a set of historic log traces fits a given process model, or vice versa. Here we explore online conformance checking, i.e., to check conformance on logs while they are written. This can be useful for near-realtime detection of errors and deviations from the desired path. While the online aspect leads to some challenges, we also study efficient detection of timing anomalies and violations of numerical invariants. The approach is implemented in CCaaS, a RESTful service that detects unfitting events and other errors in split seconds. Copyright  2015 for this paper by its authors. 

Time-gap analysis considering multi-dimensional perspective for process performance evaluation The complex port logistics process remains a challenging domain. In the present study, we closely examined the time gap from a multi-dimensional perspective comprehending the employment of various types of equipment. On the basis of our results, we herein propose a multi-dimensional time-gap analysis method that proceeds via indexing and cross-matching of index values and additionally utilizes two types of multidimensional time-gap analysis that incorporate the input of event logs. Our method can accurately identify, for selected activities, equipment and process instances that affect or cause long time-gap duration. To verify the method, we applied it to the port logistics process of an actual Asian port.  2015, ICIC International. Indexing; Multi-dimensional perspective; Process mining; Time gap analysis

A clinical pathway mining approach to enable scheduling of hospital relocations and treatment services As discussed in numerous studies, clinical pathways of patients form an appropriate tool for describing hospital processes and thereby provide a basis for increasing the effectiveness of hospitals. Developing pathways led to a considerable research investigating IT-techniques to support pathway generation. However, previous research neglected finding pathways designed to support scheduling of hospital relocations and treatment services. To close this gap, we first introduce a clinical pathway concept consisting of both pathway structure and pathway constraints suitable for scheduling tasks. Second, we provide a pathway mining method for automatically extracting corresponding pathways from standard hospital billing data required for the German §21-KHentgG. Applying our approach to a real world dataset of a university hospital, we illustrate the results using a pathway for malignant neoplasm of prostate containing feasible time windows and precedence relations of treatments, durations at attended wards as well as possible process improvements stimulated from the results.  Springer International Publishing Switzerland 2015. Clinical pathway; Hospital; Process mining; Scheduling

Mining users' intents from logs Intentions play a key role in information systems engineering. Research on process modeling has highlighted that specifying intentions can expressly mitigate many problems encountered in process modeling as lack of flexibility or adaptation. Process mining approaches mine processes in terms of tasks and branching. To identify and formalize intentions from event logs, this work presents a novel approach of process mining, called Map Miner Method (MMM). This method automates the construction of intentional process models from event logs. First, MMM estimates users' strategies (i.e., the different ways to fulfill the intentions) in terms of their activities. These estimated strategies are then used to infer users' intentions at different levels of abstraction using two tailored algorithms. MMM constructs intentional process models with respect to the Map metamodel formalism. MMM is applied on a real-world dataset, i.e. event logs of developers of Eclipse UDC (Usage Data Collector). The resulting Map process model provides a precious understanding of the processes followed by the developers, and also provide feedback on the effectiveness and demonstrate scalability of MMM. Copyright  2015, IGI Global. Hidden Markov models; Intentional process models; Machine learning; Process mining

Artifact lifecycle discovery Artifact-centric modeling is an approach for capturing business processes in terms of so-called business artifacts - key entities driving a company's operations and whose lifecycles and interactions define an overall business process. This approach has been shown to be especially suitable in the context of processes where one-to-many or manyto-many relations exist between the entities involved in the process. As a contribution towards building up a body of methods to support artifact-centric modeling, this article presents a method for automated discovery of artifact-centric process models starting from logs consisting of flat collections of event records. We decompose the problem in such a way that a wide range of existing (non-Artifact-centric) automated process discovery methods can be reused in a flexible manner. The presented methods are implemented as a package for ProM, a generic open-source framework for process mining. The methods have been applied to reverse-engineer an artifact-centric process model starting from logs of a real-life business process. Artifact-centric modeling; business process modeling; process mining

Mining learning processes from FLOSS mailing archives Evidence suggests that Free/Libre Open Source Software (FLOSS) environments provide unlimited learning opportunities. Community members engage in a number of activities both during their interaction with their peers and while making use of these environments. As FLOSS repositories store data about participants interaction and activities, we analyze participants interaction and knowledge exchange in emails to trace learning activities that occur in distinct phases of the learning process. We make use of semantic search in SQL to retrieve data and build corresponding event logs which are then fed to a process mining tool in order to produce visual workflow nets. We view these nets as representative of the traces of learning activities in FLOSS as well as their relevant flow of occurrence. Additional statistical details are provided to contextualize and describe these models.  IFIP International Federation for Information Processing 2015. FLOSS learning processes; Learning activities in open source; Mining software repositories; Process mining; Semantic search

Discovery of process in business process outsourcing domain Process mining is an emerging research discipline that sits between computational intelligence and data mining on one hand, and process modeling and analysis on the other [1]. Large volumes of data are stored in the data base in business environment, and in this process many realities are missed to get recorded. This problem can be solved by recording the business events as process itself, and not as data. Process mining has grown like an important and an active area in research. In business environment, from the existing information system, the activities are recorded as events involved in business process. Business process mining takes these event logs to discover process, control, data, organizational, and social structures.This business processes are analyzed based on event logs. These event logs can be extracted from the normal database and coherent information systems. In this paper, the process model is constructed from the unstructured event log [5] by using a set of plug-ins in ProM and Petri Net. This process model discovers a new set of process model which is compared to manually stored logs in the real world business process used in BPO domain. This proposed discovery approaches are useful to make the business process execution settings in an improvised method.  Research India Publications. Business events; Event; Event logs; Process mining; ProM

Discovering information diffusion processes based on hidden markov models for social network services As social network services (SNS) such as Facebook and Twitter have become a major means of communication on the Internet, many studies have been conducted using SNS data. Yet, the studies still have limitations in the viewpoint of dynamics of information. For example, although a variety of social network analytics visualize the relationship among people, they mainly focus on the static relationship rather than dynamic information flow on the social network. In this research, we introduce the Hidden Markov Model for Information Diffusion (HMMID) that applies HMM to process mining techniques in order to discover and visualize information flow from SNS log data. The proposed methodology helps to visualize the sequences and paths of information delivery among users from reality of SNS event log along with their probabilities on the arcs. Experiments with synthetic data and real-life Facebook data were conducted using the HMMID Miner, which have been developed on the ProM framework. The methodology is illustrated with the two kinds of experiments to show how to get knowledge on the information dynamics inside the social network.  Springer International Publishing Switzerland 2015. Hidden markov models; Information diffusion; Probabilistic process discovery; Process mining; Social network analytics

Mining invisible tasks in non-free-choice constructs The discovery of process models from event logs (i.e. process mining) has emerged as one of the crucial challenges for enabling the continuous support in the life-cycle of a process-aware information system. However, in a decade of process discovery research, the relevant algorithms are known to have strong limitations in several dimensions. Invisible task and non-free-choice construct are two important special structures in a process model. Mining invisible tasks involved in nonfree- choice constructs is still one significant challenge. In this paper, we propose an algorithm named a$. By introducing new ordering relations between tasks, a$ is able to solve this problem. a$ has been implemented as a plug-in of ProM. The experimental results show that it indeed significantly improves existing process mining techniques.  Springer International Publishing Switzerland 2015. Invisible tasks; Non-free-choice constructs; Process mining

Extracting data manipulation processes from SQL execution traces Modern data-intensive software systems manipulate an increasing amount of data in order to support users in various execution contexts. Maintaining and evolving activities of such systems rely on an accurate documentation of their behavior which is often missing or outdated. Unfortunately, standard program analysis techniques are not always suitable for extracting the behavior of data-intensive systems which rely on more and more dynamic data access mechanisms which mainly consist in run-time interactions with a database. This paper proposes a framework to extract behavioral models from data-intensive program executions. The framework makes use of dynamic analysis techniques to capture and analyze SQL execution traces. It applies clustering techniques to identify data manipulation functions from such traces. Process mining techniques are then used to synthesize behavioral models.  Springer International Publishing Switzerland 2015. Data-manipulation behavior recovery; Data-manipulation functions; Data-oriented process mining

A new similarity search approach on process models We investigate the problem of similarity search query in process model repositories: given a certain target model, compare with the process models in the repository and find their similar pattern. We seek to find an effective way to mine out the similar patterns. Using four representative models, we evaluate a new approach, with semantic and topological consideration accordingly. The experimental results show that the combination of semantic and topological analysis brings higher retrieval quality in the similarity search on process models.  Springer-Verlag Berlin Heidelberg 2015. Process mining; Process model; Similarity search

Mining social behavior in the classroom Classrooms are very well suited for research on social interactions in the wild. Hundreds of hours of student interactions are rapidly accumulated. In this paper we analyze two months of video recordings from a fourth grade class, where the teacher and a sample of 3 students selected each day wore a mini video camera mounted on eyeglasses. The data reveals different gaze patterns between groups according to gender, subject, student grade point average, sociometric scale and time of day. The patterns that were found demonstrate the promising power of first-person video recordings for understanding social interaction in the classroom.  Springer International Publishing Switzerland 2015. Classroom practices; Educational process mining; Gaze patterns; Mining social behaviour; Video analysis

A framework for next generation e-health systems and services We propose a framework for the development of next generation e-health systems and services. It results from the joint work of diverse research groups with 20 to 25 years of experience in their respective fields (e.g., business process management, medical informatics, business intelligence), and it articulates five elements: the mining of care workflows; their compliance with medical guidelines; their execution in a specialized engine capable of dealing with the inherent variability that exists in healthcare processes; the use of business intelligence techniques; and the integration with communities of practice that are key for the evolution of socio-technical systems. For each area, we describe its context and objectives, the stateof-the-art and challenges, leading up to the proposed innovation and its implications. The framework demonstrates how multidisciplinary research can enable a reinforcement of leadership in healthcare by supporting novel medical care with more predictive, individualized, effective, and safer solutions. Careflow compliance; Careflow management system; Careflows; Healthcare intelligence; Process mining

Avoiding over-fitting in ILP-based process discovery The aim of process discovery is to discover a process model based on business process execution data, recorded in an event log. One of several existing process discovery techniques is the ILP-based process discovery algorithm. The algorithm is able to unravel complex process structures and provides formal guarantees w.r.t. the model discovered, e.g., the algorithm guarantees that a discovered model describes all behavior present in the event log. Unfortunately the algorithm is unable to cope with exceptional behavior present in event logs. As a result, the application of ILP-based process discovery techniques in everyday process discovery practice is limited. This paper addresses this problem by proposing a filtering technique tailored towards ILP-based process discovery. The technique helps to produce process models that are less over-fitting w.r.t. the event log, more understandable, and more adequate in capturing the dominant behavior present in the event log. The technique is implemented in the ProM framework.  Springer International Publishing Switzerland 2015. Filtering; Integer linear programming; Process discovery; Process mining

Evolutionary computation based discovery of hierarchical business process models Business process models that describe how the execution of work in a business is structured are an important asset of modern enterprises. They serve as documentation, and, if easily understandable, allow process stakeholders to make better decisions on the business process. Traditionally, these models have been created manually after analyzing the process, which can lead to outdated information when changes are introduced into the process. Today, information systems connected to the business processes log event data reflecting the real execution of the processes, and process discovery techniques have been developed to automatically extract models from these event logs. Most of these techniques discover well formalized models such as Petri nets, which can be hard to understand in case of larger process models. The evolutionary computation based approach presented in this paper discovers process models complying to the specification of BPMN, one of the most used but not well formalized notations for documenting business processes. Our approach limits the set of possible process models to hierarchically structured models, and therefore facilitates well structured and simple results. An evaluation with eight event logs shows that, despite the limitation to well structured and simple models, the approach delivers competitive results when compared with other process discovery techniques.  Springer International Publishing Switzerland 2015. Business process management; Evolutionary algorithms; Process mining

Process discovery: A new method fitted to big event logs Business process discovery is a research field assembling techniques that allow representation of a business process, taking as input an event log where process data are stored. Several advances have been made in process discovery, but as data volume starts to weight considerably, improvement of discovery methods is crucial to follow up. In this paper, we discuss our new method, inspired from image processing techniques. Adapted to voluminous data logs, our method relies on generation of a Petri net using a matrix representation of data. The principal idea behind our approach consists of using several concepts: partial & feature blocks, filters as well as the adaptation of combinatory logic concepts to process mining in the perspective of extracting a business process model from a big event log.  2015, Asian Research Publishing Network. All rights reserved. Business process management; Distributed algorithm; Process discovery; Process mining

Complex symbolic sequence encodings for predictive monitoring of business processes This paper addresses the problem of predicting the outcome of an ongoing case of a business process based on event logs. In this setting, the outcome of a case may refer for example to the achievement of a performance objective or the fulfillment of a compliance rule upon completion of the case. Given a log consisting of traces of completed cases, given a trace of an ongoing case, and given two or more possible outcomes (e.g., a positive and a negative outcome), the paper addresses the problem of determining the most likely outcome for the case in question. Previous approaches to this problem are largely based on simple symbolic sequence classification, meaning that they extract features from traces seen as sequences of event labels, and use these features to construct a classifier for runtime prediction. In doing so, these approaches ignore the data payload associated to each event. This paper approaches the problem from a different angle by treating traces as complex symbolic sequences, that is, sequences of events each carrying a data payload. In this context, the paper outlines different feature encodings of complex symbolic sequences and compares their predictive accuracy on real-life business process event logs.  Springer International Publishing Switzerland 2015. Complex symbolic Sequence; Predictive monitoring; Process mining

Extracting Markov chain models from protocol execution traces for end to end delay evaluation in wireless sensor networks Many WSN industrial applications impose requirements in terms of end to end delay. However, the end to end delay estimation in WSNs is not a simple task because of the high dynamic of networks, the use of duty-cycled MAC protocols as well as the impact of the routing protocols. Markov-based modelling is an interesting approach to deal with this problem aiming to provide an analytical model useful for understanding protocol's behavior and to estimate the end to end delay, among other performance parameters. However, existing Markov-based analytic models abstract the reality simplifying the analysis and thus resulting models are not accurate enough for estimating the end to end delay. Furthermore, establishing an accurate Markov model using classic approaches is very difficult considering the highly dynamic behavior of the sensor nodes. In this paper, we propose a novel approach to obtain the Markov chain model of sensor nodes by means of Process Mining techniques through the code execution trace. End to end delay is then computed based on this Markov chain. Experimentations were done using IoT-LAB testbed platform. Comparisons in terms of delay are presented for two different metrics of the RPL protocol (hop count and ETX).  2015 IEEE. MAC Protocols; Markov chain; Process Mining; Wireless Sensor Network performance

Using logical decision trees to discover the cause of process delays from event logs In real-world business processes it is often difficult to explain why some process instances take longer than usual to complete. With process mining techniques, it is possible to do an a posteriori analysis of a large number of process instances and detect the occurrence of delays, but discovering the actual cause of such delays is a different problem. For example, it may be the case that when a certain activity is performed or a certain user (or combination of users) participates in the process, the process suffers a delay. In this work, we show that it is possible to retrieve possible causes of delay based on the information recorded in an event log. The approach consists in translating the event log into a logical representation, and then applying decision tree induction to classify process instances according to duration. Besides splitting those instances into several subsets, each path in the tree yields a rule that explains why a given subset has an average duration that is higher or lower than other subsets of instances. The approach is applied in two case studies involving real-world event logs, where it succeeds in discovering meaningful causes of delay, some of which having been pointed out by domain experts.  2015 Elsevier B.V. All rights reserved. Logical decision trees; Performance analysis; Process mining; Regression trees; Root cause analysis

Case analytics workbench: Platform for hybrid process model creation and evolution Hybrid process models are considered an attractive approach for modeling knowledge-intensive processes. A hybrid process model combines both imperative and declarative modeling, which can handle both the structured and the flexible parts of a business process. However, it is difficult and timeconsuming to create and refine a hybrid process model due to its structure complexity and case variability. This paper introduces the Case Analytics Workbench, an end-to-end system to accelerate hybrid process model creation and evolution by combining declarative and imperative process mining, event log clustering and human interaction in a cloud environment. We validated the effectiveness and applicability of our system by performing two case studies from insurance and health care industry respectively.  Springer International Publishing Switzerland 2015. Clustering; CMMN; Hybrid process model; Process mining

Extending process logs with events from supplementary sources Since organizations typically use more than a single IT system, information about the execution of a process is rarely available in a single event log. More commonly, data is scattered across different locations and unlinked by common case identifiers. We present a method to extend an incomplete main event log with events from supplementary data sources, even though the latter lack references to the cases recorded in the main event log. We establish this correlation by using the controlflow, time, resource, and data perspectives of a process model, as well as alignment diagnostics. We evaluate our approach on a real-life event log and discuss the reliability of the correlation under different circumstances. Our evaluation shows that it is possible to correlate a large portion of the events by using our method.  Springer International Publishing Switzerland 2015. Data Petri nets; Event correlation; Process logs; Process mining

Correlation mining: Mining process orchestrations without case identifiers Process discovery algorithms aim to capture process orchestration models from event logs. These algorithms have been designed for logs in which events that belong to the same case are related to each other - and to that case - by means of a unique case identifier. However, in service oriented systems these case identifiers are usually not stored beyond request-response pairs, which makes it hard to relate events that belong to the same case. This is known as the correlation challenge. This paper addresses the correlation challenge by introducing a new process discovery algorithm, called the correlation miner, that facilitates process discovery when events are not associated with a case identifier. Experiments performed on both synthetic and real-world event logs show the applicability of the correlation miner.  Springer-Verlag Berlin Heidelberg 2015. Event correlation; Process discovery; Process mining

Enterprise operational analysis using DEMO and the enterprise operating system Monitoring and analyzing the operation of enterprises is a key capability of Governance, Risk, and Compliance (GRC) solutions and is relevant for high-risk organizations, such as financial services. The potential of state-of-the-art process mining (data-driven process analysis) is limited by quality issues with transactional data registration and extraction. A novel approach is proposed to address these challenges: the Enterprise Operational Analysis (EOA) founded in DEMO and the Enterprise Operating System (EOS). The EOS is a software system based on enterprise engineering, and stores, interprets, and executes DEMO models as native source code. The EOS provides workflow-like capabilities and supports EOA. Combining the EOS with state-of-the-art process mining offers the following advantages: guaranteed completeness of analysis, elimination of mining for events, facilitating process conformance checking, analysis on various levels of granularity from various perspectives. It enables enterprises to systematically analyze, improve and deploy business procedures. A professional business case is analyzed.  Springer International Publishing Switzerland 2015. Demo methodology; Enterprise operating system; Enterprise operational analysis; Governance risk compliance; Process mining

Constructing probabilistic process models based on hidden markov models for resource allocation A Hidden Markov Model (HMM) is a temporal statistical model which is widely utilized for various applications such as gene prediction, speech recognition and localization prediction. HMM represents the state of the process in a discrete variable, where the values are the possible observations of the world. For the purpose of process mining for resource allocation, HMM can be applied to discover a probabilistic workflow model from activities and identify the observations based on the resources utilized by each activity. In this paper, we introduce a process discovery method that combines an organizational perspective with a probabilistic approach to address the resource allocation and improve the productivity of resource management, maximizing the likelihood of the model using the Expectation-Maximization procedure.  Springer International Publishing Switzerland 2015. Hidden markov models; Probabilistic process discovery; Process mining; Resource allocation

A sequential data analysis approach to electronic health record workflow Failure to understand clinical workflow across electronic health record (EHR) tasks is a significant contributor to usability problems. In this paper, we employed sequential data analysis methods with the aim of characterizing patterns of 5 clinicians' information-gathering across 66 patients. Two analyses were conducted. The first one characterized the most common sequential patterns as reflected in the screen transitions. The second analysis was designed to mine and quantify the frequency of sequence occurrence. We observed 27 screen-transition patterns that were employed from 2 to 7 times. Documents/Images and Intake/Output screens were viewed for nearly all patients indicating the importance of these information sources. In some cases, they were viewed more than once which may show that users are following inefficient patterns in the information gathering process. New quantitative methods of analysis as applied to interaction data can yield critical insights in robust designs that better support clinical workflow.  2015 The authors and IOS Press. Electronic health records; process mining; sequential pattern analysis; usability

Slice and Connect: Tri-Dimensional Process Discovery with Case Study of Port Logistics Process One problem of process discovery is the duplicated task, a task that appears multiple times in one process model. This paper presents "Slice and Connect," an automated tri-dimensional process discovery technique considering duplicated task. It adds the notion of pool as a group of tasks that belongs to a single entity (e.g. department, organization, country). The algorithm entails two steps: first, the event log is sliced according to the pool attribute, and then the pool dependency network (PDN) is discovered. Second, the inter-pool dependency is calculated to connect the PDNs, the result of which is a process model represented as an integrated dependency network (IDN). Duplicated task is only allowed within a different pool to clearly separate the activity context in IDN. The complexity of the process model thereby is increased; therefore, the comprehensibility of the process model is also increased.  2015 The Authors. BPMN; multi-dimensional process model; port logistics; process discovery; process mining

Towards process instances building for spaghetti processes Process Mining techniques aim at building a process model starting from an event log generated during the execution of the pro- cess. Classical process mining approaches have problems when dealing with Spaghetti Processes, i.e. processes with little or no structure, since they obtain very chaotic models. As a remedy, in previous works we pro- posed a methodology aimed at supporting the analysis of a spaghetti process by means of its most relevant subprocesses. Such approach ex- ploits graph-mining techniques, thus requiring to reconstruct the set of process instances starting from the sequential traces stored in the event log. In the present work, we discuss the main problems related to process instances building in spaghetti contexts, and introduce a proposal for ex- tending a process instance building technique to address such issues. Process instances building; Process mining; Spaghetti processes

Modelling and analysis of process execution based on data acquired from sensors networks This paper proposes a new approach for the analysis of physical processes. Based on several assumptions regarding the information available regarding the physical processes, we constrain the generation of the transition system. The method is based on the theory of regions that allows for the building compact representations as Petri Nets of transition systems and a set of explicit descriptions for some of the activities. The resulting compact model will exhibit the same behaviour as the input transition system. In order to evaluate the resulting process model, several quality dimensions have been established. Copyright  2015 SCITEPRESS - Science and Technology Publications. Future internet enterprise systems; Process mining

A thermometer for interdependence: Exploring patterns of interdependence using networks of affordances Interdependence is a central concept in systems and organizations, yet our methods for measuring it are not well developed. Here, we report on a novel method for transforming digital trace data into networks of events that can be used to visualize and measure interdependence. The edges in the network represent sequential flow and the vertices represent actors, actions and artifacts. We refer to this representation as an affordance network. As with conventional approaches such as process mining, our method uses input from a stream of time-stamped occurrences, but the representation is simpler and more appropriate for exploration and theory building. As digital trace data becomes more widely available, this method may become more useful in information systems research and practice. Like a thermometer, it helps us measure a basic property of a system that would otherwise be difficult to see. Affordance network; Exploratory data analysis; Interdependence; Narrative network; Organizational routines; Process mining

Developing a workflow management system for enterprise resource planning The company generally requires an application that can be easily configured. This can happen if the application is supported by the Workflow Management System (WFMS). WFMS which built serves to store a variety of common workflows and varied. In addition to working as a storage place, WFMS also has the ability to generate an event log that can be analyzed with the application process workflow mining and semantic search. Semantically workflows searching are e by annotated workflow metadata using the Ontology Web Language for Services (OWL-S). The capabilities of workflows searching are using SPARQL Query WordNet database. SPARQL query is used to extract data from OWL-S and database WordNet is used in calculating the value of keywords and data semantics of OWL-S. Results of the testing showed that the WFMS can do a search workflow with high accuracy from a variety of business processes in Enterprise Resource Planning (ERP). The results of the testing also show the event log generated can be analyzed using the technique of mining process.  2005 - 2015 JATIT & LLS. All rights reserved. ERP; OWL-S; Process mining; Workflow management system

Adaptation of turtle graphics method for visualization of the process execution Process mining is relatively young discipline that uses many methods to obtain a results that can be beneficial. These methods are used in different approaches that study the process instances from the statistical point of view, clustering methods are used, etc. Our intention is to present simple graphical method that can help to understand the visualized data directly. Adaptation of the turtle graphics is used to visualize the logs content - process instances. The main purpose of this paper is to present the usability of our method in the area of process mining and show its benefits for specific tasks.  Springer International Publishing Switzerland 2015. Process; Process mining; Turtle graphics

Mining duplicate tasks from discovered processes Including duplicate tasks in the mining process is a challenge that hinders the process discovery as algorithms need an extra effort to find out which events of the log belong to which transitions. To face this problem, we propose an approach that uses the local information of the log to enhance an already mined model by performing a local search over the potential tasks to be duplicated. This proposal has been validated over 36 different solutions, improving the final model in 35 out of 36 of the cases. Duplicate tasks; Process discovery; Process mining

Discovering and categorizing goal alignments from mined process variants With the emergence of contextual enterprise, organizations increasingly tend to analyze the adherence of the day to day execution of internal business processes with their stated goals. This is needed so that they can continuously evaluate and readjust their operating models and corresponding business strategies. However organizations often find it very difficult to discover and categorize the process variants in terms of their stated goal adherence from process execution logs. This is due to the challenges in resolving the extent of goal compliance as it necessitates the classification of process variants first in terms of the contextual factors associated with the process execution. In this paper, we propose our approach for discovering goal adherence of process variant instances mined from event logs. We first generate goal-service alignment models to establish correlation of process fragments with specific sub-goals of the organizations goal model. Subsequently we discover the extent of goal adherence of individual process instances by the composition of correlated sub-goals. We also associate the contextual factors with each process instance that are goal preserving in nature. Leveraging the difference in correlation and association of contextual factors we classify the instances as goal preserving executed process variants. This bottomup approach enables the organizations to study the depth and breadth of goal adherence in their organizations. Also the impact of any specific change in the goal decomposition models and the associated contextual factors can be studied with our approach. We evaluate our approach using a real industrial case study in IT Incident Management using a event log of 25000 records.  Springer International Publishing Switzerland 2015. Event logs; Process mining; Reuse; SOA; Variability

Use of frequent itemset mining techniques to analyze business processes Analysis of business process data can be used to discover reasons of delays and other problems in a business process. This paper presents an approach, which uses a simulator of production history. This simulator allows detecting problems at various production machines, e.g. extremely long queues of products waiting before a machine. After detection, data about products processed before the queue increased are collected. Frequent itemsets obtained from this dataset can be used to describe the problem and reasons of it. The whole process of frequent itemset mining will be described in this paper. It is also focused on description of several necessary modifications of basic methods usually used to discover frequent itemsets.  2015 by SCITEPRESS - Science and Technology Publications, Lda. Association rules; Business process; Frequent itemsets; Process mining; Simulator of production history

Declarative process discovery with MINERful in ProM Declarative process models consist of a set of constraints exerted over the execution of process activities. DECLARE is a declarative process modelling language that specifies a set of constraint templates along with their graphical notation. The automated discovery of DECLARE models aims at finding those constraints that are verified throughout a given event log. In this paper, we present a fast scalable tool for mining DECLARE models in ProM. Its usage is described with its application on a use case, based on a publicly available real-life benchmark. Copyright  2015 for this paper by its authors. Declarative processes; Process discovery; Process mining

Incremental learning of daily routines as workflows in a smart home environment Smart home environments should proactively support users in their activities, anticipating their needs according to their preferences. Understanding what the user is doing in the environment is important for adapting the environment's behavior, as well as for identifying situations that could be problematic for the user. Enabling the environment to exploit models of the user's most common behaviors is an important step toward this objective. In particular, models of the daily routines of a user can be exploited not only for predicting his/her needs, but also for comparing the actual situation at a given moment with the expected one, in order to detect anomalies in his/her behavior. While manually setting up process models in business and factory environments may be cost-effective, building models of the processes involved in people's everyday life is infeasible. This fact fully justifies the interest of the Ambient Intelligence community in automatically learning such models from examples of actual behavior. Incremental adaptation of the models and the ability to express/learn complex conditions on the involved tasks are also desirable. This article describes how process mining can be used for learning users' daily routines from a dataset of annotated sensor data. The solution that we propose relies on a First-Order Logic learning approach. Indeed, First-Order Logic provides a single, comprehensive and powerful framework for supporting all the previously mentioned features. Our experiments, performed both on a proprietary toy dataset and on publicly available real-world ones, indicate that this approach is efficient and effective for learning and modeling daily routines in Smart Home Environments.  2015 ACM. Incremental learning; Model of user daily routines; Process mining; Smart home environment

Khanan: Performance comparison and programming a-miner algorithm in column-oriented and relational database query languages Process-Aware Information Systems (PAIS) support business processes and generate large amounts of event logs from the execution of business processes. An event log is represented as a tuple of CaseID, Timestamp, Activity and Actor. Process Mining is a new and emerging field that aims at analyzing the event logs to discover, enhance and improve business processes and check conformance between run time and design time business processes. The large volume of event logs generated are stored in the databases. Relational databases perform well for a certain class of applications. However, there is a certain class of applications for which relational databases are not able to scale well. To address the challenges of scalability, NoSQL database systems emerged. Discovering a process model (workflow) from event logs is one of the most challenging and important Process Mining tasks. The a-miner algorithm is one of the first and most widely used Process Discovery techniques. Our objective is to investigate which of the databases (Relational or NoSQL) performs better for a Process Discovery application under Process Mining. We implement the a-miner algorithm on relational (row-oriented) and NoSQL (column-oriented) databases in database query languages so that our application is tightly coupled to the database. We conduct a performance benchmarking and comparison of the a-miner algorithm on row-oriented database and NoSQL column-oriented database.We present the comparison on various aspects like time taken to load large datasets, disk usage, stepwise execution time and compression technique.  Springer International Publishing Switzerland 2015. Apache Cassandra; Column-oriented database; MySQL; Performance comparison; Process mining; Row oriented database; a-miner algorithm

Improving process models discovery using AXOR clustering algorithm The goal of process mining is to discover process models from event logs. Real-life processes tend to be less structured and more flexible. Classical process mining algorithms face to unstructured processes, generate spaghetti-like process models which are hard to comprehend. One way to cope with these models consists to divide the log into clusters in order to analyze reduced sets of cases. In this paper, we propose a new clustering approach where cases are restricted to activity profiles. We evaluate the quality of the formed clusters using established fitness and comprehensibility metrics on the basis distance using logical XOR operator. throwing a significant real-life case study, we illustrate our approach, and we show its interest especially for flexible environments.  Springer-Verlag Berlin Heidelberg 2015. Clustering; Fitness; Process discovery; Process mining

Interactive heat map for evaluation of container handling process As part of port logistics system, a container handling process is a complex system consisting of several activities including loading, discharging, shuffling and others. Evaluating these processes is considerably complicated as some processes lie in cycle and each process might be carried out by various equipment. This paper presents a container handling process evaluation protocol that applies a process mining technique to event log data of a port information system. Interactive heat map visualization in task matrix form guides the domain expert evaluation of each process flow. The port manager can easily determine whether a particular process belongs to a bad or a good event. The cases that lead to undesirable activity are provided to give recommendations for further analysis and to improve existing processes.  2015, ICIC Express Letters Office. All rights reserved. Container handling; Heat map; Process mining; Visualization

On the discovery of declarative control flows for artful processes Artful processes are those processes in which the experience, intuition, and knowledge of the actors are the key factors in determining the decision making. They are typically carried out by the "knowledge workers," such as professors, managers, and researchers. They are often scarcely formalized or completely unknown a priori. Throughout this article, we discuss how we addressed the challenge of discovering declarative control flows in the context of artful processes. To this extent, we devised and implemented a two-phase algorithm, named MINERful. The first phase builds a knowledge base, where statistical information extracted from logs is represented. During the second phase, queries are evaluated on that knowledge base, in order to infer the constraints that constitute the discovered process. After outlining the overall approach and offering insight on the adopted process modeling language, we describe in detail our discovery technique. Thereupon, we analyze its performances, both from a theoretical and an experimental perspective. A user-driven evaluation of the quality of results is also reported on the basis of a real case study. Finally, a study on the fitness of discovered models with respect to synthetic and real logs is presented.  2015 ACM. Artful processes; Control-flow discovery; Declarative process model; MailOfMine; Process mining

An alignment-based framework to check the conformance of declarative process models and to preprocess event-log data Process mining can be seen as the "missing link" between data mining and business process management. The lion's share of process mining research has been devoted to the discovery of procedural process models from event logs. However, often there are predefined constraints that (partially) describe the normative or expected process, e.g., "activity A should be followed by B" or "activities A and B should never be both executed". A collection of such constraints is called a declarative process model. Although it is possible to discover such models based on event data, this paper focuses on aligning event logs and predefined declarative process models. Discrepancies between log and model are mediated such that observed log traces are related to paths in the model. The resulting alignments provide sophisticated diagnostics that pinpoint where deviations occur and how severe they are. Moreover, selected parts of the declarative process model can be used to clean and repair the event log before applying other process mining techniques. Our alignment-based approach for preprocessing and conformance checking using declarative process models has been implemented in ProM and has been evaluated using both synthetic logs and real-life logs from a Dutch hospital.  2013 Elsevier Ltd. All rights reserved. Conformance checking; Declare; Event-log preprocessing; LTL; Process mining

Process discovery using localized events Process mining techniques aim to analyze and improve conformance and performance of processes using event data. Process discovery is the most prominent process-mining task: A process model is derived based on an event log. The process model should be able to capture causalities, choices, concurrency, and loops. Process discovery is very challenging because of trade-offs between fitness, simplicity, precision, and generalization. Note that event logs typically only hold example behavior and cannot be assumed to be complete (to avoid over fitting). Dozens of process discovery techniques have been proposed. These use a wide range of approaches, e.g., language- or state-based regions, genetic mining, heuristics, expectation maximization, iterative log-splitting, etc. When models or logs become too large for analysis, the event log may be automatically decomposed or traces may be clustered before discovery. Clustering and decomposition are done automatically, i.e., no additional information is used. This paper proposes a different approach where a localized event log is assumed. Events are localized by assigning a nonempty set of regions to each event. It is assumed that regions can only interact through shared events. Consider for example the mining of software systems. The events recorded typically explicitly refer to parts of the system (components, services, etc.). Currently, such information is ignored during discovery. However, references to system parts may be used to localize events. Also in other application domains, it is possible to localize events, e.g., communication events in an organization may refer to multiple departments (that may be seen as regions). This paper proposes a generic process discovery approach based on localized event logs. The approach has been implemented in ProM and experimental results show that location information indeed helps to improve the quality of the discovered models.  Springer International Publishing Switzerland 2015. 

Supporting healthcare management decisions via robust clustering of event logs Business processes constitute an essential asset of organizations while the related process models help to better comprehend the process and therefore to enable effective process analysis or redesign. However, there are several working environments where flows are particularly flexible (e.g., healthcare, customer service) and process models are either very hard to get created, or they fail to reflect reality. The aim of this paper is to support decision-making by providing comprehensible process models in the case of such flexible environments. Following a process mining approach, we propose a methodology to cluster customers' flows and produce effective summarizations. We propose a novel method to create a similarity metric that is efficient in downgrading the effect of noise and outliers. We use a spectral technique that emphasizes the robustness of the estimated groups, therefore it provides process analysts with clearer process maps. The proposed method is applied to a real case of a healthcare institution delivering valuable insights and showing compelling performance in terms of process models' complexity and density.  2015 Elsevier B.V. All rights reserved. Clustering; Healthcare management; Knowledge discovery; Process mining; Robustness

Event log visualisation with conditional partial order graphs: From control flow to data Process mining techniques rely on event logs: the extraction of a process model (discovery) takes an event log as the input, the adequacy of a process model (conformance) is checked against an event log, and the enhancement of a process model is performed by using available data in the log. Several notations and formalisms for event log representation have been proposed in the recent years to enable efficient algorithms for the aforementioned process mining problems. In this paper we show how Conditional Partial Order Graphs (CPOGs), a recently introduced formalism for compact representation of families of partial orders, can be used in the process mining field, in particular for addressing the problem of compact and easy-to-comprehend visualisation of event logs with data. We present algorithms for extracting both the control flow as well as the relevant data parameters from a given event log and show how CPOGs can be used for efficient and effective visualisation of the obtained results. We demonstrate that the resulting representation can be used to reveal the hidden interplay between the control and data flows of a process, thereby opening way for new process mining techniques capable of exploiting this interplay. 

Modelling and simulating collaborative scenarios for designing an assistant ambient system that supports daily activities This paper presents the design phase of a work aiming at designing and developing a smart living device for seniors to assist them in their daily outdoor activities. We follow a participative design approach based on scenarios in order to design a socially-adapted device that will be useful to improve seniors life. To specify our system, we first provide an UML scenario metamodel to abstract all the concepts involved in our system collaborative functioning (interactions with stakeholders, environment ). This metamodel is used to generate different scenarios in order to better define future users needs and the system requirements and notably its behavior (represented with BPMN and Petri Nets). A scenario generator has been implemented for that purpose. Finally, we show how to simulate and analyze those generated scenarios using process mining techniques.  Springer International Publishing Switzerland 2015. Daily activity scenarios; Process mining; Scenario structure model; Scenarios generator

A learning analytics approach to correlate the academic achievements of students with interaction data from an educational simulator This paper presents a Learning Analytics approach for understanding the learning behavior of students while interacting with Technology Enhanced Learning tools. In this work we show that it is possible to gain insight into the learning processes of students from their interaction data. We base our study on data collected through six laboratory sessions where first-year students of Computer Engineering at the University of Genoa were using a digital electronics simulator. We exploit Process Mining methods to investigate and compare the learning processes of students. For this purpose, we measure the understandability of their process models through a complexity metric. Then we compare the various clusters of students based on their academic achievements. The results show that the measured complexity has positive correlation with the final grades of students and negative correlation with the difficulty of the laboratory sessions. Consequently, complexity of process models can be used as an indicator of variations of student learning paths.  Springer International Publishing Switzerland 2015. Complexity; Educational data mining; Educational simulator; Interaction data; Learning analytics; Process mining; Technology Enhanced Learning

Differencegraph - A ProM plugin for calculating and visualizing differences between processes The analysis of differences and commonalities between process models or between instances which progressed through the model (henceforth referred to as instance traffic) plays an important role in companies. For example, companies are often confronted with different versions or variants of a process model and hence need methods to identify redundancies or inconsistencies between them. Differencegraph is a plugin for ProM which supports the identification of differences and commonalities between process models as well as between their instance traffic. For this purpose a so-called difference graph between two process models and their instance traffic is calculated and visualized. This generated difference graph supports decision making in various business cases such as finding deviations between processes. Copyright  2015 for this paper by its authors. Differences between processes; Instance traffic; Process mining; Process model; Process visualization; Visualization

Detecting, assessing, and mitigating data inaccuracy-related risks in business processes Business process activities and their outcomes rely on data that is commonly stored in databases. If the stored data is not accurate, namely, it does not reflect the relevant real world values, the process execution might be disrupted and the process might not be able to reach its goal. Detection of such cases and analysis of their causes may help redesign processes to reduce the potential risks. In this research, we aim to develop a semi-automated method that will enable detection, assessment, and mitigation of risks related to data inaccuracy in business processes. The method will be built on and evaluated with real cases from the industry.  Springer International Publishing Switzerland 2015. Business processes; Data inaccuracy; Process design; Process mining; Risk assessment

Optimizing spaghetti process models Spaghetti-like process models are part of the lowest level of process models [5]. These are process models difficult to interpret, to understand by the human beings. There has been no effort so far for optimizing these process models. The processes need to be understood by somebody, simplified and only after that apply some optimization algorithms. This paper proposes a novel method to enable the optimization of spaghetti-like process models. The algorithm proposed separates the spaghetti process model into multiple process models using the process execution data.  2015 IEEE. Process mining; Process optimization; Spaghetti processes

Visualization of patient distributions in a hospital based on the clinical actions stored in EHR This paper presents an attempt to visualize the geographical distribution of outpatients in a hospital as a preliminary step towards the process-dynamics mining. In order to obtain the locations of patients without using devices carried by themselves, we extract clinical action records (e.g. treatments, examinations and injections) from hospital information systems and utilize the locations of information sources, under an assumption that a patient presented himself or herself at the place where an action was being recorded. Using the temporal records of clinical actions with locations, we firstly summarize the process courses frequently used in outpatient services, and then visualize the dynamics of patients by projecting the change of patient distribution onto hospital maps.  2014 IEEE. medical data mining; process mining; service science; Visualization

Log-based simplification of process models The visualization of models is essential for user-friendly human-machine interactions during Process Mining. A simple graphical representation contributes to give intuitive information about the behavior of a system. However, complex systems cannot always be represented with succinct models that can be easily visualized. Quality-preserving model simplifications can be of paramount importance to alleviate the complexity of finding useful and attractive visualizations. This paper presents a collection of log-based techniques to simplify process models. The techniques trade off visual-friendly properties with quality metrics related to logs, such as fitness and precision, to avoid degrading the resulting model. The algorithms, either cast as optimization problems or heuristically guided, find simplified versions of the initial process model, and can be applied in the final stage of the process mining life-cycle, between the discovery of a process model and the deployment to the final user. A tool has been developed and tested on large logs, producing simplified process models that are one order of magnitude smaller while keeping fitness and precision under reasonable margins.  Springer International Publishing Switzerland 2015. 

Model repair - Aligning process models to reality Process mining techniques relate observed behavior (i.e., event logs) to modeled behavior (e.g., a BPMN model or a Petri net). Process models can be discovered from event logs and conformance checking techniques can be used to detect and diagnose differences between observed and modeled behavior. Existing process mining techniques can only uncover these differences, but the actual repair of the model is left to the user and is not supported. In this paper we investigate the problem of repairing a process model w.r.t. a log such that the resulting model can replay the log (i.e., conforms to it) and is as similar as possible to the original model. To solve the problem, we use an existing conformance checker that aligns the runs of the given process model to the traces in the log. Based on this information, we decompose the log into several sublogs of non-fitting subtraces. For each sublog, either a loop is discovered that can replay the sublog or a subprocess is derived that is then added to the original model at the appropriate location. The approach is implemented in the process mining toolkit ProM and has been validated on logs and models from several Dutch municipalities.  2014 Elsevier Ltd. All rights reserved. Conformance checking; Model repair; Petri nets; Process mining

Process and deviation exploration through Alpha-algorithm and Heuristic miner techniques In this paper, we applied two methods of process mining techniques (from Discovery class/approach) in order to extract knowledge from event logs recorded by an online information system. The event log was created via information received from an online proceedings review system in Thailand. Accordingly, Alpha and Heuristic algorithms were used with the objective of automatically visualizing the models in terms of Petri nets and animated simulations. The paper eventually aimed at improving the handling of online reviews by providing techniques and tools for discovering process, control, data, organizational, and social structures from the created event log.  2014 IEEE. Alpha algorithm; Bottleneck Mining; Heuristic Mining; Model Discovery; Online Review System; Process Mining; Process Simulation

Estimation of average latent waiting and service times of activities from event logs Analysis of performance is crucial in the redesign phase of business processes where bottlenecks are identified from the average waiting and service times of activities and resources in business processes. However, such averages of waiting and service times are not readily available in most event logs that only record either the start or the completion times of events in activities. The transition times between events in such logs are the only performance features that are available. This paper proposes a novel method of estimating the average latent waiting and service times from the transition times that employs the optimization of the likelihood of the probabilistic model with expectation and maximization (EM) algorithms. Our experimental results indicated that our method could estimate the average latent waiting and service times with sufficient accuracy to enable practical applications through performance analysis.  Springer International Publishing Switzerland 2015. Convolution of gamma distributions; EM algorithm; Latent waiting and service times; Performance analysis; Process mining

Discovering models of parallel workflow processes from incomplete event logs a-algorithm is able to discover a large class of workflow (WF) nets based on the behavior recorded in event logs, with the main limiting assumption that the event log is complete. Our research has been aimed at finding ways of business process models discovering based on examples of traces, i.e., logs of workflow actions that do not meet the requirement of completeness. In this aim, we have modified the existing and introduced a new relation between activities recorded in the event log, which has led to a partial correction of the process models discovering techniques, including the a-algorithm. We have also introduced the notions of causally and weakly complete logs, from which our modified algorithm can produce the same result as the original algorithm from complete logs. The effect of these modifications on the speed of the process model discovering is mostly evident for business processes in which many activities can be performed in parallel. Therefore, this paper presents preliminary results obtained from the investigation of opportunities to discover models of parallel processes based on incomplete event logs. Copyright  2015 SCITEPRESS - Science and Technology Publications. Incomplete event log; Parallel business processes; Process mining; Process model discovery; a-algorithm

A database-oriented workflow scheduler with historical data and resource substitution possibilities This paper presents the database of a novel workflow scheduler that is able to handle resource substitution and takes into account historical data. The generated schedule can be optimized either in time or cost. The scheduler enables a resource substitution in case of an immediate event or when cost- or time-efficiency-related reasons necessitates it. The underlying database is able to handle complex workflows, represents the fleet of various resources and supports data mining from the data of the logged execution of the schedule in order to further improving the schedule. The database and the scheduler is a part of a complex project which schedules workflows described in XPDL by an agent system taking into account the real-time events and historical data served by process mining. Our scheduler system is intended to be applied both in business and industrial processes. Copyright  2015 SCITEPRESS - Science and Technology Publications All rights reserve. Database; Historical Data; Resource Substitution; Workflow Scheduler

Intelligent process management and visualization technologies (extended abstract) While process visualizations are perceived by many as very cool technologies, companies are not yet willing to embrace them as warmly and quickly as expected. Managers still demand more convincing and significant added value. Another issue might be with offering process visualization technologies as somewhat detached solutions, or not taking into account Business Intelligence solutions which might already exist in the company. The keynote aims to demonstrate how process and data visualization tools can be combined and applied to various business domains in order to increase process awareness which will lead to intelligent process management.  Springer International Publishing Switzerland 2015. Intelligent process management; Process mining; Visualization technologies

